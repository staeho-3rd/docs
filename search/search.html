<!DOCTYPE html>
<html lang="kr">
  <head>
    <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5XRCSF3');</script>
<!-- End Google Tag Manager -->
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content=",  ">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Search" />
<meta property="og:locale" content="ko_KR" />
<meta property="og:description" content="써드아이시스템(3rdeyesys) 기술문서 사이트입니다 - Ncloud 프리미엄 파트너" />
<link rel="canonical" href="https://docs.3rdeyesys.com/search/search.html" />
<meta property="og:url" content="https://docs.3rdeyesys.com/search/search.html" />
<meta property="og:site_name" content="3RDEYESYSTEM Technical Documentations" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Search" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"써드아이시스템(3rdeyesys) 기술문서 사이트입니다 - Ncloud 프리미엄 파트너","headline":"Search","url":"https://docs.3rdeyesys.com/search/search.html"}</script>
<!-- End Jekyll SEO tag -->

<title>Search | 써드아이시스템 기술문서</title>
<link rel="stylesheet" href="/v2/css/syntax.css">

<link
  rel="stylesheet"
  type="text/css"
  href="/v2/css/bootstrap.min.css">
<link rel="stylesheet" href="/fontawesome/css/all.min.css" />
<link rel="stylesheet" href="/fontawesome/css/v4.7.0.css" />
<link rel="stylesheet" href="/v2/css/modern-business.css"> <!-- Latest compiled and minified CSS -->
<!--link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"-->
<!--link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"--> <link rel="stylesheet" href="/v2/css/customstyles.css"> <link rel="stylesheet" href="/v2/css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="/v2/css/theme-ncloud.css">


<script src="/v2/js/jquery.341.min.js"></script>
<!--script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script-->

<script src="/v2/js/jquery.cookie.141.min.js"></script>
<!--script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script-->
<script src="/v2/js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="/v2/js/bootstrap.341.min.js"></script>
<!--script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script-->
<!--script src="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script-->
<!-- Anchor.js --><script src="/v2/js/anchor.420.min.js"> </script>
<!--script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script-->
<script src="/v2/js/toc.js"></script>
<script src="/v2/js/customscripts.js"></script>



<link rel="shortcut icon" href="/images/favicon.ico">

<link rel="alternate"
  type="application/rss+xml"
  title="3RDEYESYSTEM Technical Documentations"
  href="https://docs.3rdeyesys.com/rss.xml">


    <script>
      $(document).ready(function() {

// Initialize navgoco with default options
        $("#mysidebar").navgoco({
          caretHtml: '',
          accordion: true,
          openClass: 'active', // open
          save: false, // leave false or nav highlighting doesn't work right
          cookie: {
            name: 'navgoco',
            expires: false,
            path: '/'
          },
          slide: {
            duration: 400,
            easing: 'swing'
          }
        });

        window_width = $(window).width();
        if (window_width <= 990) { // 모바일 환경에서는 사이드바 접기
          $("#mysidebar").navgoco('toggle', false);
        }

        $("#collapseAll").click(function(e) {
          e.preventDefault();
          $("#mysidebar").navgoco('toggle', false);
        });

        $("#expandAll").click(function(e) {
          e.preventDefault();
          $("#mysidebar").navgoco('toggle', true);
        });

      });
    </script>
    <script>
      $(function() {
        $('[data-toggle="tooltip"]').tooltip()
      })
    </script>
    <script>
      $(document).ready(function() {
        $("#tg-sb-link").click(function() {
          if (!$("#tg-sb-link").attr("hide_sidebar")) {
            $("#tg-sb-sidebar").toggle();
            $("#tg-sb-content").toggleClass('col-md-9');
            $("#tg-sb-content").toggleClass('col-md-12');
            $("#tg-sb-icon").toggleClass('fa-toggle-on');
            $("#tg-sb-icon").toggleClass('fa-toggle-off');
          }
        });
      });
    </script>
    

    
      <script
  async
  src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6933218466698885"
  crossorigin="anonymous"></script>
    


  </head>
  <body>
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5XRCSF3"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
    <header>
      <!-- Navigation -->
<nav class="navbar2 navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fas fa-home fa-lg navbar-brand" href="/">&nbsp;<span class="projectTitle"> 3RDEYESYS Tech Docs</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-center">
                <!-- toggle sidebar button -->                
                <li><a id="tg-sb-link" hide_sidebar="" href="#"><i id="tg-sb-icon" class="fas fa-toggle-on"></i> Nav</a></li>                
                <!-- entries without drop-downs appear here -->




                
                
                                
                <li><a href="/" class="new_dot_lv_2">Docs_V3</a></li>
                
                
                                
                <li><a href="/docs/help/update/" >Update</a></li>
                
                
                                
                <li><a href="/docs/help/news/" >News</a></li>
                
                
                                
                <li><a href="/docs/help/faq/" >FAQ</a></li>
                
                
                
                
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                
                
                
                
                
                
                
                
                
                
                <li><a href="https://3rdeyesys.com/" target="_blank" rel="noopener">Company</a></li>                                
                
                
                
                <li><a href="https://www.3rdeyesys.com/question/" target="_blank" rel="noopener">1:1 문의</a></li>                                
                
                 
                               
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">                        
                            <div style="width:223px"><form action="/search/search.html" method="get">
	<input type="search" name="q" id="search-input-nav" onfocus="this.placeholder=''" onblur="this.placeholder='Search'" placeholder="Search">
	<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
	<input type="submit" value="Search" style="display: none;">
</form></div>                                               
                    </div>                    
                    <!--end search-->
                </li>
                
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



      
    </header>
    <!-- Page Content -->
    
        <div class="container">
        
        <div id="main">
          <!-- Content Row -->
          <div class="row">
            
              
              <!-- Sidebar Column -->
              <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle">Technical Documentation </li>
  
  
  
  <li>
      <a title="Compute" href="#" ><i class="fa-solid fa-server fa-xs"></i> Compute</a>
      <ul>
          
          
          
          <li><a title="VPC 환경에서 서버 생성하는 방법" href="/compute/ncloud_compute_server_vpc_create.html" >VPC 환경에서 서버 생성하는 방법</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="Classic 환경 Linux 서버 접속 방법" href="#">Classic 환경 Linux 서버 접속 방법</a>
              <ul>                  
                  
                  
                  
                  <li><a title="공인IP 없을 때" href="/compute/ncloud_compute_server_connect_no_public_ip.html">공인IP 없을 때</a></li>
                  
                  
                  
                  
                  
                  <li><a title="공인IP 있을 때" href="/compute/ncloud_compute_server_connect_by_public_ip.html">공인IP 있을 때</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
          
          
          <li><a title="서버 스펙 변경 제한 사항" href="/compute/ncloud_compute_server_spec_change.html" >서버 스펙 변경 제한 사항</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="디스크(스토리지) 설정" href="#">디스크(스토리지) 설정</a>
              <ul>                  
                  
                  
                  
                  <li><a title="스토리지 추가 생성 기본 가이드" href="/compute/ncloud_compute_server_storage_add_guide.html">스토리지 추가 생성 기본 가이드</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Linux 디스크 추가 상세 가이드" href="/compute/ncloud_compute_server_storage_add_detail_process.html">Linux 디스크 추가 상세 가이드</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Linux 서버 디스크 LVM 구성하기" href="/compute/ncloud_compute_server_storage_lvm_create.html">Linux 서버 디스크 LVM 구성하기</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Windows 디스크 추가 가이드" href="/compute/ncloud_compute_server_windows_storage_add_detail_process.html">Windows 디스크 추가 가이드</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Linux 서버 디스크 크기 확장" href="/compute/ncloud-compute-server-storage-extend-guide-linux.html">Linux 서버 디스크 크기 확장</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Windows 서버 디스크 크기 확장" href="/compute/ncloud-compute-server-storage-extend-guide-windows.html">Windows 서버 디스크 크기 확장</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
          
          
          <li><a title="Classic 환경 Micro 서버 제한 사항" href="/compute/ncloud_compute_server_micro_type_limit.html" >Classic 환경 Micro 서버 제한 사항</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC 환경에서 Micro 서버 생성하기" href="/compute/ncloud-compute-micro-type-server-create-vpc.html" >VPC 환경에서 Micro 서버 생성하기</a></li>          
                    
          
          
          
          
          
          <li><a title="서버 정지 시 요금할인" href="/compute/ncloud_compute_server_stop_price.html" >서버 정지 시 요금할인</a></li>          
                    
          
          
          
          
          
          <li><a title="Linux 서버 SSH 접속 보안 설정하기" href="/compute/ncloud_compute_server_ssh_security_setting.html" >Linux 서버 SSH 접속 보안 설정하기</a></li>          
                    
          
          
          
          
          
          <li><a title="서버 관리자 비밀번호 초기화하기" href="/compute/ncloud-compute-server-admin-password-reset.html" >서버 관리자 비밀번호 초기화하기</a></li>          
                    
          
          
          
          
          
          <li><a title="서버 인증키 변경하는 방법" href="/compute/ncloud-compute-server-change-authentication-key.html" >서버 인증키 변경하는 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Linux 서버 SSH Key로 접속하는 방법" href="/compute/ncloud-compute-server-connect-by-ssh-key.html" >Linux 서버 SSH Key로 접속하는 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="X-Forwarded-For로 Client IP 기록하기" href="/compute/ncloud_compute_server_x_forwarded_for_client_ip_logging_guide.html" >X-Forwarded-For로 Client IP 기록하기</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; Windows IIS에서 IP 기록하기" href="/compute/ncloud-compute-server-x-forwarded-for-client-ip-logging-iis-guide.html" >&nbsp;&nbsp; L &nbsp; Windows IIS에서 IP 기록하기</a></li>          
                    
          
          
          
          
          
          <li><a title="https 리다이렉트 - Apache/CentOS" href="/compute/ncloud_compute_server_http_to_https_centos.html" >https 리다이렉트 - Apache/CentOS</a></li>          
                    
          
          
          
          
          
          <li><a title="https 리다이렉트 - Apache/Ubuntu" href="/compute/ncloud_compute_server_http_to_https_ubuntu.html" >https 리다이렉트 - Apache/Ubuntu</a></li>          
                    
          
          
          
          
          
          <li><a title="https 리다이렉트-Apache/Rocky Linux" href="/compute/ncloud-compute-server-http-to-https-rocky-linux.html" >https 리다이렉트-Apache/Rocky Linux</a></li>          
                    
          
          
          
          
          
          <li><a title="Repository 변경해 리눅스 패키지 설치" href="/compute/ncloud_compute_server_repository_change_on_private_network.html" >Repository 변경해 리눅스 패키지 설치</a></li>          
                    
          
          
          
          
          
          <li><a title="Rocky Linux 서버 소개" href="/compute/ncloud-compute-server-rocky-linux-guide.html" >Rocky Linux 서버 소개</a></li>          
                    
          
          
          
          
          
          <li><a title="Rocky Linux 미러 사이트 문제 (XEN)" href="/compute/ncloud-compute-server-rocky-linux-repository-mirror-site-error-troubleshooting.html" >Rocky Linux 미러 사이트 문제 (XEN)</a></li>          
                    
          
          
          
          
          
          <li><a title="Rocky Linux 미러 사이트 문제 (KVM)" href="/compute/ncloud-compute-server-rocky-linux-kvm-hypervisor-repository-mirror-site-error-troubleshooting.html" >Rocky Linux 미러 사이트 문제 (KVM)</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="AutoScaling" href="#">AutoScaling</a>
              <ul>                  
                  
                  
                  
                  <li><a title="Classic 환경 AutoScaling 설정" href="/compute/ncloud_compute_autoscaling_classic_guide.html">Classic 환경 AutoScaling 설정</a></li>
                  
                  
                  
                  
                  
                  <li><a title="VPC 환경 AutoScaling 설정" href="/compute/ncloud-compute-autoscaling-vpc-guide.html">VPC 환경 AutoScaling 설정</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Auto Scaling 서비스 제한사항" href="/compute/ncloud_compute_autoscaling_limit.html">Auto Scaling 서비스 제한사항</a></li>
                  
                  
                  
                  
                  
                  <li><a title="AutoScaling 이벤트 설정 방법" href="/compute/ncloud_compute_autoscaling_event_setting.html">AutoScaling 이벤트 설정 방법</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          <li class="subfolders">
              <a title="Cloud Functions" href="#">Cloud Functions</a>
              <ul>                  
                  
                  
                  
                  <li><a title="Cloud Functions Action을 cmd에서 C#으로 작성하기" href="/compute/ncloud_compute_cloud_functions_dotnet_csharp_cmd.html">Cloud Functions Action을 cmd에서 C#으로 작성하기</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Cloud Functions Action을 Visual Studio에서 C#으로 작성하기" href="/compute/ncloud_compute_cloud_functions_dotnet_csharp_vs.html">Cloud Functions Action을 Visual Studio에서 C#으로 작성하기</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Cloud Functions에서 gmail을 통해 SMTP로 메일 발송" href="/compute/ncloud_compute_cloud_functions_php_smtp_via_gmail_with_phpmailer.html">Cloud Functions에서 gmail을 통해 SMTP로 메일 발송</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          <li class="subfolders">
              <a title="LAMP" href="#">LAMP</a>
              <ul>                  
                  
                  
                  
                  <li><a title="LAMP 기본 환경 설정 정보" href="/compute/ncloud_compute_lamp_config_basic.html">LAMP 기본 환경 설정 정보</a></li>
                  
                  
                  
                  
                  
                  <li><a title="LAMP(CentOS) 기본 명령어와 환경설정 파일 위치" href="/compute/ncloud_compute_lamp_config_centos.html">LAMP(CentOS) 기본 명령어와 환경설정 파일 위치</a></li>
                  
                  
                  
                  
                  
                  <li><a title="LAMP(Ubuntu) 기본 명령어와 환경설정 파일 위치" href="/compute/ncloud_compute_lamp_config_ubuntu.html">LAMP(Ubuntu) 기본 명령어와 환경설정 파일 위치</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Rocky Linux Apache 웹서버에 SSL 인증서 설정하는 방법" href="/compute/ncloud-compute-lamp-apache-ssl-setting-rocky-linux-guide.html">Rocky Linux Apache 웹서버에 SSL 인증서 설정하는 방법</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          <li class="subfolders">
              <a title="NginX" href="#">NginX</a>
              <ul>                  
                  
                  
                  
                  <li><a title="CentOS에 NginX 설치, 설정" href="/compute/ncloud_compute_lemp_nginx_install_setting_centos_guide.html">CentOS에 NginX 설치, 설정</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Ubuntu에 NginX 설치, 설정" href="/compute/ncloud_compute_lemp_nginx_install_setting_ubuntu_guide.html">Ubuntu에 NginX 설치, 설정</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Rocky Linux에 NginX 설치, 설정" href="/compute/ncloud-compute-lemp-nginx-install-setting-rocky-linux-guide.html">Rocky Linux에 NginX 설치, 설정</a></li>
                  
                  
                  
                  
                  
                  <li><a title="CentOS NginX SSL 인증서 설정" href="/compute/ncloud_compute_lemp_nginx_ssl_setting_centos_guide.html">CentOS NginX SSL 인증서 설정</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Ubuntu NginX SSL 인증서 설정" href="/compute/ncloud_compute_lemp_nginx_ssl_setting_ubuntu_guide.html">Ubuntu NginX SSL 인증서 설정</a></li>
                  
                  
                  
                  
                  
                  <li><a title="로드밸런서 환경 Client IP 확인" href="/compute/ncloud-compute-nginx-client-ip-logging-guide.html">로드밸런서 환경 Client IP 확인</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
          
          
          <li><a title="CentOS 6에서 pip - Python 설치하기" href="/compute/ncloud_compute_server_pip_python_install_centos6.html" >CentOS 6에서 pip - Python 설치하기</a></li>          
                    
          
          
          
          
          
          <li><a title="Classic환경 서버이미지 타 계정 공유" href="/compute/ncloud_compute_server_image_share_classic.html" >Classic환경 서버이미지 타 계정 공유</a></li>          
                    
          
          
          
          
          
          <li><a title="Classic 환경 Windows 서버이미지 VPC 환경으로 복제" href="/compute/ncloud_compute_server_windows_server_image_copy_classic_to_vpc.html" >Classic 환경 Windows 서버이미지 VPC 환경으로 복제</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Containers" href="#" ><i class="fa-solid fa-dharmachakra fa-xs"></i> Containers</a>
      <ul>
          
          
          
          <li><a title="Kubernetes 생성 및 제어 | Linux" href="/containers/ncloud-containers-kubernetes-service-start-guide-linux.html" >Kubernetes 생성 및 제어 | Linux</a></li>          
                    
          
          
          
          
          
          <li><a title="Kubernetes 생성 및 제어 | Windows" href="/containers/ncloud-containers-kubernetes-service-start-guide-windows.html" >Kubernetes 생성 및 제어 | Windows</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Networking" href="#" ><i class="fa-solid fa-network-wired fa-xs"></i> Networking</a>
      <ul>
          
          
          
          <li><a title="주요 서비스 포트(Port) 정보" href="/networking/ncloud_networking_service_port_info.html" >주요 서비스 포트(Port) 정보</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC 구성요소" href="/networking/ncloud_networking_vpc_overview.html" >VPC 구성요소</a></li>          
                    
          
          
          
          
          
          <li><a title="ACG와 NACL 비교" href="/networking/ncloud_networking_vpc_acg_nacl.html" >ACG와 NACL 비교</a></li>          
                    
          
          
          
          
          
          <li><a title="Classic Load Balancer ACG 설정" href="/networking/ncloud_networking_load_balancer_acg.html" >Classic Load Balancer ACG 설정</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC Load Balancer 상품군의 변화" href="/networking/ncloud_networking_vpc_load_balancer.html" >VPC Load Balancer 상품군의 변화</a></li>          
                    
          
          
          
          
          
          <li><a title="Application Load Balancer 생성하기" href="/networking/ncloud_networking_load_balancer_application_lb.html" >Application Load Balancer 생성하기</a></li>          
                    
          
          
          
          
          
          <li><a title="Load Balancer에서 http to https" href="/networking/ncloud_networking_load_balancer_http_to_https.html" >Load Balancer에서 http to https</a></li>          
                    
          
          
          
          
          
          <li><a title="로드밸런서 접속 로그 확인하는 방법" href="/networking/ncloud-networking-load-balancer-application-lb-access-log.html" >로드밸런서 접속 로그 확인하는 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Load Balancer 인증서 교체하는 방법" href="/networking/ncloud-networking-load-balancer-certificate-change.html" >Load Balancer 인증서 교체하는 방법</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="Proxy Protocol로 Client IP 확인" href="#">Proxy Protocol로 Client IP 확인</a>
              <ul>                  
                  
                  
                  
                  <li><a title="CentOS 서버에서 확인" href="/networking/ncloud-networking-proxy-protocol-client-ip-logging-centos.html">CentOS 서버에서 확인</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Ubuntu 서버에서 확인" href="/networking/ncloud-networking-proxy-protocol-client-ip-logging-ubuntu.html">Ubuntu 서버에서 확인</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Rocky Linux 서버에서 확인" href="/networking/ncloud-networking-proxy-protocol-client-ip-logging-rocky-linux.html">Rocky Linux 서버에서 확인</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
          
          
          <li><a title="Subnet 과 NAT Gateway 비교" href="/networking/ncloud_networking_vpc_subnet_natgw.html" >Subnet 과 NAT Gateway 비교</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC 환경에서 NAT Gateway 설정하기" href="/networking/ncloud_networking_natgw_routetb.html" >VPC 환경에서 NAT Gateway 설정하기</a></li>          
                    
          
          
          
          
          
          <li><a title="Global DNS 사용 가이드 - 도메인 추가" href="/networking/ncloud_networking_global_dns_guide.html" >Global DNS 사용 가이드 - 도메인 추가</a></li>          
                    
          
          
          
          
          
          <li><a title="DNS TXT 레코드 225자 이상 등록하기" href="/networking/ncloud-networking-global-dns-configure-long-txt-record.html" >DNS TXT 레코드 225자 이상 등록하기</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC Peering 생성 가이드" href="/networking/ncloud_networking_vpc_peering_guide.html" >VPC Peering 생성 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="IPsecVPN과 FortiGate 장비 연동" href="/networking/ncloud-networking-ipsecvpn-fortigate-setting-guide.html" >IPsecVPN과 FortiGate 장비 연동</a></li>          
                    
          
          
          
          
          
          <li><a title="내 공인 IP 주소 확인하기" href="/networking/ncloud-networking-find-my-ip-address.html" >내 공인 IP 주소 확인하기</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Storage" href="#" ><i class="fa-solid fa-hdd fa-xs"></i> Storage</a>
      <ul>
          
          
          
          <li><a title="네이버 클라우드 스토리지 비교" href="/storage/ncloud_storage_compare.html" >네이버 클라우드 스토리지 비교</a></li>          
                    
          
          
          
          
          
          <li><a title="AWS CLI를 이용 Object Storage 접속" href="/storage/ncloud_storage_object_storage_aws_cli_connect.html" >AWS CLI를 이용 Object Storage 접속</a></li>          
                    
          
          
          
          
          
          <li><a title="Object Storage Lifecycle 정책 설정" href="/storage/ncloud_storage_object_storage_lifecycle_management.html" >Object Storage Lifecycle 정책 설정</a></li>          
                    
          
          
          
          
          
          <li><a title="Object Storage 데이터를 Archive Storage로 자동으로 이동시키는 방법" href="/storage/ncloud_storage_object_storage_transfer_to_archive_storage.html" >Object Storage 데이터를 Archive Storage로 자동으로 이동시키는 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Object Storage 연동이 필수인 서비스" href="/storage/ncloud_storage_object_storage_required_service.html" >Object Storage 연동이 필수인 서비스</a></li>          
                    
          
          
          
          
          
          <li><a title="CloudBerry Explorer 사용방법" href="/storage/ncloud_storage_object_storage_s3_client_cloudberry_explorer.html" >CloudBerry Explorer 사용방법</a></li>          
                    
          
          
          
          
          
          <li><a title="S3 Browser 사용방법" href="/storage/ncloud_storage_object_storage_s3_client_s3browser.html" >S3 Browser 사용방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Cyberduck 사용방법" href="/storage/ncloud_storage_object_storage_s3_client_cyberduck.html" >Cyberduck 사용방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Archive Storage CLI 활용 - Windows" href="/storage/ncloud_storage_archive_storage_cli_windows_guide.html" >Archive Storage CLI 활용 - Windows</a></li>          
                    
          
          
          
          
          
          <li><a title="Archive Storage API 인증 토큰 생성" href="/storage/ncloud_storage_archive_storage_api_access_token_create.html" >Archive Storage API 인증 토큰 생성</a></li>          
                    
          
          
          
          
          
          <li><a title="Archive Storage API - 오브젝트 조회" href="/storage/ncloud_storage_archive_storage_api_get_container_by_php.html" >Archive Storage API - 오브젝트 조회</a></li>          
                    
          
          
          
          
          
          <li><a title="NAS 볼륨 Linux 서버에 마운트하기" href="/storage/ncloud_storage_nas_vpc_guide.html" >NAS 볼륨 Linux 서버에 마운트하기</a></li>          
                    
          
          
          
          
          
          <li><a title="백업 서비스 기본 가이드" href="/storage/ncloud-storage-backup-service-basic-guide.html" >백업 서비스 기본 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="백업 서비스 상세 가이드 - Linux Data" href="/storage/ncloud-storage-backup-service-linux-data-guide.html" >백업 서비스 상세 가이드 - Linux Data</a></li>          
                    
          
          
          
          
          
          <li><a title="백업 서비스 상세 가이드 - 윈도 Data" href="/storage/ncloud-storage-backup-service-windows-data-guide.html" >백업 서비스 상세 가이드 - 윈도 Data</a></li>          
                    
          
          
          
          
          
          <li><a title="Object Storage Content-Type 변경" href="/storage/ncloud-storage-object-storage-mimetype-contenttype-change-guide.html" >Object Storage Content-Type 변경</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L Content-Type 일괄 적용, 변경" href="/storage/ncloud-storage-object-storage-contenttype-bulk-change-guide.html" >&nbsp;&nbsp; L Content-Type 일괄 적용, 변경</a></li>          
                    
          
          
          
          
          
          <li><a title="Object Storage Bucket에 CORS 설정" href="/storage/ncloud-storage-object-storage-bucket-cors-setting-guide.html" >Object Storage Bucket에 CORS 설정</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; CORS를 SDK for S3 API로 설정" href="/storage/ncloud-storage-object-storage-bucket-cors-setting-api-sdk-guide.html" >&nbsp;&nbsp; L &nbsp; CORS를 SDK for S3 API로 설정</a></li>          
                    
          
          
          
          
          
          <li><a title="Object Storage Bucket 접근 로그 설정" href="/storage/ncloud-storage-object-storage-log-management-guide.html" >Object Storage Bucket 접근 로그 설정</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Database" href="#" ><i class="fa-solid fa-database fa-xs"></i> Database</a>
      <ul>
          
          
          
          <li><a title="설치형 DB와 관리형 Cloud DB 비교" href="/database/ncloud_database_compare.html" >설치형 DB와 관리형 Cloud DB 비교</a></li>          
                    
          
          
          
          
          
          <li><a title="MySQL DB 자동백업 방법" href="/database/ncloud_database_mysql_auto_backup.html" >MySQL DB 자동백업 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="MySQL, MariaDB my.cnf 위치" href="/database/ncloud_database_mysql_mariadb_config_my_cnf.html" >MySQL, MariaDB my.cnf 위치</a></li>          
                    
          
          
          
          
          
          <li><a title="MySQL, MariaDB bind-address 위치" href="/database/ncloud_database_mysql_mariadb_config_bind_address.html" >MySQL, MariaDB bind-address 위치</a></li>          
                    
          
          
          
          
          
          <li><a title="CentOS에서 MariaDB 외부접속 허용" href="/database/ncloud_database_mariadb_access_from_remote_centos.html" >CentOS에서 MariaDB 외부접속 허용</a></li>          
                    
          
          
          
          
          
          <li><a title="Ubuntu에서 MariaDB 외부접속 허용" href="/database/ncloud_database_mariadb_access_from_remote_ubuntu.html" >Ubuntu에서 MariaDB 외부접속 허용</a></li>          
                    
          
          
          
          
          
          <li><a title="Rocky Linux에 MySQL 5.7 설치 방법" href="/database/ncloud-database-mysql-57-install-on-rocky-linux.html" >Rocky Linux에 MySQL 5.7 설치 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Rocky Linux에 MySQL 8.0 최신 버전" href="/database/ncloud-database-mysql-8-latest-version-install-on-rocky-linux.html" >Rocky Linux에 MySQL 8.0 최신 버전</a></li>          
                    
          
          
          
          
          
          <li><a title="MySQL 저장 디렉토리 변경해서 설치" href="/database/ncloud-database-mysql-datadir-change-install-guide.html" >MySQL 저장 디렉토리 변경해서 설치</a></li>          
                    
          
          
          
          
          
          <li><a title="CentOS MySQL Object Storage 백업" href="/database/ncloud_database_mysql_object_storage_auto_backup_centos.html" >CentOS MySQL Object Storage 백업</a></li>          
                    
          
          
          
          
          
          <li><a title="Ubuntu MySQL Object Storage 백업" href="/database/ncloud_database_mysql_object_storage_auto_backup_ubuntu.html" >Ubuntu MySQL Object Storage 백업</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC 환경 Cloud DB for MySQL 생성" href="/database/ncloud_database_cloud_db_for_mysql_guide.html" >VPC 환경 Cloud DB for MySQL 생성</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; MySQL Public 도메인 접속" href="/database/ncloud_database_cloud_db_for_mysql_public_domain_guide.html" >&nbsp;&nbsp; L &nbsp; MySQL Public 도메인 접속</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC 환경 Cloud DB for MSSQL 생성" href="/database/ncloud-database-cloud-db-for-mssql-guide.html" >VPC 환경 Cloud DB for MSSQL 생성</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; MSSQL Public 도메인 접속" href="/database/ncloud-database-cloud-db-for-mssql-public-domain-guide.html" >&nbsp;&nbsp; L &nbsp; MSSQL Public 도메인 접속</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; MSSQL 메뉴와 기능 소개" href="/database/ncloud-database-cloud-db-for-mssql-setting-manage-guide.html" >&nbsp;&nbsp; L &nbsp; MSSQL 메뉴와 기능 소개</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="Replication - MySQL, MariaDB" href="#">Replication - MySQL, MariaDB</a>
              <ul>                  
                  
                  
                  
                  <li><a title="MySQL(MARIADB) Replication 생성" href="/database/ncloud_database_mysql_mariadb_replication.html">MySQL(MARIADB) Replication 생성</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MySQL GTID Replication 상세 가이드" href="/database/ncloud-database-mysql-gtid-replication.html">MySQL GTID Replication 상세 가이드</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MySQL Multi Source Replication 생성" href="/database/ncloud-database-mysql-multi-source-replication.html">MySQL Multi Source Replication 생성</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MariaDB Multi Source Replication" href="/database/ncloud-database-mariadb-multi-source-replication.html">MariaDB Multi Source Replication</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          <li class="subfolders">
              <a title="Database Migration 서비스 가이드" href="#">Database Migration 서비스 가이드</a>
              <ul>                  
                  
                  
                  
                  <li><a title="MySQL 5.7 ㅡ> MysQL 5.7" href="/database/ncloud-database-db-migration-from-mysql57-to-mysql57-guide.html">MySQL 5.7 ㅡ> MysQL 5.7</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MySQL 5.7 ㅡ> MysQL 8.0" href="/database/ncloud-database-db-migration-from-mysql57-to-mysql80-guide.html">MySQL 5.7 ㅡ> MysQL 8.0</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MySQL 8.0 ㅡ> MysQL 8.0" href="/database/ncloud-database-db-migration-from-mysql80-to-mysql80-guide.html">MySQL 8.0 ㅡ> MysQL 8.0</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MariaDB ㅡ> MysQL 8.0" href="/database/ncloud-database-db-migration-from-mariadb-to-mysql80-guide.html">MariaDB ㅡ> MysQL 8.0</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
          
          
          <li><a title="MySQL DB Engine 업그레이드" href="/database/ncloud-database-cloud-db-for-mysql-db-engine-upgrade-guide.html" >MySQL DB Engine 업그레이드</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="PostgreSQL" href="#">PostgreSQL</a>
              <ul>                  
                  
                  
                  
                  <li><a title="CDB PostgreSQL 생성 | CentOS" href="/database/ncloud-database-cloud-db-for-postgresql-guide-centos.html">CDB PostgreSQL 생성 | CentOS</a></li>
                  
                  
                  
                  
                  
                  <li><a title="CDB PostgreSQL 생성 | Ubuntu" href="/database/ncloud-database-cloud-db-for-postgresql-guide-ubuntu.html">CDB PostgreSQL 생성 | Ubuntu</a></li>
                  
                  
                  
                  
                  
                  <li><a title="CDB PostgreSQL Public 도메인" href="/database/ncloud-database-cloud-db-for-postgresql-public-domain-guide.html">CDB PostgreSQL Public 도메인</a></li>
                  
                  
                  
                  
                  
                  <li><a title="설치형 PostgreSQL | CentOS" href="/database/ncloud-database-postgresql-install-connect-guide-centos.html">설치형 PostgreSQL | CentOS</a></li>
                  
                  
                  
                  
                  
                  <li><a title="설치형 PostgreSQL | Ubuntu" href="/database/ncloud-database-postgresql-install-connect-guide-ubuntu.html">설치형 PostgreSQL | Ubuntu</a></li>
                  
                  
                  
                  
                  
                  <li><a title="설치형 PostgreSQL | Rocky Linux" href="/database/ncloud-database-postgresql-install-connect-guide-rocky-linux.html">설치형 PostgreSQL | Rocky Linux</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
          
          
          <li><a title="MySQL DB root Password 설정, 변경" href="/database/ncloud_database_mysql_root_password_set_update_guide.html" >MySQL DB root Password 설정, 변경</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="Cloud DB MySQL 읽기 부하 분산" href="#">Cloud DB MySQL 읽기 부하 분산</a>
              <ul>                  
                  
                  
                  
                  <li><a title="Classic 환경" href="/database/ncloud-database-cloud-db-for-mysql-read-load-balancing.html">Classic 환경</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Network LB | VPC 환경" href="/database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-lb.html">Network LB | VPC 환경</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Network Proxy LB | VPC 환경" href="/database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-proxy-lb.html">Network Proxy LB | VPC 환경</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
          
          
          <li><a title="MySQL 복구 시 ERROR 1227 해결" href="/database/ncloud_database_cdb_mysql_restore_error_1227_troubleshooting.html" >MySQL 복구 시 ERROR 1227 해결</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Security" href="#" ><i class="fa-solid fa-shield fa-xs"></i> Security</a>
      <ul>
          
          
          
          <li><a title="Security 서비스 요약" href="/security/ncloud_security_service_summary.html" >Security 서비스 요약</a></li>          
                    
          
          
          
          
          
          <li><a title="Ncloud vs On-Premise Security 비교" href="/security/ncloud_security_onpremise_compare.html" >Ncloud vs On-Premise Security 비교</a></li>          
                    
          
          
          
          
          
          <li><a title="ACG 설정 기본 가이드" href="/security/ncloud_security_acg_guide.html" >ACG 설정 기본 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="Custom ACG 설정 예시" href="/security/ncloud-security-acg-setting-sample.html" >Custom ACG 설정 예시</a></li>          
                    
          
          
          
          
          
          <li><a title="WAF 서비스 요금 정보" href="/security/ncloud-security-security-monitoring-waf-price-info.html" >WAF 서비스 요금 정보</a></li>          
                    
          
          
          
          
          
          <li><a title="SSL인증서 DCV 인증 방법 정리" href="/security/ncloud_security_ssl_dcv_method.html" >SSL인증서 DCV 인증 방법 정리</a></li>          
                    
          
          
          
          
          
          <li><a title="Certificate Manager 인증서 등록 방법" href="/security/ncloud-security-certificate-manager-register-ssl-certificate-guide.html" >Certificate Manager 인증서 등록 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Classic 환경에서 SSL VPN 설정, 접속" href="/security/ncloud_security_ssl_vpn_classic_guide.html" >Classic 환경에서 SSL VPN 설정, 접속</a></li>          
                    
          
          
          
          
          
          <li><a title="VPC 환경에서 SSL VPN 설정, 접속" href="/security/ncloud_security_ssl_vpn_vpc_guide.html" >VPC 환경에서 SSL VPN 설정, 접속</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Management" href="#" ><i class="fa-solid fa-chart-line fa-xs"></i> Management</a>
      <ul>
          
          
          
          <li><a title="Classic 환경 vs VPC 환경 비교" href="/management/ncloud_management_classic_vs_vpc_guide.html" >Classic 환경 vs VPC 환경 비교</a></li>          
                    
          
          
          
          
          
          <li><a title="Sub Account 생성 가이드" href="/management/ncloud_management_sub_account_guide.html" >Sub Account 생성 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="API Key 접근 제한 설정하는 방법" href="/management/ncloud-management-sub-account-api-gateway-access-control-guide.html" >API Key 접근 제한 설정하는 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="STS 기간 제한 API AccessKey 발급" href="/management/ncloud-management-sub-account-sts-temporary-accesskey-create-guide.html" >STS 기간 제한 API AccessKey 발급</a></li>          
                    
          
          
          
          
          
          <li><a title="Classic 환경 Monitoring 서비스 설정" href="/management/ncloud_management_classic_monitoring_guide.html" >Classic 환경 Monitoring 서비스 설정</a></li>          
                    
          
          
          
          
          
          <li><a title="Windows 서버 모니터링 성능 정보 수집 오류 해결 방법" href="/management/ncloud_management_monitoring_win_perf_data_error_troubleshoot.html" >Windows 서버 모니터링 성능 정보 수집 오류 해결 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Cloud Insight 설정 가이드" href="/management/ncloud_management_cloud_insight_guide.html" >Cloud Insight 설정 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; Rule Template 설정 가이드" href="/management/ncloud-management-cloud-insight-rule-template-guide.html" >&nbsp;&nbsp; L &nbsp; Rule Template 설정 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="Webservice Monitoring System 가이드" href="/management/ncloud_management_webservice_monitoring_system_guide.html" >Webservice Monitoring System 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="Webservice Monitoring System 스텝" href="/management/ncloud_management_webservice_monitoring_system_step_guide.html" >Webservice Monitoring System 스텝</a></li>          
                    
          
          
          
          
          
          <li><a title="Cloud Log Analytics 설정 가이드" href="/management/ncloud-management-cloud-log-analytics-guide.html" >Cloud Log Analytics 설정 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; 수집 로그 유형" href="/management/ncloud-management-cloud-log-analytics-template-info.html" >&nbsp;&nbsp; L &nbsp; 수집 로그 유형</a></li>          
                    
          
          
          
          
          
          <li><a title="&nbsp;&nbsp; L &nbsp; IIS Log 수집하는 방법" href="/management/ncloud-management-cloud-log-analytics-windows-iis-log-collect-guide.html" >&nbsp;&nbsp; L &nbsp; IIS Log 수집하는 방법</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="API" href="#" ><i class="fa-solid fa-code-branch fa-xs"></i> API</a>
      <ul>
          
          
          
          <li><a title="PHP로 Ncloud API 호출하기 샘플" href="/api/ncloud_api_call_php_sample.html" >PHP로 Ncloud API 호출하기 샘플</a></li>          
                    
          
          
          
          
          
          <li><a title="C#으로 Ncloud API 호출하기 샘플" href="/api/ncloud_api_call_csharp_sample.html" >C#으로 Ncloud API 호출하기 샘플</a></li>          
                    
          
          
          
          
          
          <li><a title="Python으로 Ncloud API 호출하기 샘플" href="/api/ncloud_api_call_python_sample.html" >Python으로 Ncloud API 호출하기 샘플</a></li>          
                    
          
          
          
          
          
          <li><a title="PowerShell에서 Ncloud API 호출 샘플" href="/api/ncloud-api-call-powershell-sample.html" >PowerShell에서 Ncloud API 호출 샘플</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Application Service" href="#" ><i class="fa-solid fa-laptop-code fa-xs"></i> Application Service</a>
      <ul>
          
          
          
          <li><a title="PHP로 nShortURL 이용하기 샘플" href="/application-service/ncloud_application_service_nshorturl_php_sample.html" >PHP로 nShortURL 이용하기 샘플</a></li>          
                    
          
          
          
          
          
          <li><a title="Cloud Outbound Mailer 대량 메일" href="/application-service/ncloud_application_service_cloud_outbound_mailer_bulk_mail_send.html" >Cloud Outbound Mailer 대량 메일</a></li>          
                    
          
          
          
          
          
          <li><a title="Cloud Outbound Mailer 도메인 인증 방법" href="/application-service/ncloud-application-service-cloud-outbound-mailer-domain-authentication.html" >Cloud Outbound Mailer 도메인 인증 방법</a></li>          
                    
          
          
          
          
          
          <li><a title="Papago Korean Name Romanizer" href="/application-service/ncloud_application_service_papago_korean_name_romanizer_php_sample.html" >Papago Korean Name Romanizer</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="AI Services" href="#" ><i class="fa-solid fa-microchip fa-xs"></i> AI Services</a>
      <ul>
          
          
          
          <li><a title="Clova OCR - Template 생성 가이드" href="/ai-services/ncloud-ai-services-clova-ocr-template-ocr-guide.html" >Clova OCR - Template 생성 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="Clova OCR - API 연동 PHP 샘플" href="/ai-services/ncloud-ai-services-clova-ocr-template-ocr-api-guide.html" >Clova OCR - API 연동 PHP 샘플</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Media" href="#" ><i class="fa-solid fa-play-circle fa-xs"></i> Media</a>
      <ul>
          
          
          
          <li><a title="VOD Station 생성 가이드" href="/media/ncloud-media-vod-station-guide.html" >VOD Station 생성 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="Video Player Enhancement 가이드" href="/media/ncloud-media-video-player-enhancement-guide.html" >Video Player Enhancement 가이드</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Dev Tools" href="#" ><i class="fa-solid fa-gear fa-xs"></i> Dev Tools</a>
      <ul>
          
          
          
          <li><a title="SourceCommit에서 GitHub Repository 복사해오기" href="/dev-tools/ncloud-dev-tools-source-commit-external-repository-copy.html" >SourceCommit에서 GitHub Repository 복사해오기</a></li>          
                    
          
          
          
          
          
          <li><a title="SourceCommit 리포지토리 Git 클라이언트로 로컬PC에 복제하기" href="/dev-tools/ncloud-dev-tools-source-commit-git-client-clone-guide.html" >SourceCommit 리포지토리 Git 클라이언트로 로컬PC에 복제하기</a></li>          
                    
          
          
          
          
          
          <li><a title="Jenkins 설치 가이드 | CentOS" href="/dev-tools/ncloud-dev-tools-jenkins-server-install-guide-centos.html" >Jenkins 설치 가이드 | CentOS</a></li>          
                    
          
          
          
          
          
          <li><a title="Jenkins 설치 가이드 | Ubuntu" href="/dev-tools/ncloud-dev-tools-jenkins-server-install-guide-ubuntu.html" >Jenkins 설치 가이드 | Ubuntu</a></li>          
                    
          
          
          
          
          
          <li><a title="Jenkins 설치 가이드 | Rocky Linux" href="/dev-tools/ncloud-dev-tools-jenkins-server-install-guide-rocky-linux.html" >Jenkins 설치 가이드 | Rocky Linux</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="AWS" href="#" ><i class="fab fa-aws fa-xs"></i> AWS</a>
      <ul>
          
          
          
          <li><a title="AWS S3 수명주기 (LifeCycle) 설정" href="/aws/aws_s3_lifecycle_management.html" >AWS S3 수명주기 (LifeCycle) 설정</a></li>          
                    
          
          
          
          
          
          <li><a title="AWS CLOUDWATCH LOG 수집" href="/aws/aws_cloud_watch_log.html" >AWS CLOUDWATCH LOG 수집</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="ETC" href="#" ><i class="fab fa-markdown fa-xs"></i> ETC</a>
      <ul>
          
          
          
          <li><a title="Gmail smtp 메일발송 인증오류 해결" href="/etc/etc_smtp_auth_to_google_gmail_account.html" >Gmail smtp 메일발송 인증오류 해결</a></li>          
                    
          
          
          
          
          
          <li><a title="PHP로 텔레그램 메시지 전송하기" href="/etc/etc_php_to_telegram_message_send.html" >PHP로 텔레그램 메시지 전송하기</a></li>          
                    
          
          
          
          
          
          <li><a title="Pdf 문서 합치기 PHP로 구현" href="/etc/etc_pdf_merge_php_sample.html" >Pdf 문서 합치기 PHP로 구현</a></li>          
                    
          
          
          
          
          
          <li><a title="PhpSpreadsheet 설정 샘플 코드" href="/etc/etc_phpspreadsheet_sample_code.html" >PhpSpreadsheet 설정 샘플 코드</a></li>          
                    
          
          
          
          
          
          <li><a title="Jekyll Documentation Theme 설치" href="/etc/etc_jekyll_documentation_theme_install.html" >Jekyll Documentation Theme 설치</a></li>          
                    
          
          
          
          
          
          <li><a title="Jekyll Doc Theme 문서 작성 가이드" href="/etc/etc_jekyll_documentation_theme_page_create_guide.html" >Jekyll Doc Theme 문서 작성 가이드</a></li>          
                    
          
          
          
          
          
          <li><a title="jekyll 설치(윈도 10) with base-theme" href="/etc/etc_jekyll_install.html" >jekyll 설치(윈도 10) with base-theme</a></li>          
                    
          
          
          
          
          
          <li><a title="jekyll base-theme 커스터마이징" href="/etc/etc_jekyll_base_theme_customizing.html" >jekyll base-theme 커스터마이징</a></li>          
                    
          
          
          
          
          
          <li><a title="mkdocs 설치 (윈도 10)" href="/etc/etc_mkdocs_install.html" >mkdocs 설치 (윈도 10)</a></li>          
                    
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Tag archives" href="#" ><i class="fa-solid fa-file-archive fa-xs"></i> Tag archives</a>
      <ul>
          
          
          
          <li><a title="Tag archives overview" href="/tag/tag_archives_overview.html" >Tag archives overview</a></li>          
                    
          
          
          <li class="subfolders">
              <a title="Tag archive pages" href="#">Tag archive pages</a>
              <ul>                  
                  
                  
                  
                  <li><a title="Classic pages" href="/tag/tag_classic.html">Classic pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="VPC pages" href="/tag/tag_vpc.html">VPC pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Apache pages" href="/tag/tag_apache.html">Apache pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Linux pages" href="/tag/tag_linux.html">Linux pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="CentOS pages" href="/tag/tag_centos.html">CentOS pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Ubuntu pages" href="/tag/tag_ubuntu.html">Ubuntu pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="SSH pages" href="/tag/tag_ssh.html">SSH pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="DATABASE pages" href="/tag/tag_database.html">DATABASE pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MySql pages" href="/tag/tag_mysql.html">MySql pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="MariaDB pages" href="/tag/tag_mariadb.html">MariaDB pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Cloud DB pages" href="/tag/tag_clouddb.html">Cloud DB pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Load Balancer pages" href="/tag/tag_load_balancer.html">Load Balancer pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Storage pages" href="/tag/tag_storage.html">Storage pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="ACG pages" href="/tag/tag_acg.html">ACG pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Subnet pages" href="/tag/tag_subnet.html">Subnet pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="DNS pages" href="/tag/tag_dns.html">DNS pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Price pages" href="/tag/tag_price.html">Price pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Cloud Functions pages" href="/tag/tag_cloud_functions.html">Cloud Functions pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title=".Net (C#) pages" href="/tag/tag_csharp.html">.Net (C#) pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Account pages" href="/tag/tag_account.html">Account pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Log pages" href="/tag/tag_log.html">Log pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Monitoring pages" href="/tag/tag_monitoring.html">Monitoring pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Analytics pages" href="/tag/tag_analytics.html">Analytics pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="API pages" href="/tag/tag_api.html">API pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="PHP pages" href="/tag/tag_php.html">PHP pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Media pages" href="/tag/tag_media.html">Media pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Object Storage pages" href="/tag/tag_object_storage.html">Object Storage pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Archive Storage pages" href="/tag/tag_archive_storage.html">Archive Storage pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="BackUp pages" href="/tag/tag_backup.html">BackUp pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="NAS pages" href="/tag/tag_nas.html">NAS pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="AWS pages" href="/tag/tag_aws.html">AWS pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="S3 pages" href="/tag/tag_s3.html">S3 pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Auto Scaling pages" href="/tag/tag_autoscaling.html">Auto Scaling pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Limit pages" href="/tag/tag_limit.html">Limit pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Proxy pages" href="/tag/tag_proxy.html">Proxy pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="SSL pages" href="/tag/tag_ssl.html">SSL pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="VPN pages" href="/tag/tag_vpn.html">VPN pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Python pages" href="/tag/tag_python.html">Python pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Install pages" href="/tag/tag_install.html">Install pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="LEMP pages" href="/tag/tag_lemp.html">LEMP pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="NginX pages" href="/tag/tag_nginx.html">NginX pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Windows pages" href="/tag/tag_windows.html">Windows pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="SMTP pages" href="/tag/tag_smtp.html">SMTP pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Gmail pages" href="/tag/tag_gmail.html">Gmail pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="NAT Gateway pages" href="/tag/tag_natgateway.html">NAT Gateway pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Route Table pages" href="/tag/tag_route_table.html">Route Table pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="VPC Peering pages" href="/tag/tag_vpc_peering.html">VPC Peering pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Authentication pages" href="/tag/tag_auth.html">Authentication pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Password pages" href="/tag/tag_password.html">Password pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Mail pages" href="/tag/tag_mail.html">Mail pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Excel pages" href="/tag/tag_excel.html">Excel pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Markdown pages" href="/tag/tag_markdown.html">Markdown pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="Jekyll pages" href="/tag/tag_jekyll.html">Jekyll pages</a></li>
                  
                  
                  
                  
                  
                  <li><a title="GitHub pages" href="/tag/tag_github.html">GitHub pages</a></li>
                  
                  
                  
              </ul>
          </li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



              </div>
              
            

            <!-- Content Column -->
            <div class="col-md-9" id="tg-sb-content">
              <div class="post-header">
  
    <h1 class="post-title-main">Search</h1>
  
</div>




<div class="post-content" >

  

  
  

  <p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>
<ul id="search-results"></ul>

<script>
	window.data = {
		
			
				
			
		
			
				
					
					
					"aws-aws-cloud-watch-log-html": {
						"id": "aws-aws-cloud-watch-log-html",
						"title": "AWS CLOUDWATCH LOG 수집 매뉴얼",
						"categories": "",
						"url": " /aws/aws_cloud_watch_log.html",
						"content": "사전 작업\n\nIAM 계정생성 및 권한 부여\n\ncloudwatch log수집을 위해서는 서버 작업과 별도로 IAM 계정생성과 권한할당 작업을 선 진행하여야하며 작업이 완료된 후 계정의 액세스키[^1], 비밀키를 발급 받는다.\n\n\n  계정생성\n    \n      계정생성- 계정이름 입력- 액서스 유형 Programmatic access 선택\n    \n  \n  권한설정\n    \n      기존 정책 직접 연결 선택 - CloudWatchAgentServerPolicy정책 추가\n    \n  \n  키확인\n    \n      액세스 키 확인 및 비밀키 확인\n    \n  \n\n\n서버 작업\n\n설치 작업\n\n\n  awslogs 설치는 다음 명령어를 통해 설치\nyum -y install awslogs\n  \n    aws configure를 통한 IAM 키 입력\n\n    aws configure 명령어 입력 - 액세스키 요구 및입력 - 비밀키 요구및 입력(위 IAM계정의 키 입력)\n  \n\n\n설정 관련\n\n\n  \n    /etc/awslogs/awscli.conf\n\n    region = ap-northeast-2 추가 설정없이 리전만 로그 수집을 위한 리전으로 변경\n  \n  \n    /etc/awslogs/awslog.conf\n\n    해당 컨피그 파일의 제일 하단에 로그 수집 대상 로그를 아래의 형식으로 작성\n\n    [/var/log/messages] – 수집로그 경로와 파일 지정\n\n    datetime_format = %b %d %H:%M:%S (로그의 데이터 포맷 지정)\n\n    file = /var/log/messages (로그 파일 위치)\n\n    buffer_duration = 5000 (로그 이벤트를 일괄 처리하는 기간을 지정합니다. 최소값은 5000ms이고, 기본값은 5000ms입니다.)\n\n    log_stream_name = {instance_id} (대상로그 스트림 이름 지정{instance_id}, {hostname}, {ip_address})\n\n    initial_position = start_of_file\n\n    log_group_name = /var/log/messages(cloudwatch 로그 그룹네임 지정 )\n\n    time_zone=LOCAL\n\n    multi_line_start_pattern ={datetime_format} (로그 줄 단위 기준점. datetime_fomat 멀티라인 처리)\n  \n  \n    /var/log/awslogs.log\n\n    awslogs서비스 실행 후 발생되는 로그.\n  \n\n\n실행 및 자동실행 등록\n\n\n  실행 명령어 service awslogs start\n  리붓시 자동실행 등록 chkconfig awslogs on (amazon linux2 인 경우 systemctl enable awslogsd.service)\n\n\ncloudwatch 설정\n\n정상적으로 서버의 로그가 수집된다면 cloudwatch - log항목에서 서버에서 지정한 로그 그룹네임이 보이며 이를 클릭시 서버 인스턴스 ID별로 로그 수집되는 내역 확인 가능\n\n수집된 데이터는 대시보드를 통해 데이터를 보여주는기능은 바로 가능하나 이를 가지고 그래프를 통한 시각화를 할수 없어 지표를 통한 그래프를 생성하여야함.\n\n\n  \n    cloudwatch -로그- 로그그룹중 필터기능을 쓸 지표선택 -지표 필터 클릭\n  \n  \n    지표 필터 추가 버튼 클릭\n  \n  \n    필터링 하고자하는 값을 넣고 [정규식지원]패턴 테스트 후 지표할당 클릭\n  \n  \n    이후 지표 네임스페이스는 로그 그룹 네임 중 추출하고자하는 지표영역 지표이름은 해당 지표를 선택\n  \n  \n    cloudwatch - 지표 선택 - 모든 지표에서 로그 그룹 필터를 적용한 로그 그룹의 incomingLogEvents선택\n  \n  \n    그래프로 표시된 지표 탭 선택 - 필터가 적용된 그래프가 나오며 그래프의 작업 대시보드 추가를 선택하여\n\n    대시보드로 그래프 등록\n  \n\n\n오류 대처 법\n\n로그 수집이 되지 않고 awslogs.log파일에 아래와 같이 로그 가 찍히는 경우 처리 방안\n\n reason: timestamp is more than 2 hours in future.\n\n\n  /var/lib/awslogs/agent-state를 삭제\n    \n      해당 방법으로 처리시 수집되는 로그가 처음부터 다시 로그가 수집됩\n    \n  \n  sqlite3 명령어를 통해 agent-state 오류 처리\n    \n      sudo sqlite3 /var/lib/awslogs/agent-state\n      select * from stream_state; 통해 문제가 되는 소스ID확인\n      select * from push_state where k=”확인된 소스ID”;\n      update push_state set v=’… insert new value here …’  where k=’7675f84405fcb8fe5b6bb14eaa0c4bfd’;\n      service awslogs restart\n    \n  \n\n\n참고 URL\n\nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/AgentReference.html\nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html\nhttps://stackoverflow.com/questions/40604940/cloudwatch-logs-acting-weird"
					}
					
				
			
		
			
				
					,
					
					"aws-aws-s3-lifecycle-management-html": {
						"id": "aws-aws-s3-lifecycle-management-html",
						"title": "AWS S3 수명 주기 (LifeCycle) 설정하기",
						"categories": "",
						"url": " /aws/aws_s3_lifecycle_management.html",
						"content": "개요\nAWS S3에서는 버킷내 특정 디렉토리 하위 파일들에 대해 지정된 날짜가 지난 후 만료(삭제)가 되도록 설정할 수 있습니다. \n수명 주기 관리(LifeCycle Management)라고 불리는 이 방법은 파일관리 뿐만 아니라 비용절감에도 도움이 됩니다.\n\n수명주기 설정\nAWS 콘솔에 접속 후 수명 주기를 적용할 S3 버킷으로 이동해 [관리] 메뉴 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[수명 주기 규칙 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n수명 주기 규칙 이름을 입력하고, 규칙 범위는 [하나 이상의 필터를 사용하여 이 규칙의 범위 제한]을 선택합니다.\n접두사에는 수명 주기를 적용할 디렉토리나 파일 등의 필터를 작성합니다. 예를 들어 images 디렉토리가 포함된 모든 파일에 적용하려면 images/ 라고 입력합니다. 이때 버킷명은 제외하고 입력해야 합니다.\n\n\n  \n  \n    \n  \n\n\n수명 주기 규칙 작업에서 [객체의 현재버전 만료],  [객체의 이전버전 영구 삭제] 두가지 항목을 선택하면, 몇일 후에 삭제할 것인지를 설정할 수 있는 [객체 생성 후 경과 일수], [객체가 이전 버전이 된 후 경과 일수] 항목이 나타납니다. \n여기에 원하는 날짜를 각각 입력하고, [규칙 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n주의사항\nAWS 수명 주기 관련해서 주의해야 할 사항이 몇가지 있습니다.\n\n수명 주기 규칙 작동 시점\n수명 주기 규칙이 생각한 것보다 늦게 작동하는 경우가 있습니다. 이는 Amazon S3가 객체의 전환 또는 만료(삭제) 날짜를 익일 자정(UTC)부터 계산하기 때문입니다.\n예를 들어 2020년 1월 1일 10:30(UTC)에 객체를 생성하고 3일 후 객체가 만료(삭제)되도록 수명 주기 규칙을 설정할 경우 객체의 만료(삭제) 날짜는 2020년 1월 5일 00:00(UTC)이 됩니다. \n따라서 수명 주기 규칙이 충족되었는지 확인하기 전에 충분한 시간이 경과했는지 확인해야 합니다.\n\n수명 주기 규칙 접두사 필터 설정\n수명 주기 규칙에서 접두사 필터에 디렉토리를 지정할 경우 접두사 필터의 끝에 / 문자를 지정해야 합니다. 접두사 필터의 처음에 / 문자가 있으면 수명 주기 규칙이 올바르게 평가되지 않습니다.\n즉, images 디렉토리가 포함된 모든 파일에 적용하려면 images/ 라고 입력해야 합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  AWS S3 수명 주기 관리 가이드\n    \n      https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lifecycle-mgmt.html\n    \n  \n  수명 주기 규칙 작동 지연 관련 FAQ\n    \n      https://aws.amazon.com/ko/premiumsupport/knowledge-center/s3-lifecycle-rule-delay/"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-jekyll-base-theme-customizing-html": {
						"id": "etc-etc-jekyll-base-theme-customizing-html",
						"title": "jekyll base-theme 커스터마이징",
						"categories": "",
						"url": " /etc/etc_jekyll_base_theme_customizing.html",
						"content": "폰트 교체\nbase-theme는 기본 폰트가 Merriweather로 되어 있습니다.\n영어 표기에는 적당하지만, 한글 표기에는 좋지 않아 나눔고딕 폰트로 변경하였습니다.\n\n그리고 폰트 파일을 별도로 추가하기 보다는 구글에서 제공하는 폰트 경로를 설정하는 방식으로 교체했습니다.\n구글에서 제공하는 폰트 리스트와 적용 방법은 아래 사이트에서 확인 가능합니다.\nhttps://fonts.google.com/\n\nhtml 수정\n\n파일 위치 : \\_layouts\\default.html\n&lt;link rel=\"preconnect\" href=\"https://fonts.gstatic.com\"&gt;\n&lt;link href=\"https://fonts.googleapis.com/css2?family=Nanum+Gothic&amp;display=swap\" rel=\"stylesheet\"&gt; \n\n\ncss 수정\n\n파일 위치: \\_sass\\typography.scss\nbody {\n  height: 100%;\n  max-height: 100%;\n  font-family: 'Nanum Gothic', sans-serif;\n  }\n\n\n한글 검색 오류 수정\nbase-theme 기본 설정으로는 한글 등 utf-8 언어 검색이 되지 않습니다.\n그에 따라 몇가지 수정을 하면 한글 검색이 가능해집니다.\n\njs 파일 위치: \\js\\search.js\n\n기존:\nwindow.index = lunr(function () {\n\t\tthis.field(\"id\");\n\t\tthis.field(\"title\", {boost: 10});\n\t\tthis.field(\"categories\");\n\t\tthis.field(\"url\");\n\t\tthis.field(\"content\");\n\t});\n\n수정: \nwindow.index = new lunr.Index;\nwindow.index.field('id');\nwindow.index.field('title', { boost: 10 });\nwindow.index.field('author');\nwindow.index.field('category');\nwindow.index.field('content');\n\n\n다음으로 charset 을 설정합니다.\nhtml 파일 위치 : \\search.html\n기존: \n&lt;script src=\"{{ site.baseurl }}/js/lunr.min.js\"&gt;&lt;/script&gt;\n&lt;script src=\"{{ site.baseurl }}/js/search.js\"&gt;&lt;/script&gt;\n\n수정: \n&lt;script src=\"{{ site.baseurl }}/js/lunr.min.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n&lt;script src=\"{{ site.baseurl }}/js/search.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n\n상단 header bg 교체\n\n파일 위치: \\_sass\\header.scss\n\n기존:\nheader {\n\tbackground: $header-color;\n}\n\n수정: \nheader {\n\tbackground: url(\"/images/ncp-header-bg.png\");\n\tbackground-size: 2200px;\n}\n\n\nlogo 파일 교체\n\n파일 위치: \\_includes\\logo.html\n\n\n기존:\n&lt;svg version=\"1.1\" id=\"Layer_1\" ..중략.. xml:space=\"preserve\"&gt;\n\t ..중략..\n&lt;/svg&gt;\n\n수정:\n&lt;img src=\"/images/title_logo_white.png\" style=\"width:160px;height:33px;margin-top:5px\"&gt;\n\n\n상단 메뉴 수정\n\n파일 위치: \\_data\\navigation.yml\n\n- name: Docs\n  link: /\n  target: _self\n- name: FAQ\n  link: /faq/\n  target: _self\n- name: Company\n  link: https://3rdeyesys.com\n  target: _blank\n\n\n상단 header에 검색 박스 추가\n\n파일 위치: \\_includes\\navigation.html\n\n{% if page.url != \"/\" %}\n\t&lt;span style=\"width:100px\"&gt;\\{% include search.html %}&lt;/span&gt;\n{% endif %}\t\n&lt;/nav&gt;\n\n\n하단 footer social 아이콘 수정\n\n파일 위치: \\_data\\footer.yml\n\n- name:\n  link: https://www.facebook.com/3rdeyesys\n  social_icon: Facebook\n  target: _blank\n- name:\n  link: mailto:biz@3rdeyesys.com\n  social_icon: Email\n  target: _blank\n\n\n코드 블럭 스타일 수정\n\n  첫째줄만 들여쓰기 되는 현상 수정\n  컨텐츠 넓이 정도로 영역이 자동 할당되도록 수정\n  과도한 padding, margin 영역 축소\n\n\n파일 위치: \\_sass\\dark-theme.scss\n\n기존:\n.highlight { \n padding: 10px 15px;\n}\n \n수정: \n.highlight { \n  padding: 7px 30px 7px 10px;\n  display:inline-block;\n}\n\n\n파일 위치: \\_sass\\elements.scss\n\n기존:\ncode, pre, tt {\t\n\tpadding: 2px 5px;\n}\n \n수정: \ncode, pre, tt {\t\n\tmargin: 0px;\n\tdisplay:inline-block;\n}"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-jekyll-documentation-theme-install-html": {
						"id": "etc-etc-jekyll-documentation-theme-install-html",
						"title": "Jekyll Documentation Theme 설치 가이드",
						"categories": "",
						"url": " /etc/etc_jekyll_documentation_theme_install.html",
						"content": "Documentation Theme 특징\n이 기술문서에 사용된 Documentation Theme의 가장 큰 특징은 다음과 같습니다.\n\n- 문서를 카테고리별로 정렬해서 보여주는 네비게이션 리스트\n- 문서 상단에 보여주는 문서 목차 (TOC)\n- 다양한 상단 네비게이션 구성\n- Tag를 활용해서 비슷한 주제의 문서를 함께 확인할 수 있음\n\n\n  \n  \n    \n  \n\n\n설치 전체과정 요약\n\n\n  Ruby 설치\n  ridk 설치\n  Documentation Theme 다운로드\n  Jekyll gem 설치\n  Bundler 설치\n\n\n Tip: 이미 Ruby 2.5등 3.0 이전 버전이 설치되어 있더라도 3.0을 설치하시는 걸 추천드립니다. build 속도 개선 등 많은 기능이 향상 되었습니다.\n\nRuby 설치\njekyll 최신 버전은 2022-03-03 현재 v.3.1이지만 여기서는 Documentation Theme를 기반으로 하기 때문에 호환이 잘되는 3.0을 설치합니다.\n\nRuby Installer 다운로드 경로\nhttps://rubyinstaller.org/downloads/\n\n위 사이트에서 rubyinstaller-devkit-3.0.3-1-x64 를 다운 받아 설치하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nRuby 설치 화면에서 PATH와 파일 확장자 연결에 체크 되어 있는지 확인하고 [Install] 버튼을 클릭합니다.\n\n  \n  \n    \n  \n\n\n설치할 컴포넌트 선택화면에서 모두 선택하거나 최소한 MSYS2 development toolchain은 꼭 선택하고 [Next] 버튼을 클릭합니다. 설치에 필요한 공간은 972MB 정도 됩니다.\n\n  \n  \n    \n  \n\n\nRuby 설치가 끝나면서 완료화면에 Run ‘ridk install’ to setup MSYS2 and development toolchain. 이라는 옵션이 나타납니다. \n꼭 설치해야 하는 툴이므로 반드시 선택하고 완료를 해서 바로 설치화면으로 이동하도록 합니다.\n\n\n  \n  \n    \n  \n\n\nridk 설치\n앞단계인 Ruby 설치 완료에서 ridk install을 선택했다면 ridk 설치 커맨드 창이 나타납니다.\n(혹시 선택하지 않았다면 커맨드 창을 열어서 ridk install 을 입력하면 됩니다)\n이때 설치 옵션을 선택할 수 있는데 Enter 키를 입력하면 기본 옵션인 1, 3으로 설치가 진행됩니다.\n\n\n  \n  \n    \n  \n\n\nDocumentation Theme 설치\nDocumentation Theme는 jekyll의 여러 테마 중에서 문서 작성에 특화된 테마입니다.\n\n다운로드 경로\nhttps://github.com/tomjoht/documentation-theme-jekyll\n\n위 다운로드 경로에서 소스를 직접 다운 받거나 GitHub Desktop을 이용해서 가져오면 됩니다.\n\nLive Demo\n실제 Documentaion Theme를 적용하면 어떤 사이트를 만들 수 있는지 미리 확인해볼 수 있는 Live Demo 사이트가 있습니다.\nhttps://idratherbewriting.com/documentation-theme-jekyll/\n\nJekyll gem 설치\n우선 jekyll을 설치합니다.\n\ngem install jekyll\n\n\nBundler 설치\n\n\n  다운로드 받은 Documentation theme 폴더를 오픈합니다.\n  Gemfile 과 Gemfile.lock 파일을 삭제하거나 이름을 변경합니다.\n  다음 명령으로 bundler를 설치합니다: gem install bundler\n  \n    Bundler를 초기화 합니다: bundle init\n\n    초기화 작업이 진행되면서 Gemfile 파일이 생성됩니다.\n  \n  \n    Gemfile을 열어서 기존 내용을 삭제하고 다음 내용으로 변경합니다.\n\n    source \"https://rubygems.org\"\n  \ngem 'jekyll', '~&gt; 4.2.1'\n\ngroup :jekyll_plugins do \n  gem 'jekyll-seo-tag', '~&gt; 2.7.0'\n  gem 'jekyll-sitemap', '~&gt; 1.4.0'\n  gem 'wdm', '~&gt; 0.1.1'\n  gem 'kramdown-parser-gfm'\nend\n\ngem \"webrick\", \"~&gt; 1.7\"\n    \n  \n  Gemfile을 저장합니다.\n  다음 명령어로 필요한 gem을 설치합니다: bundle install\n\n\n사이트 실행, 접속\n작업하면서 결과물을 확인할 때는 다음과 같은 명령어로 입력하고 브라우져에서 http://127.0.0.1:4000/ 로 접속하시면 되니다.\n\nbundle exec jekyll serve\n\n\n최종 결과 화면\n위 절차대로 모두 실행하면 아래와 같은 화면을 볼 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n사이트 빌드\n작업이 끝난 결과물을 실제 서버나 gitHub에 업로드, 배포할 경우에는 다음 명령어로 빌드 한 후에 _site에 생성된 html 등을 사용하시면 됩니다.\n\nbundle exec jekyll build\n\n\n추가 패키지 설치\n혹시 사이트 실행, 접속에서 오류가 발생하면 나타나는 메시지를 보고 처리를 해주면 됩니다.\n혹시 필요한 gem이 설치되지 않았을 경우에는 다음과 같이 설치해주면 됩니다.\n\n# gem 수동 설치 예시\ngem install public_suffix -v 3.0.1"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-jekyll-documentation-theme-page-create-guide-html": {
						"id": "etc-etc-jekyll-documentation-theme-page-create-guide-html",
						"title": "Jekyll Documentation Theme 문서 작성 기본 가이드",
						"categories": "",
						"url": " /etc/etc_jekyll_documentation_theme_page_create_guide.html",
						"content": "문서 편집툴\n\nVisual Studio Code\nWindows에서 Jekyll 문서를 편집하는 경우에는 Command 창을 열어서 로컬 사이트를 실행하거나 빌드하고, 오류가 발생하면 실시간으로 나타나는 오류 메시지를 확인하면서 작업하게 됩니다. \n이때 문서 편집툴과 Command 창을 별도로 띄워놓고 확인하는 것이 불편한데 Visual Studio Code를 사용하면 아래 스샷처럼, 문서 편집화면과 터미널 창을 함께 보면서 작업 가능해서 무척 편리합니다.\n\n\n  다운로드: https://code.visualstudio.com/\n\n\n\n  \n  \n\n\nmd 파일 생성\n작성하려는 문서를 markdown 파일의 확장자인 .md 파일로 생성합니다.\n\n파일 경로\n파일경로는 /pages 폴더 아래쪽에 카테고리 별로 적당히 나누어서 관리하기 편하게 구성하면 됩니다.\n\n# 파일 경로와 폴더 구성 예시\n- pages\n  L api\n    L ncloud_api_call_csharp_sample.md\n    L ncloud_api_call_php_sample.md\n    L ncloud_api_call_python_sample.md\n\n  L database\n    L ncloud_database_compare.md\n    L ncloud_database_mysql_auto_backup.md        \n  \n\n\n문서 속성 설정\n문서 상단에 아래 예시와 같은 각 문서의 속성을 설정하는 부분이 있습니다.\n\n---\ntitle: Jekyll Documentation Theme 문서 작성 기본 가이드\ndescription: Jekyll Documentation Theme 문서 작성하는 기본 방법입니다\nkeywords: Markdown, Windows, Hugo\ntags: [markdown, jekyll, windows]\nsidebar: docs_main_sidebar\npermalink: /etc/etc_jekyll_documentation_theme_page_create_guide.html\nlast_updated: 2022-03-07\n---\n\n\ntitle\ntitle 항목은 문서 제목과 최종 html의 &lt;title&gt;태그, &lt;meta property=”og:title” /&gt; 태그 등에 사용됩니다.\n\n&lt;title&gt;Jekyll Documentation Theme 문서 작성 기본 가이드 | 써드아이시스템 기술문서&lt;/title&gt;\n&lt;meta property=\"og:title\" content=\"Jekyll Documentation Theme 문서 작성 기본 가이드\" /&gt;\n&lt;meta property=\"twitter:title\" content=\"Jekyll Documentation Theme 문서 작성 기본 가이드\" /&gt;\n\n\n\n  \n  \n\n\nkeywords\nkeywords 항목은 최종 html의 &lt;meta name=”keywords” &gt; 태그에 사용됩니다.\n\n&lt;meta name=\"keywords\" content=\"Markdown, Windows, Hugo\"&gt;\n\n\ndescription\ndescription 항목은 문서 요약 내용인 summary와 최종 html의 &lt;meta name=”description” /&gt; 태그와 &lt;meta property=”og:description” /&gt; 태그에 사용됩니다.\n\n&lt;meta name=\"description\" content=\"Jekyll Documentation Theme 문서 작성하는 기본 방법입니다\"&gt;\n&lt;meta property=\"og:description\" content=\"Jekyll Documentation Theme 문서 작성하는 기본 방법입니다\" /&gt;\n\n\n\n  \n  \n\n\ntags\ntags를 설정해 두면 동일한 tag를 가진 문서들을 모아서 함께 볼 수 있습니다.\n\n\n  \n  \n\n\nsidebar\n전체 문서를 카테고리 별로 표시하는 왼쪽 사이드바의 이름을 설정합니다.\n경우에 따라서는 사이드바를 여러 개 만들어서 문서 성격에 따라 다르게 표시할 수도 있습니다.\nsidebar 파일은 /_data/sidebars/ 폴더에 docs_main_sidebar.yml 형식으로 있습니다.\n\npermalink\npermalink는 문서의 최종 html 페이지 URL 입니다. md 파일의 위치와 관계없이 원하는 형태의 URL로 설정할 수 있습니다.\n\n# md 파일 위치 예시\n/pages/compute/server/server_compare.md\n\n# permalink 예시\n/compute/compute_server_compare.html\n\n\nlast_updated\n문서의 최종 수정일을 뜻하는 것으로 날짜 기준으로 최근 업데이트된 문서를 정렬한다거나 여러 가지로 사용할 수 있습니다.\n\n목차 레벨 설정\n목차 레벨은 3가지로 구분됩니다.\n\n## Second-level heading\n\n\nResult:\n Second-level heading\n\n\n\n### Third-level heading\n\nResult:\n Third-level heading\n\n\n\n#### Fourth-level heading\n\n\nResult:\n Fourth-level heading\n\n이미지 설정\n이미지는 이미지에 대한 html 태그가 설정된 파일을 include 하게 됩니다.\n\n{% include image.html file=\"etc/etc_jekyll_documentation_theme_page_create_guide_03.png\" width=\"845\" alt=\"Jekyll Documentation Theme 문서 작성하는 기본 방법\" %}\n\n\n실제 image.html 파일 내용은 다음과 같습니다.\n\n&lt;figure&gt;\n{% if {{include.url}} %}&lt;a class=\"no_icon\" target=\"_blank\" rel=\"noopener\" href=\"{{include.url}}\"&gt;{% endif %}\n&lt;img class=\"docimage\" src=\"/images/{{include.file}}\" alt=\"{{include.alt}}\" \n{% if {{include.width}} %}style=\"width: {{include.width}}px; \n{% if {{include.width &gt;= '850'}} %}max-width: 100%\n{% endif %}\"\n{% endif %} /&gt;\n{% if {{include.url}} %}&lt;/a&gt;{% endif %}\n{% if {{include.caption}} %}&lt;figcaption&gt;{{include.caption}}&lt;/figcaption&gt;{% endif %}\n&lt;/figure&gt;\n\n\nURL 링크 설정\nURL 링크는 markdown에서 기본으로 제공되는 형식이 있지만 target 설정이나 word-break 등의 스타일을 적용하기 불편해서 html 태그를 그대로 사용합니다.\n\n&lt;a href=\"https://rubyinstaller.org/downloads/\" target=\"_blank\" style=\"word-break:break-all;\"&gt;https://rubyinstaller.org/downloads/&lt;/a&gt;\n\n\n링크에 적용된 style=’work-break:break-all’은 한글이 아닌 영문만으로 구성된 주소 등은 길이가 길 경우 다음 줄로 내려가서 표시되지 않고 지정된 영역을 벗어나서 표시되는 경우가 있는데 이를 방지하고 강제로 다음 줄로 내려서 표시하는 기능입니다.\n\nCode Syntax highlighting 설정\nSyntax highlighting은 다음과 같이 적용할 수 있습니다.\n\n\n``` c#\nbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\nbyte[] bytes = Encoding.UTF8.GetBytes(message);\nusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\n{\n\tbyte[] hash = sha256.ComputeHash(bytes);\n\tmsgSignature = Convert.ToBase64String(hash);\n}\n```\n\n\n결과는 다음과 같이 표시됩니다.\n\nbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\nbyte[] bytes = Encoding.UTF8.GetBytes(message);\nusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\n{\n\tbyte[] hash = sha256.ComputeHash(bytes);\n\tmsgSignature = Convert.ToBase64String(hash);\n}\n\n\nSyntax highlighting이 지원되는 대표적인 형식 리스트는 다음과 같습니다.\n\n\n  apache, batch, c, config(conf), console, cpp(c++), csharp(c#), css\n  docker, email, go, html, java, javascript(js), json, jsp, liquid\n  markdown(md), nginx, objective_c(objc), perl, php, powershell, python\n  ruby, scss, sql, ssh, swift, xml, yml(yml)\n\n\nAlert, CallOut 설정\n문서 내용 중에 강조나 경고, Tip 등을 표시하기 위해 Alert이나 CallOut 기능을 사용합니다.\n\nAlerts\nAlerts 사용 방법은 아래와 같고 4종류가 있습니다.\n{% include note.html content=\"This is note.\" %}\n\n\n Note: This is note.\n\n Tip: This is tip.\n\n Warning: This is warning.\n\n Important: This is important.\n\n\n그리고, 앞쪽의 Note, Tip 등을 다른 글자로 바꾸려면 다음과 같이 title 항목을 적용하면 됩니다.\n\n{% include note.html title=\"제목\" content=\"This is note.\" %}\n\n 제목: This is note.\n\n{% include warning.html title=\"ERROR 1227 (42000)\" content=\"Access denied; you need (at least one) the SUPER...\" %}\n\n ERROR 1227 (42000): Access denied; you need (at least one) the SUPER…\n\n\nCallOut Version-1\n기본으로 제공되는 CallOut Version-1은 다음과 같이 사용합니다.\n\n{% include callout_v2.html type=\"danger\" content=\"This is my **danger** type callout\" %}\n\n사용 가능한 종류는 다음과 같습니다.\nThis is my danger type callout\n\nThis is my default type callout\n\nThis is my primary type callout\n\nThis is my success type callout\n\nThis is my info type callout\n\nThis is my warning type callout\n\nCallOut Version-2\n기본으로 제공되는 Version-1에서 스타일을 변경한 CallOut Version-2는 다음과 같이 level 속성도 추가해서 사용합니다. level의 기본 값은 3입니다.\n\n{% include callout_v2.html type=\"danger\" level=\"3\" content=\"This is my **danger** type callout version-2\" %}\n\n\nThis is my danger type callout version-2 level-1\n\nThis is my default type callout version-2 level-2\n\nThis is my primary type callout version-2 level-3\n\nThis is my success type callout version-2 level-3\n\nThis is my info type callout version-2 level-4\n\nThis is my warning type callout version-2 level-5\n\n사이드바 설정\n제일 중요한 사이드바는 /_data/sidebars/docs_main_sidebar.yml 파일이며 다음과 같이 설정합니다.\n여기서 주의해야 할 것은 들여쓰기 간격이 일치해야 오류가 발생하지 않습니다.\n\n\n  title : 사이드바에 표시되는 제목입니다. 너무 길 경우 적당히 줄이는 것을 추천합니다.\n  url : 문서 url 전체 경로입니다.\n\n\n- title: 서버 접속 방법(Linux) - 공인IP 없을 때\n  url: /compute/ncloud_compute_server_connect_no_public_ip.html\n  output: web\n\n\nSubFolder 등이 포함된 전체적인 구조는 다음과 같습니다.\nentries:\n- title: sidebar\n  product: Technical Documentation\n  version: \n  folders:\n\n  - title: Compute\n    icon: fa-solid fa-server\n    url: /compute/ncloud_compute_server_connect_no_public_ip.html\n    output: web\n    folderitems:\n\n    - title: 서버 접속 방법(Linux) - 공인IP 없을 때\n      url: /compute/ncloud_compute_server_connect_no_public_ip.html\n      output: web\n    \n      subfolders:\n      - title: Cloud Functions\n        output: web\n        subfolderitems:\n\n        - title: Cloud Functions Action을 cmd에서 C#으로 작성하기\n          url: /compute/ncloud_compute_cloud_functions_dotnet_csharp_cmd.html\n          output: web\n  \n  - title: Networking\n    icon: fas fa-network-wired\n    url: /networking/ncloud_networking_service_port_info.html\n    output: web\n    folderitems:\n\n    - title: 주요 서비스 포트(Port) 정보\n      url: /networking/ncloud_networking_service_port_info.html\n      output: web\n\n  - title: Tag archives\n    icon: fas fa-file-archive\n    url: /tag/tag_archives_overview.html\n    output: web\n    folderitems:\n\n    - title: Tag archives overview\n      url: /tag/tag_archives_overview.html\n      output: web\n\n      subfolders:\n      - title: Tag archive pages\n        output: web\n        subfolderitems:\n\n        - title: Classic pages\n          url: /tag/tag_classic.html\n          output: web\n\n\ntag 설정\ntag를 표시하기 위해서는 몇가지 단계를 거쳐야 합니다.\n\n\n  문서 속성 설정에 tag 정보 추가하기\n  허용 tag list 파일에 추가하기\n  tag 문서 추가하기\n  사이드바에 추가하기\n\n\n문서 속성 설정에 tag 정보 추가\n이 내용은 위에서 이미 살펴본 내용입니다. 문서 상단 속성 설정에 추가하면 됩니다.\ntags: [markdown, jekyll, windows]\n\n\n허용 tag list 파일에 추가\n/_data/tags.yml 파일에 tag를 추가합니다.\n\nallowed-tags:\n  - account\n  - acg\n  - analytics\n\n\ntag 문서 추가\n/tags/ 폴더에 tag_account.md처럼 문서를 작성합니다.\n\n문서는 다음과 같이 구성됩니다. title, tagName, permalink 이렇게 3가지 정보만 설정하면 됩니다.\n\ntitle: \"Account\"\ntagName: account\nsearch: exclude\npermalink: /tag/tag_account.html\nsidebar: docs_main_sidebar\nfolder: tags\n\n\n사이드바에 추가\n사이드바 /_data/sidebars/docs_main_sidebar.yml 파일에 추가해줍니다.\n\n- title: Account pages\n  url: /tag/tag_account.html\n  output: web\n\n\n위치는 아래쪽에 아래와 같은 구성으로 되어있습니다.\n- title: Tag archives\n    icon: fas fa-file-archive\n    url: /tag/tag_archives_overview.html\n    output: web\n    folderitems:\n\n    - title: Tag archives overview\n      url: /tag/tag_archives_overview.html\n      output: web\n\n      subfolders:\n      - title: Tag archive pages\n        output: web\n        subfolderitems:\n\n        - title: Classic pages\n          url: /tag/tag_classic.html\n          output: web\n\n\nTop 메뉴 설정\n상단 네비게이션 메뉴는 /_data/topnav.yml 파일에서 설정할 수 있습니다.\n\n\n  url: 내부 페이지 링크\n  external_url : 외부 사이트 링크\n\n\ntopnav:\n- title: Topnav\n  items:\n    - title: Update\n      url: /update/update.html\n    - title: News\n      url: /news/news.html\n    - title: FAQ\n      url: /faq/faq.html\n    - title: Tag\n      url: /tag/tag_archives_overview.html\n    - title: Company\n      external_url: https://3rdeyesys.com/\n    - title: 1:1 문의하기\n      external_url: https://www.3rdeyesys.com/question/"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-jekyll-install-html": {
						"id": "etc-etc-jekyll-install-html",
						"title": "jekyll 설치(윈도 10) with base-theme",
						"categories": "",
						"url": " /etc/etc_jekyll_install.html",
						"content": "설치 전체과정 요약\n\n\n  Ruby 설치\n  ridk 설치\n  gem 업데이트\n  jekyll, Bundler 설치\n\n\nRuby 설치\n일반적으로 jekyll를 사용한다면 최신 버전을 사용하면 되겠지만 여기서는 base-theme를 기반으로 하기 때문에 호환에 잘되는 2.5를 설치합니다.\n\nRuby Installer 다운로드 경로\nhttps://rubyinstaller.org/downloads/\n\n위 사이트에서 rubyinstaller-devkit-2.5.8-2-x64 를 다운 받아 설치하면 됩니다.\n\nRuby 설치가 끝나면서 완료화면에 Run ‘ridk install’ to setup MSYS2 and development toolchain. 이라는 옵션이 나타납니다.\n반드시 선택하고 완료를 하시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\nridk 설치\n앞단계인 Ruby 설치 완료에서 ridk install을 선택했다면 ridk 설치 커맨드 창이 나타납니다.\n(혹시 선택하지 않았다면 커맨드 창을 열어서 ridk install 을 입력하면 됩니다)\n이때 설치 옵션을 선택할 수 있는데 1,2,3 을 선택하고 Enter 키를 입력하면 설치가 진행됩니다.\n\n\n  \n  \n    \n  \n\n\ngem 업데이트\n\ngem update\n\n\nJekyll, Bundler 설치\n\ngem install jekyll bundler\n\n\nbase-theme 설치\nbase-theme는 jekyll의 여러 테마 중에서 CloudCannon에서 제작한 테마입니다.\n\n\n  \n  \n    \n  \n\n\n다운로드 경로\nhttps://github.com/CloudCannon/base-jekyll-template\n\n위 다운로드 경로에서 소스를 직접 다운 받거나 GitHub Desktop을 이용해서 가져오면 됩니다.\n\n블로그 실행, 접속\n작업하면서 결과물을 확인할 때는 다음과 같은 명령어로 입력하고 브라우져에서 http://127.0.0.1:4000/ 로 접속하시면 되니다.\n\nbundle exec jekyll serve\n\n\n사이트 빌드\n작업이 끝난 결과물을 실제 서버나 gitHub에 업로드, 배포할 경우에는 다음 명령어로 빌드 한 후에 _site에 생성된 html 등을 사용하시면 됩니다.\n\nbundle exec jekyll build\n\n\n추가 패키지 설치\n혹시 블로그 실행, 접속에서 오류가 발생하면 나타나는 메시지를 보고 처리를 해주면 됩니다.\n혹시 필요한 gem이 설치되지 않았을 경우에는 다음과 같이 설치해주면 됩니다.\n\ngem install public_suffix -v 3.0.1\n\n\n기본 블로그 생성\n위에서 소개한 것처럼 테마를 사용하는 것이 아닌 기본 설정만의 블로그를 새로 만들려면 다음과 같이 입력하면 됩니다.\n\njekyll new PATH\n\n기본 블로그를 만들고 접속하면 다음과 같은 화면이 나타납니다."
					}
					
				
			
		
			
				
					,
					
					"etc-etc-mkdocs-install-html": {
						"id": "etc-etc-mkdocs-install-html",
						"title": "mkdocs 설치 (윈도 10)",
						"categories": "",
						"url": " /etc/etc_mkdocs_install.html",
						"content": "설치 전체과정 요약\n\n\n  \n    Python 다운로드\n  \n  \n    Python 설치\n\n    2-1. Add Python 3.9 to PATH 옵션 선택\n\n    2-2. Disable path length limit 선택\n  \n  \n    mkdocs 설치\n\n    3-1. pip install mkdocs-material\n\n    3-2. python.exe -m pip install –upgrade pip\n\n    3-3. pip install mkdocs-awesome-pages-plugin\n\n    3-4. mkdocs new {폴더명}\n\n    3-5. cd blog-mkdocs 이동 후 mkdocs serve\n  \n\n\nPython 다운로드\nmkdocs를 사용하려면 먼저 Python을 설치해야 합니다.\n\nhttps://www.python.org/downloads/\n\n2020-11-27일 현재 최신버전은 3.9.0입니다.\n\nPython 설치하기\n\nPATH 추가\nPython 설치 시작화면에 PATH에 python을 추가하는 옵션이 있습니다. \n“Add Python 3.9 to PATH” 옵션을 선택하고 설치를 시작하면 됩니다.\n\nPATH 문자 길이 제한 해제\n윈도에는 기본설정에 파일경로가 최대 260자로 제한되어 있는데, 이 제한을 풀것인지 확인하는 과정입니다.\n“Disable path length limit” 옵션이 나오는데, 특별한 문제가 없다면 해제하고 가면 됩니다.\n\nmkdocs 설치\nmkdocs 설치하는 방법이 여러가지 있지만 가장 많이 사용되는 테마인 material 테마를 적용한 상태로 설치합니다.\npip install mkdocs-material\n\n\npip 업그레이드\nmkdocs를 설치하고 나면 pip 업그레이드에 대한 안내가 나옵니다.\nWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the 'c:\\users\\{***}\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n\n안내에 나온대로 pip를 업그레이드 해줍니다.\npython.exe -m pip install --upgrade pip\n\n\nawesome-pages-plugin 설치\n문서 구조나 네비게이션을 좀 더 쉽게 표현하고 구성하게 해주는 플러그인입니다.\n기본적으로 설치해두는 것이 여러모로 편리합니다.\npip install mkdocs-awesome-pages-plugin\n\n\n블로그 문서 생성\n이제 기본으로 필요한 것들은 다 설치했으니 블로그를 만들어봅시다.\nmkdocs new {폴더명}\nmkdocs new blog-mkdocs\n\n\n블로그 실행\n이제 웹브라우져에서 블로그를 확인해봅시다.\n위에서 만들어진 폴더로 이동합니다.\ncd blog-mkdocs\nmkdocs serve\n\n\n그러면 http://127.0.0.1:8000 주소로 접속하면 기본 블로그를 확인해볼 수 있고 \nmkdocs serve 명령으로 문서 변경을 실시간으로 감지해서 문서를 수정하면 브라우져에 바로바로 반영됩니다.\n\n블로그 배포문서 생성\n이제 만들어진 블로그 문서를 github 등이나 기타 서버로 배포하려면 다음과 같은 명령어를 입력하면 됩니다.\nmkdocs build\n\n그러면 아까 만들어진 blog-mkdocs 폴더 밑에 site 라는 폴더가 생성되고 그곳에 필요한 html 문서들이 만들어집니다.\n\n설치과정 스크린샷 모음"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-pdf-merge-php-sample-html": {
						"id": "etc-etc-pdf-merge-php-sample-html",
						"title": "Pdf 문서 합치기 PHP로 구현하는 방법",
						"categories": "",
						"url": " /etc/etc_pdf_merge_php_sample.html",
						"content": "개요\n요즘은 회사 업무에서 파일을 전달할 때 PDF 문서를 활용하는 경우가 매우 많습니다. \n그런데 이때 보내야 하는 PDF 문서가 여러개 일 경우 받는 쪽에서 각각의 파일을 일일이 열어봐야 해서 불편한 경우가 있습니다.\n이럴때 여러 PDF 문서를 합쳐서 하나의 문서로 만들어 보내면 편리한 경우에 사용할 수 있는 PDF 문서 합치기 - merge 기능을 PHP로 구현하는 방법입니다.\n\n라이브러리 설치\nPDF 문서를 합쳐 주는 기능을 가진 라이브러리는 [ php pdf merger ]라고 검색해보면 여러가지 버전이 존재하는데 여기서는 Jurosh 라는 사람이 만든 것을 사용하겠습니다.\n우선 composer 를 이용해서 라이브러리를 설치합니다.\n\n~# composer require jurosh/pdf-merge\n\n\n기본 사용법\n아래 기본 사용법은 라이브러리 개발자가 GitHub에 올려둔 가이드에 있는 사용법입니다.\n&lt;?php\n\n  require 'vendor/autoload.php';\n\n  // and now we can use library\n  $pdf = new \\Jurosh\\PDFMerge\\PDFMerger;\n\n  // add as many pdfs as you want\n  $pdf-&gt;addPDF('path/to/source/file.pdf', 'all', 'vertical')\n    -&gt;addPDF('path/to/source/file1.pdf', 'all')\n    -&gt;addPDF('path/to/source/file2.pdf', 'all', 'horizontal');\n\n  // call merge, output format `file`\n  $pdf-&gt;merge('file', 'path/to/export/dir/file.pdf');\n?&gt;\n\n\n응용 사용법\n여기서는 파일 업로드 웹페이지를 통해 업로드 된 여러 파일들을 합쳐서 다운로드 받는 방식으로 구현해보겠습니다.\n\n&lt;? php\n\n  require 'vendor/autoload.php';\n  \n  $pdf = new \\Jurosh\\PDFMerge\\PDFMerger;\n\n\n  $source_file_array = Array();\n  $source_filename_array = Array();\n\n  $source_file_array = $_FILES[\"pdf_file\"];\n  $source_filename_array = $source_file_array[\"name\"];\n  $upload_filename_array = $source_file_array[\"tmp_name\"];\n\n  $cnt_file = count($source_filename_array);\n\n  for ($i = 0; $i &lt; $cnt_file; $i++)\n  {\n    $pdf-&gt;addPDF($upload_filename_array[$i], 'all', 'vertical');    \n  }\n\n  $output_filename = $source_filename_array[0];\n\n  $pdf-&gt;merge('download', $output_filename);\n?&gt;\n\n\n\n업로드 된 파일명 배열에 저장\n&lt;? php\n\n  $source_file_array = $_FILES[\"pdf_file\"];\n  $source_filename_array = $source_file_array[\"name\"];\n  $upload_filename_array = $source_file_array[\"tmp_name\"];\n?&gt;\n\n\n\n합칠 파일들 리스트에 추가\n업로드 된 개수 만큼 파일들을 리스트에 추가합니다.\n$pdf-&gt;addPDF의 파라미터에는 옵션으로 페이지와 문서방향이 들어갑니다.\n$pdf-&gt;addPDF(파일경로, 페이지, 문서방향);\n\n&lt;? php\n\n  $cnt_file = count($source_filename_array);\n  for ($i = 0; $i &lt; $cnt_file; $i++)\n  {\n    $pdf-&gt;addPDF($upload_filename_array[$i], 'all', 'vertical');    \n  }\n\n  /* 사용 예시\n  $pdf-&gt;addPDF($upload_filename_array[$i], 'all', 'vertical');\n  $pdf-&gt;addPDF($upload_filename_array[$i], '1,3,6', 'horizontal');\n  $pdf-&gt;addPDF($upload_filename_array[$i], '12-16', 'vertical');\n  */\n?&gt;\n\n\n\n파일 합치기\n합치기 옵션은 [download], [browser], [file], [string] 이렇게 4가지가 있습니다.\n보통 로컬PC로 다운로드 받을 때는 [download], 서버에 저장할 때는 [file]를 선택하면 됩니다.\n&lt;? php\n\n  $pdf-&gt;merge('download', $output_filename);\n  $pdf-&gt;merge('browser', $output_filename);\n  $pdf-&gt;merge('file', $output_filename);\n  $pdf-&gt;merge('string', $output_filename);\n?&gt;\n\n\n\n한글 깨짐 해결\n\nPDF 파일을 합치면 문서 내의 텍스트는 한글이나 기타 UTF-8 문자들이 문제없이 잘나타납니다.\n그런데 파일명은 UTF-8이 지원되지 않아 한글이 깨지는 현상이 나타납니다.\n\n이를 해결하기 위해서는 여기서 사용한 pdf merger 소스 파일을 수정해야 합니다.\n소스파일 위치는 ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php 입니다.\n\nPDFMerger.php 파일에서 파일 합치기 함수 merge를 찾습니다.\n&lt;? php\n\n  /* ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php */\n  \n  /*== 기존 ==*/ \n  public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf') {\n\n    /* ====*/\n    /* 중략 */\n    /* ====*/\n\n    if ($mode == 'S') {\n        return $fpdi-&gt;Output($outputpath, 'S');\n    } else {\n        if ($fpdi-&gt;Output($outputpath, $mode) == '') {\n      return true;\n        } else {\n      throw new Exception(\"Error outputting PDF to '$outputmode'.\");\n      return false;\n        }\n    }\n  }\n\n  /*== 수정 ==*/ \n  public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf') {\n\n    /* ====*/\n    /* 중략 */\n    /* ====*/\n\n    if ($mode == 'S') {\n        return $fpdi-&gt;Output($outputpath, 'S', true);\n    } else {\n        if ($fpdi-&gt;Output($outputpath, $mode, true) == '') {\n      return true;\n        } else {\n      throw new Exception(\"Error outputting PDF to '$outputmode'.\");\n      return false;\n        }\n    }\n  }\n?&gt;\n\n\n\n위에서 바뀐 부분은 Output 함수의 파라미터 하나입니다.\n&lt;? php\n  // 기존\n  $fpdi-&gt;Output($outputpath, 'S');\n  $fpdi-&gt;Output($outputpath, $mode);\n  \n  // 수정\n  $fpdi-&gt;Output($outputpath, 'S', true);\n  $fpdi-&gt;Output($outputpath, $mode, true);\n?&gt;\n\n\n\n왜 그런지 실제 Output 함수가 선언된 곳을 찾아가보겠습니다.\n파일 위치는 ./vendor/setasign/fpdf/fpdf.php 입니다.\n아래와 같이 Output 함수의 파라미터는 3개로 마지막이 UTF-8 여부를 설정하는 것이었습니다.\n그러므로 마지막 파라미터를 true 로 설정만 해도 한글, UTF-8 문제가 해결됩니다.\n\n&lt;? php\n\n  /* ./vendor/setasign/fpdf/fpdf.php */\n\n  function Output($dest='', $name='', $isUTF8=false)\n  {\n\t/* 중략 */\n  }\n?&gt;\n\n\n문서 속성 추가\n또 하나의 문제가 제목, 작성자, 주제 등의 문서 속성 정보가 추가되지 않는다는 점입니다.\n이 또한 파일 2개를 수정해야 합니다.\n\n문서 합치기 파일 (ex: pdf_merge.php)\n&lt;? php\n  // 문서 속성 정보를 추가합니다.\n  $author = \"써드아이시스템\";\n  $creator = \"써드아이시스템\";\n  $title = \"문서 제목\";\n  $subject = \"문서 주제\";\n  $keywords = \"키워드\";\n\n  // merge 함수에 문서 속성 옵션을 추가합니다.\n  $pdf-&gt;merge('download', $output_filename, $author, $creator, $title, $subject, $keywords);\n?&gt;\n\n\n\nmerge 함수 정의 파일 (PDFMerger.php)\n위치 : ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php\n\n&lt;? php\n\n  /* ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php */\n\n  // 파라미터 추가\n  public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf', $author = '3rdEYESYS', $creator = '3rdEYESYS', $title = 'title', $subject = 'subject', $keywords = 'keywords') {\n    \n    /* 중략 */\n\n    // 속성 항목 설정\n    $fpdi-&gt;SetAuthor($author, true);\n    $fpdi-&gt;setCreator($creator, true);\n    $fpdi-&gt;setTitle($title, true);\n    $fpdi-&gt;setSubject($subject, true);\n    $fpdi-&gt;setKeywords($keywords, true);\n  }\n?&gt;\n\n\n문서 속성을 저렇게 설정하면 되는 이유는 해당 함수가 정의된 곳을 찾아보면 알 수 있습니다.\n\n파일 위치는 ./vendor/setasign/fpdf/fpdf.php 입니다.\n\n&lt;? php\n\n  /* ./vendor/setasign/fpdf/fpdf.php */\n\n  function SetTitle($title, $isUTF8=false)\n  {\n    // Title of document\n    $this-&gt;metadata['Title'] = $isUTF8 ? $title : utf8_encode($title);\n  }\n\n  function SetAuthor($author, $isUTF8=false)\n  {\n    // Author of document\n    $this-&gt;metadata['Author'] = $isUTF8 ? $author : utf8_encode($author);\n  }\n\n  function SetSubject($subject, $isUTF8=false)\n  {\n    // Subject of document\n    $this-&gt;metadata['Subject'] = $isUTF8 ? $subject : utf8_encode($subject);\n  }\n\n  function SetKeywords($keywords, $isUTF8=false)\n  {\n    // Keywords of document\n    $this-&gt;metadata['Keywords'] = $isUTF8 ? $keywords : utf8_encode($keywords);\n  }\n\n  function SetCreator($creator, $isUTF8=false)\n  {\n    // Creator of document\n    $this-&gt;metadata['Creator'] = $isUTF8 ? $creator : utf8_encode($creator);\n  }\n?&gt;\n\n\n참고 URL\n\n  PDF Merge GitHub Source and Download\n    \n      https://github.com/jurosh/php-pdf-merge"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-php-to-telegram-message-send-html": {
						"id": "etc-etc-php-to-telegram-message-send-html",
						"title": "PHP로 텔레그램 비공개 채널에 메시지 전송하기",
						"categories": "",
						"url": " /etc/etc_php_to_telegram_message_send.html",
						"content": "개요\n업무를 진행하다보면 서버나 서비스에 장애가 발생했을 때 즉시 알림을 받거나 서버 상태 모니터링이나 매출 등의 서비스 이용 지표 등을 매일 자동으로 통보 받는 경우가 있습니다. \n예전에는 이메일이나 SMS 메시지로 받는 경우가 대부분이었는데, 요즘은 관련된 사람들이 함께 들어와 있는 메신저 채팅방으로 알림을 동시에 받는 경우도 많아지고 있습니다.\n그럴 때 사용하는 방법 중에서 여기서는 텔레그램(Telegram)의 대화방인 비공개 채널에 메시지를 전송하는 것을 PHP로 구현해보겠습니다.\n\n구현 순서\n\n  텔레그램 채팅 봇을 생성\n  텔레그램 채널을 비공개로 생성\n  비공개 채널에 위에서 생성한 채팅 봇을 관리자로 등록\n  PHP로 채팅 봇을 이용해 비공개 채널에 메시지를 전송\n\n\n채팅 봇 생성\n텔레그램(Telegram) 메신저에서 채팅 봇을 생성하고 관리해주는 봇인 [BotFather]를 검색합니다. \n여러 개의 봇들이 나타나는데 그 중에서 인증 마크가 붙어 있는 텔레그램 공식 봇을 선하고 채팅 방에  들어갑니다.\n\n\n  \n  \n    \n  \n\n\n[BotFather] 채팅 봇 방에 들어가면 채팅 봇에 대한 설명과 봇 API 매뉴얼 링크를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n이제 채팅 봇 생성을 위해 /start 명령을 입력하면 아래와 같이 채팅 봇 생성, 관리에 대한 명령어들을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 새로운 채팅 봇을 생성하는 명령어인 /newbot을 입력하면, 채팅 봇 이름과 채팅 봇 유저명을 입력하라는 안내가 나옵니다. \n차례대로 입력하면 되는데, 여기서 입력하는 이름을 텔레그램 내에서 고유한 값이므로 간단한 이름을 입력하면 중복된 이름이라 생성이 되지 않으니 자신만의 고유한 이름을 입력합니다.\n\n그리고 두번째로 입력하는 채팅 봇 유저명(username for your bot)은 반드시 마지막이 bot로 끝나야 합니다. \n두가지 모두 입력하고 나면 아래쪽에 채팅 봇과 연동하기 위한 API Token을 확인할 수 있는데, 이 Token을 PHP에서 사용하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n채팅 봇이 생성되었는지 텔레그램에서 검색해보면 아래와 같이 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n채널 생성\n채널을 생성하기 위해 텔레그램 왼쪽 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n메뉴 화면에서 [채널 만들기]를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n원하는 채널명을 입력하고, 만들기를 클릭하면, 공개-비공개를 선택할 수 있는데 여기서는 [비공개 채널]을 선택하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n저장하고 나면 다음으로 [참가자 추가] 화면이 나타나는데 위에서 생성했던 채팅 봇 이름을 입력해서 확인하고, 선택 후에 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n그러면 아래와 같이 [봇은 관리자로서만 추가될 수 있습니다]라는 메시지가 나타납니다. 바로 [관리자로 세우기] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n관리자의 권한은 여러가지가 있는데 원하는 권한을 부여하고 [저장] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n채팅 방 ID 확인\n메시지를 전송하기 위해서는 현재 생성된 비공개 채널의 chat_id를 확인해야 합니다.\n우선, 채널에서 아무 메시지나 입력합니다. (꼭 하셔야 합니다)\n\n\n  \n  \n    \n  \n\n\n다음으로 웹브라우저에서 다음 주소를 입력합니다.  주소에는 위에서 확인했던 API Token이 들어갑니다.\n\nhttps://api.telegram.org/bot[API Token]/getUpdates\n\n# 예시\nhttps://api.telegram.org/bot123456789:JFDS89FMJK8932-MKJE8FNBH3289I/getUpdates\n\n\n입력하면 나타나면 결과에서 “chat” : {“id” : -12586498, ….} 와 같은 형식의 id 값을 복사합니다. 이 값이 바로 비공개 채널의 chat_id 입니다.\n\n\n  \n  \n    \n  \n\n\n메시지 전송 코드 작성\n마지막으로 메시지를 전송하는 PHP 코드를 작성해보겠습니다.\n위에서 구했던 [API Token], [chat_id]를 아래 코드에 입력하고 실행하면 됩니다.\n&lt;?php\n\n  function php_to_telegram_msg_send($msg) \n  {\n    $api_token = \"API Token\";\n    $chat_id = \"채팅방 ID\";\n    $api_url = \"https://api.telegram.org/bot\".$api_token.\"/sendMessage\";\n\n    $post_vars = \"chat_id=\".$chat_id.\"&amp;text=\".urlencode($msg);\n    $content_type = \"Content-Type: application/x-www-form-urlencoded\";\n\n    $ch = curl_init();\n\n    curl_setopt($ch, CURLOPT_URL, $api_url);\n    curl_setopt($ch, CURLOPT_HEADER, false);\n    curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n    curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);\n    curl_setopt($ch, CURLOPT_POST, true);\n    curl_setopt($ch, CURLOPT_TIMEOUT, 5);\n    curl_setopt($ch, CURLOPT_HTTPHEADER, array($content_type));\n    curl_setopt($ch, CURLOPT_POSTFIELDS, $post_vars);\n\n    $return = curl_exec($ch);\n\n    curl_close($ch);\n\n    return $return;\n  }\n\n\n  $tgm_msg = \"\";\t\t\n  $tgm_msg = $tgm_msg.\"메시지 테스트\";\n\n  $output = php_to_telegram_msg_send($tgm_msg);\t\n?&gt;\n\n\n위 코드를 실행하면 아래와 같이 비공개 채널에 메시지가 도착한 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n메시지 스타일 적용\n텔레그램 채팅 봇 API는 메시지에 bold, underline 등의 몇가지 html 스타일을 지원합니다.\nhtml 스타일을 적용하기 위해서는 전송 파라미터에 parse_mode=html을 추가해야 합니다.\n그러면 위 전송 코드 중에서 변경해야 하는 코드만 정리해보겠습니다.\n\n&lt;?php\n\n  /* 전송 파라미터에 parse_mode=html을 추가합니다. */\n  $post_vars = \"chat_id=\".$chat_id.\"&amp;text=\".urlencode($msg).\"&amp;parse_mode=html\";\t\t\n\n  $tgm_msg = $tgm_msg.\"&lt;b&gt;bold&lt;/b&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;i&gt;italic&lt;/i&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;code&gt;\\$now_date = date('Y-m-d');&lt;/code&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;s&gt;strike&lt;/s&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;u&gt;underline&lt;/u&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;pre language='php'&gt;\\$now_date = date('Y-m-d');&lt;/pre&gt;\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"email@test.com\".\"\\r\\n\";\n  $tgm_msg = $tgm_msg.\"&lt;pre&gt;email@test.com&lt;/pre&gt;\".\"\\r\\n\";\n?&gt;\n\n\n위 코드처럼 스타일을 적용하고 실행하면 아래와 같이 표시됩니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  텔레그램 채팅 봇 안내\n    \n      https://core.telegram.org/bots/\n    \n  \n  텔레그램 채팅 봇 API 가이드\n    \n      https://core.telegram.org/bots/api/\n    \n  \n  텔레그램 채팅 봇 API 메시지 스타일 가이드\n    \n      https://core.telegram.org/api/entities/"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-phpspreadsheet-sample-code-html": {
						"id": "etc-etc-phpspreadsheet-sample-code-html",
						"title": "PhpSpreadsheet 설정 샘플 코드",
						"categories": "",
						"url": " /etc/etc_phpspreadsheet_sample_code.html",
						"content": "개요\nPHP에서 Excel 문서를 읽거나 Excel 형태로 문서를 저장해야 할 때 주로 PhpSpreadsheet를 사용하게 됩니다. \n이전에는 PHPExcel이라는 이름이었으나 현재는 해당 버전의 개발-유지보수가 중단되고 새로운 프로젝트로 PhpSpreasheet라는 이름으로 업그레이드 되었습니다.\n또한 PhpSpreadsheet는 Excel 뿐만 아니라 PDF 형식으로도 파일을 저장할 수 있어서 많이 사용되고 있습니다. \n이번에는 이 PhpSpreadsheet로 문서를 저장할 때 사용하는 주요 소스 코드의 샘플을 정리해보겠습니다.\n\n클래스 로드\n\n&lt;?php\n    require 'vendor/autoload.php';\n\n    use PhpOffice\\PhpSpreadsheet\\IOFactory;\n    use PhpOffice\\PhpSpreadsheet\\Spreadsheet;\n\n    $spreadsheet = new Spreadsheet();\n?&gt;\n\n\n기본 설정\n\n&lt;? php\n\n    // 문서 가로,세로 방향 설정\t\n    $spreadsheet-&gt;getActiveSheet()-&gt;getPageSetup()\n    -&gt;setOrientation(\\PhpOffice\\PhpSpreadsheet\\Worksheet\\PageSetup::ORIENTATION_PORTRAIT);\n\n    // 문서 사이즈 설정\n    $spreadsheet-&gt;getActiveSheet()-&gt;getPageSetup()\n    -&gt;setPaperSize(\\PhpOffice\\PhpSpreadsheet\\Worksheet\\PageSetup::PAPERSIZE_A4);\n\n    // 문서 정보 설정\n    $spreadsheet-&gt;getProperties()-&gt;setCreator(\"써드아이시스템\")\n    -&gt;setLastModifiedBy(\"써드아이시스템\")\n    -&gt;setTitle(\"문서 타이틀\")\n    -&gt;setSubject(\"문서 제목\")\n    -&gt;setDescription(\"문서 설명\")\n    -&gt;setKeywords(\"키워드\")\n    -&gt;setCategory(\"카테고리\");\n\n\n    // 문서 좌우 여백 설정\n    $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setTop(0.5);\t\n    $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setBottom(0.25);\n    $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setRight(0.75);\n    $spreadsheet-&gt;getActiveSheet()-&gt;getPageMargins()-&gt;setLeft(0.75);\n?&gt;\n\n\n셀 값 설정\n\n&lt;? php\t\n    $spreadsheet-&gt;setActiveSheetIndex(0)-&gt;setCellValue(\"C11\", $value);\n    $spreadsheet-&gt;setActiveSheetIndex(0)-&gt;setCellValue(\"B25\", \"셀 값 설정\\r\\n다음 줄\");\n?&gt;\n\n\n셀에 이미지 설정\n\n\n&lt;? php\n    $drawing_logo = new \\PhpOffice\\PhpSpreadsheet\\Worksheet\\Drawing();\t\n    $drawing_logo-&gt;setName('Logo');\n    $drawing_logo-&gt;setDescription('3rdEYESYS Logo');\n    $drawing_logo-&gt;setPath('/ncp/data/www/img/3rdeyesys_logo.png');\n    $drawing_logo-&gt;setCoordinates('A1');\n    $drawing_logo-&gt;setWidth(230);\n    $drawing_logo-&gt;getShadow()-&gt;setVisible(true);\n    $drawing_logo-&gt;setWorksheet($spreadsheet-&gt;getActiveSheet());\n?&gt;\n\n\n셀 병합\n\n&lt;? php\t\n    // 동일한 행에서 병합\n    $spreadsheet-&gt;getActiveSheet()-&gt;mergeCells(\"A1:D1\");\n\n    // 여러 행에서 병합\n    $spreadsheet-&gt;getActiveSheet()-&gt;mergeCells(\"G5:I7\");\n\n    // 변수 사용\n    for ($j = 52; $j &lt;= 57; $j++)\n    {\n      $spreadsheet-&gt;getActiveSheet()-&gt;mergeCells(\"B\".$j.\":C\".$j);\n    }\n?&gt;\n\n\n행 높이 설정\n&lt;?php\n\n    for ($j = 1; $j &lt;= 5; $j++)\n    {\n      $spreadsheet-&gt;getActiveSheet()-&gt;getRowDimension($j)-&gt;setRowHeight(12);\n    }\n\n    $spreadsheet-&gt;getActiveSheet()-&gt;getRowDimension(10)-&gt;setRowHeight(35);\n?&gt;\n\n\n열 너비 설정\n\n&lt;?php\n\n    // 특정 열 너비 설정\n    $spreadsheet-&gt;getActiveSheet()-&gt;getColumnDimension(\"A\")-&gt;setWidth(3);\n\n    // 범위 내 여러 열 너비 설정\n    foreach(range(\"B\",\"J\") as $columnID) \n    {\n      $spreadsheet-&gt;getActiveSheet()-&gt;getColumnDimension($columnID)-&gt;setWidth(15);\n    }\n?&gt;\n\n\n셀 스타일 지정\n\n&lt;?php\n\n    // 셀 스타일을 배열 형식으로 저장\n    // 순서대로 border, font, 배경색 지정하는 스타일\n    $styleArray_Cell = [\n      'borders' =&gt; [\n        'allBorders' =&gt; [\n          'borderStyle' =&gt; \\PhpOffice\\PhpSpreadsheet\\Style\\Border::BORDER_THIN,\n          'color' =&gt; ['argb' =&gt; 'FF20AFA5']\n        ]\n      ],\n      'font' =&gt; [\n        'bold' =&gt; true,\n        'size' =&gt; 9,\n        'color'    =&gt; ['argb' =&gt; 'FFFFFFFF'],\n      ],\n      'fill' =&gt;[\n        'fillType' =&gt; \\PhpOffice\\PhpSpreadsheet\\Style\\Fill::FILL_SOLID,\n        'color' =&gt; ['argb' =&gt; 'FF20AFA5']\n      ]\n    ];\n\n    // 특정 셀에 스타일 적용\n    $spreadsheet-&gt;getActiveSheet()\n    -&gt;getStyle(\"B40\")-&gt;applyFromArray($styleArray_Cell);\n  \n    // 특정 범위의 여러 셀에 스타일 동시 적용\n    $spreadsheet-&gt;getActiveSheet()\n    -&gt;getStyle(\"G45:G46\")-&gt;applyFromArray($styleArray_Cell);\n\n    // 특정 셀에 폰트 스타일 직접 적용\n    $spreadsheet-&gt;getActiveSheet()\n    -&gt;getStyle(\"B80\")-&gt;getFont()-&gt;setSize(13)-&gt;setBold(true);\n\t\n?&gt;\n\n\nPDF 로 저장\n\n&lt;?php\n    $spreadsheet-&gt;setActiveSheetIndex(0);\n\n    // Mpdf 클래스 별로 설치해야 함\n    IOFactory::registerWriter('Pdf', \\PhpOffice\\PhpSpreadsheet\\Writer\\Pdf\\Mpdf::class);\n\n    $out_put_file_full_name = \"sample.pdf\";\n\n    // Redirect output to a client’s web browser (PDF)\n    header('Content-Type: application/pdf; charset=utf-8' );\n    header('Content-Disposition: attachment;filename=\"'.$out_put_file_full_name.'\"');\n    header('Cache-Control: max-age=0');\n\n    $writer = IOFactory::createWriter($spreadsheet, 'Pdf');\n    $writer-&gt;save('php://output');\n    exit;\n?&gt;\n\nPhpSpreadsheet를 사용해서 pdf 파일을 저장하려면 Mpdf 를 추가로 설치해야 합니다. \n이와 관련된 내용은 다음 문서에서 다시 정리하겠습니다.\n\nExcel로 저장\n\n&lt;?php\n    $spreadsheet-&gt;setActiveSheetIndex(0);\n\n    // Redirect output to a client’s web browser (Excel2007)\n    $out_put_file_full_name = \"sample.xlsx\";\n\n    header('Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet');\n    header('Content-Disposition: attachment;filename=\"'.$out_put_file_full_name.'\"');\n    header('Cache-Control: max-age=0');\n\n    // If you're serving to IE over SSL, then the following may be needed\n    header ('Expires: Mon, 26 Jul 2022 05:00:00 GMT'); // Date in the past\n    header ('Last-Modified: '.gmdate('D, d M Y H:i:s').' GMT'); // always modified\n    header ('Cache-Control: cache, must-revalidate'); // HTTP/1.1\n    header ('Pragma: public'); // HTTP/1.0\n\n    $writer = IOFactory::createWriter($spreadsheet, 'Xlsx');\t\n    $writer-&gt;save('php://output');\n    exit;\n?&gt;\n\n\n참고 URL\n\n  PhpSpreadsheet Documentation\n    \n      https://phpspreadsheet.readthedocs.io/\n    \n  \n  PhpSpreadsheet GitHub Source and Download\n    \n      https://github.com/PHPOffice/PhpSpreadsheet"
					}
					
				
			
		
			
				
					,
					
					"etc-etc-smtp-auth-to-google-gmail-account-html": {
						"id": "etc-etc-smtp-auth-to-google-gmail-account-html",
						"title": "Gmail을 이용해 smtp 메일 발송할 때 인증오류 해결 방법",
						"categories": "",
						"url": " /etc/etc_smtp_auth_to_google_gmail_account.html",
						"content": "개요\n웹서버나 애플리케이션 등에서 gmail 계정을 이용해서 smtp로 메일을 발송하는 경우가 있습니다.\n관리자의 안내 메일이나 소수회원을 위한 다량메일 발송등을 하는 것이 그런 경우인데\n예전에는 보안 수준이 낮은 앱의 액세스 허용 옵션으로 가능했었지만, 최근에는 이 설정으로도 해결되지 않는 경우가 많습니다.\n\n이럴 때 확실하게 인증할 수 있는 방법이 구글계정 2단계 인증 사용과 앱 비밀번호 설정입니다.\n\n인증 오류 메시지\n위에서 이야기한 2단계 인증과 앱 비밀번호를 사용하지 않고 smtp로 구글계정에 로그인 하려고 하면 다음과 같은 오류 메시지가 나타나는 경우가 있습니다.\n\n 인증 오류 메시지: The SMTP server requires a secure connection or the client was not authenticated.\nThe server response was: 5.7.0 Authentication Required.\n\n이 문제, 인증 오류 메시지를 해결하려면 아래 내용대로 설정을 하시면 해결됩니다.\n\n2단계 인증\n2단계 인증이란 구글계정에 로그인 할 때 아이디와 비밀번호 외에 추가로 인증 절차를 거쳐 로그인을 인증하는 것을 말합니다.\n2단계 인증 방법에는 다음과 같은 종류가 있습니다.\n\n\n  Google 메시지\n  앱 비밀번호\n  백업 코드\n  백업 전화\n  휴대전화 내장 보안 키\n\n\n인증 설정하기\n우선 구글계정으로 로그인해서 계정-보안 메뉴로 이동합니다.\n보안 메뉴에서 [Google에 로그인]이라는 곳에 보면 [2단계 인증] 메뉴가 있습니다. \n현재는 사용 안함으로 설정되어 있는데 클릭해서 설정을 시작합니다.\n\nhttps://myaccount.google.com/security\n\n\n  \n  \n    \n  \n\n\n2단계 인증에 대한 기본적인 안내와 함께 설정이 시작됩니다.\n\n\n  \n  \n    \n  \n\n\n2단계 로그인할 때 메시지를 받을 기기가 나타납니다. 또는 보안 키 장치나 다른 방법을 옵션으로 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n로그인을 하고 나면 관련 메시지가 앞 단계에서 선택한 장치에 도착합니다. 저는 휴대폰을 선택했기에 Gmail 앱을 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n이렇게 휴대폰의 Gmail 앱을 열면 안내 메시지가 도착해있고, [예] 버튼을 선택하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n휴대폰에서 [예]를 선택하면 설정화면이 자동으로 다음으로 넘어와 있습니다.\n여기서는 백업 옵션에 대한 방법을 선택합니다. 저는 문자 메시지를 선택했습니다.\n\n\n  \n  \n    \n  \n\n\n잠시 후에 휴대폰 문자메시지로 [국외발신] G-254796(이)가 Google 인증코드입니다. 라는 메시지가 도착합니다.\n이 중에서 뒤에 있는 6자리 숫자 코드를 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n이제 마지막으로 2단계 인증을 사용할 것인지 최종 확인을 합니다. [사용 설정] 버튼을 클릭하시면 2단계 인증이 적용됩니다.\n\n\n  \n  \n    \n  \n\n\n적용된 2단계 인증에 대한 안내화면입니다. Google 메시지가 2단계 인증 기본값으로 설정되어 있고, 그 외에 음성 또는 문자 메시지도 이용 가능하다는 내용입니다.\n이제 위쪽에 있는 뒤로 돌아가기 버튼을 클릭해서 메인화면으로 돌아갑니다.\n\n\n  \n  \n    \n  \n\n\n메인화면으로 돌아가면 2단계 인증이 사용으로 설정된 것을 확인할 수 있고, 그 아래에 앱 비밀번호 항목이 새로 생긴 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n앱 비밀번호 설정\n앱 비밀번호 설정을 시작하면 어떤 앱에서 사용할 것인지, 기기는 어떤 것인지 선택하는 화면이 나옵니다.\n메일, 캘린더, 연락처, Youtube 등이 있는데 저희는 Smtp를 할 것이기 때문에 기타(맞춤 이름)을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n기타를 선택하면 기기선택은 필요없기 때문에 앱 이름만 원하는대로 입력합니다. 여기서는 Smtp Client라고 입력하고 생성 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n드디어 16자리 앱 비밀번호가 생성되었습니다.  이 번호를 반드시 복사해서 따로 저장을 하고 확인 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n앱 비밀번호 화면에서는 현재 생성된 비밀번호를 삭제하거나 추가 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다시 계정 보안 메인 화면으로 돌아오면 앱 비밀번호 1개가 설정되었다는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n앱 비밀번호 적용\n그러면 smtp 소스코드에서 어떻게 앱 비밀번호를 적용하는지 확인해보겠습니다.\n\nPHP\n$mail = new PHPMailer();\n$mail-&gt;IsSMTP();\n$mail-&gt;SMTPAuth = true;\n$mail-&gt;SMTPSecure = \"tls\";\n$mail-&gt;Host = \"smtp.gmail.com\";\n$mail-&gt;Port = 587;\n$mail-&gt;Username = \"Gmail 계정\";\n$mail-&gt;Password = \"앱 비밀번호\";\n\n\n.Net C#\nSmtpClient client = new SmtpClient(\"smtp.gmail.com\", 587);\nclient.UseDefaultCredentials = false;\nclient.EnableSsl = true;\nclient.DeliveryMethod = SmtpDeliveryMethod.Network;\nclient.Credentials = new System.Net.NetworkCredential(\"Gmail 계정\", \"앱 비밀번호\");\n\n\n이렇게 기존에 gmail 계정 비밀번호를 입력하던 곳에 앱 비밀번호를 입력하면 문제없이 잘 접속됩니다.\n\n기타 사항\n앱 비밀번호는 PC에서 Outlook으로 gmail을 연동할 때 등 여러 경우에 아래와 같이 설정해서 사용할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n그리고 2단계 인증을 사용하게 되면 기존의 보안 수준이 낮은 앱의 액세스 설정을 사용할 수 없습니다."
					}
					
				
			
		
			
				
					,
					
					"faq-faq-html": {
						"id": "faq-faq-html",
						"title": "FAQ",
						"categories": "",
						"url": " /faq/faq.html",
						"content": "Cloud Log Analytics에서 로그 수집 설정을 하려고 할 때 Rocky Linux 서버를 선택할 수 없습니다\n            \n        \n        \n            \n                Ncloud(네이버 클라우드) Cloud Log Analytics는 아직까지 Rocky Linux 서버를 지원하지 않습니다. 차후에 업데이트 될 예정입니다.\n                \n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                Cloud Outbound Mailer의 Template에 등록한 이미지가 보이지 않습니다\n            \n        \n        \n            \n                Ncloud(네이버 클라우드) Cloud Outbound Mailer Template에 등록한 이미지의 유효기간은 3개월이며, 해당 이미지를 사용하여 메일을 발송한 기록이 없는 경우에는 3개월 이전에 삭제될 수도 있습니다. 해당 이미지를 재사용해야 한다면 다시 등록하고 사용하시면 됩니다.\n                \n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                Oracle DB를 사용할 수 있나요?\n            \n        \n        \n            \n                Oracle DB를 사용하려면 네이버 클라우드 플랫폼 서비스 중 [Bare Metal Server]를 구매하셔야 합니다.  더불어, Oracle DB는 Oracle 사의 클라우드 라이선스 정책으로 인하여 네이버 클라우드 플랫폼의 서버 및 서비스로 제공할 수 없기 때문에 고객님께서 직접 라이선스를 구매하셔서 사용하는 BYOL(Bring Your Own Licence)로 이용하셔야 합니다.\n                - 참고문서: https://www.ncloud.com/support/faq/all/787\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                Network Load Balancer는 멀티존 설정을 할 수 없는건가요?\n            \n        \n        \n            \n                현재 Network Load Balancer는 멀티존을 지원하지 않습니다. KR-1, KR-2 두개의 Zone 중에서 한 곳을 선택해서 생성하시기 바랍니다. 하지만, Network Proxy Load Balancer, Application Load Balancer는 멀티존을 지원합니다.\n                - 참고문서: /database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-lb.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                CDN+와 GCDN을 이용 중인데 대용량 파일이 다운로드되지 않습니다.\n            \n        \n        \n            \n                CDN+와 GCDN에서 [설정 변경 &gt; 캐싱 설정 &gt; Large File Optimization 사용]을 체크하신 후에 다운로드 해보시기 바랍니다. 해당 옵션을 체크 하지 않았을 경우 2G이상의 대용량 파일이 다운로드 되지 않는 경우가 있으니 꼭 체크하시고 테스트 해보시길 권장합니다.\n                - 참고문서: https://guide.ncloud-docs.com/docs/networking-networking-8-1#%EC%BA%90%EC%8B%B1-%EC%84%A4%EC%A0%95\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                AWS S3 데이터를 네이버 클라우드 Object Storage로 이전할 수 있는 방법은 없나요?\n            \n        \n        \n            \n                이전 가능합니다. 네이버 클라우드에 있는 Object Migration 서비스를 이용하면 AWS S3에 있는 데이터를 그대로 이전할 수 있습니다. 현재는 AWS S3만 지원하지만, 향후에는 Microsoft Azure, Google Cloud Platform 등 다양한 클라우드를 지원할 예정입니다.\n                - 참고문서: https://www.ncloud.com/product/migration/objectMigration\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 VPC환경에서 Application Load Balancer를 만들었는데 왜 접속이 되지 않는가요?\n            \n        \n        \n            \n                네이버 클라우드 VPC 환경에서 Load Balancer가 정상 작동하기 위해서는 Network ACL과 Server ACG 설정에서 Load Balancer가 속한 Subnet 대역과 접속포트를 허용해 주어야 합니다. 자세한 내용은 아래 링크 문서를 참고하시기 바랍니다.\n                - 참고문서: /networking/ncloud_networking_load_balancer_application_lb.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 Archive Storage 이용해지는 어떻게 하나요?\n            \n        \n        \n            \n                네이버 클라우드 Archive Storage는 현재 이용해지 기능이 존재하지 않습니다. 다만, 생성된 버킷과 저장된 파일을 모두 삭제하면 더 이상 과금되지 않으니 걱정하지 않으셔도 됩니다.\n                \n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드에서 디스크를 추가할 수 없는 서버도 있나요?\n            \n        \n        \n            \n                네이버 클라우드에서 서버에 직접 추가되는 디스크는 Block Storage로 Micro 타입의 서버, Bare Metal 서버, Application Server Launcher는 Block Storage를 추가할 수 없습니다.\n                - 참고문서: /storage/ncloud_storage_compare.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드에서 서버당 디스크는 최대 얼마까지 추가할 수 있나요?\n            \n        \n        \n            \n                네이버 클라우드에서 서버에 직접 추가되는 디스크는 Block Storage로 최대 2,000GB를 지원하며, 서버 1대당 최대 16개의 스토리지를 추가할 수 있습니다.\n                - 참고문서: /storage/ncloud_storage_compare.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 Classic 환경에서 사용하던  Block Storage, NAS, Object Storage, Archive Storage 를 VPC 환경에서 사용할 수 있나요?\n            \n        \n        \n            \n                Block Storage, NAS는 환경에 종속적이라 사용할 수 없지만, Object Storage와 Archive Storage는 환경에 독립적인 스토리지이기 때문에 Classic, VPC 어느 쪽에서 만들더라도 양쪽 모두에서 공용으로 사용할 수 있습니다.\n                \n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 Object Storage에 업로드 할 수 있는 파일의 최대 사이즈는 얼마인가요?\n            \n        \n        \n            \n                네이버 클라우드 Object Storage는 콘솔에서 업로드시 파일당 최대 2GB, API 사용시 파일당 최대 10TB까지 업로드 가능합니다. (전체 저장용량에는 제한이 없습니다)\n                \n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 Load Balancer에서 지원하는 서버 부하 방식은 어떤 것이 있나요?\n            \n        \n        \n            \n                네이버 클라우드 Load Balancer에서 지원하는 서버 부하 분산 방식에는 Round Robin, Least Connection, Source IP Hash 가 있습니다.\n                \n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 Object Storage에서 지정된 수명주기의 모든 파일과 폴더를 이동하려면 Object 이름 규칙을 어떻게 설정해야 하나요?\n            \n        \n        \n            \n                네이버 클라우드 Object Storage에서 Lifecycle Management 관리대상을 설정할 때 수명주기에 해당하는 모든 파일과 폴더를 일괄 이동하려면 Object 이름 규칙에 아무것도 입력하지 말고, 빈 공백으로 두시면 됩니다.\n                - 참고문서: /storage/ncloud_storage_object_storage_lifecycle_management.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 AutoScaling 그룹 이벤트는 어디에서 설정하나요?\n            \n        \n        \n            \n                네이버 클라우드 AutoScaling 그룹 이벤트는 Console - Monitoring - Group Event Setting 메뉴에서 설정할 수 있습니다. 그리고 사전에 AutoScaling Group을 설정하셔야 합니다.\n                - 참고문서: /compute/ncloud_compute_server_autoscaling_event_setting.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                AWS의 EBS와 비슷한 네이버 클라우드의 스토리지는 어떤 것인가요?\n            \n        \n        \n            \n                네이버 클라우드에서 하드 디스크를 추가 하듯이 서버에 할당하여 사용하는 스토리지는 Block Storage입니다. Console화면에서는 별도의 메뉴가 없고, 해당 서버의 관리 메뉴에서 스토리지 생성 기능을 이용하시면 됩니다.\n                - 참고문서: /storage/ncloud_storage_compare.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                AWS의 S3와 비슷한 네이버 클라우드의 서비스는 어떤 것인가요?\n            \n        \n        \n            \n                네이버 클라우드에서 어떤 종류의 데이터든지 언제 어디서나 데이터를 저장하고 확인할 수 있는 객체 스토리지 서비스는 Object Storage입니다.\n                - 참고문서: /storage/ncloud_storage_compare.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 Application Server는 상세 모니터링을 어떻게 하면 확인할 수 있나요?\n            \n        \n        \n            \n                네이버 클라우드 Application Server Launcher 서비스에서 실행한 Application Server는 개발이나 테스트 용도의 최소 스펙과 최소 기능으로 제공되는 서버로, 기본 모니터링 외에 상세 모니터링은 제공되지 않습니다. 그 외에도 스토리지 추가, 스펙 변경 등도 제공되지 않습니다.\n                \n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드에서 VPC는 최대 몇개까지 생성할 수 있나요?\n            \n        \n        \n            \n                네이버 클라우드에서 VPC는 고객의 계정마다 최대 3개를 생성할 수 있으며, 각 VPC는 최대 넷마스크 0.0.255.255/16 (IP 65,536개) 크기의 네트워크 주소 공간을 제공합니다\n                - 참고문서: /compute/ncloud_compute_server_vpc_create.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 VPC 환경에서 ACG는 몇개까지 생성할 수 있나요?\n            \n        \n        \n            \n                네이버 클라우드는 VPC 당 최대 500개까지 ACG를 생성할 수 있습니다.\n                - 참고문서: /security/ncloud_security_acg_guide.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드 Classic 환경에서 ACG는 몇개까지 생성할 수 있나요?\n            \n        \n        \n            \n                네이버 클라우드는 Classic 환경에서 계정당 최대 100개까지 ACG를 생성할 수 있습니다.\n                - 참고문서: /security/ncloud_security_acg_guide.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                AWS의 Security Group과 비슷한 네이버 클라우드의 서비스는 어떤 것인가요?\n            \n        \n        \n            \n                네이버 클라우드에서 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스는 ACG(Access Control Group)입니다.\n                - 참고문서: /security/ncloud_security_acg_guide.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드에서 추가 가능한 스토리지의 최대 사이즈와 개수는 얼마인가요?\n            \n        \n        \n            \n                네이버 클라우드에서 스토리지는 최대 2,000GB를 지원하며, 서버 1대당 최대 16개의 스토리지를 이용할 수 있습니다.\n                - 참고문서: /storage/ncloud_server_storage_add_guide.html\n            \n        \n                        \n    \n    \n        \n    \n    \n        \n            \n                네이버 클라우드에서 서버를 계정당 최대 몇 대까지 생성할 수 있나요?\n            \n        \n        \n            \n                네이버 클라우드에서 한 계정당 생성할 수 있는 최대 서버 수는 리전별로 기본 50대입니다. 서버 수 한도를 조정하려면 고객지원으로 문의해야 합니다.\n                - 참고문서: /compute/ncloud_compute_server_autoscaling_limit.html"
					}
					
				
			
		
			
		
			
				
					,
					
					"ai-services-ncloud-ai-services-clova-ocr-template-ocr-api-guide-html": {
						"id": "ai-services-ncloud-ai-services-clova-ocr-template-ocr-api-guide-html",
						"title": "Ncloud Clova OCR - Template OCR API 연동 PHP 샘플 예제",
						"categories": "",
						"url": " /ai-services/ncloud-ai-services-clova-ocr-template-ocr-api-guide.html",
						"content": "개요\nNcloud (네이버 클라우드) [Clova OCR]은 전송한 문서나 이미지를 인식하여 사용자가 지정한 영역의 텍스트와 데이터를 정확하게 추출하는 서비스입니다. 여기서는 API를 이용해서 \nTemplate OCR로 [사업자등록증]을 인식하는 예제를 PHP 코드로 정리해보겠습니다.\n\n서비스 배포\n테스트는 Template을 미리 생성한 상태에서 진행해보겠습니다. Template 생성 방법은 아래 링크의 문서에서 확인하시면 됩니다.\n\n\nNcloud Clova OCR 서비스 중에서 Template OCR 사용 방법\n\n\n\n  [배포 관리]에서 [서비스 배포] 버튼을 클릭해서 해당 템플릿을 서비스 배포합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  서비스 배포 확인 팝업창에서 [확인] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [서비스 배포]가 완료되면 아래와 같이 배포 상태와 배포 종료 시간을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nAPI Gateway 연동\n[설정] - [API Gateway 연동] 탭에서 [연동] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [API Gateway 연동]은 기본이 자동 연동입니다. API 연동에 필요한 [Secret Key]를 만들기 위해서 [생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  생성된 [Secret key]와 [API Gateway Invoke URL]을 복사해서 API 연동 코드에 사용합니다.\n\n\n\n  \n  \n    \n  \n\n\n인식 필드\nAPI 연동 코드를 작성하기 전에 이전에 생성했던 템플릿에서 인식 필드를 다시 한번 확인했보겠습니다.\n\n\n  필드 01: 등록번호\n  필드 02: 법인명\n  필드 03: 대표자\n  필드 04: 사업장 소재지\n  필드 05: 업태\n  필드 06: 종목\n\n\n\n  \n  \n    \n  \n\n\nPHP 샘플 코드\nClova OCR API는 크게 2가지 방법으로 나눌 수 있습니다.\n\n\n  파일 URL을 전달하는 방법\n  파일을 업로드하는 방법\n\n\n아래 PHP 코드는 2가지 방법으로 각각 구현되어 있습니다. 그리고 각 코드의 상세 설명은 아래쪽에서 정리해보겠습니다.\n\n\n  \n      \n          파일 URL \n      \n  \n      \n          파일 업로드 \n      \n  \n\n\n  \n      \n&lt;?php  \n\n  // Secret Key\n  $ncloud_clova_ocr_secretkey = \"Ijkouhuh89bj89yBHt86ghvhj&amp;T*^VHJ&amp;T*R^FVHJHJ\";  \n\n  // API Gateway Invoke URL\n  $api_url = \"https://***.apigw.ntruss.com/custom/v1/28410/****중간 생략****/infer\";\n\n  // Template ID\n  $ncloud_clova_ocr_template_ids = [28222];\n    \n  $unixtimestamp =  round(microtime(true) * 1000);\n\n  // http 호출 헤더값 설정\n  $http_header = array();        \n  $http_header[0] = \"X-OCR-SECRET: \".$ncloud_clova_ocr_secretkey.\"\";\n  $http_header[1] = \"Content-Type:application/json; charset=utf-8\";\n\n  $ocr_request_id = \"ocr-test\".$unixtimestamp;\n\n  // 전송할 값들을 배열 형태로 저장\n  $postvars = [\n    \"version\"=&gt; \"V2\",\n    \"requestId\"=&gt; $ocr_request_id,\n    \"timestamp\"=&gt; $unixtimestamp,\n    \"lang\"=&gt; \"ko\",\n    \"images\"=&gt; [\n      [\n        \"format\"=&gt; \"jpg\",\n        \"name\"=&gt; \"ocr-test\",\n        \"data\"=&gt; null,\n        \"url\"=&gt; \"https://kr.object.ncloudstorage.com/(버킷 이름)/ocr-test.jpg\",\n        \"templateIds\"=&gt; $ncloud_clova_ocr_template_ids\n      ]\n    ]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환\n  $json_portvars = json_encode($postvars);\n\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);  \n  curl_setopt($ch, CURLOPT_POST, TRUE);\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\n\n  $json_response = curl_exec($ch);\n  $err = curl_error($ch);\n  $status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n\n  curl_close($ch);\n\n  \n  if ($json_response &amp;&amp; $status_code == \"200\")\n  {\n    $obj_response_array = json_decode($json_response, true);\n\n    $obj_clova_ocr_data = $obj_response_array[\"images\"][0];\n\n    // 사업자 등록번호\n    $business_number = $obj_clova_ocr_data[\"fields\"][0];\n    $business_number= $business_number[\"inferText\"];\n\n    //=============== 중간 생략 ================= //\n\n    // 종목\n    $business_item = $obj_clova_ocr_data[\"fields\"][5];\n    $business_item= $business_item[\"inferText\"];\n\n    echo(\"사업자 등록번호:\".$business_number.\"&lt;br /&gt;\");\n    echo(\"종목:\".$business_item.\"&lt;br /&gt;\");\n  } \n  else \n  {\n    $obj_error_response_array = json_decode($json_response, true);\n  }\n\n  \n?&gt;\n\n\n\n  \n      \n&lt;?php  \n\n  // 업로드한 파일을 바이너리로 읽어서 BASE64로 인코딩\n  $ocr_upload_file = $_FILES[\"clova_ocr_upload_file\"];\n  $ocr_upload_file_tmp_name = $ocr_upload_file[\"tmp_name\"];\n\n  $ocr_upload_file_binary = fread(fopen($ocr_upload_file_tmp_name, \"r\"), filesize($ocr_upload_file_tmp_name));\n  $ocr_upload_file_string = base64_encode($ocr_upload_file_binary);\n\n  // Secret Key\n  $ncloud_clova_ocr_secretkey = \"Ijkouhuh89bj89yBHt86ghvhj&amp;T*^VHJ&amp;T*R^FVHJHJ\";  \n\n  // API Gateway Invoke URL\n  $api_url = \"https://***.apigw.ntruss.com/custom/v1/28410/****중간 생략****/infer\";\n\n  // Template ID\n  $ncloud_clova_ocr_template_ids = [28222];\n    \n  $unixtimestamp =  round(microtime(true) * 1000);\n\n  // http 호출 헤더값 설정\n  $http_header = array();        \n  $http_header[0] = \"X-OCR-SECRET: \".$ncloud_clova_ocr_secretkey.\"\";\n  $http_header[1] = \"Content-Type:application/json; charset=utf-8\";\n\n  $ocr_request_id = \"ocr-test\".$unixtimestamp;\n\n  // 전송할 값들을 배열 형태로 저장\n  $postvars = [\n    \"version\"=&gt; \"V2\",\n    \"requestId\"=&gt; $ocr_request_id,\n    \"timestamp\"=&gt; $unixtimestamp,\n    \"lang\"=&gt; \"ko\",\n    \"images\"=&gt; [\n      [\n        \"format\"=&gt; \"jpg\",\n        \"name\"=&gt; \"ocr-test\",\n        \"data\"=&gt; $clova_ocr_upload_file_string,\n        \"url\"=&gt; null,\n        \"templateIds\"=&gt; $ncloud_clova_ocr_template_ids\n      ]\n    ]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환\n  $json_portvars = json_encode($postvars);\n\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);  \n  curl_setopt($ch, CURLOPT_POST, TRUE);\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\n\n  $json_response = curl_exec($ch);\n  $err = curl_error($ch);\n  $status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n\n  curl_close($ch);\n\n  \n  if ($json_response &amp;&amp; $status_code == \"200\")\n  {\n    $obj_response_array = json_decode($json_response, true);\n\n    $obj_clova_ocr_data = $obj_response_array[\"images\"][0];\n\n    // 사업자 등록번호\n    $business_number = $obj_clova_ocr_data[\"fields\"][0];\n    $business_number= $business_number[\"inferText\"];\n\n    //=============== 중간 생략 ================= //\n\n    // 종목\n    $business_item = $obj_clova_ocr_data[\"fields\"][5];\n    $business_item= $business_item[\"inferText\"];\n\n    echo(\"사업자 등록번호:\".$business_number.\"&lt;br /&gt;\");\n    echo(\"종목:\".$business_item.\"&lt;br /&gt;\");\n  } \n  else \n  {\n    $obj_error_response_array = json_decode($json_response, true);\n  }\n\n  \n?&gt;\n\n\n\n  \n\n\n코드 상세 설명\n\n\n  우선, 도메인에서 API Gateway 연동 후에 생성된 Secret Key와 Invoke URL을 복사해서 입력하고, Template ID도 설정합니다.\n\n\n&lt;?php  \n  // Secret Key\n  $ncloud_clova_ocr_secretkey = \"Ijkouhuh89bj89y****중간 생략****j&amp;T*^VHJ&amp;T*R^FVHJHJ\";  \n\n  // API Gateway Invoke URL\n  $api_url = \"https://***.apigw.ntruss.com/custom/v1/*****/****중간 생략****/infer\";\n\n  // Template ID\n  $ncloud_clova_ocr_template_ids = [28222];\n?&gt;\n\n\n\n  다음으로 http 호출 헤더값으로, 위에서 변수에 저장했던 Secret Key와 Content-Type을 설정합니다.\n\n\n&lt;?php\n  // http 호출 헤더값 설정\n  $http_header = array();        \n  $http_header[0] = \"X-OCR-SECRET: \".$ncloud_clova_ocr_secretkey.\"\";\n  $http_header[1] = \"Content-Type:application/json; charset=utf-8\";\n?&gt;\n\n\n\n  다음으로 POST로 전송할 값들을 json 형태로 저장합니다.\n\n\n\n  \n      \n          파일 URL \n      \n  \n      \n          파일 업로드 \n      \n  \n\n\n  \n      \n&lt;?php\n  // 전송할 값들을 배열 형태로 저장\n  $postvars = [\n    \"version\"=&gt; \"V2\",\n    \"requestId\"=&gt; $ocr_request_id,\n    \"timestamp\"=&gt; $unixtimestamp,\n    \"lang\"=&gt; \"ko\",\n    \"images\"=&gt; [\n      [\n        \"format\"=&gt; \"jpg\",\n        \"name\"=&gt; \"ocr-test\",\n        \"data\"=&gt; null,\n        \"url\"=&gt; \"https://kr.object.ncloudstorage.com/(버킷 이름)/ocr-test.jpg\",\n        \"templateIds\"=&gt; $ncloud_clova_ocr_template_ids\n      ]\n    ]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환\n  $json_portvars = json_encode($postvars);\n?&gt;\n\n\n  \n      \n&lt;?php\n  // 업로드한 파일을 바이너리로 읽어서 BASE64로 인코딩\n  $ocr_upload_file = $_FILES[\"clova_ocr_upload_file\"];\n  $ocr_upload_file_tmp_name = $ocr_upload_file[\"tmp_name\"];\n\n  $ocr_upload_file_binary = fread(fopen($ocr_upload_file_tmp_name, \"r\"), filesize($ocr_upload_file_tmp_name));\n  $ocr_upload_file_string = base64_encode($ocr_upload_file_binary);\n\n  // 전송할 값들을 배열 형태로 저장\n  $postvars = [\n    \"version\"=&gt; \"V2\",\n    \"requestId\"=&gt; $ocr_request_id,\n    \"timestamp\"=&gt; $unixtimestamp,\n    \"lang\"=&gt; \"ko\",\n    \"images\"=&gt; [\n      [\n        \"format\"=&gt; \"jpg\",\n        \"name\"=&gt; \"ocr-test\",\n        \"data\"=&gt; $ocr_upload_file_string,\n        \"url\"=&gt; null,\n        \"templateIds\"=&gt; $ncloud_clova_ocr_template_ids\n      ]\n    ]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환\n  $json_portvars = json_encode($postvars);\n?&gt;\n\n\n  \n\n\n\n  version: “V2”로 고정\n  requestId: 임의의 값\n  timestamp: UNIX TimeStamp\n  lang: 판독할 문서의 언어\n  images: 판독할 문서의 정보\n    \n      format: 문서 포맷 (jpg, jpeg, png, tiff, pdf 등)\n      name: 임의의 값\n      data: 파일을 업로드할 경우의 파일 데이터, URL을 전송할 경우 이 값은 null로 설정\n      url: 파일의 url을 전송할 경우에 사용, 파일을 업로드할 경우 이 값은 null로 설정\n      templateIds: 판독에 사용할 Template 아이디들을 배열 형태로 설정\n    \n  \n\n\n\n\n\n  준비를 모두 마쳤으면 API를 호출합니다.\n\n\n&lt;?php\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);  \n  curl_setopt($ch, CURLOPT_POST, TRUE);\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\n\n  $json_response = curl_exec($ch);\n  $err = curl_error($ch);\n  $status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n?&gt;\n\n\n\n  마지막으로 API 호출 후 반환된 결과 값을 파싱해서 출력해봅니다.\n\n\n&lt;?php\n    $obj_response_array = json_decode($json_response, true);\n\n    $obj_clova_ocr_data = $obj_response_array[\"images\"][0];\n\n    // 사업자 등록번호\n    $business_number = $obj_clova_ocr_data[\"fields\"][0];\n    $business_number= $business_number[\"inferText\"];\n\n    //=============== 중간 생략 ================= //\n\n    // 종목\n    $business_item = $obj_clova_ocr_data[\"fields\"][5];\n    $business_item= $business_item[\"inferText\"];\n\n    echo(\"사업자 등록번호:\".$business_number.\"&lt;br /&gt;\");\n    echo(\"종목:\".$business_item.\"&lt;br /&gt;\");\n?&gt;\n\n\nTemplate을 생성할 때 설정했던 인식 필드에서 [필드 01]은 첫번째 값으로 반환되므로 여기서는 $obj_clova_ocr_data[“fields”][0]에 해당됩니다.\n마찬가지로 나머지 필드도 순서대로 가져오면 인식된 값을 확인할 수 있습니다.\n\n결과\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud CLOVA OCR 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/clovaocr-overview\n    \n  \n  Ncloud CLOVA OCR Template 생성 가이드\n    \n      https://guide.ncloud-docs.com/docs/clovaocr-template\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2024-02-19\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"ai-services-ncloud-ai-services-clova-ocr-template-ocr-guide-html": {
						"id": "ai-services-ncloud-ai-services-clova-ocr-template-ocr-guide-html",
						"title": "Ncloud Clova OCR 서비스 중에서 Template OCR 사용 방법 안내",
						"categories": "",
						"url": " /ai-services/ncloud-ai-services-clova-ocr-template-ocr-guide.html",
						"content": "개요\nNcloud (네이버 클라우드) [Clova OCR]은 전송한 문서나 이미지를 인식하여 사용자가 지정한 영역의 텍스트와 데이터를 정확하게 추출하는 서비스입니다. 여기서는 [Clova OCR]에서 제공하는 OCR 서비스 종류 중에서 [Template OCR]의 사용 방법을 [사업자등록증]을 예시로 정리해보겠습니다.\n\n서비스 이용 시 주의 사항\n[Clova OCR] 이용 시 주의 사항은 다음과 같습니다.\n\n\n  서비스 계정당 권장되는 호출 성능은 최대 1 tps입니다. 더 높은 호출 성능을 원하는 경우 고객 지원으로 문의하셔야 합니다.\n  인식 요청 시 45도 이상 회전된 문서는 인식률이 저하될 수 있습니다.\n\n\nOCR 종류\n[Clova OCR]에서 제공하는 OCR 서비스의 종류는 다음과 같습니다.\n\n\n  General OCR: 텍스트/표를 추출하는 OCR\n  Template OCR: 판독 영역을 직접 지정하여 인식값 추출 후 테스트 및 결과 전송이 가능한 템플릿 빌더를 지원하는 OCR\n  Document OCR: 머신러닝 기반으로 문서의 의미적 구조를 이해하는 특화 모델 엔진을 탑재하여 입력 정보(key-value)를 자동 추출하는 OCR\n\n\n도메인 생성\n우선 [CLOVA OCR] - [Domain]에서 [도메인 생성] 버튼을 클릭합니다.\n\n  \n  \n    \n  \n\n\n\n  General OCR과 Template OCR을 위한 [일반/템플릿 도메인]과 Document OCR을 위한 [특화 모델 도메인]중에서 [일반/템플릿 도메인 생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n생성\n도메인명과 도메인 코드를 입력하고, 지원 언어를 선택합니다.\n서비스 타입은 템플릿, 인식 모델은 Basic, 서비스 플랜은 Free를 선택하고 [생성] 버튼을 클릭합니다.\n\n\n⁃ CLOVA OCR은 도메인별 서비스 플랜에 따라 요금이 부과됩니다.\n⁃ Free 서비스 플랜을 제외한 모든 서비스 플랜은 CLOVA OCR API를 호출하지 않아도 기본 요금이 부과됩니다.\n⁃ 서비스 플랜에 따라 기본으로 제공되는 API 호출 수가 다르며, 기본 제공 건수 초과 시 추가 요금이 부과됩니다.\n\n\n\n  \n  \n    \n  \n\n\n템플릿 생성\n이제 템플릿을 생성하기 위해 도메인 정보에서 오른쪽 끝에 있는 [템플릿 빌더] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n템플릿 빌더\n템플릿 빌더 화면에서는 API Gateway 연동, 템플릿 관리, 테스트, 사용 지표 확인등을 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  왼쪽에 있는 메뉴에서 [템플릿 목록]을 선택하고, [템플릿 생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n템플릿 기본 정보 입력\n템플릿 기본 정보 항목에서 [템플릿명]을 입력하고 [확인] 버튼을 클릭해서 사용 가능한 템플릿 이름인지 확인합니다.\n\n\n  \n  \n    \n  \n\n\n\n  사용 가능한 [템플릿명]인 것이 확인되면 아래쪽에 있는 대표 샘플 이미지 등록 영역이 활성화 됩니다. 이 영역을 클릭해서 대표 샘플 이미지를 등록합니다.\n\n\n\n  \n  \n    \n  \n\n\n대표 샘플 설정\n대표 샘플 이미지를 등록하면 [대표 샘플명]을 입력해야 [대표 샘플의 판독 필드]를 지정할 수 있다는 안내 메시지가 나타나니다.\n\n  \n  \n    \n  \n\n\n\n  [대표 샘플명]을 입력하고 [확인] 버튼을 클릭하면 [대표 샘플의 판독 필드]를 지정할 수 있는데 [사업자등록증] 부분을 선택했습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [대표 샘플의 판독 필드]를 지정하고 나면, 템플릿 분류의 정확도 향상을 위해 대표 샘플명과 비슷한 유사어를 등록하라는 안내 메시지를 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [유사어 관리] 버튼을 클릭해서 [대표 샘플명]인 [사업자등록증]의 유사어를 [사 업 자 등 록 증], [사업자 등록증]등으로 입력했습니다.\n\n\n\n  \n  \n    \n  \n\n\n판독 필드 지정\n이제 실제로 이미지에서 판독할 필드를 지정해보겠습니다.\n\n[필드 추가] 버튼을 클릭하면 필드 지정 영역이 이미지 위에 나타나는데, 원하는 영역을 선택하고 [] 아이콘을 클릭합니다. 여기서는 등록번호 영역을 선택했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  판독 필드 선택을 하고 나면 오른쪽 아래에 첫번째 판독 필드를 뜻하는 [필드 01] 항목이 생성되는데, 여기에 [필드 이름]을 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  마찬가지로 [법인명], [대표자], [사업장 소재지], [업태], [종목]까지 총 6개 필드를 지정하고, [필드 이름]을 입력한 후 [저장] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n배포 관리\n생성이 끝난 템플릿을 실제로 사용하려면 [베타 배포]를 해야 합니다. 왼쪽 상단에 있는 [배포 관리] 메뉴로 이동해서 [베타 배포] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [베타 배포] 확인 팝업에서 [확인] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [베타 배포]가 완료되면 현재 배포 상태를 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n테스트\n베타 배포가 끝났으면 이제 테스트를 해보겠습니다. [테스트] 메뉴에서 [파일 업로드] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  파일 업로드 팝업창에서 파일을 업로드 합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  테스트할 파일을 업로드하면 무료 테스트 횟수 300회에 대한 안내를 볼 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n테스트 결과\n테스트 결과 화면에서는 왼쪽에 업로드된 이미지 파일의 판독 영역을 볼 수 있고 오른쪽에는 판독 영역에서 판독한 텍스트를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n요금관련 주의 사항\n\n\n⁃ General OCR 및 Free 서비스 플랜을 제외한 모든 서비스 플랜의 경우 CLOVA OCR API 호출을 하지 않아도 기본 유지 비용이 발생하므로 주의해 주십시오.\n⁃ CLOVA OCR API 호출 수는 서비스 플랜별 제공 건수가 다르며 포함 구간 초과 시 추가 비용이 발생하므로 주의해 주십시오.\n⁃ Template OCR의 1회 호출 기준은 빌더에서 설정한 템플릿의 인식 영역의 수(최대 50개)입니다. 초과 시 추가 과금이 발생합니다.  Template의 Box 영역의 수가 130개인 경우 3회 API 호출로 과금\n&#8259; Batch 기능 이용 시 긴 이미지, 표 추출 등 설정에 따라 추가 비용이 발생하므로 주의해 주십시오.\n\n\n참고 URL\n\n  Ncloud CLOVA OCR 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/clovaocr-overview\n    \n  \n  Ncloud CLOVA OCR Templage 생성 가이드\n    \n      https://guide.ncloud-docs.com/docs/clovaocr-template\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2024-02-14\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"api-ncloud-api-call-powershell-sample-html": {
						"id": "api-ncloud-api-call-powershell-sample-html",
						"title": "Windows PowerShell에서 Ncloud API를 호출하는 샘플 예제",
						"categories": "",
						"url": " /api/ncloud-api-call-powershell-sample.html",
						"content": "개요\n네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 Windows PowerShell에서 호출하는 샘플 예제를 정리해봅니다.\n네이버 클라우드 API는 RESTful API 방식으로 제공되며, XML와 JSON 형식으로 응답합니다\n우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\nAPI 호출 샘플 코드\n\nfunction Sign-Request(\n    [string] $api_server,\n    [string] $api_url,         \n    [string] $apicall_method,      \n    [string] $ncloud_accesskey,  \n    [string] $ncloud_secretkey \n)\n{   \n    $unixtimestamp = [DateTimeOffset]::Now.ToUnixTimeSeconds() * 1000\n    \n    $space = \" \"\n    $new_line = \"`n\"\n \n    $message = $apicall_method + $space +\n                $api_url + $new_line +\n                $unixtimestamp + $new_line +\n                $ncloud_accesskey                    \n\n    $signature = Compute-HMACSHA256Hash $ncloud_secretkey $message\n    \n    # Return request headers\n    return @{\n        \"x-ncp-apigw-timestamp\" = $unixtimestamp;\n        \"x-ncp-iam-access-key\" = $ncloud_accesskey;\n        \"x-ncp-apigw-signature-v2\" = $signature\n    }\n}\n\nfunction Compute-HMACSHA256Hash(\n    [string] $secret,      # base64 encoded\n    [string] $content\n)\n{\n    $hmacsha = New-Object System.Security.Cryptography.HMACSHA256\n    try {\n        $hmacsha.key = [Text.Encoding]::UTF8.GetBytes($secret)\n        $signature = $hmacsha.ComputeHash([Text.Encoding]::UTF8.GetBytes($message))   \n        \n        return [Convert]::ToBase64String($signature)\n    }\n    finally {\n        $hmacsha.Dispose()\n    }\n}\n\n# API 서버와 URL 예시 : 상품별 가격 리스트 호출 api\n$api_server = \"https://billingapi.apigw.ntruss.com\";\n$api_url = \"/billing/v1/product/getProductPriceList\";\n$api_url = $api_url + \"?regionCode=KR&amp;productItemKindCode=VSVR\";\n\n$apicall_method = \"GET\"\n$body = $null\n$ncloud_accesskey = \"Ncloud AccessKey\"\n$ncloud_secretkey = \"Ncloud SecretKey\"\n$api_full_url = $api_server + $api_url\n\n$headers = Sign-Request $api_server $api_url $apicall_method $ncloud_accesskey $ncloud_secretkey\n\nInvoke-WebRequest -Uri $api_full_url -Method $apicall_method -Headers $headers  -Body $body\n\n\n코드 상세 설명\n\n유닉스 타임 스탬프\n$unixtimestamp = [DateTimeOffset]::Now.ToUnixTimeSeconds() * 1000\n\n네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요합니다.\n계산한 날짜 값에 1000을 곱해서 13자리로 만듭니다.\n\nhmac으로 암호화할 문자열 설정\n암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\n\n$space = \" \"\n$new_line = \"`n\"\n\n$message = $apicall_method + $space +\n            $api_url + $new_line +\n            $unixtimestamp + $new_line +\n            $ncloud_accesskey\t\n\n네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 `n을 이용해서 하나의 문자열로 설정합니다.\n\n API 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\n\nhmac_sha256 방식으로 암호화\n$signature = Compute-HMACSHA256Hash $ncloud_secretkey $message\n\nfunction Compute-HMACSHA256Hash(\n    [string] $secret,      # base64 encoded\n    [string] $content\n)\n{\n    $hmacsha = New-Object System.Security.Cryptography.HMACSHA256\n    try {\n        $hmacsha.key = [Text.Encoding]::UTF8.GetBytes($secret)\n        $signature = $hmacsha.ComputeHash([Text.Encoding]::UTF8.GetBytes($message))   \n        \n        return [Convert]::ToBase64String($signature)\n    }\n    finally {\n        $hmacsha.Dispose()\n    }\n}\n\nhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 $message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\n\nhttp 호출 헤더값 설정\n# Return request headers\nreturn @{\n    \"x-ncp-apigw-timestamp\" = $unixtimestamp;\n    \"x-ncp-iam-access-key\" = $ncloud_accesskey;\n    \"x-ncp-apigw-signature-v2\" = $signature\n}\n\nAPI를 호출할 때는 http 헤더값에 다음 3가지를 추가해서 호출합니다.\n\n  유닉스 타임스탬프\n  네이버 클라우드 API AccessKey\n  hmac_256 으로 암호화한 문자열\n\n\n여기서 전송하는 타임스탬프는 위에서 $message를 암호화할 때 사용한 타임스탬프와 동일한 값이어야 합니다.\n\n\n네이버 클라우드 인증키\n$ncloud_accesskey = \"Ncloud AccessKey\"\n$ncloud_secretkey = \"Ncloud SecretKey\"\t\n\n네이버 클라우드 인증키는 네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\napi 호출\n$headers = Sign-Request $api_server $api_url $apicall_method $ncloud_accesskey $ncloud_secretkey\nInvoke-WebRequest -Uri $api_full_url -Method $apicall_method -Headers $headers  -Body $body \n\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\n리턴값은 호출하는 용도별로 json 또는 xml 형태로 반환됩니다.\n\n응답 예시\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;getProductPriceListResponse&gt;\n  &lt;requestId&gt;397d3d13-2b2a-42d2-96d0-20ff63df69dc&lt;/requestId&gt;\n  &lt;returnCode&gt;0&lt;/returnCode&gt;\n  &lt;returnMessage&gt;success&lt;/returnMessage&gt;\n  &lt;totalRows&gt;121&lt;/totalRows&gt;\n  &lt;productPriceList&gt;\n    &lt;productPrice&gt;\n      &lt;productItemKind&gt;\n        &lt;code&gt;VSVR&lt;/code&gt;\n        &lt;codeName&gt;Server (VPC)&lt;/codeName&gt;\n      &lt;/productItemKind&gt;\n      &lt;productItemKindDetail&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productItemKindDetail&gt;\n     ''' 중략 '''\n      &lt;softwareType/&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productTypeDetail/&gt;\n      &lt;gpuCount&gt;0&lt;/gpuCount&gt;\n      &lt;cpuCount&gt;24&lt;/cpuCount&gt;\n      &lt;memorySize&gt;137438953472&lt;/memorySize&gt;\n      &lt;baseBlockStorageSize&gt;4123168604160&lt;/baseBlockStorageSize&gt;\n      &lt;dbKind/&gt;\n      &lt;osInfomation/&gt;\n      &lt;platformType/&gt;\n      &lt;osType/&gt;\n      &lt;platformCategoryCode/&gt;\n      &lt;diskType&gt;\n        &lt;code&gt;LOCAL&lt;/code&gt;\n        &lt;codeName&gt;Local storage&lt;/codeName&gt;\n      &lt;/diskType&gt;\n      &lt;diskDetailType&gt;\n        &lt;code&gt;SSD&lt;/code&gt;\n        &lt;codeName&gt;SSD&lt;/codeName&gt;\n      &lt;/diskDetailType&gt;\n      &lt;generationCode&gt;G1&lt;/generationCode&gt;     \n    ''' 중략 '''\n  &lt;/productPriceList&gt;\n&lt;/getProductPriceListResponse&gt;\n\n\n참고 URL\n\n\n  네이버 클라우드 API 가이드\n    \n      https://api.ncloud-docs.com/docs/api-overview"
					}
					
				
			
		
			
				
					,
					
					"application-service-ncloud-application-service-cloud-outbound-mailer-domain-authentication-html": {
						"id": "application-service-ncloud-application-service-cloud-outbound-mailer-domain-authentication-html",
						"title": "Ncloud Cloud Outbound Mailer 도메인 인증 방법 3가지(SPF, DKIM, DMARC) 안내",
						"categories": "",
						"url": " /application-service/ncloud-application-service-cloud-outbound-mailer-domain-authentication.html",
						"content": "개요\nNcloud (네이버 클라우드) Cloud Outbound Mailer를 사용할 때 도메인을 등록하고 SPF(Sender Policy Framework), DKIM(DomainKeys Identified Mail), DMARC(Domain-based Message Authentication, Reporting, and Conformance) 인증을 받으면 발신자 자격을 입증할 수 있고 타인이 도메인을 사칭해 메일을 발송하는 것을 막을 수 있습니다.\n\n또한, 인증된 도메인임을 증명함으로써 수신측 메일 서비스에서 차단되거나 스팸 처리될 가능성도 매우 낮아지는 이점이 있으므로 가능하면 도메인 인증을 하는 것이 좋습니다.\n\n Gmail 공지: \n특히 Gmail에서는 2024년 2월부터 새로운 이메일 발신자 가이드라인을 적용하면서 도메인 인증을 받지 않은 경우 메일이 스팸처리되거나 제대로 전송되지 않을 수 있다고 공지하고 있습니다. \n- Gmail 공지 : https://support.google.com/a/answer/81126?sjid=17985022532965146045-AP\n\n\n도메인 인증 종류\n\n  SPF(Sender Policy Framework) 인증: 메일 발신자 정보가 DNS에 등록된 메일 서버 정보와 일치하는지 확인하여 발신자 위조 여부를 확인합니다.\n  DKIM(DomainKeys Identified Mail) 인증: 메일 헤더에 디지털 서명을 추가하여 메일의 위변조 여부를 확인합니다.\n  DMARC(Domain-based Message Authentication, Reporting, and Conformance) 인증: SPF 및 DKIM과 함께 작동하여 메일 발신자를 인증하면서, SPF 및 DKIM 인증에 실패한 도메인의 발신 메일을 어떻게 처리할지 설정할 수 있습니다.\n\n\n위 3가지 인증을 모두 적용해야 메일이 문제 없이 도착할 수 있습니다.\n\n도메인 등록\n[Cloud Outbound Mailer] - [Domain Management]에서 [도메인 등록] 버튼을 클릭합니다.\n이미 도메인이 등록되어 있다면 다음 단계로 이동합니다.\n\n\n  \n  \n    \n  \n\n\n등록 절차\n\n  이메일 발송 주소로 사용할 도메인을 입력 후, 인증 토큰 생성 버튼을 클릭합니다.\n  인증 토큰이 생성되면 [복사하기] 버튼을 클릭하여 인증 토큰 정보를 복사합니다.\n  [등록] 버튼을 클릭하여 도메인 등록을 완료합니다.\n  복사한 인증 토큰을 등록하신 도메인 DNS의 TXT 레코드에 추가합니다.\n  Domain Management 메뉴에서 등록된 도메인 선택 후, [인증] 버튼을 클릭합니다.\n  DNS 변경의 적용에는 시간이 소요될 수 있습니다. 정상적으로 TXT 레코드 등록을 완료했으나 인증이 되지 않는 경우 잠시 후 다시 [인증] 버튼을 클릭해 주세요.\n\n\n\n  \n  \n    \n  \n\n\n인증 대기\n등록을 완료하면 아래와 같이 미인증 상태로 인증대기 중인 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n인증 토큰 적용\n해당 도메인을 등록한 DNS 서비스 업체에서 [인증 토큰]을 등록하면 되는데, 여기서는 Ncloud의 DNS 서비스인 [Global DNS]에서 아래와 같이 등록했습니다.\n\n\n  \n  \n    \n  \n\n\n인증 확인\nDNS 서비스에 [인증 토큰]을 등록하고 잠시 기다렸다가 [도메인 인증 토큰] 항목에 있는 [인증] 버튼을 클릭하면 아래와 같이 [인증 일시] 시각을 확인할 수 있습니다.\n\n인증에 실패했다는 메시지가 나타날 경우 조금 더 기다렸다가 다시 [인증] 버튼을 클릭해보고, 그래도 인증에 실패하면 DNS에 [인증 토큰]이 제대로 등록되었는지 확인해보시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\nSPF 인증\n도메인 인증이 끝났으면 다음으로 [SPF] 인증을 해보겠습니다.\n\nSPF(Sender Policy Framework) 인증은 메일 발신자 정보가 DNS에 등록된 메일 서버 정보와 일치하는지 확인하여 발신자 위조 여부를 확인하기 위한 인증입니다.\n\n\n  우선 [SPF 레코드] 항목에 있는 [보기] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n인증 레코드 확인\n팝업에 나타난 인증 레코드를 복사합니다.\n\nv=spf1 include:email.ncloud.com ~all\n\n\n\n  \n  \n    \n  \n\n\nDNS 레코드 등록\n위에서 복사한 인증 레코드를 DNS에 등록합니다. 이때 기존에 등록된 SPF 레코드가 존재할 경우에는 기존 레코드 문자열에 포함해서 등록해야 합니다.\n\n# 신규 등록일 경우\nv=spf1 include:email.ncloud.com ~all\n\n# 다른 SPF 레코드가 존재할 경우 예시\nv=spf1 ip4:123.123.123.123 include:email.ncloud.com ~all\n\n\n  \n      \n          신규 등록일 경우 \n      \n  \n      \n          다른 SPF 레코드가 존재할 경우 \n      \n  \n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n\n\n인증 확인\n인증 레코드를 등록하고 잠시 기다렸다가 [SPF 레코드] 항목에 있는 [인증] 버튼을 클릭하면 아래와 같이 [인증 일시] 시각을 확인할 수 있습니다.\n\n인증에 실패했다는 메시지가 나타날 경우 조금 더 기다렸다가 다시 [인증] 버튼을 클릭해보고, 그래도 인증에 실패하면 DNS에 [인증 레코드]가 제대로 등록되었는지 확인해보시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\n인증 사용\n인증이 완료되었으면, 향후 [Cloud Outbound Mailer]에서 메일을 발송할 때 [SPF 인증]이 적용되도록 [사용]하기를 설정해야 합니다. 아래 스샷처럼 [SPF 레코드] 항목에 있는 [사용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [SPF 인증] 사용하기가 설정되면 아래와 같이 [사용 중] 상태로 바뀌면서 [사용 중지] 버튼이 활성화 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nDKIM 인증\n다음으로 [DKIM] 인증을 해보겠습니다.\n\nDKIM(DomainKeys Identified Mail) 인증은 메일 헤더에 디지털 서명을 추가하여 메일의 위변조 여부를 확인하기 위한 인증입니다.\n\n\n  우선 [DKIM] 서명키를 확인하기 위해 [DKIM 레코드] 항목에 있는 [보기] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n서명 키 확인\n아래와 같이 팝업에 나타난 [DKIM] 서명키를 복사해서 DNS에 등록합니다.\n\n\n  \n  \n    \n  \n\n\nDNS에 등록할 때 TXT 레코드의 호스트명은 반드시 mailer._domainkey를 사용해야 합니다.\n\n\n- TXT 레코드는 255자의 길이 제한이 있는데, Ncloud에서 제공하는 DKIM 서명키는 255자를 넘기 때문에 분할하여, multi-line으로 등록하셔야 합니다. \n- Ncloud Global DNS를 사용할 경우에는 분할할 필요 없이 그대로 등록하면 자동으로 분할 등록되므로 편리합니다. \n- DNS 설정에서 255자 이상의 TXT 레코드 등록하는 방법: https://docs.3rdeyesys.com/networking/ncloud-networking-global-dns-configure-long-txt-record.html\n\n\nDNS 등록\n아래와 같이 호스트명을 mailer._domainkey로 입력하고, [DKIM] 서명키를 등록했습니다.\n\n\n  \n  \n    \n  \n\n\n인증 사용\n인증이 완료되었으면, 향후 [Cloud Outbound Mailer]에서 메일을 발송할 때 [DKIM 인증]이 적용되도록 [사용]하기를 설정해야 합니다. 아래 스샷처럼 [DKIM] 항목에 있는 [사용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [DKIM 인증] 사용하기가 설정되면 아래와 같이 [사용 중] 상태로 바뀌면서 [사용 중지] 버튼이 활성화 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nDMARC 인증\n[DMARC] 인증은 다른 인증과 달리 레코드 값을 직접 설정해서 등록해야 합니다. 자세한 방법은 아래쪽에서 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\nDMARC 레코드 값 준비\n\n\n  DMARC 레코드 이름, 즉 호스트명은 반드시 _dmarc를 입력해야 합니다.\n  DMARC 레코드의 값은 아래와 같은 형식으로 구성됩니다.\n예시: v=DMARC1; p=none; aspf=r; adkim=r; rua=mailto:report@example.com\n\n\n\n\n  \n    \n      항목\n      입력 값 및 설명\n      필수 여부      \n    \n  \n  \n    \n        v\n        \n            버전을 의미\n            DMARC1으로 입력\n         \n        필수       \n    \n    \n        p\n        \n            수신 서버에서 DMARC로 인증되지 않은 메일에 대한 처리 방법\n            - none: 조치하지 않고 메일 수신\n            - quarantine: 스팸 메일함으로 수신\n            - reject: 수신을 차단하고 반송 처리\n         \n        필수       \n    \n    \n        sp\n        \n            하위 도메인에서 전송된 메일에 대한 정책\n            - none: 조치하지 않고 메일 수신\n            - quarantine: 스팸 메일함으로 수신\n            - reject: 수신을 차단하고 반송 처리\n         \n        필수 아님       \n    \n    \n        aspf\n        \n            메일 정보와 spf 서명의 문자열 일치 여부 설정\n            - s: 모든 부분 일치\n            - r: (기본값) 부분 일치를 허용 (서브 도메인 허용)\n         \n        필수 아님       \n    \n    \n        adkim\n        \n            메일 정보와 dkim 서명의 문자열 일치 여부 설정\n            - s: 모든 부분 일치\n            - r: (기본값) 부분 일치를 허용 (서브 도메인 허용)\n         \n        필수 아님       \n    \n    \n        rua\n        \n            해당 도메인의 DMARC 처리 보고서를 수신할 이메일 주소            \n            - 메일 주소 앞에 mailto: 입력\n            - 쉼표(,)를 연결하여 여러 이메일 주소 지정 가능\n         \n        필수 아님       \n    \n  \n  \n\n\n\n\nDNS 등록\n아래와 같이 호스트명을 _dmarc로 입력하고, [DMARC] 레코드를 등록했습니다.\n\n\n  \n  \n    \n  \n\n\n인증 확인\n인증 레코드를 등록하고 잠시 기다렸다가 [DMARC 인증] 항목에 있는 [인증 일시] 시각이 나타나는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n도메인 인증 결과 테스트\n실제로 Gmail로 메일을 발송한 후 인증 결과를 테스트 해보겠습니다.\n\nGmail 계정쪽으로 메일을 발송한 후 Gmail에 접속해서 도착한 메일을 선택하고 오른쪽 끝에 있는 [  ] 아이콘을 클릭하면 나타나는 메뉴에서 [원본 보기]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n인증 PASS\n메일의 [원본 보기]를 확인해보면 아래와 같이 [SPF], [DKIM], [DMARC] 3가지 인증 모두 PASS 즉, 인증이 정상적으로 완료되었다는 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud Outbound Mailer 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/email-email-1-1\n    \n  \n  Ncloud Cloud Outbound Mailer 도메인 인증 가이드\n    \n      https://guide.ncloud-docs.com/docs/cloudoutboundmailer-use-domain\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2024-01-26\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"containers-ncloud-containers-kubernetes-service-start-guide-linux-html": {
						"id": "containers-ncloud-containers-kubernetes-service-start-guide-linux-html",
						"title": "Kubernetes Service 클러스터 생성 및 제어 가이드 | Linux",
						"categories": "",
						"url": " /containers/ncloud-containers-kubernetes-service-start-guide-linux.html",
						"content": "개요\nNcloud (네이버 클라우드) VPC 환경에서 Kubernetes(쿠버네티스) 서비스를 생성하고 Linux 환경에서 제어하는 방법에 대해 소개합니다.\n\n쿠버네티스란?\n쿠버네티스(Kubernetes, K8S)는 배포, 스케일링, 그리고 컨테이너화된 애플리케이션의 관리를 자동화 해주는 오픈 소스 컨테이너 오케스트레이션 엔진으로 \n구글에서 처음 개발하기 시작했으나 현재는 구글이 오픈소스 프로젝트로 공개한 상태입니다.\n\n특징\n쿠버네티스는 다음과 같은 특징이 있으며, 자세한 내용은 쿠버네티스 공식 페이지를 참고하시기 바랍니다.\n\nhttps://kubernetes.io/ko/docs/home/\n\n\n  서비스 디스커버리와 로드 밸런싱\n  스토리지 오케스트레이션\n  자동화된 롤아웃과 롤백\n  자동화된 빈 패킹(bin packing)\n  자동화된 복구(self-healing)\n  시크릿과 구성 관리\n\n\n사전 준비\n먼저 쿠버네티스 클러스터에 사용할 전용 VPC와 Private 또는 Public Subnet 그리고, Load Balancer용 Subnet이 필요합니다.\n\n\n  \n  \n    \n  \n\n\nIP 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /17~/26 범위의 Subnet, 로드밸런서 전용 Subnet이 필요합니다.\nDocker Bridge 대역의 충돌을 방지하기 위해 172.17.0.0/16 범위 내의 Private Subnet, 로드밸런서 전용Subnet은 선택할 수 없습니다.\n\n쿠버네티스 서비스 위치\nNcloud 쿠버네티스 서비스는 [콘솔] - [Services] - [Containers]에 위치하고 있습니다.\n\n\n  \n  \n    \n  \n\n\n클러스터 생성\n\nVPC와 Subnet이 준비되었다면, 다음으로 [Kubernetes Sevice] - [Cluster]에서 생성하기를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n클러스터 설정\n생성할 클러스터의 정보를 설정해줍니다. \n네트워크 타입은 Private과 Public 중에서 선택할 수 있습니다.\n\nKubernetes Service를 위한 ACG는 자동으로 생성됩니다.\n\n현재 지원되고 있는 Kubernetes 버전은 [1.26.10], [1.27.9] 입니다.\n\n\n  \n  \n    \n  \n\n\nNAT Gateway 생성\nPrivate Subnet을 선택했을 경우에는 아래와 같이 NAT Gateway 생성 안내 팝업이 나타나는데,\nNAT Gateway를 생성해야 아웃바운드 트래픽을 활성화할 수 있기 때문입니다.\n\n\n  \n  \n    \n  \n\n\n팝업에서 링크를 클릭해서 NAT Gateway 화면으로 이동해 NAT Gateway를 생성합니다.\n\nNAT Gateway 생성 가이드는 아래 문서를 참고하시기 바랍니다. \n- VPC 환경에서 NAT Gateway 설정하기\n\n\n  \n  \n    \n  \n\n\n노드풀 설정\n노드풀 이름을 입력하고, 서버 이미지와 서버 타입을 선택하고 [추가] 버튼을 클릭합니다.\n\n현재 지원되고 있는 OS는 [ubuntu 18.04], [ubuntu 20.04] 입니다.\n\n\n  \n  \n    \n  \n\n\n인증키 설정\n다음으로 워커노드의 인증키를 설정 합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n설정 정보를 최종적으로 확인한 후 생성버튼을 클릭하여 클러스터를 생성합니다.\n\n쿠버네티스 클러스터 생성은 30분 정도 소요되므로 여유를 갖고 기다리시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n생성 완료\n생성이 완료되면 아래와 같이 클러스터와 노드풀의 정보를 확인할 수 있습니다.\n클러스터 정보 중에서 클러스터 UUID는 아래쪽에서 IAM 인증 Kubeconifg 파일을 생성할 때 필요하니 확인해두시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\n[Server] 메뉴에 가면 노드풀 설정에 따라 생성된 서버를 확인할 수 있습니다.\n(서버 이름은 노드풀 이름으로 입력한 문자열 기준으로 생성되는데, 여기서는 test123-O-OOO 이런 식으로 생성되었습니다.)\n\n그리고, 추가로 테스트를 위한 CentOS 서버(k8s-test)를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\nIAM 인증 설정\n클러스터를 제어하기 위해서는 네이버 클라우드 쿠버네티스 서비스에서 제공하는 IAM 인증을 설정해야 합니다.\n\nncp-iam-authenticator 설치\nNcloud에서 제공하는 ncp-iam-authenticator 바이너리를 통해 iam 인증 config 파일을 생성 할 수 있습니다.\n\n\n  ncp-iam-authenticator 바이너리를 다운로드 합니다.\n\n\n~# curl -o ncp-iam-authenticator https://kr.object.ncloudstorage.com/nks-download/ncp-iam-authenticator/v1.0.5/linux/amd64/ncp-iam-authenticator\n\n\n  \n  \n    \n  \n\n\n\n  다운받은 바이너리에 실행 권한을 추가 합니다.\n\n\n~# chmod +x ./ncp-iam-authenticator\n\n\n  \n  \n    \n  \n\n\n\n  bin/ncp-iam-authenticator 파일을 생성하고  $PATH에 추가합니다.\n  bash Profile에 추가 합니다.\n\n\n~# mkdir -p $HOME/bin &amp;&amp; cp ./ncp-iam-authenticator $HOME/bin/ncp-iam-authenticator &amp;&amp; export PATH=$PATH:$HOME/bin\n\n~# echo 'export PATH=$PATH:$HOME/bin' &gt;&gt; ~/.bash_profile\n\n\n\n  \n  \n    \n  \n\n\n\n  ncp-iam-authenticator가 정상 작동 하는지 테스트 합니다.\n\n\n~# ncp-iam-authenticator help\n\n\n\n  \n  \n    \n  \n\n\nAPI Access Key 생성\n[Sub Account] - [Sub Accounts]에서 본인의 계정을 선택하고, [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나는데[추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\n\n : \n메인 계정은 최대 권한을 가지기 때문에 메인 계정으로 생성한 API도 메인 계정과 동일한 최대 권한을 가지게 됩니다. 그러므로 메인 계정으로 API Key를 생성하게 되면 이 Key가 유출되었을 때 심각한 문제가 생기기 때문에 반드시 서브 계정에서 API Key를 생성해야 합니다.\n\n\n\n  \n  \n    \n  \n\n\nKubeconfig 파일 생성\n\n환경변수 설정\nAPI 인증키를 2가지 방법 중 하나를 이용해 환경변수에 등록합니다.\n\n\n  첫번째 방법: OS 환경 변수 설정\n\n\n~# export NCLOUD_ACCESS_KEY={Ncloud API AccessKey}\n~# export NCLOUD_SECRET_KEY={Ncloud API SecretKey}\n~# export NCLOUD_API_GW=https://ncloud.apigw.ntruss.com\n\n\n  \n  \n    \n  \n\n\n\n  두번째 방법: 사용자 환경 홈 디렉터리에 configure 설정\n\n\n~# mkdir .ncloud \n~# cat &lt;&lt; EOF &gt; .ncloud/configure\n[DEFAULT]\nncloud_access_key_id = {Ncloud API AccessKey}\nncloud_secret_access_key = {Ncloud API SecretKey}\nncloud_api_url = https://ncloud.apigw.ntruss.com\nEOF\n\n\n  \n  \n    \n  \n\n\nKubeconifg 파일 생성\n환경변수에 등록이 되었다면 파일을 생성 할 차례입니다.\n아래 명령어로 클러스터에 대한 IAM 인증 Kubeconifg 파일을 생성합니다.\n\n클러러스터 UUID 값은 클러스터 상세보기의 [클러스터 이름 (UUID)] 에서  확인 할수 있습니다.\n\n~# ncp-iam-authenticator create-kubeconfig --region &lt;region-code&gt; --clusterUuid &lt;cluster-uuid&gt; --output &lt;FileName&gt;.yaml\n\n## 예시\n~# ncp-iam-authenticator create-kubeconfig --region KR --clusterUuid 12345678-1234-1234-1234-1234567890 --output kubeconfig.yaml\n\n\n\n  \n  \n    \n  \n\n\nkubectl 설치\n쿠버네티스 클러스터를 제어할 kubectl을 설치하기 위해 필요한 파일을 다운로드 받습니다.\n\n~# curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n\n\n\n  \n  \n    \n  \n\n\n다운 받은 파일을 설치합니다.\n\n~# sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# 버전 확인\n~# kubectl version --client --output=yaml\n\n\n\n  \n  \n    \n  \n\n\nkubectl 실행\n생성한 IAM 인증 kubeconfig 파일을 이용하여 kubectl 명령어를 테스트하여 정상 동작 하는지 확인 합니다.\n실행하면 아래와 같이 현재 동작 중인 노드 서버 리스트를 확인할 수 있습니다.\n\n~# kubectl get node --kubeconfig kubeconfig.yaml\n\n\n  \n  \n    \n  \n\n\n실행 명령어 단축\n위와 같은 kubectl 명령은 뒤쪽에 kubeconfig 환경 설정 파일까지 입력해야 해서 다소 불편한데, 간단하게 줄일 수 있는 방법이 있습니다.\n\n우선 만들어진 kubeconfig.yaml 파일을 .kube/ 디렉토리 아래에 config로 이름을 바꾸어 이동 혹은 복사 합니다.\n\n~# cp kubeconfig.yaml .kube/config\n\n\n이렇게 하면 Kubectl을 사용 시 아래와 같이 –kuebeconfig 명령어 없이 사용 할 수 있습니다.\n\n~# kubectl get node\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  쿠버네티스 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8soverview\n    \n  \n  클러스터 이용 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8suse-cluster\n    \n  \n  kubectl 설치 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8sstart#Kubectl\n    \n  \n  Windows 환경에서 쿠버네티스 제어하기\n    \n      https://docs.3rdeyesys.com/containers/ncloud-containers-kubernetes-service-start-guide-windows.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-05-15\n          문서 최초 생성\n        \n      \n        \n          2024-02-01\n          쿠버네티스 버전 업데이트 내역 반영"
					}
					
				
			
		
			
				
					,
					
					"containers-ncloud-containers-kubernetes-service-start-guide-windows-html": {
						"id": "containers-ncloud-containers-kubernetes-service-start-guide-windows-html",
						"title": "Kubernetes Service 클러스터 생성 및 제어 가이드 | Windows",
						"categories": "",
						"url": " /containers/ncloud-containers-kubernetes-service-start-guide-windows.html",
						"content": "개요\nNcloud (네이버 클라우드) VPC 환경에서 Kubernetes(쿠버네티스) 서비스를 생성하고 Windows 환경에서 제어하는 방법에 대해 소개합니다.\n\n쿠버네티스란?\n쿠버네티스(Kubernetes, K8S)는 배포, 스케일링, 그리고 컨테이너화된 애플리케이션의 관리를 자동화 해주는 오픈 소스 컨테이너 오케스트레이션 엔진으로 \n구글에서 처음 개발하기 시작했으나 현재는 구글이 오픈소스 프로젝트로 공개한 상태입니다.\n\n특징\n쿠버네티스는 다음과 같은 특징이 있으며, 자세한 내용은 쿠버네티스 공식 페이지를 참고하시기 바랍니다.\n\nhttps://kubernetes.io/ko/docs/home/\n\n\n  서비스 디스커버리와 로드 밸런싱\n  스토리지 오케스트레이션\n  자동화된 롤아웃과 롤백\n  자동화된 빈 패킹(bin packing)\n  자동화된 복구(self-healing)\n  시크릿과 구성 관리\n\n\n사전 준비\n먼저 쿠버네티스 클러스터에 사용할 전용 VPC와 Private 또는 Public Subnet 그리고, Load Balancer용 Subnet이 필요합니다.\n\n\n  \n  \n    \n  \n\n\nIP 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /17~/26 범위의 Subnet, 로드밸런서 전용 Subnet이 필요합니다.\nDocker Bridge 대역의 충돌을 방지하기 위해 172.17.0.0/16 범위 내의 Private Subnet, 로드밸런서 전용Subnet은 선택할 수 없습니다.\n\n쿠버네티스 서비스 위치\nNcloud 쿠버네티스 서비스는 [콘솔] - [Services] - [Containers]에 위치하고 있습니다.\n\n\n  \n  \n    \n  \n\n\n클러스터 생성\n\nVPC와 Subnet이 준비되었다면, 다음으로 [Kubernetes Sevice] - [Cluster]에서 생성하기를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n클러스터 설정\n생성할 클러스터의 정보를 설정해줍니다. \n네트워크 타입은 Private과 Public 중에서 선택할 수 있습니다.\n\nKubernetes Service를 위한 ACG는 자동으로 생성됩니다.\n\n현재 지원되고 있는 Kubernetes 버전은 [1.24.0], [1.25.8] 입니다.\n\n\n  \n  \n    \n  \n\n\nNAT Gateway 생성\nPrivate Subnet을 선택했을 경우에는 아래와 같이 NAT Gateway 생성 안내 팝업이 나타나는데,\nNAT Gateway를 생성해야 아웃바운드 트래픽을 활성화할 수 있기 때문입니다.\n\n\n  \n  \n    \n  \n\n\n팝업에서 링크를 클릭해서 NAT Gateway 화면으로 이동해 NAT Gateway를 생성합니다.\n\nNAT Gateway 생성 가이드는 아래 문서를 참고하시기 바랍니다. \n- VPC 환경에서 NAT Gateway 설정하기\n\n\n  \n  \n    \n  \n\n\n노드풀 설정\n노드풀 이름을 입력하고, 서버 이미지와 서버 타입을 선택하고 [추가] 버튼을 클릭합니다.\n\n현재 지원되고 있는 OS는 [ubuntu 16.04], [ubuntu 18.04], [ubuntu 20.04] 입니다.\n\n\n  \n  \n    \n  \n\n\n인증키 설정\n다음으로 워커노드의 인증키를 설정 합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n설정 정보를 최종적으로 확인한 후 생성버튼을 클릭하여 클러스터를 생성합니다.\n\n쿠버네티스 클러스터 생성은 20분 정도 소요되므로 여유를 갖고 기다리시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n생성 완료\n생성이 완료되면 아래와 같이 클러스터와 노드풀의 정보를 확인할 수 있습니다.\n클러스터 정보 중에서 클러스터 UUID는 아래쪽에서 IAM 인증 Kubeconifg 파일을 생성할 때 필요하니 확인해두시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\n[Server] 메뉴에 가면 노드풀 설정에 따라 생성된 서버를 확인할 수 있습니다.\n(서버 이름은 노드풀 이름으로 입력한 문자열 기준으로 생성되는데, 여기서는 test123-O-OOO 이런 식으로 생성되었습니다.)\n\n\n  \n  \n    \n  \n\n\nIAM 인증 설정\n클러스터를 제어하기 위해서는 네이버 클라우드 쿠버네티스 서비스에서 제공하는 IAM 인증을 설정해야 합니다.\n\nncp-iam-authenticator 설치\nNcloud에서 제공하는 ncp-iam-authenticator 바이너리를 통해 iam 인증 config 파일을 생성 할 수 있습니다.\n\n\n  ncp-iam-authenticator 바이너리를 다운로드 합니다.\n\n\n&gt; curl -o ncp-iam-authenticator.exe https://kr.object.ncloudstorage.com/nks-download/ncp-iam-authenticator/v1.0.5/windows/amd64/ncp-iam-authenticator.exe\n\n\n  \n  \n    \n  \n\n\n\n  ncp-iam-authenticator가 정상 작동 하는지 테스트 합니다.\n\n\n&gt; ncp-iam-authenticator help\n\n\n\n  \n  \n    \n  \n\n\nAPI 인증키 생성\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nKubeconfig 파일 생성\nAPI 인증키를 2가지 방법 중 하나를 이용해 환경변수에 등록합니다.\n\n1. OS 환경 변수 설정\n\n&gt; SET NCLOUD_ACCESS_KEY={Ncloud API AccessKey}\n&gt; SET NCLOUD_SECRET_KEY={Ncloud API SecretKey}\n&gt; SET NCLOUD_API_GW=https://ncloud.apigw.ntruss.com\n\n\n  \n  \n    \n  \n\n\n2. 사용자 계정 홈 폴더에 configure 설정\nWindows 사용자 계정 폴더에 .ncloud 폴더를 만들고 아래와 같은 내용으로 configure 파일을 생성합니다.\n\n&gt; mkdir C:\\Users\\{User Account}\\.ncloud\n&gt; copy con C:\\Users\\{User Account}\\.ncloud\\configure\n[DEFAULT]\nncloud_access_key_id = {Ncloud API AccessKey}\nncloud_secret_access_key = {Ncloud API SecretKey}\nncloud_api_url = https://ncloud.apigw.ntruss.com\n^Z\n\n\n  \n  \n    \n  \n\n\n3. Kubeconifg 파일 생성\n환경변수에 등록이 되었다면 파일을 생성 할 차례입니다.\n아래 명령어로 클러스터에 대한 IAM 인증 Kubeconifg 파일을 생성합니다.\n\n클러러스터 UUID 값은 클러스터 상세보기의 [클러스터 이름 (UUID)] 에서  확인 할수 있습니다.\n\n&gt; ncp-iam-authenticator create-kubeconfig --region &lt;region-code&gt; --clusterUuid &lt;cluster-uuid&gt; --output &lt;FileName&gt;.yaml\n\n## 예시\n&gt; ncp-iam-authenticator create-kubeconfig --region KR --clusterUuid 12345678-1234-1234-1234-1234567890 --output kubeconfig.yaml\n\n\n\n  \n  \n    \n  \n\n\nkubectl 설치\n쿠버네티스 클러스터를 제어할 kubectl을 설치하기 위해 필요한 파일을 다운로드 받고, 버전 정보를 확인합니다.\n\n아래 두가지 방법 중에 하나를 선택해 다운로드 받으시면 됩니다.\n\nDownload the latest release v1.24.0\n\n&gt; curl -LO https://dl.k8s.io/release/v1.24.0/bin/windows/amd64/kubectl.exe\n\n\n&gt; kubectl version --client --output=yaml\n\n\n\n  \n  \n    \n  \n\n\nkubectl 실행\n생성한 IAM 인증 kubeconfig 파일을 이용하여 kubectl 명령어를 테스트하여 정상 동작 하는지 확인 합니다.\n실행하면 아래와 같이 현재 동작 중인 노드 서버 리스트를 확인할 수 있습니다.\n\n&gt; kubectl get node --kubeconfig kubeconfig.yaml\n\n\n  \n  \n    \n  \n\n\n실행 명령어 단축\n위와 같은 kubectl 명령은 뒤쪽에 kubeconfig 환경 설정 파일까지 입력해야 해서 다소 불편한데, 간단하게 줄일 수 있는 방법이 있습니다.\n\n우선 만들어진 kubeconfig.yaml 파일을 .kube/ 디렉토리 아래에 config로 이름을 바꾸어 이동 혹은 복사 합니다.\n\n&gt; copy kubeconfig.yaml .kube\\config\n\n\n이렇게 하면 Kubectl을 사용 시 아래와 같이 –kuebeconfig 명령어 없이 사용 할 수 있습니다.\n\n&gt; kubectl get node\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  쿠버네티스 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8soverview\n    \n  \n  클러스터 이용 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8suse-cluster\n    \n  \n  kubectl 설치 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8sstart#Kubectl\n    \n  \n  Linux 환경에서 쿠버네티스 제어하기\n    \n      https://docs.3rdeyesys.com/containers/ncloud-containers-kubernetes-service-start-guide-linux.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lamp-apache-ssl-setting-rocky-linux-guide-html": {
						"id": "compute-ncloud-compute-lamp-apache-ssl-setting-rocky-linux-guide-html",
						"title": "Rocky Linux에서 Apache SSL 인증서 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-lamp-apache-ssl-setting-rocky-linux-guide.html",
						"content": "개요\nNcloud (네이버 클라우드) Rocky Linux (록키 리눅스) 서버에 Apache 웹서버를 설치하고, HTTPS 접속을 위한 SSL 인증서 설정하고, HTTP로 접속 시에 HTTPS로 리다이렉트하는 방법까지 정리해보겠습니다.\n\n테스트 환경\n테스트에 사용할 서버 환경은 다음과 같습니다.\n\n\n⁃ OS: Rocky Linux 8.6 \n⁃ 웹서버: Apache 2.4  \n⁃ 테스트 사이트:  rocky-https-test.com\n\n\n\n  \n  \n    \n  \n\n\n패키지 업데이트\n우선 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 해보겠습니다.\n\n~# dnf -y upgrade-minimal\n\n\n[dnf upgrade-minimal]과 [dnf update-minimal]의 차이점에 대해 [man dnf] 명령어로 매뉴얼을 살펴보면 Rocky Linux에서 패키지 업데이트를 위한 기본 명령어는 [dnf upgrade-minimal]이며, [dnf update-minimal]는 더 이상 사용되지 않는 별칭이라고 합니다.\n\n\n~# man dnf\n#--- 중략 ---#\nUpgrade-Minimal Command\n       Command: upgrade-minimal\n       Aliases: up-min\n       Deprecated aliases: update-minimal\n\n\n\n  \n  \n    \n  \n\n\nApache 웹서버 설치\n\n\n  Apache 버전 확인\n[Rocky Linux 8.6]에서 기본으로 지원하는 Apache 버전을 확인해보면 [Apache 2.4]인 것을 확인할 수 있습니다.\n\n\n~# dnf module list httpd\n\n\n\n  \n  \n    \n  \n\n\n\n  Apache 2.4 설치\n\n\n~# dnf -y install httpd\n\n\n\n  \n  \n    \n  \n\n\n\n  Apache 실행, 상태 확인\n설치를 마쳤으면 Apache를 실행하고 상태를 확인합니다.\n\n\n~# systemctl start httpd\n~# systemctl status httpd\n\n\n\n  \n  \n    \n  \n\n\n테스트용 웹사이트 생성\n테스트에 필요한 웹사이트 홈 디렉토리와 웹페이지를 생성합니다.\n\n~# mkdir -p  /ncloud/data/www/rocky-https-test.com/\n~# vim /ncloud/data/www/rocky-https-test.com/index.html\n\n&lt;!doctype html&gt;\n&lt;html lang=\"kr\"&gt;\n &lt;head&gt;\n  &lt;meta charset=\"UTF-8\"&gt;\n  &lt;title&gt;Rocky Linux HTTPS Test Site&lt;/title&gt;\n &lt;/head&gt;\n &lt;body&gt;\n    &lt;h1&gt;Rocky Linux HTTPS Test Site&lt;/h1&gt;\n &lt;/body&gt;\n&lt;/html&gt;\n\n\n  \n  \n    \n  \n\n\nApache 환경 설정 파일 생성\nrocky-https-test.com 웹사이트에 대한 Apache 환경 설정 파일을 생성하고, HTTP 접속에 필요한 80 포트용 설정을 추가합니다.\n\n~# vim /etc/httpd/conf.d/rocky-https-test.com.conf\n\n\n&lt;VirtualHost *:80&gt;\n    ServerName rocky-https-test.com\n    DocumentRoot /ncloud/data/www/rocky-https-test.com\n    DirectoryIndex index.htm index.html\n\n    CustomLog \"/var/log/httpd/rocky-https-test.com-access_log\" combined\n    ErrorLog  \"/var/log/httpd/rocky-https-test.com-error_log\"\n\n    &lt;Directory /ncloud/data/www/rocky-https-test.com&gt;\n        Options None\n        AllowOverride None\n        Require all granted\n    &lt;/Directory&gt;\n&lt;/VirtualHost&gt;\n\n\n  \n  \n    \n  \n\n\n\n  설정 파일을 저장한 후에 Apache 데몬을 재시작합니다.\n\n\n~# systemctl restart httpd\n\n\n\n  \n  \n    \n  \n\n\nhosts 파일 수정\n지금과 같이 테스트용으로 임의 설정한 도메인(rocky-https-test.com)으로 접속하게 될 경우에는 hosts 파일을 수정해야 합니다.\n실제 도메인을 사용할 경우에는 아래 과정이 필요 없기에 다음 단계로 바로 이동하시면 됩니다.\n\n윈도우 10에서 hosts 파일은 C:\\Windows\\System32\\drivers\\etc 에 존재하는데 직접 수정할 수가 없으므로 다음과 같은 단계를 거쳐야 합니다.\n\n\n  C:\\Windows\\System32\\drivers\\etc\\hosts 파일을 임의의 작업 폴더 (예: D:\\Work)로 복사합니다.\n  복사한 hosts 파일을 수정해서 123.456.789.123 rocky-https-test.com 처럼 접속할 IP 주소와 도메인을 추가합니다.\n  수정한 파일을 C:\\Windows\\System32\\drivers\\etc 위치로 덮어쓰기 합니다.\n  덮어쓰기 할 때 관리자 권한이 필요하다는 안내 메시지가 나타나면 [계속] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nACG (방화벽) 설정\n테스트로 생성했던 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다.\n\n\n  \n  \n    \n  \n\n\n\n  ACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n내부 테스트용 ACG 설정\n내부 테스트용 설정은 ACG 규칙 설정 화면에서 [Inbound] 탭에서 [myIp] 버튼을 클릭해서 현재 접속한 PC나 회사 IP를 입력하고, HTTP용 80포트와 HTTPS용 443포트를 추가합니다.\n\n\n  \n  \n    \n  \n\n\n라이브 서비스용 ACG 설정\n라이브 서비스용 설정은 접근 소스에는 [0.0.0.0/0]을 입력하고, 마찬가지로 HTTP용 80포트와 HTTPS용 443포트를 추가합니다.\n\n\n  \n  \n    \n  \n\n\nHTTP 접속 테스트\nACG 설정을 마쳤으면 웹브라우저에 테스트용 사이트의 주소 [http://rocky-https-test.com]으로 접속을 해보면 문제 없이 잘 접속되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nSSL 인증서 설정\n\nmod_ssl 설치\n\n~# dnf -y install mod_ssl\n\n\n  \n  \n    \n  \n\n\n\n  우선 인증서 저장용 디렉토리를 생성합니다.\n\n\n~# mkdir -p /root/ssl/\n\n\n\n  \n  \n    \n  \n\n\nSSL 테스트 인증서 생성\n여기서는 테스트용 인증서를 생성해서 사용하게 되는데, 정식 서비스의 경우 SSL 인증서 발급 기관에서 정식 인증서를 발급 받아 사용하게 됩니다.\n정식 인증서를 사용하는 경우에는 테스트 인증서 생성 단계는 건너띄고 다음 단계로 이동하시면 되겠습니다.\n\n~# openssl req -newkey rsa:2048 \\\n-nodes -keyout /root/ssl/rocky-https-test.com.key \\\n-x509 -days 365 -out /root/ssl/rocky-https-test.com.crt\n\n\n  \n  \n    \n  \n\n\n\n  인증서 파일이 제대로 생성되었는지 확인합니다.\n\n\n~# ls -al /root/ssl/\n\n\n  \n  \n    \n  \n\n\nHTTPS용 환경 설정 추가\n앞에서 생성했던 환경 설정 파일 [rocky-https-test.com.conf]에 HTTPS용 설정을 추가합니다.\n\n~# vim /etc/httpd/conf.d/rocky-https-test.com.conf\n\n&lt;VirtualHost *:443&gt;\n    ServerName rocky-https-test.com\n    DocumentRoot /ncloud/data/www/rocky-https-test.com\n    DirectoryIndex index.htm index.html\n\n    CustomLog \"/var/log/httpd/rocky-https-test.com-ssl-access_log\" combined\n    ErrorLog  \"/var/log/httpd/rocky-https-test.com-ssl-error_log\"\n\n    SSLEngine on\n    SSLProtocol -all +TLSv1.2 +TLSv1.3 \n    SSLHonorCipherOrder on\n    SSLCipherSuite PROFILE=SYSTEM\n\n    SSLCertificateFile /root/ssl/rocky-https-test.com.crt\n    SSLCertificateKeyFile /root/ssl/rocky-https-test.com.key\n\n    &lt;Directory /ncloud/data/www/rocky-https-test.com&gt;\n        Options None\n        AllowOverride None\n        Require all granted\n    &lt;/Directory&gt;\n&lt;/VirtualHost&gt;\n\n\n  \n  \n    \n  \n\n\n\n- SSLProtocol: SSL Protocol에 대한 설정은 [TLS v1.2], [TLS v1.3] 만 허용하고, 나머지 Protocol은 모두 거부하도록 설정했습니다. \n- 정식 인증서에서는 [SSLCertificateFile], [SSLCertificateKeyFile] 외에도 [SSLCertificateChainFile], [SSLCACertificateFile] 등의 키 설정이 필요하게 되는데, 자세한 내용은 인증서 발급 대행사에서 인증서를 발급 받을 때 포함되어 있는 가이드 문서를 참고하시면 됩니다.\n\n\n\n\n  설정 파일을 저장한 후에 Apache 데몬을 재시작합니다.\n\n\n~# systemctl restart httpd\n\n\n\n  \n  \n    \n  \n\n\nHTTPS 접속 테스트\n설정을 마쳤으면 웹브라우저에서 HTTPS로 [https://rocky-https-test.com]에 접속을 해보면 문제 없이 잘 접속되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n인증서 확인\nHTTPS로 테스트 사이트에 접속 후에 인증서를 확인해보면 위에서 테스트로 생성했던 정보가 제대로 설정되어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nHTTP 접속 시 HTTPS로 리다이렉트\n이제 HTTPS 설정까지 마쳤으니 HTTP로 접속하는 경우에 HTTPS로 리다이렉트 시키는 설정을 적용해보겠습니다.\n\n방법 - 1\n첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\n앞에서 설정한 HTTP용 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\n\n~# vim /etc/httpd/conf.d/rocky-https-test.com.conf\n\n&lt;VirtualHost *:80&gt;\n    ServerName rocky-https-test.com\n\n    Redirect permanent / https://rocky-https-test.com/\n    # 또는\n    # Redirect 301 / https://rocky-https-test.com/\n&lt;/VirtualHost&gt;    \n\n\n  \n  \n    \n  \n\n\n리다이렉트 여부 확인\n웹브라우저에서 [F12] 키로 개발자 모드로 변경한 후에 [http://rocky-https-test.com/]로 접속을 해보면 아래 스샷처럼 HTTP 301 상태코드를 반환하면서 [https://rocky-https-test.com/]로 리다이렉트된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n방법 - 2\n두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\n\n&lt;VirtualHost *:80&gt;\n    ServerName rocky-https-test.com\n\n    RewriteEngine On\n    RewriteCond %{HTTPS} !on\n    RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n&lt;/VirtualHost&gt; \n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Rocky Linux Apache Multiple Site 설정 가이드\n    \n      https://docs.rockylinux.org/guides/web/apache-sites-enabled/\n    \n  \n  Rocky Linux Apache with ‘mod_ssl’ 가이드\n    \n      https://docs.rockylinux.org/guides/web/mod_SSL_apache/"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lemp-nginx-install-setting-rocky-linux-guide-html": {
						"id": "compute-ncloud-compute-lemp-nginx-install-setting-rocky-linux-guide-html",
						"title": "Rocky Linux에서 NginX 설치, 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-lemp-nginx-install-setting-rocky-linux-guide.html",
						"content": "개요\nNcloud (네이버 클라우드) Rocky Linux (록키 리눅스) 서버에 NginX 최신 버전을 Package로 설치하고 기본 설정을 하는 방법에 대한 내용을 정리해보겠습니다.\n\n서버 환경\n\n\n⁃ OS: Rocky Linux 8.6 \n⁃ NginX: NginX 1.23.1  \n⁃ 테스트 사이트: nginx-test.com\n\n\n서버 준비\nNcloud 콘솔에서 Rocky Linux 8.6 서버를 아래와 같이 준비했습니다.\n\n\n  \n  \n    \n  \n\n\n패키지 업데이트\n우선 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 해보겠습니다.\n\n~# dnf -y upgrade-minimal\n\n dnf: Dandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 \nFedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n리포지토리 설정 파일 추가\nNginX 최신버전(mainline)을 설치하기 위해서는 epel-release 리포지토리 패키지가 필요하고, epel-release 리포지토리 패키지를 설치하기 위해서는 Extras 저장소 설정 파일이 필요합니다.\n우선, Extras 저장소 설정 파일을 준비합니다. 이미 생성되어 있는 경우에는 다음 단계로 넘어가도 되고, 그렇지 않을 경우 아래와 같은 내용으로 파일을 생성합니다.\n\n~# vi /etc/yum.repos.d/Rocky-Extras.repo\n\n\n# Rocky-Extras.repo\n\n[extras]\nname=Rocky Linux $releasever - Extras\n#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=extras-$releasever\nbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\ngpgcheck=1\nenabled=1\ncountme=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\n\n\n\n  \n  \n    \n  \n\n\nEPEL 저장소 패키지 설치\n다음으로 epel-release 저장소 패키지를 설치하겠습니다.\n\n~# dnf -y install epel-release\n\n\n\n  \n  \n    \n  \n\n\nNginX 버전 선택\n설치할 NginX 버전 버전을 선택합니다.\n\nNginX 버전 리스트\n우선, Ncloud Rocky Linux 8.6에서 지원하는 NginX 버전을 확인합니다.\n리스트를 살펴보면 1.14가 기본 버전인 것을 알 수 있습니다.\n\n~# dnf module list nginx\n\n\n\n  nginx 1.14 (default)\n  nginx 1.16\n  nginx 1.18\n  nginx 1.20\n  nginx mainline\n\n\n\n  \n  \n    \n  \n\n\n버전 활성화 정보 초기화\n다음으로 위에서 확인했던 nginx 버전 활성화 정보를 초기화 합니다. 현재 활성화 된 버전이 존재하느냐에 따라 나타나는 메시지가 다릅니다.\n\n~# dnf module reset nginx\n\n\n\n  활성화 된 버전이 없을 때\n\n\n  \n  \n    \n  \n\n\n\n  활성화 된 버전이 있을 때\n\n\n  \n  \n    \n  \n\n\nmainline 버전 활성화\n최신 버전인 mainline 버전을 활성화합니다.\n\n~# dnf module enable nginx:mainline\n\n\nNginX는 stable, mainline 두가지 버전이 있습니다. \nNginX의 공식 설명에 따르면 버그 수정이나 보안 패치 등은 항상 mainline 버전에 먼저 적용되기 때문에 mainline을 사용하는 것을 추천한다고 합니다. \nstable 버전을 사용하는 주된 경우는 third-party 모듈을 사용하고 있어서 신규 버전에서 호환성 문제가 발생할 가능성이 걱정될 때라고 합니다.\n\n\n  \n  \n    \n  \n\n\nNginX 설치\nNginX를 설치합니다. 설치된 버전은 다음과 같습니다.\n\n~# dnf -y install nginx\n~# nginx -v\n\n\n  NginX: 1.23.1\n\n\n\n  \n  \n    \n  \n\n\n디렉토리 설정\n다음으로 홈으로 사용할 디렉토리를 생성하고, 해당 디렉토리의 소유권을 설정하겠습니다.\n그리고, NginX가 정상 작동하는지 확인해보기 위해 설치시에 포함된 index.html을 포함한 파일들을 홈 디렉토리로 복사합니다.\n\n# 테스트 사이트 홈 디렉토리 생성\n~# mkdir -p /ncloud/data/www/nginx-test/\n\n# 해당 디렉토리에 nginx에 권한 부여\n~# chown -R nginx:nginx /ncloud/data/www/nginx-test\n\n# nginx 샘플 페이지를 사이트 디렉토리로 복사\n~# cp /usr/share/nginx/html/*.* /ncloud/data/www/nginx-test/\n\n# 복사된 파일들 확인\n~# ls -al /ncloud/data/www/nginx-test/\n\n\n  \n  \n    \n  \n\n\n환경 설정\n\n설정 파일 위치\nNginX 환경 설정 파일의 위치는 /etc/nginx/ 디렉토리입니다. tree 명령으로 해당 디렉토리에서 conf와 관련된 파일 리스트와 디렉토리 구조를 확인하면 다음과 같습니다.\n\n~# tree -P *conf* /etc/nginx/\n\n\n\n  \n  \n    \n  \n\n\n기본 설정 파일\n위에서 확인할 수 있는 파일들 중에서 기본 환경 설정 파일은 /etc/nginx/nginx.conf 입니다.\nnginx.conf 파일을 열어보면 아래와 같이 server {…}로 시작되는 사이트 설정에 관련된 부분도 있지만,\ninclude /etc/nginx/conf.d/*.conf 와 같이 conf.d 디렉토리에 있는 설정 파일을 모두 불러오도록 되어 있습니다.\n\n물론, 사이트 설정을 nginx.conf 파일에 직접 설정해도 되지만, 여러 개의 사이트를 설정해야 하는 경우도 생각해서 conf.d 디렉토리에 사이트 이름별로 환경 설정 파일을 별도로 만들어서 진행하도록 하겠습니다.\n\n~# vi /etc/nginx/nginx.conf\n\n\n\n  \n  \n    \n  \n\n\n기본 설정 주석 처리\nserver {…} 부분을 모두 주석 처리합니다.\n\n\n  \n  \n    \n  \n\n\n환경 설정 파일 생성\nnginx-test.com 이라는 도메인의 사이트 설정을 nginx-test.conf 설정 파일을 생성해서 저장합니다.\n\n~# vi /etc/nginx/conf.d/nginx-test.conf\n\n\n  server {\n    listen    80;\n    listen    [::]:80;\n\n    # 사이트 도메인 설정\n    server_name    nginx-test.com www.nginx-test.com;\n\n    # 홈 디렉토리, 기본 문서 설정\n    root      /ncloud/data/www/nginx-test;\n    index     index.html index.htm;\n\n    # 404 error 페이지 설정\n    error_page 404 /404.html;\n      location = /404.html {\n    }\n\n    # 50x error 페이지 설정\n    error_page 500 502 503 504 /50x.html;\n      location = /50x.html {\n      root    /ncloud/data/www/nginx-test;\n    }\n\n    # .htaccess 파일 접근 금지 설정\n    location ~ /\\.ht {\n      deny    all;\n    }\n}\n\n\n\n  \n  \n    \n  \n\n\nNginX 실행\n설정을 모두 마쳤으면 NginX를 시작하고 상태를 확인합니다.\n\n~# systemctl enable nginx\n~# systemctl start nginx\n~# systemctl status nginx\n\n\n  \n  \n    \n  \n\n\nhosts 파일 수정\n지금과 같이 테스트용으로 임의 설정한 도메인(nginx-test.com)으로 접속하게 될 경우에는 hosts 파일을 수정해야 합니다.\n실제 도메인을 사용할 경우에는 아래 과정이 필요 없기에 다음 단계로 바로 이동하시면 됩니다.\n\n윈도우 10에서 hosts 파일은 C:\\Windows\\System32\\drivers\\etc 에 존재하는데 직접 수정할 수가 없으므로 다음과 같은 단계를 거쳐야 합니다.\n\n\n  C:\\Windows\\System32\\drivers\\etc\\hosts 파일을 임의의 작업 폴더 (예: D:\\Work)로 복사합니다.\n  복사한 hosts 파일을 수정해서 123.456.789.123 nginx-test.com 처럼 접속할 IP 주소와 도메인을 추가합니다.\n  수정한 파일을 C:\\Windows\\System32\\drivers\\etc 위치로 덮어쓰기 합니다.\n  덮어쓰기 할 때 관리자 권한이 필요하다는 안내 메시지가 나타나면 [계속] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n사이트 접속\nNginX가 정상 작동하면 아래와 같이 서버 접속 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Rocky Linux NginX 설치 기본 가이드\n    \n      https://docs.rockylinux.org/guides/web/nginx-mainline/\n    \n  \n  Rocky Linux NginX Multi Site 설치 가이드\n    \n      https://docs.rockylinux.org/guides/web/nginx-multisite/"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-micro-type-server-create-vpc-html": {
						"id": "compute-ncloud-compute-micro-type-server-create-vpc-html",
						"title": "Ncloud VPC 환경에서 무료 서버(Micro Type) 이용하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-micro-type-server-create-vpc.html",
						"content": "개요\nNcloud (네이버 클라우드)는 체험 및 테스트 용도로 최초 결제 수단 등록 월부터 1년간 무료로 사용할 수 있는 Micro 타입 서버를 제공하고 있습니다. 전에는 Classic 환경에서만 이용할 수 있었는데, 최근 업데이트 이후 VPC 환경에서도 이용할 수 있게 되었기에, VPC 환경에서 무료 서버인 Micro 타입 서버를 생성하는 과정을 정리해보겠습니다.\n\nMicro 타입 서버 특징\n\n  스펙: vCPU 1개, 메모리 1GB\n  계정당 1대만 이용 가능\n  체험용으로 가용성 및 성능 보장 불가\n  거주지 국가가 한국인 경우만 제공\n  신규 가입 후 최초 결제 수단 등록 월부터 1년간 무료 제공, 1년이 지나면 월요금제로 과금\n  최초 결제 수단 등록 월은 포털 마이페이지 &gt; 결제수단 관리에서 확인\n  Network Interface는 1개만 이용 가능\n  3세대(g3) 서버로 KVM 하이퍼바이저 기반의 서버만 제공\n  기본 스토리지는 10 GB까지만 무료이며, 용량을 늘리거나 추가하는 스토리지의 경우 유료 과금\n\n\n서버 생성\n[VPC] 환경에서 서버(Server)를 생성하려면 사전에 [VPC]와 [Subnet]이 생성되어 있어야 하는데, 혹시 처음 [VPC] 환경에 접속하셔서 [VPC]와 [Subnet]이 존재하지 않는 경우는 아래 문서를 보고 미리 생성하고 오셔야 합니다.\n\n\nVPC 환경에서 서버 생성하는 방법 (VPC, Subnet 생성 포함)\n\n\nServer 서비스 위치\n[Server] 서비스는 [Console] - [Services] - [Compute]에 위치해 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  [Server] - [Server]에서 [서버 생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n서버 생성 콘솔 선택\nNcloud 서버 생성 콘솔화면은 신규 기능이 업데이트 되면서 2가지를 선택할 수 있습니다. Micro 타입 서버는 KVM 하이퍼바이저 기반의 서버이므로  [신규 콘솔 화면]으로 진행하겠습니다.\n\n\n  기존 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)를 생성할 수 있습니다.\n  신규 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)뿐만 아니라 KVM 기반 및 다양한 성능을 제공하는 기본 스토리지로 서버(g3)를 생성할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n서버 이미지 선택\nMicro 타입 서버를 생성하려면 하이퍼바이저 기준으로 [KVM] 서버 이미지를 선택하면 됩니다. 현재 Ncloud에서 제공되는 [KVM] 서버 이미지는 아래와 같이 [Rocky Linux 8.8], [Ubuntu 20.04], [CentOS 7.8] 이렇게 3가지 입니다. 여기서는 Ubuntu 20.04로 생성해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n서버 설정\n서버 설정 단계에서는 [VPC]와 [Subnet]을 선택하고  [서버 스펙]과 [요금제], [Network Interface], [공인 IP 할당 여부] 등을 선택하게 됩니다. 서버는 1년간 무료이지만, 공인 IP를 할당하게 되면 공인 IP 비용이 청구됩니다.\n\n\n  \n  \n    \n  \n\n\n스토리지 설정\nKVM 하이퍼바이저 기반인 Micro 타입서버는 기본 스토리지 10GB까지만 무료로 제공되며, 용량을 늘릴 경우 비용이 발생합니다.\n\n\n  \n  \n    \n  \n\n\n인증키 설정\n인증키 이름을 입력하고, [인증키 생성 및 저장] 버튼을 클릭해서 인증키를 로컬 PC에 다운로드 받아서 안전한 곳에 보관해야 합니다. 기존에 사용하고 있던 인증키가 있을 경우에는 [보유하고 있는 인증키 이용]을 선택하면 됩니다.\n\n 인증키: 인증키는 해당 서버의 관리자 비밀번호를 확인하는데 사용되므로 안전한 곳에 잘 보관해야 합니다.\n\n\n  \n  \n    \n  \n\n\n네트워크 접근 설정\n네트워크 접근은 [ACG]로 설정하게 되는데, ACG(Access Control Group)는 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스로, 서버에 별도의 복잡한 방화벽 구축없이 간단하게 서버에 대한 네트워크 접근 제어를 할 수 있습니다.\n[VPC]를 생성하면 자동으로 생성되는 기본 ACG를 선택하거나 별도로 생성한 ACG가 있을 경우 해당 ACG를 선택하면 됩니다. 적용할 ACG는 최대 3개까지 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 생성 완료\n모든 단계를 마치고 나면 아래와 같이 서버가 생성된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 접속\n생성된 서버에 접속해서 vCPU와 Memory 상태를 확인해보면 다음과 같습니다.\n\n~# grep -c processor /proc/cpuinfo\n~# free\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud 서버 접속 가이드\n    \n      https://guide.ncloud-docs.com/docs/server-access-vpc\n    \n  \n  Ncloud 서버 인증키 변경하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-change-authentication-key.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-06-21\n          문서 최초 생성\n        \n      \n        \n          2023-09-11\n          지원하는 서버 이미지 추가 내용 업데이트"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-nginx-client-ip-logging-guide-html": {
						"id": "compute-ncloud-compute-nginx-client-ip-logging-guide-html",
						"title": "Load Balancer에 연동된 NginX에서 Client IP 기록하고 확인하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-nginx-client-ip-logging-guide.html",
						"content": "개요\nNcloud (네이버 클라우드)에서 Load Balancer에 연동된 NginX 웹서버를 사용할 때 Load Balancer IP가 아닌 실제 Client IP를 기록하고 확인하는 방법을 알아보겠습니다.\n결론부터 이야기 하자면 NginX에서는 Apache와 달리 별도의 모듈 설치나 환경 설정 파일 수정 없이도 자동으로 실제 Client IP와 Load Balancer IP가 동시에 모두 기록됩니다. 어떻게 기록되는지 테스트 결과를 보면서 확인해보겠습니다.\n\n테스트 환경\n\n\n⁃ Server-1: CentOS 7.8 \n⁃ Server-2: Ubuntu 20.04 \n⁃ NginX: NginX 1.23.1  \n\n\n서버 준비\nNcloud 콘솔에서 CentOS 7.8, Ubuntu 20.04 두 대의 서버를 아래와 같이 준비했습니다.\n\nNginX를 설치하는 방법은 아래 문서를 참고하시기 바랍니다. \n- CentOS에 NginX 설치하기\n- Ubuntu에 NginX 설치하기\n\n\n\n  \n  \n    \n  \n\n\nLoad Balancer 준비\nLoad Balancer도 [Application Load Balancer]를 [10.0.4.0] 대역으로 설정해서 준비했습니다.\n\nApplication Load Blancer 의 생성 가이드는 아래 문서를 참고하시기 바랍니다. \n- VPC 환경에서 Application Load Balancer 생성하기\n\n\n  \n  \n    \n  \n\n\nAccess Log 확인\nNcloud의 상품인 [Cloud Log Analytics]에서 NginX의 로그를 확인해보면 아래와 같이 Log 내용에 앞쪽에는 [Load Balancer IP]가 기록되어 있고, 제일 뒤쪽에는 [실제 Client IP]가 기록되어 있는 것을 확인할 수 있습니다. 해당 서버들에는 오로지 NginX만 설치했고, 다른 모듈을 설치하거나 환경 설정 파일을 변경하지 않은 상태입니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Rocky Linux NginX 설치 기본 가이드\n    \n      https://docs.rockylinux.org/guides/web/nginx-mainline/\n    \n  \n  Rocky Linux NginX Multi Site 설치 가이드\n    \n      https://docs.rockylinux.org/guides/web/nginx-multisite/"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-admin-password-reset-html": {
						"id": "compute-ncloud-compute-server-admin-password-reset-html",
						"title": "Ncloud 서버 어드민 패스워드(관리자 비밀번호) 초기화하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-server-admin-password-reset.html",
						"content": "개요\nNcloud (네이버 클라우드) 서버의 [관리자 비밀번호] 즉, [어드민 패스워드]를 초기화하는 방법을 정리해보겠습니다.\n\n어드민 패스워드를 초기화하게 되는 경우는 다음과 같은 경우가 있습니다.\n\n  보안을 위해 주기적으로 비밀번호를 변경하는 경우\n  해킹이나 패스워드 유출 등이 의심되어 비밀번호를 변경해야 하는 경우\n  담당자 퇴사 등으로 비밀번호 변경이 필요한 경우\n\n\n비밀번호 확인\n비밀번호를 초기화 하기 전에 먼저 비밀번호를 확인하는 방법부터 알아보겠습니다.\n(Linux, Windows 서버 모두 동일합니다.)\n\n어드민 패스워드(관리자 비밀번호) 확인은 서버를 선택하고, [서버 관리 및 설정 변경] - [관리자 비밀번호 확인] 메뉴를 선택하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n[관리자 비밀번호]를 확인하려면 서버를 생성할 때 사용한 *.pem 형태의 인증키를 사용해야 합니다.\n\n\n  \n  \n    \n  \n\n\npem 인증키를 사용하면 아래와 같이 비밀번호를 확인할 수 있습니다.\n\nLinux\n\n  \n  \n    \n  \n\n\nWindows\n\n  \n  \n    \n  \n\n\n비밀번호 초기화\n위에서 확인해본 어드민 패스워드(관리자 비밀번호)를 초기화 하려면, 먼저 서버를 정지시키고 [서버 관리 및 설정 변경] - [관리자 비밀번호 초기화] 메뉴를 선택하면 됩니다.\n\n[관리자 비밀번호 초기화] 기능은 마스터 계정에서만 가능합니다. 서브 어카운트에서는 메뉴가 활성화 되지 않습니다.\n\n[관리자 비밀번호 초기화] 기능은 서버를 [정지] 시킨 상태에서만 가능합니다.\n\n\n  \n  \n    \n  \n\n\n사용자 확인\n[관리자 비밀번호 초기화]를 하려면 먼저 아래와 같이 접속 계정의 비밀번호를 입력해서 사용자 확인을 먼저 해야 합니다.\n\n\n  \n  \n    \n  \n\n\n인증키 확인\n비밀번호를 초기화 할 때에도 확인할 때와 마찬가지로 pem 인증키를 사용해야 합니다.\n\n\n  \n  \n    \n  \n\n\n초기화\n인증키를 확인하고 나면 아래와 같이 비밀번호가 초기화 되고, 정지 상태인 서버를 [지금 시작]할 것인지, [나중에 시작]할 것인지 묻는 창이 나타납니다. \n여기서는 [지금 시작] 버튼을 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n서버 시작\n[지금 시작] 버튼을 클릭하면 아래와 같이 정지되어 있던 서버가 다시 시작됩니다.\n\n\n  \n  \n    \n  \n\n\n초기화된 비밀번호 확인\n서버가 시작된 후에 다시 [관리자 비밀번호 확인]을 해보면 아래와 같이 비밀번호가 초기화 되고 새로운 비밀번호가 할당된 것을 확인할 수 있습니다.\n\nLinux\n\n  \n  \n    \n  \n\n\nWindows\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud 서버 정보 확인 및 서버 관리 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-server-manage-vpc\n    \n  \n  Ncloud 서버 인증키 변경하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-change-authentication-key.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-change-authentication-key-html": {
						"id": "compute-ncloud-compute-server-change-authentication-key-html",
						"title": "Ncloud 서버 인증키 변경하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-server-change-authentication-key.html",
						"content": "개요\nNcloud (네이버 클라우드) 서버의 인증키는 서버의 [관리자 비밀번호 확인], [비밀번호 초기화] 등에 꼭 필요한 *.pem 형태의 파일입니다. \n그런데 만약 인증키를 분실했을 경우에는 다른 인증키로 변경해야 하는데, 어떻게 변경하는지 정리해보겠습니다.\n\n인증키 변경\n인증키를 변경하려면 먼저 서버를 정지시키고, 서버를 선택한 후에 [서버 관리 및 설정 변경] - [서버 인증키 변경] 메뉴를 선택하면 됩니다.\n\n[서버 인증키 변경] 기능은 마스터 계정에서만 가능합니다. 서브 어카운트에서는 메뉴가 활성화 되지 않습니다.\n\n[서버 인증키 변경] 기능은 서버를 [정지] 시킨 상태에서만 가능합니다.\n\n\n  \n  \n    \n  \n\n\n사용자 확인\n인증키를 변경하려면 먼저 사용자 확인을 해야 하므로, [인증 메일 발송] 버튼을 클릭하면 등록된 메일주소로 인증 메일이 발송됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n인증 메일 확인\n메일을 열어보면 아래와 같이 인증 메시지를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n인증 메시지 입력\n메일에서 확인한 인증 메시지를 입력하면 인증이 완료됩니다.\n\n\n  \n  \n    \n  \n\n\n인증키 선택\n변경할 인증키는 기존에 있는 다른 인증키를 선택할 수도 있고, 새로운 인증키를 생성할 수도 있습니다.\n여기서는 [새로운 인증키]를 생성해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n인증키 생성 및 저장\n새로운 인증키 이름을 입력하고 [인증키 생성 및 저장] 버튼을 클릭하면 인증키가 다운로드 됩니다.\n인증키 다운로드 완료 후에 [변경] 버튼을 클릭하면 인증키가 변경됩니다.\n\n\n  \n  \n    \n  \n\n\n인증키 변경 완료\n서버 인증키가 변경되고 나면 정지 상태인 서버를 [지금 시작]할 것인지, [나중에 시작]할 것인지 묻는 창이 나타납니다.\n여기서는 [지금 시작] 버튼을 선택하겠습니다.\n\nLinux\n\n  \n  \n    \n  \n\n\nWindows\n\n  \n  \n    \n  \n\n\n비밀번호 확인\n변경된 인증키로 서버 관리자 비밀번호를 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\nLinux\n\n  \n  \n    \n  \n\n\nWindows\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud 서버 정보 확인 및 서버 관리 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-server-manage-vpc\n    \n  \n  Ncloud 서버 관리자 비밀번호 초기화하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-admin-password-reset.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-connect-by-ssh-key-html": {
						"id": "compute-ncloud-compute-server-connect-by-ssh-key-html",
						"title": "Ncloud 서버에 SSH Key를 이용해 접속하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-server-connect-by-ssh-key.html",
						"content": "개요\n리눅스 서버에 접속하는 방법은 [아이디-패스워드]로 접속하는 방법과 [SSH Key]를 이용해 접속하는 방법이 있습니다.\nNcloud (네이버 클라우드)에서는 기본으로 [아이디-패스워드]로 접속하는 방법을 제공하고 있으므로 여기서는 다른 방법인 [SSH Key]를 이용해 서버에 접속하는 방법을 정리해보게겠습니다.\n\n테스트 서버 준비\n테스트로 사용할 서버는 [Rocky Linux 8.6] 서버로 생성했습니다.\n\n\n  \n  \n    \n  \n\n\nSSH Key 생성\n우선 Ncloud 제공하는 [아이디-패스워드] 방식으로 서버에 접속한 후, 아래의 명령으로 SSH key를 생성합니다.\n\n~# ssh-keygen -t rsa -m pem\n\n\n\n  \n  \n    \n  \n\n\n상세 설명\n위의 SSH Key 생성 화면에서 몇가지를 좀 더 자세히 살펴보겠습니다.\n\n\n  Key 저장 위치 설정\n아래 스샷처럼 생성된 [SSH Key]를 어느 위치에 저장할 것인지 확인하는 단계입니다. 아무것도 입력하지 않고 Enter 키를 입력하면 기본 저장 위치인 [/root/.ssh/id_rsa]에 저장됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Key 파일 암호 설정\n보안을 좀 더 강화하려면 [SSH Key]를 사용할 때 암호(passphrase)를 입력하도록 설정할 수 있습니다. 아무것도 입력하지 않으면 암호 없이 사용하게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n생성된 Key 확인\nKey가 생성된 디렉토리로 이동해서 살펴보면 [id_rsa], [id_rsa.pub] 이렇게 2개의 파일이 생성된 것을 확인할 수 있습니다.\n\n\n  id_rsa: Private Key\n  id_rsa.pub: Public Key\n\n\n\n  \n  \n    \n  \n\n\nKey 파일명 변경\nmv 명령어를 사용해 [SSH Key] 인증에서 사용할 파일명으로 변경 합니다.\n\n~# mv id_rsa id_rsa.pem\n~# mv id_rsa.pub authorized_keys\n\n\n  \n  \n    \n  \n\n\nPrivate Key 복사\n위에서 생성된 [Private Key]인 [id_rsa.pem] 파일을 로컬 PC로 가져오는 방법은 크게 2가지가 있는데 편하신 방법을 사용하면 되겠습니다.\n\n\n  암호화 텍스트로 구성된 파일의 내용을 복사해서 로컬 PC 텍스트 편집기에 붙여넣고 새로운 파일로 저장하는 방법\n  [WinSCP], [FileZilla] 등의 SFTP 프로그램을 이용해서 파일을 로컬 PC로 전송하는 방법\n\n\n방법 1: 텍스트 복사\n[id_rsa.pem] 파일은 암호화된 텍스트로 구성된 파일이므로 파일 내용을 확인해서 복사합니다.\n\n\n  \n  \n    \n  \n\n\n\n  복사한 내용을 로컬 PC의 텍스트 편집기에 붙여 넣고 저장합니다.\n\n\n\n  \n  \n    \n  \n\n\n방법 2: WinSCP 접속\n[WinSCP]로 서버에 접속하면 처음에는 파일이나 디렉토리가 전혀 보이지 않습니다. 즉, 인증키 파일이 저장된 [.ssh] 디렉토리가 숨겨진 디렉토리이기 때문입니다.\n\n\n  \n  \n    \n  \n\n\n\n  숨겨진 디렉토리를 확인하기 위해 [옵션] - [설정] 메뉴에 들어갑니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [설정] 창에서 [패널]을 선택하면 위쪽에 [숨김 파일 표시] 옵션이 있는데 이 옵션을 체크하고 [확인] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\nKey 전송\n[숨김 파일 표시] 옵션을 체크하면 아래와 같이 [.ssh] 디렉토리를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  [.ssh] 디렉토리에 들어가서 [id_rsa.pem] 파일을 로컬 PC로 전송합니다.\n\n\n\n  \n  \n    \n  \n\n\nPPK 파일 변환\n[SSH Key] 인증으로 서버에 접속할 때 주로 사용하는 프로그램이 [PuTTY]인데, [Putty]에서는 [PEM] 파일이 아니라 [PPK]파일을 사용하기 때문에 [PEM] 파일을 [PPK]파일로 변환해야 합니다. 이럴 때 사용하는 것이 [PuTTY Key Generator] 즉, [PuTTYgen]인데, [PuTTY] 통합 설치 파일에 포함되어 있습니다.\n\nPuTTY 설치\n[PuTTYgen] 사이트에 접속해서 [PuTTY]를 다운로드 받고 설치합니다.\n\n  https://www.puttygen.com/\n\n\n\n  \n  \n    \n  \n\n\n\n  설치가 완료되었으면 로컬 PC에서 [PuTTYgen]을 찾아서 실행합니다.\n\n\n\n  \n  \n    \n  \n\n\nKey 변환\n우선 위에서 로컬 PC로 전송받았던 [id_rsa.pem]을 파일을 불러오기 위해 [PuTTYgen] 화면에서 가운데에 있는 [Load] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  파일 선택창에서 파일 확장자를 [All Files]로 선택 하고 [id_rsa.pem] 파일을 선택하고 [열기] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Notice] 팝업에서 [확인] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Save private key] 버튼을 눌러 PPK 파일로 변환합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Key 파일에 암호 즉, [passphrase]가 없을 경우 경고 팝업이 뜨는데 [예] 버튼을 클릭해서 다음 단계로 넘어 갑니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  파일명을 입력 후 [저장] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n서버 접속\n이제 위에서 변환 저장한 Key 파일로 서버에 접속해보겠습니다.\n\nPuTTY 설정\n우선, [PuTTY] 프로그램을 실행합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [Host Name (or IP address)]에 접속할 서버의 IP를 입력합니다. 또는 [계정@서버IP] 형식으로 미리 로그인 계정을 입력해두는 방법도 있습니다. \n(예: 123.456.789.012 또는 root@123.456.789.012)\n\n\n\n  \n      \n          IP만 입력 \n      \n  \n      \n          계정@IP 입력 \n      \n  \n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n\n\n\n  좌측의 Category에서 [Conncetion] - [SSH] - [Auth] - [Credentials] 설정 메뉴에서 [Private key file for authentication] 항목에 위에서 변환 저장했던 파일을 선택하기 위해 [Browser] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  위에서 저장했던 test-key.PPK 파일을 선택 합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  다음으로 아래쪽에 있는 [Open] 버튼을 클릭해서 서버에 접속합니다.\n\n\n\n  \n  \n    \n  \n\n\n서버 접속 완료\n그러면 아래와 같이 비밀번호 입력 없이 [Authenticating with public key “imported-openssh-key”]라는 메시지가 나타나면서 서버에 접속됩니다.\n(PuTTY 접속 설정 [Host Name]에 IP만 입력했을 경우에는 [login as]에 로그인 계정을 입력해야 합니다.)\n\n\n  \n      \n          IP만 입력 \n      \n  \n      \n          계정@IP 입력 \n      \n  \n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n\n\n참고 URL\n\n  Ncloud 서버 접속 가이드\n    \n      https://guide.ncloud-docs.com/docs/server-access-vpc\n    \n  \n  Ncloud 서버 인증키 변경하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-change-authentication-key.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-http-to-https-rocky-linux-html": {
						"id": "compute-ncloud-compute-server-http-to-https-rocky-linux-html",
						"title": "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Rocky Linux",
						"categories": "",
						"url": " /compute/ncloud-compute-server-http-to-https-rocky-linux.html",
						"content": "개요\nNcloud (네이버 클라우드) Rocky Linux (록키 리눅스) 서버 Apache 웹서버에서 http 접속 시에 https로 강제 리다이렉트 시키는 방법은 크게 2가지가 있는데 각각에 대해 정리해보겠습니다.\n\n테스트 환경\n테스트에 사용한 서버 환경은 다음과 같습니다.\n\n\n⁃ OS: Rocky Linux 8.6 \n⁃ 웹서버: Apache 2.4  \n⁃ 테스트 사이트:  rocky-https-test.com\n\n\n방법1 : Redirect 옵션\n첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\nHTTP 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\n\n&lt;VirtualHost *:80&gt;\n    ServerName 사이트_도메인\n\n    Redirect permanent / https://사이트_도메인/    \n&lt;/VirtualHost&gt;    \n\n\n  \n  \n    \n  \n\n\n\n  301 리다이렉트: Redirect permanent / https://사이트_도메인/\n  302 리다이렉트: Redirect / https://사이트_도메인/\n  301 리다이렉트: Redirect 301 / https://사이트_도메인/\n  302 리다이렉트: Redirect 302 / https://사이트_도메인/\n  307 리다이렉트: Redirect 307 / https://사이트_도메인/\n  308 리다이렉트: Redirect 308 / https://사이트_도메인/\n\n\n방법2 : RewirteRule 옵션\n두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\n\n&lt;VirtualHost *:80&gt;\n    ServerName 사이트_도메인\n\n    RewriteEngine On\n    RewriteCond %{HTTPS} !on\n    RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n&lt;/VirtualHost&gt; \n\n\n  \n  \n    \n  \n\n\n위 설정 중에서 [R=301,L] 이 부분에 원하는 상태코드를 입력하면 됩니다.\n\n  301 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n  302 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=302,L]\n  307 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=307,L]\n  \n    308 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=308,L]\n  \n  설정 파일을 저장한 후에 Apache 데몬을 재시작합니다.\n\n\n~# systemctl restart httpd\n\n\n\n  \n  \n    \n  \n\n\n리다이렉트 여부 확인\n웹브라우저에서 [F12] 키로 개발자 모드로 변경한 후에 [http]로 접속을 해보면 아래 스샷처럼 HTTP 301 상태코드를 반환하면서 [https]로 리다이렉트된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nSSL 모듈 설치\n리다이렉트 설정과 관계없이 SSL 인증서를 설정하고 HTTPS 접속을 하려면 [mod_ssl]가 설치되어 있어야 하는데, 혹시나 설치되어 있지 않다면 설치하셔야 합니다.\n\n~# dnf -y install mod_ssl\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Rocky Linux에서 Apache SSL 인증서 설정하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-lamp-apache-ssl-setting-rocky-linux-guide.html\n    \n  \n  Rocky Linux Apache with ‘mod_ssl’ 가이드\n    \n      https://docs.rockylinux.org/guides/web/mod_SSL_apache/"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-rocky-linux-guide-html": {
						"id": "compute-ncloud-compute-server-rocky-linux-guide-html",
						"title": "Ncloud에서 제공하는 록키 리눅스(Rocky Linux) 서버 소개",
						"categories": "",
						"url": " /compute/ncloud-compute-server-rocky-linux-guide.html",
						"content": "개요\nRocky Linux (록키 리눅스)는 CentOS의 서비스 지원 종료로 대안으로 떠오른 CentOS 기반의 리눅스 OS입니다.\nNcloud (네이버 클라우드)는 이 록키 리눅스의 핵심 파트너로 선정되어 국내에서 록키 리눅스 인프라와 기술지원을 위해 협력해왔고, 드디어 Ncloud 콘솔에서 록키 리눅스를 제공하기 시작했기에 간단하게 소개해보려고 합니다.\n\n제공 버전\nNcloud에서는 현재 Rocky Linux 8.6 버전을 VPC 환경에서 제공하고 있습니다.\n\n\n  \n  \n    \n  \n\n\n설치할 소프트웨어\n록키 리눅스 서버를 실행하고 보통 자주 사용하게 되는 아래의 소프트웨어들을 설치하고 확인해보겠습니다.\n\n  Apache\n  PHP\n  NGINX\n  MariaDB (MySQL)\n\n\n접속 화면\n서버를 생성하고 접속하면 아래와 같이 Ncloud 로고가 크게 표시된 화면을 볼 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n패키지 업데이트\n우선 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 해보겠습니다.\n\n~# dnf -y upgrade-minimal\n\n dnf: Dandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 \nFedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nApache, PHP 설치\n설치할 소프트웨어 중에서 Apache와 PHP를 동시에 설치해보겠습니다.\n\n~# dnf -y install httpd php\n\n\n설치된 버전은 다음과 같습니다.\n\n  Apache: 2.4.37\n  PHP: 7.2.24\n\n\n\n  \n  \n    \n  \n\n\n접속화면\n설치 완료 후에 웹브라우저로 접속해보면 다음과 같이 Apache 로고가 포함된 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nPHP 버전 리스트\nNcloud Rocky Linux 8.6에서 지원하는 PHP 버전은 다음과 같이 확인해볼 수 있습니다.\n리스트를 확인해보면 7.2버전이 기본이고, 현재 활성화된 버전도 7.2버전인 것을 알 수 있습니다.\n\n~# dnf module list php\n\n\n\n  PHP 7.2 (default)\n  PHP 7.3\n  PHP 7.4\n  PHP 8.0\n\n\n\n  \n  \n    \n  \n\n\nPHP 버전 변경\n기본으로 설치된 7.2 버전에서 다른 버전으로 변경하는 방법에 대해 알아보겠습니다. 여기서는 8.0으로 변경해보겠습니다.\n\n버전 활성화 정보 초기화\n우선 위에서 확인했던 php 버전 활성화 정보를 초기화 합니다.\n\n~# dnf module reset php\n\n\n\n  \n  \n    \n  \n\n\nPHP 8.0 활성화\n다음으로 8.0 버전을 활성화 합니다.\n\n~# dnf module enable php:8.0\n\n\n\n  \n  \n    \n  \n\n\nPHP 8.0 설치\n마지막으로 8.0 버전을 설치하고 버전을 확인해봅니다.\n\n~# dnf -y install php\n~# php -v\n\n\n\n  \n  \n    \n  \n\n\nNginX 설치\n다음으로 NginX 최신버전(mainline)으로 설치해보겠습니다.\nNginX 최신버전(mainline)을 설치하기 위해서는 epel-release 리포지토리 패키지가 필요하고, epel-release 리포지토리 패키지를 설치하기 위해서는 Extras 저장소 설정 파일이 필요합니다.\n\n리포지토리 설정 파일 추가\n우선, Extras 저장소 설정 파일 준비합니다. 이미 생성되어 있는 경우에는 다음 단계로 넘어가도 되고, 그렇지 않을 경우 아래와 같은 내용으로 파일을 생성합니다.\n\n~# vi /etc/yum.repos.d/Rocky-Extras.repo\n\n\n# Rocky-Extras.repo\n\n[extras]\nname=Rocky Linux $releasever - Extras\n#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=extras-$releasever\nbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\ngpgcheck=1\nenabled=1\ncountme=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\n\n\n\n  \n  \n    \n  \n\n\nEPEL 리포지토리 패키지 설치\n다음으로, NginX 최신 버전을 설치하기 위해 epel-release 리포지토리 패키지를 설치하겠습니다.\n\n~# dnf -y install epel-release\n\n\n\n  \n  \n    \n  \n\n\nNginX 버전 리스트\n위 준비사항이 모두 완료되었으면, Ncloud Rocky Linux 8.6에서 지원하는 NginX 버전을 확인합니다.\n리스트를 살펴보면 1.14가 기본 버전이고, 현재 활성화된 버전도 1.14인 것을 알 수 있습니다.\n\n~# dnf module list nginx\n\n\n\n  nginx 1.14 (default)\n  nginx 1.16\n  nginx 1.18\n  nginx 1.20\n  nginx mainline\n\n\n\n  \n  \n    \n  \n\n\n버전 활성화 정보 초기화\n우선 위에서 확인했던 nginx 버전 활성화 정보를 초기화 합니다.\n혹시 활성화된 버전이 없을 경우에는 별다른 변화 없이 과정이 완료됩니다.\n\n~# dnf module reset nginx\n\n\n\n  \n  \n    \n  \n\n\nmainline 버전 활성화\n최신 버전인 mainline 버전을 활성화합니다.\n\n~# dnf module enable nginx:mainline\n\n\n  \n  \n    \n  \n\n\n설치\nNginX 설치합니다. 설치된 버전은 다음과 같습니다.\n\n~# dnf -y install nginx\n~# nginx -v\n\n\n  NGINX: 1.23.1\n\n\n\n  \n  \n    \n  \n\n\n접속화면\n설치 완료 후에 nginx를 실행 시키고, 웹브라우저로 접속해보면 다음과 같이 NGINX 로고가 포함된 화면을 확인할 수 있습니다.\n\n~# systemctl enable nginx\n~# systemctl start nginx\n\n\n\n  \n  \n    \n  \n\n\nMariaDB (MySQL) 설치\n\nMariaDB 버전 리스트\n우선, Ncloud Rocky Linux 8.6에서 지원하는 MariaDB 버전을 확인합니다.\n리스트를 살펴보면 10.3이 기본 버전인 것을 알 수 있습니다.\n\n~# dnf module list mariadb\n\n\n\n  mariadb 10.3 (default)\n  mariadb 10.5\n\n\n\n  \n  \n    \n  \n\n\n설치\nRocky Linux에서는 기본 DB가 MariaDB이고, 설치할 때도 [mariadb-server]로 설치하게 됩니다.\n여기서는 기본 버전으로 설치하겠습니다.\n\n~# dnf -y install mariadb-server\n\n\n\n  \n  \n    \n  \n\n\nMariaDB 데몬을 시작합니다.\n그런데 자세히 보시면 생성된 symlink가 [mysql.service]인 것을 확인할 수 있습니다. 즉, MariaDB를 실행할 때는 [mysql] 명령을 입력하면 된다는 뜻입니다.\n\n~# systemctl enable mariadb\n~# systemctl start mariadb\n\n\n\n  \n  \n    \n  \n\n\nDB 접속\n[mysql] 명령을 입력하면 아래와 같이 MariaDB 서버에 접속됩니다.\n설치된 DB 서버 버전은 다음과 같습니다.\n\n  MariaDB: 10.3.32\n\n\n~# mysql\n\n\n\n  \n  \n    \n  \n\n\n웹 콘솔\nRocky Linux는 웹브라우저에서 서버에 접속해서 서버를 관리할 수 있는 웹 콘솔을 제공하는데, 처음 서버에 접속했던 콘솔화면을 보면 아래와 같이 웹 콘솔을 활성화하는 방법이 안내되어 있습니다.\n\n\n  \n  \n    \n  \n\n\n아래 명령어를 입력하면 [9090] 포트로 접속할 수 있는 웹 콘솔이 활성화됩니다.\n~# systemctl enable --now cockpit.socket\n\n\n  \n  \n    \n  \n\n\n웹 콘솔 접속\n먼저, ACG에서 [9090] 포트를 오픈하고, [https://{서버 IP}:9090]으로 접속하면 아래와 같은 화면을 볼 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n웹 콘솔 화면\n웹 콘솔에 접속하면 서버 상태와 시스템 정보, CPU-메모리 사용량 등을 확인할 수 있고, 그 외에도 여러 가지 기능을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n버전 활성화 오류 해결 방법\n[dnf module enable ] 명령으로 다른 버전을 활성화하려고 할 때 아래와 같은 오류가 발생하는 경우가 있습니다.  \n오류 메시지 하단에 보면 [**dnf module reset **] 명령을 입력하면 해결된다 합니다.\n\n Error: It is not possible to switch enabled streams of a module unless explicitly enabled via configuration option module_stream_switch. \nIt is recommended to rather remove all installed content from the module, and reset the module using ‘dnf module reset &lt;module_name&gt;’ command. After you reset the module, you can install the other stream.\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n명령을 입력하고 처리가 완료되면 [dnf module enable &lt;module_name&gt;:&lt;module_version&gt;] 명령을 다시 입력하면 됩니다.\n#예시\n~# dnf module reset php\n~# dnf module reset nginx\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Rocky Linux 공식 가이드\n    \n      https://docs.rockylinux.org/guides/\n    \n  \n  Rocky Linux Apache 설정\n    \n      https://docs.rockylinux.org/guides/web/apache-sites-enabled/\n    \n  \n  Rocky Linux NGINX 설정\n    \n      https://docs.rockylinux.org/guides/web/nginx-multisite/\n    \n  \n  Rocky Linux MariaDB 설치\n    \n      https://docs.rockylinux.org/guides/database/database_mariadb-server/"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-rocky-linux-kvm-hypervisor-repository-mirror-site-error-troubleshooting-html": {
						"id": "compute-ncloud-compute-server-rocky-linux-kvm-hypervisor-repository-mirror-site-error-troubleshooting-html",
						"title": "Ncloud KVM Hypervisor 타입의 Rocky Linux 서버 Repository 미러 사이트 오류 문제 해결 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-server-rocky-linux-kvm-hypervisor-repository-mirror-site-error-troubleshooting.html",
						"content": "개요\nNcloud (네이버 클라우드)에서 KVM Hypervisor 타입의 록키 리눅스(Rocky Linux) 8.8 서버를 제공하고 있는데, 서버를 생성하고 나서 Apache, PHP 등의 패키지를 설치할 때 패키지 다운로드 사이트 또는 미러 사이트에서 8.8 버전에 대한 패키지 정보를 찾을 수 없다는 메시지가 나타나면서 패키지를 설치할 수 없는 경우가 있습니다. \nXEN Hypervisor 타입의 서버에서는 문제가 없는데 왜 KVM Hypervisor 타입 서버에서만 이런 문제가 생기는지와 어떻게 하면 해결할 수 있는지를 정리해보겠습니다.\n\n오류 상황\n콘솔에서 서버를 생성한 후에 아무 것도 하지 않고 테스트로 Apache를 설치해보려고 했는데, 오류 메시지가 나타나면서 설치를 할 수 없었습니다. 또한 Extras 리포지토리 미러 사이트도 Ncloud 내부 서버가 아닌 록키 리눅스 공식 미러 사이트로 연결하려고 시도한 것을 확인할 수 있습니다.\n\n이때, 혹시 외부와 통신이 안되어서 그런 것이 아닐까 오해할 수 있는데, 아래 오류 메시지를 보면 미러 사이트에 접속할 수 없다는 것이 아니고, 파일을 찾을 수 없다는 404 에러 메시지인 것을 알 수 있습니다. 즉, 외부 통신은 아무 문제 없다는 것입니다.\n\n~# dnf -y install httpd\n\nRocky Linux 8.8 - Extras                                 501  B/s | 3.3 kB     00:06\nErrors during downloading metadata for repository 'extras':\n  - Status code: 404 for https://rocky-linux-asia-east2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 35.241.40.125)\n  - Status code: 404 for https://rocky-linux-asia-south2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.149.203.6)\n  - Status code: 404 for https://rocky-linux-asia-northeast3.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 35.186.196.188)\n  - Status code: 404 for https://rocky-linux-asia-northeast1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.160.117.186)\n  - Status code: 404 for https://rocky-linux-me-west1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.149.26.62)\n  - Status code: 404 for https://rocky-linux-asia-east1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 35.186.202.231)\n  - Status code: 404 for https://rocky-linux-asia-southeast1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.160.39.155)\n  - Status code: 404 for https://rocky-linux-asia-southeast2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.111.41.84)\n  - Status code: 404 for https://rocky-linux-asia-northeast2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.107.160.108)\n  - Status code: 404 for https://rocky-linux-asia-south1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.120.3.13)\nError: Failed to download metadata for repo 'extras': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\n\n\n  \n  \n    \n  \n\n\n외부 통신이 되지 않는 경우\n외부 통신이 되지 않는 경우는 아래와 같이 더 이상 진행이 되지 않고 계속 멈춰있는 상태가 되므로 여기서 다뤄보는 문제와는 관계가 없습니다.\n\n\n  \n  \n    \n  \n\n\n해결 방법-1\n첫번째 방법은 패키지를 설치할 때 미러 사이트 주소에서 404 에러가 발생하는 [Extras] 저장소를 비활성화하는 옵션을 적용하는 방법입니다.\n\n~# dnf -y install httpd --disablerepo=extras\n\n\n\n  \n  \n    \n  \n\n\n해결 방법-2\n두번째 방법은 [Rocky-Extras.repo] 리포지토리 설정파일의 주소를 Ncloud 내부 서버로 변경하는 방법입니다.\n\n# vim /etc/yum.repos.d/Rocky-Extras.repo\n\n# Rocky-Extras.repo\n\n#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=extras-$releasever\n#baseurl=http://dl.rockylinux.org/$contentdir/$releasever/extras/$basearch/os/\n\nbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\n\n\n\n  \n  \n    \n  \n\n\n\n  주소 변경 후에 아파치를 설치해보면 문제 없이 잘 설치 되는 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nKVM vs XEN\n그런데 XEN 하이퍼바이저 타입의 서버에서는 아무 문제 없이 설치가 잘되는데 왜 KVM 하이퍼바이저 타입의 서버에서만 문제가 생기는 것인지 궁금해서 두 타입의 서버의 리포지토리 파일들을 비교해봤습니다.\n\nKVM 타입\n우선, 문제가 발생한 KVM 하이퍼바이저 타입의 서버에서 리포지토리 파일의 리스트를 확인해봤습니다.\n리스트에는 [AppStream], [BaseOS], [Extras] 리포지토리 파일 뿐만 아니라 다수의 파일이 존재하는 것을 알 수 있습니다.\n\n~# ls -al /etc/yum.repos.d/\n\nRocky-AppStream.repo\nRocky-BaseOS.repo\nRocky-Debuginfo.repo\nRocky-Devel.repo\nRocky-Extras.repo\nRocky-HighAvailability.repo\nRocky-Media.repo\nRocky-NFV.repo\nRocky-Plus.repo\nRocky-PowerTools.repo\nRocky-ResilientStorage.repo\nRocky-RT.repo\nRocky-Sources.repo\n\n\n\n  \n  \n    \n  \n\n\nXEN 타입\n다음으로, 문제가 없는 XEN 하이퍼바이저 타입의 서버에서 리포지토리 파일의 리스트를 확인해봤습니다.\n그런데, 여기는 [AppStream], [BaseOS] 단 두가지의 리포지토리 파일만 존재하는 것을 알 수 있었습니다.\n\n~# ls -al /etc/yum.repos.d/\n\nRocky-AppStream.repo\nRocky-BaseOS.repo\n\n\n  \n  \n    \n  \n\n\n해결 방법-3\n세번째 해결 방법은 위에서 확인했 듯이 [/etc/yum.repos.d/] 경로에 있는 리포지토리 파일 리스트에서 [AppStream], [BaseOS] 두가지만 남겨두고 나머지 파일들은 다른 곳에 백업하고 나서 지우면 이상 없이 패키지 설치가 가능합니다.\n\n\n  \n  \n    \n  \n\n\n원인 분석\n원인을 찾기 위해 처음에 문제가 생겼을 때 나타났던 오류 메시지에서 리포지토리 미러사이트 주소를 하나 선택해서 접속해봤습니다.\n접속해봤더니 패키지 관련 디렉토리나 파일들은 존재하지 않고 [README.txt] 안내 파일만 존재하는 것을 알 수 있었습니다.\n\n\nhttps://rocky-linux-asia-east1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/\n\n\n\n  \n  \n    \n  \n\n\nREADME.txt\n해당 파일을 클릭해서 열어보니 아래와 같이 파일들이 다른 곳으로 옮겨졌으니 그쪽에서 확인해보라는 메시지를 확인할 수 있었습니다.\n즉, Rocky Linux 8.8 버전은 출시된지 오래된 버전이어서 미러링 사이트들에서는 삭제되고, 공식 다운로드 사이트의 별도의 디렉토리로 옮겨진 것으로 판단이됩니다.\n\nThis content has been moved to the Rocky Linux Vault\n\nhttps://dl.rockylinux.org/vault/rocky/8.8/\n\n\n  \n  \n    \n  \n\n\n공식 사이트\n위 파일에서 확인한 공식 사이트로 접속해보니 아래와 같이 패키지 관련 디렉토리가 존재하는 것을 알 수 있었습니다.\n\n\nhttps://dl.rockylinux.org/vault/rocky/8.8/\n\n\n\n  \n  \n    \n  \n\n\n해결 방법-4\n원인 분석에서 확인했 듯이 공식 사이트의 별도 디렉토리에 패키지 파일들이 존재하므로 [Rocky-Extras.repo] 리포지토리 파일을 아래와 같이 수정하는 방법도 가능합니다.\n\n# vim /etc/yum.repos.d/Rocky-Extras.repo\n\n# Rocky-Extras.repo\n\n#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=extras-$releasever\n#baseurl=http://dl.rockylinux.org/$contentdir/$releasever/extras/$basearch/os/\n#baseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\n\nbaseurl=https://dl.rockylinux.org/vault/rocky/$releasever/extras/$basearch/os/\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Rocky Linux 서버 소개\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-rocky-linux-guide.html\n    \n  \n  Rocky Linux 미러 사이트 리스트\n    \n      https://mirrors.rockylinux.org/mirrormanager/mirrors/Rocky\n    \n  \n  Ncloud XEN Hypervisor 타입의 Rocky Linux 8.6 서버 Repository 미러 사이트 오류 문제 해결 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-rocky-linux-repository-mirror-site-error-troubleshooting.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-12-28\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-rocky-linux-repository-mirror-site-error-troubleshooting-html": {
						"id": "compute-ncloud-compute-server-rocky-linux-repository-mirror-site-error-troubleshooting-html",
						"title": "Ncloud XEN Hypervisor 타입의 Rocky Linux 8.6 서버 Repository 미러 사이트 오류 문제 해결 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-server-rocky-linux-repository-mirror-site-error-troubleshooting.html",
						"content": "개요\nNcloud (네이버 클라우드)에서 XEN Hypervisor 타입의 록키 리눅스(Rocky Linux) 8.6 서버를 제공하고 있는데, 패키지를 설치할 때 간혹 패키지 다운로드 사이트 또는 미러 사이트에서 8.6 버전에 대한 패키지 정보를 찾을 수 없다는 메시지가 나타나면서 패키지를 설치할 수 없는 경우가 있습니다. \n그렇다면 왜 이런 문제가 생기는지와 어떻게 하면 해결할 수 있는지를 정리해보겠습니다.\n\n오류 상황\n테스트로 아파치를 설치해보려고 했는데, 오류 메시지가 나타나면서 설치를 할 수 없었습니다. 또한 리포지토리 미러 사이트도 Ncloud 내부 서버가 아닌 록키 리눅스 공식 미러 사이트로 연결하려고 시도한 것을 확인할 수 있습니다.\n\n~# dnf -y install httpd\n\nRocky Linux 8.6 - Extras                                 5.4 kB/s |  20 kB     00:03\nErrors during downloading metadata for repository 'extras':\n  - Status code: 404 for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64&amp;repo=extras-8.6 (IP: 151.101.26.132)\n  - Status code: 404 for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64&amp;repo=extras-8.6 (IP: 146.75.94.132)\nError: Failed to download metadata for repo 'extras': Cannot prepare internal mirrorlist: Status code: 404 for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64&amp;repo=extras-8.6 (IP: 151.101.26.132)\n\n\n  \n  \n    \n  \n\n\n미러 사이트 확인\n오류 메시지에 나온 공식 미리 사이트에 접속해보니 [AppStream], [extras] 등 모든 8.6 버전에 대한 정보가 사라진 것을 확인할 수 있었습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상황 요약 정리\n현재 확인되는 오류 상황을 정리해보면 다음과 같습니다.\n\n\n  패키지를 검색하는 저장소가 [AppStream] 이나 [BaseOS]가 아닌 [Extras]로 변경되어 있다.\n  리포지토리 미러 사이트를 Ncloud 내부 서버가 아닌 외부에 있는 록키 리눅스 공식 미러 사이트로 접속시도 하고 있다.\n  외부에 있는 록키 리눅스 공식 미러 사이트에서는 공식 지원이 종료되는 8.6 버전에 대한 데이터가 이미 삭제되어 있다.\n\n\n원인 분석\n원인 분석을 하기 위해 서버의 리포지토리 설정을 확인해보겠습니다.\n\n리포지토리 설정 - 오류 서버\n[/etc/yum.repos.d/] 디렉토리에 있는 리포지토리 설정 파일을 확인해보면 아래와 같이 다수의 파일이 존재하는 것을 확인할 수 있습니다.\n\n~# ls -al /etc/yum.repos.d/\n\n\n\n  \n  \n    \n  \n\n\n\n  위에서 확인한 설정 파일들 중에서 [Rocky-Extras.repo] 파일을 열어서 미러 사이트 주소를 확인해보면, Ncloud 내부 서버가 아닌 아래와 같이 록키 리눅스 공식 사이트로 설정되어 있는 것을 알 수 있습니다.\n\n\n~# vi /etc/yum.repos.d/Rocky-Extras.repo\n\n\n\n  \n  \n    \n  \n\n\n리포지토리 설정 - 정상 서버\n그렇다면 아무 문제 없는 정상적인 서버의 경우는 어떤지 비교해서 살펴보겠습니다.\n\n마찬가지로 [/etc/yum.repos.d/] 디렉토리에 있는 리포지토리 설정 파일을 확인해보면 오류가 발생한 서버와 달리 아래와 같이 [Rocky-AppStream.repo], [Rocky-BaseOS.repo] 이렇게 2가지 파일만 존재하는 것을 확인할 수 있습니다.\n\n~# ls -al /etc/yum.repos.d/\n\n\n  \n  \n    \n  \n\n\n\n  또한 2가지 설정 파일들 중에서 [Rocky-AppStream.repo] 파일을 열어서 미러 사이트 주소를 확인해보면, 록키 리눅스 공식 사이트는 주석 처리가 되어 있고, [baseurl]이 [repo.ncloud.com] 이라는 Ncloud 내부 서버로 설정되어 있는 것을 알 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n원인 추적\n오류가 발생한 서버와 정상적인 서버의 차이점을 비교 추적해보니 오류가 발생한 서버에서는 서버 생성 후에 패키지 업데이트가 진행된 것을 알 수 있었습니다. \n서버 생성 후에 설치된 패키지들의 업데이트를 적용하기 위해 [dnf upgrade]를 실행했고, 그에 따라 리포지토리 정보가 변경되었다는 것을 알 수 있었습니다.\n\n~# dnf -y upgrade\n\n\n\n  \n  \n    \n  \n\n\n\n[dnf upgrade]와 [dnf update]의 차이점에 대해 [man dnf] 명령어로 매뉴얼을 살펴보면 Rocky Linux에서 패키지 업데이트를 위한 기본 명령어는 [dnf upgrade]이며, [dnf update]는 더 이상 사용되지 않는 별칭이라고 합니다.\n\n\n~# man dnf\n#--- 중략 ---#\nUpgrade Command\n       Command: upgrade\n       Aliases: up\n       Deprecated aliases: update, upgrade-to, update-to, localupdate\n\n\n\n  \n  \n    \n  \n\n\n해결 방법\n이 문제를 해결하는 방법은 몇가지가 있는데 차례대로 정리해보겠습니다.\n\n방법-1\n첫번째 방법은 [Rocky-Extras.repo] 리포지토리 설정파일의 주소를 Ncloud 내부 서버로 변경하는 방법입니다.\n\n# Rocky-Extras.repo\n\n#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=AppStream-$releasever\nbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\n\n\n\n  \n  \n    \n  \n\n\n\n  주소 변경 후에 아파치를 설치해보면 문제 없이 잘 설치 되는 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n방법-2\n두번째 방법은 패키지를 설치할 때 미러 사이트 주소가 변경된 [Extras] 저장소를 비활성화하는 옵션을 적용하는 방법입니다.\n\n~# dnf -y install httpd --disablerepo=extras\n\n\n  \n  \n    \n  \n\n\n사전 예방책\n위 방법들은 패키지 업데이트 후에 문제를 해결하는 방법이므로, 사전에 이런 문제가 생기지 않도록 하는 것도 선택지 중의 하나입니다. 가능한 방법은 다음 2가지 입니다.\n\n  패키지 업데이트를 진행하지 않는 방법\n  보안-버그 수정 사항만 최소한으로 업데이트 하는 방법\n\n\n패키지 최소 업데이트\n보안-버그 수정 사항만 최소한으로 업데이트 하는 [upgrade-minimal] 옵션으로 업데이트를 했을 경우에는 아래와 같이 리포지토리 파일에 변화가 없어서 이후 패키지 설치에 오류가 생기지 않습니다.\n\n~# dnf -y upgrade-minimal\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Rocky Linux 서버 소개\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-rocky-linux-guide.html\n    \n  \n  Rocky Linux 미러 사이트 리스트\n    \n      https://mirrors.rockylinux.org/mirrormanager/mirrors/Rocky\n    \n  \n  Ncloud KVM Hypervisor 타입의 Rocky Linux 서버 Repository 미러 사이트 오류 문제 해결 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-rocky-linux-kvm-hypervisor-repository-mirror-site-error-troubleshooting.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-06-29\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-storage-extend-guide-linux-html": {
						"id": "compute-ncloud-compute-server-storage-extend-guide-linux-html",
						"title": "Ncloud 블록 스토리지 (디스크) 크기 확장하는 방법 - 리눅스",
						"categories": "",
						"url": " /compute/ncloud-compute-server-storage-extend-guide-linux.html",
						"content": "개요\nNcloud(네이버 클라우드) 리눅스 환경 서버의 블록스토리지 볼륨 크기를 확장하고 적용하는 방법을 정리해보겠습니다.\n\n테스트 환경\n\n  CentOS 7.8\n  Ubuntu 20.04\n  추가 블록스토리지 10GB\n\n\nOS 영역에서 사용하는 50G 블록스토리지 외에 아래와 같이 추가로 할당 된 10G의 블록스토리지의 크기를 변경하고 적용해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n추가 블록 스토리지 할당 방법에 대한 가이드는 아래의 링크를 참조 바랍니다.\n\n\n  Linux 스토리지(디스크) 추가 상세 가이드\n\n\n스토리지 스냅샷 백업\n아래와 같이 [Console] - [Server] - [Storage]에서 크기를 변경할 스토리지를 선택하고 [스토리지 설정] - [스냅샷 생성] 메뉴를 선택합니다.\n\n블록스토리지의 크기를 변경하는 과정에 만에 하나 있을지 모르는 상황에 대비해서 해당 블록스토리지의 스냅샷을 생성해서 백업해 두는 것을 적극 권장합니다.\n\n\n  \n  \n    \n  \n\n\n스냅샷 이름을 입력하고 스냅샷을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n스토리지 크기 변경\n스냅샷 생성이 끝났으면 스토리지 크기를 변경하기 위해 [스토리지 설정] - [크기 변경] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n서버 정지 알림\n스토리지 크기 변경은 서버가 정지된 상태에서만 가능하므로, 혹시 서버가 동작중인 경우 아래와 같은 알림이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n서버 정지\n먼저 스토리지가 장착된 서버를 정지하겠습니다.\n\n\n  \n  \n    \n  \n\n\n크기 변경\n서버를 정지한 후 크기 변경 메뉴를 선택하면 아래와 같이 변경할 크기를 입력할 수 있습니다.  최대 2,000GB까지 가능합니다.\n\n스토리지 크기는 확대만 가능하며, 축소 기능은 제공하지 않습니다.\n\n\n  \n  \n    \n  \n\n\n변경할 크기를 입력하고 [확인] 버튼을 클릭하면 크기 변경 작업이 진행됩니다. 이후에 서버에서 해당 스토리지의 파티션 확장 등의 작업을 추가로 진행해야 정상적으로 사용할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 디스크 파티션 확장\nNcloud 콘솔에서 블록스토리지 크기를 변경 완료했으면 다음으로 서버에 접속해서 할당된 디스크의 파티션을 확장해야 합니다.\n\n디스크 마운트 해제\n일반적으로 추가 디스크는 서버가 재시작되어도 사용하는데 문제 없도록 fstab에 마운트 정보를 등록해두기 때문에 서버가 재시작되면서 자동으로 마운트 되어있습니다.\n\n마운트 된 상태에서는 파티션 확장을 할 수 없으므로 먼저 마운트를 해제합니다. 여기서는 마운트 해제가 잘 되었는지 df 명령으로 확인을 해보았습니다.\n\n~# umount /dev/xvdb1\n~# df -hT\n\n\n  \n  \n    \n  \n\n\ngrowpart 패키지 설치\n디스크 파티션 확장에 필요한 growpart 패키지를 설치합니다.\n\nCentos\n~# yum -y install cloud-utils-growpart\n\n\n  \n  \n    \n  \n\n\nUbntu\n이미 해당 패키지가 설치되어 있는 경우에는 아래와 같이 추가 설치 없이 통과됩니다.\n~# apt-get install cloud-guest-utils \n\n\n\n  \n  \n    \n  \n\n\n파티션 확장\n파티션을 확장할 때 growpart 명령 실행 후의 다음 단계는 EXT, XFS 등 디스크의 파일 시스템 타입에 따라 차이가 있으니 확인하고 진행하셔야 합니다.\n\n# growpart {장치명} {파티션 번호}\n~# growpart /dev/xvdb 1\n\n\n  \n  \n    \n  \n\n\nXFS 시스템\nxfs 파일 시스템은 마운트를 먼저 하고 최종 파티션 확장 작업을 진행합니다.\n\n~# mount /dev/xvdb1 /mnt/data\n~# xfs_growfs /dev/xvdb1\n\n\n\n  \n  \n    \n  \n\n\n작업이 모두 끝난 후에 디스크 상태를 확인해보면 아래와 같이 문제 없이 확장된 것을 알 수 있습니다.\n\n~# df -hT\n\n\n  \n  \n    \n  \n\n\nEXT4 시스템\next4 파일 시스템은 최종 파티션 확장 작업을 먼저 진행하고 나서 마운트를 하게 됩니다.\n\n~# e2fsck -f /dev/xvdb1\n~# resize2fs /dev/xvdb1\n~# mount /dev/xvdb1 /mnt/data\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n~# df -hT\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud 블록 스토리지 크기 확장 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-compute-4-1-v2-vpc"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-storage-extend-guide-windows-html": {
						"id": "compute-ncloud-compute-server-storage-extend-guide-windows-html",
						"title": "Ncloud 블록 스토리지 (디스크) 크기 확장하는 방법 - 윈도우",
						"categories": "",
						"url": " /compute/ncloud-compute-server-storage-extend-guide-windows.html",
						"content": "개요\nNcloud(네이버 클라우드) 윈도우 환경 서버의 블록스토리지 볼륨 크기를 확장하고 적용하는 방법을 정리해보겠습니다.\n\n테스트 환경\n\n  Windows Server 2019 (64-bit) English Edition\n  추가 블록스토리지 10GB\n\n\nOS 영역에서 사용하는 100G 블록스토리지 외에 아래와 같이 추가로 할당 된 10G의 블록스토리지의 크기를 변경하고 적용해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n추가 블록 스토리지 할당 방법에 대한 가이드는 아래의 링크를 참조 바랍니다.\n\n\n  Windows 스토리지(디스크) 추가 상세 가이드\n\n\n스토리지 스냅샷 백업\n아래와 같이 [Console] - [Server] - [Storage]에서 크기를 변경할 스토리지를 선택하고 [스토리지 설정] - [스냅샷 생성] 메뉴를 선택합니다.\n\n블록스토리지의 크기를 변경하는 과정에 만에 하나 있을지 모르는 상황에 대비해서 해당 블록스토리지의 스냅샷을 생성해서 백업해 두는 것을 적극 권장합니다.\n\n\n  \n  \n    \n  \n\n\n스냅샷 이름을 입력하고 스냅샷을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n스토리지 크기 변경\n스냅샷 생성이 끝났으면 스토리지 크기를 변경하기 위해 [스토리지 설정] - [크기 변경] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n서버 정지 알림\n스토리지 크기 변경은 서버가 정지된 상태에서만 가능하므로, 혹시 서버가 동작중인 경우 아래와 같은 알림이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n서버 정지\n먼저 스토리지가 장착된 서버를 정지하겠습니다.\n\n\n  \n  \n    \n  \n\n\n크기 변경\n서버를 정지한 후 크기 변경 메뉴를 선택하면 아래와 같이 변경할 크기를 입력할 수 있습니다.  최대 2,000GB까지 가능합니다.\n\n스토리지 크기는 확대만 가능하며, 축소 기능은 제공하지 않습니다.\n\n\n  \n  \n    \n  \n\n\n변경할 크기를 입력하고 [확인] 버튼을 클릭하면 크기 변경 작업이 진행됩니다. 이후에 서버에서 해당 스토리지의 파티션 확장 등의 작업을 추가로 진행해야 정상적으로 사용할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 디스크 파티션 확장\n서버에 접속해 Disk Management를 실행하면 아래와 같이 확장된 추가 블록스토리지의 모습이 보입니다.\n\n\n  \n  \n    \n  \n\n\nDisk Management\nDisk Management 툴은 아래의 방법으로 간단하게 실행할 수 있습니다.\n\n\n  명령 실행 (윈도우키+r) : diskmgmt.msc\n\n\n\n  \n  \n    \n  \n\n\n볼륨 확장\n기존에 할당되어 있던 10GB 볼륨을 선택하고 마우스 오른쪽 버튼을 클릭한 후 [Extend Volume] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n볼륨 확장 팝업 창에서 [Next] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nSelect Disks\n콘솔에서 추가한 10GB 스토리지가 추가 디스크로 선택되어 있습니다. 전체 용량을 모두 확장할 것이므로 특별한 수정 없이 [Next] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n볼륨 확장 작업이 끝났으면 [Finish] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n디스크 크기 확인\n작업 완료 후 확인해보면 기존 10GB에서 20GB로 확장된 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud 블록 스토리지 크기 확장 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-compute-4-1-v2-vpc"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-x-forwarded-for-client-ip-logging-iis-guide-html": {
						"id": "compute-ncloud-compute-server-x-forwarded-for-client-ip-logging-iis-guide-html",
						"title": "IIS에서 X-Forwarded-For를 이용해 Client IP 기록하기",
						"categories": "",
						"url": " /compute/ncloud-compute-server-x-forwarded-for-client-ip-logging-iis-guide.html",
						"content": "개요\nX-Forwarded-For (XFF) 는 HTTP Header 중 하나로 Load Balancer(로드밸런서)나 Proxy Server를 통해 웹서버에 접속하는 Client의 IP 주소를 식별하는 표준 헤더입니다.\n웹서버나 WAS 앞쪽에 Load Balancer 혹은 Proxy Server 등이 위치하게 된다면 서버 접근 로그에는 Client IP가 아닌 Load Balancer 혹은 Proxy Server의 IP 주소가 기록됩니다. \n이때 웹 어플리케이션에서 X-Forwarded-For 헤더를 이용하면 Client IP를 서버 접근 로그에 남길 수 있습니다.\n\n여기서는 Load Balancer와 연동된 Windows Server의 IIS에서 X-Forwarded-For를 이용해 IIS(Internet Information Services) Log에 Clinet의 IP를 기록하는 과정을 살펴보겠습니다.\n\n테스트 환경\n테스트는 Windows 서버를 Load Balancer와 연동한 후 Cloud Log Analytics에서 IIS Log를  수집해 IP 주소를 확인하는 방식으로 진행하겠습니다.\n\nNetwork 환경\n\n  VPC 대역 : 10.0.0.0/16\n  Subnet 대역 (Server) : 10.0.0.0/24\n  Subnet 대역 (Load Balancer) : 10.0.4.0/24\n\n\nServer 환경\n\n  Windows Server 2019 (64-bit) English Edition\n\n\n테스트 서버\n위 서버 환경에서 정리한 대로 Windows 서버를 준비했습니다. VPC 환경에서 서버 생성하는 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 서버 생성하는 방법\n\n\n\n  \n  \n    \n  \n\n\n로드밸런서도 마찬가지로 준비하고, 서버와 연동까지 완료했습니다. VPC 환경에서 로드밸런서를 생성하는 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 Application Load Balancer 생성하는 방법\n\n\n\n  로드밸런서 상세 정보에서 [10.0.4.0/24]로 표시되는 서브넷 정보를 기억했다가 아래쪽에서 테스트할 때 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n설정 전 테스트\n우선, X-Forwarded-For (XFF) 설정을 하기 전에 어떻게 기록이 남는지 확인해보겠습니다.\n\nIIS 접속 로그 확인\nWindows IIS 접속 로그를 [Cloud Log Analytics]에서 확인하는 방법은 아래 문서를 참고하시며 됩니다.\n\n\n⁃ Cloud Log Analytics에서 Windows IIS Log 수집하는 방법\n\n\nCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 Load Balancer의 IP 대역 (10.0.4.xx)이 기록된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nIIS 설정\n이제 실제 Client IP가 기록 되도록 설정을 변경해보겠습니다.\n\n\n  IIS Manager를 실행시켜서 메뉴 중에 [Logging]을 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Logging] 화면에서 [Format]은 기본 값인 [W3C] 그대로 두고 [Log File] 항목의 [Select Fields] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [W3C Logging Fields] 팝업창에서 [Custom Fields] 항목의 [Add Field] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Add Custom Field] 팝업창에서 [Field Name], [Source] 두가지 항목 모두에 [X-Forwarded-For]를 입력하고 [OK] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Custom Fields]에 [X-Forwarded-For] 설정이 추가된 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  팝업창을 닫고 [IIS Manager] - [Logging] 설정 화면 오른쪽에 있는 [Apply]를 클릭해서 변경된 설정을 적용합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  변경된 설정이 적용되었다는 메시지를 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n설정 후 테스트\n위와 같이 서버에서 설정을 모두 마친 후에 로드 밸런서 URL로 접속합니다.\n이후에 Cloud Log Analytics에서 로그를 확인해보면 아래와 같이 실제 접속한 Client의 IP가 추가로 기록된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  X-Forwarded-For 안내\n    \n      https://developer.mozilla.org/ko/docs/Web/HTTP/Headers/X-Forwarded-For\n    \n  \n  Cloud Log Analytics에서 Windows IIS Log 수집하는 방법\n    \n      https://docs.3rdeyesys.com/management/ncloud-management-cloud-log-analytics-windows-iis-log-collect-guide.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-11-17\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mssql-guide-html": {
						"id": "database-ncloud-database-cloud-db-for-mssql-guide-html",
						"title": "VPC환경에서 Cloud DB for MSSQL 생성하기",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-mssql-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) VPC 환경에서 관리형 MSSQL DB 서버인 Cloud DB for MSSQL 생성 및 접속 방법에 대하여 정리해보겠습니다.\n\n테스트 환경\n\n  VPC와 Private Subnet\n  Cloud DB for MSSQL 15.0.4.198.2 Standard Edition (MSSQL 2019)\n  DB 접속 테스트용 서버 windows 2019 64bit en\n\n\nCloud DB for MSSQL 서비스 위치\n[콘솔] - [Services] - [Database]에서  [Cloud DB for MSSQL]을 찾을 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nCloud DB for MSSQL 서버 생성\n[Cloud DB for MSSQL] - [DB Server]에서 [DB server 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서버 설정\n생성할 서버의 스펙 선택 및 세부정보를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nCloud DB for MSSQL은 고가용성(HA) 기능 즉, 서버 이중화를 기본으로 지원합니다. 운영 중인 Principal Server에서 장애가 발생하여 정상적인 서비스가 불가능한 경우 Mirror Server로 자동 Failover 합니다. DNS 방식으로 이중화를 구성하므로 별도의 애플리케이션 변경이 필요 없습니다.\n\n Subnet 선택 주의사항: 서버를 생성 후에는 Subnet 변경이 불가합니다. 내부 서버를 통해 접근하거나 SSL VPN을 이용해 접속할 경우는 Private Subnet으로 설정하고, 회사 PC 등 외부에서 접근이 필요하실 경우는 ACG에서 IP 제한을 적용한 후 Public Subnet으로 설정하면 됩니다. \n\n여기서는 내부 서버를 통해 접근하는 방식을 테스트할 예정이므로 Private Subnet을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nCloud DB for MSSQL의 스토리지 용량은 최소 100GB부터 10GB씩 자동 증가되며 최대 2TB까지 사용 가능합니다. \n\nDB 설정\n다음으로 계정 정보와 DB 접속 포트 등을 입력하고, Backup 관련 설정을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nBackup 파일 보관 기간은 최소 1일 부터 최대 30일까지 선택 가능하며 FullBackup만 지원하고 있습니다. Backup 시간은 자동 또는 수동모드로 변경하여 시간 지정이 가능합니다.\n\nCloud DB for MSSQL 서버는 고가용성을 선택할 경우 서버 생성까지 대략 1시간 정도가 소요되니 여유를 갖고 기다리시면 됩니다.\n\nDB 생성 완료\n생성될 서버의 최종 정보를 확인하고 서버를 생성하면 아래와 같이 기본 옵션으로 선택했던 고가용성에 해당하는 Principal, Mirror 이렇게 2대의 서버가 생성된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n테스트용 Windows 서버 생성\nCloud DB for MSSQL 서버에 접속할 테스트 용도의 Windows 서버를 생성하고, 서버 정보에서 ACG 설정에 필요한 사설(비공인) IP를 확인합니다. 이 비공인 IP는 아래쪽 ACG 설정에서 사용하게 됩니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n이제 테스트용 Windows 서버에서 Cloud DB for MSSQL로 접속할 수 있도록 ACG를 설정해야 합니다.\n\n생성된 MSSQL DB 서버의 상세 정보를 살펴보면 DB 생성 과정에서 ACG가 자동으로 생성, 적용되어 있는 것을 아래와 같이 확인할 수 있습니다.\n\n  ACG 옆에 있는 아이콘을 클릭해서 ACG 화면으로 이동합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  위에서 확인했던 Cloud DB for MSSQL의 ACG [cloud-mssql-***]를 선택 후 ACG 설정을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Inbound 규칙에 위에서 확인했던 테스트용 Windows 서버의 비공인 IP를 접근 소스로 등록하고 허용 포트 1433을 추가합니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 서버 접속\n\nSQL Server Management Studio 설치\n테스트용 Windows 서버에 할당된 공인IP로 접속해 MSSQL Client인 SSMS (SQL Server Management Studio)를 다운로드하고 설치합니다.\n\n\n⁃  SSMS (SQL Server Management Studio) 다운로드\n\n\n\n  \n  \n    \n  \n\n\n설치된 SSMS (SQL Server Management Studio)를 찾아서 실행합니다.\n\n\n  \n  \n    \n  \n\n\nDB Server Private 도메인 확인\nCloud DB for MSSQL 서버에 접속하기 위해서는 DB 서버 생성 시에 설정된 Private 도메인을 이용해야 하는데, 아래 화면처럼 DB 서버 상세 정보에서 Private 도메인을 확인할 수 있습니다. 해당 Private 도메인 주소를 복사해서 다음 단계인 DB 로그인 창에 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nDB 로그인\n로그인 접속 화면에서 정보를 입력하고 접속합니다.\n\n\n  Server name : {MSSQL DB Server의 Private 도메인}, {접속 포트} (쉼표로 구분하여 입력)\n  Authentication : [SQL Server Authentication] 으로 변경합니다.\n  Login 및 Password : DB 서버 생성과정에서 입력한 유저 정보를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  정상적으로 접속된 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for MSSQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbformssql-start-vpc\n    \n  \n  SSMS (SQL Server Management Studio) 다운로드\n    \n      https://learn.microsoft.com/ko-kr/sql/ssms/download-sql-server-management-studio-ssms"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mssql-public-domain-guide-html": {
						"id": "database-ncloud-database-cloud-db-for-mssql-public-domain-guide-html",
						"title": "Cloud DB for MSSQL 생성후 Public 도메인으로 접속하기",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-mssql-public-domain-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) VPC 환경에서 관리형 MSSQL DB 서버인 Cloud DB for MSSQL 생성 Public 도메인으로 접속하는 방법에 대하여 정리해보겠습니다.\n\n테스트 환경\n\n  VPC와 Public Subnet\n  Cloud DB for MSSQL 15.0.4.198.2 Standard Edition (MSSQL 2019)\n\n\nCloud DB for MSSQL 서비스 위치\n[콘솔] - [Services] - [Database]에서  [Cloud DB for MSSQL]을 찾을 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nCloud DB for MSSQL 서버 생성\n[Cloud DB for MSSQL] - [DB Server]에서 [DB server 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서버 설정\n생성할 서버의 스펙 선택 및 세부정보를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nCloud DB for MSSQL은 고가용성(HA) 기능 즉, 서버 이중화를 기본으로 지원합니다. 운영 중인 Principal Server에서 장애가 발생하여 정상적인 서비스가 불가능한 경우 Mirror Server로 자동 Failover 합니다. DNS 방식으로 이중화를 구성하므로 별도의 애플리케이션 변경이 필요 없습니다.\n\n Subnet 선택 주의사항: 서버를 생성 후에는 Subnet 변경이 불가합니다. 회사 PC 등 외부에서 접근이 필요하실 경우는 ACG에서 IP 제한을 적용한 후 Public Subnet으로 설정하고, 내부 서버를 통해 접근하거나 SSL VPN을 이용해 접속할 경우는 Private Subnet으로 설정하면 됩니다. \n\n여기서는 외부에서 접근하는 방식을 테스트할 예정이므로 Public Subnet을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nCloud DB for MSSQL의 스토리지 용량은 최소 100GB부터 10GB씩 자동 증가되며 최대 2TB까지 사용 가능합니다. \n\nDB 설정\n다음으로 계정 정보와 DB 접속 포트 등을 입력하고, Backup 관련 설정을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nBackup 파일 보관 기간은 최소 1일 부터 최대 30일까지 선택 가능하며 FullBackup만 지원하고 있습니다. Backup 시간은 자동 또는 수동모드로 변경하여 시간 지정이 가능합니다.\n\nCloud DB for MSSQL 서버는 고가용성을 선택할 경우 서버 생성까지 대략 1시간 정도가 소요되니 여유를 갖고 기다리시면 됩니다.\n\nDB 생성 완료\n생성될 서버의 최종 정보를 확인하고 서버를 생성하면 아래와 같이 기본 옵션으로 선택했던 고가용성에 해당하는 Principal, Mirror 이렇게 2대의 서버가 생성된 것을 확인할 수 있습니다. 또한 Subnet도 [Public Subnet]으로 설정된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n이제 외부에서 Cloud DB for MSSQL로 접속할 수 있도록 ACG를 설정해야 합니다.\n\n생성된 MSSQL DB 서버의 상세 정보를 살펴보면 DB 생성 과정에서 ACG가 자동으로 생성, 적용되어 있는 것을 아래와 같이 확인할 수 있습니다.\n\n  ACG 옆에 있는 아이콘을 클릭해서 ACG 화면으로 이동합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  위에서 확인했던 Cloud DB for MSSQL의 ACG [cloud-mssql-***]를 선택 후 ACG 설정을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Inbound 규칙에서 접근 소스는 [myIp] 버튼을 클릭해서 현재 IP 즉, 사무실 IP 등을 등록하고 허용 포트 1433을 추가합니다.\n\n\n\n  \n  \n    \n  \n\n\nPublic 도메인 할당\n다음으로, 사무실 등의 외부에서 Cloud DB에 접속하려면 Public 도메인을 추가로 할당해야 합니다.  [DB 관리] - [Public 도메인 관리] 메뉴를 클릭해 Public 도메인을 신청합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Public 도메인 신청 팝업을 확인하고 [예] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  신청 후 잠시 기다렸다 Cloud DB for MSSQL 서버의 상세 정보를 살펴보면 아래와 같이 [Public 도메인]이 할당된 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 서버 접속\n\nSQL Server Management Studio 설치\n사무실 PC에 MSSQL Client인 SSMS (SQL Server Management Studio)를 다운로드하고 설치합니다.\n\n\n⁃  SSMS (SQL Server Management Studio) 다운로드\n\n\n\n  \n  \n    \n  \n\n\n\n  설치된 SSMS (SQL Server Management Studio)를 찾아서 실행합니다.\n\n\n\n  \n  \n    \n  \n\n\nDB Server Public 도메인 확인\n아래 화면처럼 DB 서버 상세 정보에서 확인한 Public 도메인 주소를 복사해서 다음 단계인 DB 로그인 창에 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nDB 로그인\n로그인 접속 화면에서 정보를 입력하고 접속합니다.\n\n\n  서버 이름 : {MSSQL DB Server의 Public 도메인}, {접속 포트} (쉼표로 구분하여 입력)\n  인증 : [SQL Server 인증] 으로 변경합니다.\n  로그인 및 암호 : DB 서버 생성과정에서 입력한 유저 정보를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  정상적으로 접속된 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for MSSQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbformssql-start-vpc\n    \n  \n  SSMS (SQL Server Management Studio) 다운로드\n    \n      https://learn.microsoft.com/ko-kr/sql/ssms/download-sql-server-management-studio-ssms"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mssql-setting-manage-guide-html": {
						"id": "database-ncloud-database-cloud-db-for-mssql-setting-manage-guide-html",
						"title": "Cloud DB for MSSQL의 메뉴와 주요 기능에 대한 소개",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-mssql-setting-manage-guide.html",
						"content": "개요\nNcloud (네이버 클라우드) Cloud DB for MSSQL의 메뉴와 주요 기능에 대한 간략한 소개를 정리해보겠습니다.\n\n테스트 환경\n\n  VPC와 Private Subnet\n  Cloud DB for MSSQL 15.0.4.198.2 Standard Edition (MSSQL 2019)\n\n\nCloud DB for MSSQL 서비스 위치\n[Cloud DB for MSSQL]은 [콘솔] - [Services] - [Database]에서 찾을 수 있습니다.\n\n그리고 Cloud DB for MSSQL에는 다음과 같은 메뉴들이 있는데, 자세한 내용은 아래쪽에서 메뉴별로 하나씩 소개해보겠습니다.\n\n  DB Server\n  Monitoring\n  Backup\n  Event\n  Config Group\n\n\n\n  \n  \n    \n  \n\n\nDB Server 메뉴\nDB Server 메뉴에서는 MSSQL Server를 생성, 삭제하거나 운영 중인 MSSQL Server 목록을 확인할 수 있습니다. 또한 운영 중인 MSSQL Server의 스펙을 변경하거나 관리자(User) 계정 등을 관리할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n재시작\n서버를 재시작합니다. 정지 기능은 제공하지 않습니다.\n\nDB Server 삭제\nDB Server를 삭제합니다. 동시에 Mirror 도 같이 삭제 되며, 삭제하는 DB Server의 모든 데이터는 삭제됩니다.\n이때, 백업된 데이터도 같이 삭제되고 삭제 이후에는 복구 할 수 없으니 만약의 경우를 대비하여 백업 데이터를 별도로 보관하는 것도 좋은 방법입니다.\n\nMonitoring\nDB Dashboard, Performance, DB Logs, Audit Logs 등의 메뉴를 제공하여 각 종 로그와 성능 지표를 확인할 수 있도록 Monitoring 서비스 항목으로 이동합니다.\n\nDB 관리\n\n\n  DB Server 상세보기\n    \n      DB Config 관리: DB Config Croup 변경이 가능합니다.\n      Database 관리:  Databases를 생성 및 삭제할 수 있습니다.\n      Db User 관리: 관리자용 DB 계정의 비밀번호를 변경할 수 있습니다.\n      Backup 설정관리: Backup 파일의 보관 기간 및 Backup 시간을 관리합니다.\n      DB 스펙변경: DB Server의 스펙을 변경합니다.\n      Audit 설정 관리: Audit 설정을 활성화 하면 DB 서버의 로그인 기록 및 데이터베이스 내 오브젝트 생성, 변경, 삭제 기록(DDL)을 남길 수 있습니다.\n      Log 다운로드: Error Log, Default Trace File, Agent Log, Audit Log 파일을 다운로드 할 수 있습니다.\n    \n  \n\n\nDB 스펙 변경은 동일한 DB 서비스 이름으로 서비스 되는 모든 서버(Principle, Mirror, Slave 등)가 똑같이 변경되며 DB Server가 재시작 됩니다. 또한, 재시작 동안에는 DB Server 접속할 수 없습니다.\n\n\n  Slave 추가 : 선택한 DB Service의 Slave DB Server를 추가합니다.\n  읽기가능 시간 조정 : 매일 정해진 시간에 읽기 가능하도록 설정하여 batch 등에 사용할 수 있습니다. (Slave DB 생성 후 적용가능)\n  고가용성 설정 변경 : DB Server를 Stand Alone 또는 고가용성 구성으로 변경하며, 이때 서버 스펙, DB 설정 정보는 동일하게 설정됩니다.\n  Public 도메인 관리 : 외부에서 접근할 수 있는 Public 도메인을 신청할 수 있습니다.\n  MSSQL Engine Upgrade : DB Server Engine 버전을 업그레이드 합니다.\n\n\nMSSQL Engine Upgrade는 리스트에 있는 전체 서버의 버전이 변경되고, 버전 업그레이드 중에는 DB서버 접근이 차단됩니다.\n\nMonitoring 메뉴\n\nMSSQL Server 성능 및 이력에 대한 모니터링 정보를 확인할 수 있습니다. Monitoring은 별도의 추가 비용 없이 사용이 가능합니다.\n\nDB Dashboard\nMonitoring에서 제공하고 있는 대시보드는 여러 개의 그래픽 차트로 구성되어 있으며, 사용자는 서버별로 확인하고 싶은 대시보드에서 원하는 정보만 디스플레이하여 직관적으로 확인할 수 있습니다. 대시보드에서 보여주는 정보는 매분 수집하여 표시하되 평균값을 보여줍니다.\n\n\n  \n  \n    \n  \n\n\nPerformance\n운영 중인 MSSQL Server의 성능 관련 모니터링 정보를 보여줍니다.\n\n\n  \n  \n    \n  \n\n\nDB Logs\n운영 중인 MSSQL Server에서 발생한 모든 로그의 발생 시간 및 내용을 기록하여 보여줍니다.\n\n\n  \n  \n    \n  \n\n\nBackup 메뉴\nBackup에서는 Cloud DB for MSSQL을 사용 중인 사용자의 캐시 데이터를 안전하게 보관하기 위해 서버별로 설정해놓은 백업 정보를 확인할 수 있습니다. 또한 장애가 발생하여 캐시 데이터가 손실된 경우 보관 중이던 백업 파일로 복원을 진행할 수도 있으며, 고가용성 설정을 사용하는 서버 뿐만 아니라 Stand Alone Server도 백업 및 복원 기능을 사용할 수 있습니다.\n\n기본 수행 규칙\n백업과 복원을 사용하기 위해서 우선 Cloud DB for MSSQL에서 제공하고 있는 백업에 대한 기본 수행 규칙을 이해하는 것이 좋습니다.\n\n\n  백업 수행 방식\n    \n      풀백업: 하루 한 번씩 매일 수행\n      자동 설정과 사용자 정의 설정 가운데 선택\n        \n          자동 설정: MSSQL Server 생성 시 임의의 시간이 지정되며, 이후 처음 백업된 시간과 유사한 시간에 백업 수행\n          사용자 정의 설정: 사용자가 선택한 시간 +15분 내 백업 수행 시작\n        \n      \n      로그백업: 15분 간격으로 자동 수행. 시간 설정 불가\n    \n  \n  백업 파일\n    \n      보관 기간: 사용자 설정에 따라 최대 30일까지 보관 가능\n      저장 위치: 별도의 데이터 스토리지(백업 파일 크기에 따라 스토리지 계약 진행)\n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  DB 서비스 이름: 사용자가 지정한 DB Service 이름\n  Backup 보관일: 백업 파일을 데이터 스토리지에 저장하여 보관하는 최대 일수\n  FullBackup 시작 시간: 매일 1회 풀백업을 수행하는 시간\n  보관중인 Backup 데이터 크기: 완료된 백업 파일의 총 크기 (풀백업과 로그백업 파일의 합)\n  FullBackup 데이터 크기: 풀백업 파일의 크기\n  Log Backup 데이터 크기: 풀백업 이후에 생성된 로그백업의 크기\n  Log Backup 수: 풀백업 이후에 생성된 로그백업의 개수\n  상세정보 보기: 서버별 생성된 백업 파일 목록의 상세 정보 및 복원\n\n\nBackup 리스트 확인\n[Backup] - [상세정보 보기] - [상세내역]에서 백업 수행을 완료하여 서버별로 생성된 백업 파일 목록을 확인하고 복원할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  DB 이름: 백업된 DB 이름\n  FullBackup 시작시간: 백업이 시작된 시간\n  FullBackup 종료시간: 백업이 완료된 시간\n  FullBackup 크기: 백업 파일의 사이즈\n  연관된 Log Backup 크기: 풀백업 이후 생성된 로그백업의 사이즈\n\n\n복원\n[Backup] - [상세정보 보기] - [상세내역] - [복원하기] 기능으로 보관되어 있는 백업 파일 목록 가운데 원하는 백업 파일을 선택하여 MSSQL Server를 복원할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nBackup 파일 보관 기간 내의 원하는 시간으로 DB 복원이 가능합니다. 복원 요청 시 신규 DB Server가 생성되며, 선택한 시간으로 DB 데이터가 복원됩니다. 그리고, 생성된 DB Server는 Stand Alone 모드로 복원됩니다.\n\n\n  \n  \n    \n  \n\n\nEvent 메뉴\nCloud DB for MSSQL 서버에서 발생한 이벤트 이력을 확인할 수 있습니다. 알람 항목과 임계치를 지정하여 이벤트를 생성하면 해당 이벤트가 발생할 때 메일과 SMS로 통보받을 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n이벤트 알림 설정은 [Event Rule 설정(Cloud Insight)]을 클릭하여 Cloud Insight 서비스로 이동하여 설정 가능합니다.\n\nCloud Insight 설정 방법은 아래 링크를 참조합니다.\n\n\n⁃  모니터링 서비스 Cloud Insight 설정 가이드\n⁃  모니터링 서비스 Cloud Insight Rule Template 설정 가이드\n\n\nConfig Group 메뉴\nConfig Group에서는 생성한 MSSQL Server를 그룹핑하여 그룹에 속한 서버들에 동일한 설정값을 지정하여 효율적으로 관리할 수 있고 생성, 변경, 삭제할 수 있습니다. 생성된 Config Group은 여러 MSSQL Service에 적용이 가능하며 MSSQL 설치 기본값이 포함된 Config Group이 기본 제공됩니다.\n\n\n  \n  \n    \n  \n\n\nConfig Group 생성\n\n\n  \n  \n    \n  \n\n\nConfig 변경\n기본 Config Group는 임의로 변경할 수 없으며, 추가로 생성한 Config Group만 변경이 가능합니다.\n\n\n  \n  \n    \n  \n\n\n삭제\n기본 Config Group은 삭제가 불가능 합니다. 추가로 생성한 Config Group만 삭제가 가능합니다.\n\n참고 URL\n\n  Ncloud Cloud DB for MSSQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbformssql-start-vpc\n    \n  \n  Ncloud Cloud DB for MSSQL 기능 상세 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbformssql-dbserver-vpc"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mysql-db-engine-upgrade-guide-html": {
						"id": "database-ncloud-database-cloud-db-for-mysql-db-engine-upgrade-guide-html",
						"title": "Ncloud Cloud DB for MySQL - DB Engine 업그레이드 가이드",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-mysql-db-engine-upgrade-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Cloud DB for MySQL에서는 DB Engine을 업그레이드할 수 있는데, Minor 버전 업그레이드(예: 5.7.32  5.7.40)와 Major 버전 업그레이드(예: 5.7.x  8.0.x)가 있습니다. 각각에 대해 업그레이드 하는 방법에 대해 아래쪽에서 살펴보겠습니다.\n\n업그레이드 진행 방식\n\n⁃ 리스트에 있는 전체 서버의 버전이 변경되고, 버전 업그레이드 중인 서버는 접근이 차단 됩니다.\n⁃ Master DB 는 Standby Master DB 로 전환하여 서비스 접근 차단은 최소한으로 유지합니다.\n   (Master DB Failover 기능으로 변경되는 시간과 동일합니다.)\n\n⁃ 업그레이드 작업은 1대씩 순차적으로 진행되고, Server 1대에 5분 내외로 작업 시간이 소요 됩니다.\n   (작업 순서 : Recovery  Slave  Master)\n\n⁃ Stand Alone Server 는 업그레이드 되는 동안 DB 접속이 되지 않습니다.\n⁃ Major 버전 업그레이드로 인해 DB config 의 default 값이 변경될 수 있습니다.\n⁃ Stand Alone Server 는 Major 버전 업그레이드 기능을 지원하지 않습니다.\n\n\nMinor 버전 업그레이드\n아래와 같이 Cloud DB for MySQL 서버를 5.7.32 버전으로 준비했습니다.\n\n\n  \n  \n    \n  \n\n\nDB서버를 선택하고 [DB 관리] - [MySQL Engine Upgrade] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[DB 엔진 버전]에서 업그레이드 가능한 버전을 선택할 수 있는데, 여기서는 [5.7.40]을 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n업그레이드 중에는 [Status]가 [업그레이드]로 표시됩니다.\n\n\n  \n  \n    \n  \n\n\n업그레이드가 끝나면 아래와 같이 [DB 엔진 버전]이 [5.7.40]으로 변경되었고, [Master]와 [Standby Master] 서버가 서로 바뀐 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nMajor 버전 업그레이드\n[Major 버전 업그레이드] 항목을 체크하고 [DB 엔진 버전]에서 업그레이드 가능한 버전에서 [8.0.32]를 선택하겠습니다.\n\n주의사항\n\n⁃ Major 버전 업그레이드로 인한 애플리케이션 호환성 검토를 먼저 진행한 후에 업그레이드 하시는 것을 권장합니다.\n⁃ Major 버전 업그레이드는 고가용성 구성인 경우만 작업이 가능합니다.\n⁃ Major 버전 업그레이드 시 이전 버전으로 rollback이 불가능합니다.\n⁃ Major 버전 업그레이드 시 DB config 의 default 값이 변경될 수 있습니다.\n⁃ Major 버전 업그레이드 시 Major 버전 업그레이드 전으로 시점 복구가 불가능합니다.\n⁃ Major 버전 업그레이드 시 Major 버전 업그레이드 전의 백업본은 신규 서비스 생성만 가능합니다.\n\n\n\n  \n  \n    \n  \n\n\n[Major 버전 업그레이드]는 호환성 체크 등 업그레드 작업에 문제가 없을지 미리 점검을 진행하게 됩니다.\n\n Warning: 업그레이드 점검에서 오류가 발견될 경우 업그레이드가 불가능합니다.\n\n\n  \n  \n    \n  \n\n\n업그레이드 점검이 문제없이 완료되었으면 [예] 버튼을 클릭해서 업그레이드를 진행합니다.\n\n\n  \n  \n    \n  \n\n\n업그레이드가 완료되면 아래와 같이 [DB 엔진 버전]이 위에서 선택했던 [8.0.32]로 변경된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud MySQL Engine Upgrade 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-2#mysql-engine-upgrade\n    \n  \n  Ncloud Cloud DB for MySQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbformysql-overview\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-12-06\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mysql-read-load-balancing-network-lb-html": {
						"id": "database-ncloud-database-cloud-db-for-mysql-read-load-balancing-network-lb-html",
						"title": "VPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 로드밸런서로 분산시키는 방법",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-lb.html",
						"content": "개요\nMySQL DB서버의 부하를 줄이기 위해 보통 읽기 전용 DB서버를 생성하게 되는데, 읽기 전용 서버를 여러대 생성해서 로드밸런서(Load Balancer)로 연결하면 읽기 부하를 분산 시키고 좀 더 안정적인 서비스가 가능해집니다.\n\n여기서는 Ncloud (네이버 클라우드) VPC 환경에서 관리형 DB인 Cloud DB for MySQL의 읽기 전용 Slave DB를 네트워크 로드밸런서(Network Load Balancer)에 연결하고 제대로 부하가 분산되는지 확인해보겠습니다.\n\n사전 준비\nDB 접속과 부하 분산을 테스트할 서버가 필요합니다. 여기서는 CentOS 7.8 서버를 준비했습니다.\n\nDB 서버 생성\n우선 [Cloud DB for MySQL] - [DB Server]에서 DB를 생성합니다.\n\n서버 설정\nDB엔진 버전과 VPC, 그리고 Subnet을 선택합니다.\n\n[고가용성 지원]을 선택하면 [Standby DB]도 추가로 생성되고, [Multi Zone]을 선택하면 Master와 Standby Master DB를 각각 [서로 다른 Zone에 생성]해서 안정성을 높일 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 서버 타입, 스토리지 타입, 스토리지 용량, DB 서버 이름, DB 서비스 이름 등을 입력합니다.\nPrivate Sub 도메인을 선택하고 입력하면 [*.{Private Sub Domain}.vpc-cdb.ntruss.com] 같은 형식으로 도메인이 생성됩니다.\n\n\n  \n  \n    \n  \n\n\nDB 설정\nUSER ID, DB 접근 HOST(IP), USER 암호, 접속 포트, DB명 등을 입력합니다.\n고가용성을 선택한 경우 [Backup]은 기본으로 무조건 사용하게 됩니다.\n\n 접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nSlave DB Server 추가\nDB가 생성되었으면 [Master] DB를 선택하고, [DB 관리]에서 [Slave 추가] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\nSlave DB Server를 추가할 때 설정할 수 있는 것은 Subnet 입니다. 부하 분산을 위해서는 2대 이상을 추가해야 하는데, 여기서는 테스트를 위해 2대를 추가하겠습니다.\n우선 첫번째 Slave DB Server는 KR-2 존에 추가했습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 두번째 Slave DB Server는 KR-1 존에 추가해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n이렇게 Slave DB Server 2대를 추가해서 [Master], [Standy Master] 포함 총 4대의 서버가 생성되었습니다.\n\n[Master] DB 서버와 첫번째 [Slave] DB 서버는 KR-2 존에, [Standy Master] DB 서버와 두번째 [Slave] DB 서버는 KR-1 존에 생성해서 안정성을 높이는 구조를 선택했습니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정\n다음으로 Load Balancer와 Cloud DB for Mysql을 연결할 Target Group을 설정해보겠습니다.\n\nTarget Group 생성\n여기서 중요한 항목은 프로토콜입니다. [Network Load Balancer]에 사용할 Target Group이므로 [TCP]를 선택합니다.\n포트는 Cloud DB for Mysql 생성 시에 사용했던 포트를 입력해야 하는데 여기서는 3306을 사용하겠습니다.\n\n\n  \n  \n    \n  \n\n\nHealth Check 설정\nHealth Check 설정에서는 TCP 프로토콜을 선택합니다. 포트는 마찬가지로 3306을 입력합니다.\n\n\n  \n  \n    \n  \n\n\nTarget 추가\nTarget 추가 화면에 가면 앞에서 생성했던 Slave DB Server 2대를 확인할 수 있는데, 선택 후에 오른쪽으로 이동시킵니다.\n\n\n  \n  \n    \n  \n\n\nLoad Balancer 생성\n여기서는 [네트워크 프록시 로드밸런서 (Network Load Balancer)]를 선택합니다.\n\n\n애플리케이션 로드밸런서(Application Load Balancer)는 Cloud DB for MySQL의 부하분산에 사용할 수 없습니다.\n\n\n\n  \n  \n    \n  \n\n\n로드밸런서 생성\n현재 네트워크 로드밸런서는 멀티존으로 구성할 수 없습니다. 그래서 서브넷 선택에서도 1개만 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n리스너 설정\n리스너 프로토콜은 TCP, 포트는 3306으로 설정합니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 선택\n위에서 생성했던 Target Group을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n네트워크 로드밸런서와 연동을 할 때는 로드밸런서의 Subnet 대역 뿐만 아니라 [네트워크 로드밸런서]에 접근하는 장비의 공인 IP를 [Cloud DB for MySQL]의 ACG에 추가해야 합니다.\n\n\n⁃ 네트워크 로드밸런서는 보다 고속으로 분산처리를 하기 위해 DSR(Direct Server Return)로 동작합니다. \n⁃ 그래서 로드밸런서에 접속하는 서버 IP를 Target Group에 묶인 장비(여기서는 DB 서버)에 그대로 전달하게 됩니다. \n⁃ 그러므로 ACG에는 로드밸런서의 Subnet 대역이 아닌 접속하는 서버의 공인 IP를 허용해 주어야 합니다.\n\n\nTest 서버 공인 IP 확인\n테스트를 위해 미리 준비해 둔 CentOS를 설치한 서버입니다. ACG 설정에 추가할 공인 IP를 확인합니다.\n\n\n  \n  \n    \n  \n\n\nLoad Balancer 서브넷 확인\nACG에 추가할 멀티존으로 구성된 로드밸런서의 서브넷을 확인합니다.\n그리고, 테스트 시에 접속할 로드밸런서의 접속 정보를 메모해 둡니다.\n\n\n  \n  \n    \n  \n\n\nACG 확인\n[Cloud DB for MySQL]의 [Master] DB를 선택하고 [ACG] 항목 옆의 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[ACG] 리스트에서 해당 ACG를 선택하고 [ACG 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 추가\n필요한 ACG 규칙을 추가합니다. 여기서는 테스트에 필요한 다음 항목들을 추가했습니다.\n\n  Test CentOS Server -&gt; Cloud DB for MySQL 접근 규칙\n  Load Balancer -&gt; Cloud DB for MySQL 접근 규칙\n\n\n\n  \n  \n    \n  \n\n\n테스트 서버 설정\nDB 부하 분산 테스트에 사용할 서버에 MySQL Client를 설치합니다.\n\n Note: CentOS 7부터는 yum으로 설치하는 MySQL의 기본 데이터베이스가 MariaDB로 변경되었습니다.\n\n~# yum -y install mysql\n\n\n  \n  \n    \n  \n\n\n부하 분산 테스트\n설치된 MySQL Client를 이용해서 Load Balancer 도메인으로 접속한 후에 접속한 DB 서버의 호스트명을 확인하는 쿼리를 실행합니다.\n\n여러 차례 반복해보면 아래와 같이 위에서 추가했던 Slave DB [test-003-OOO], [test-004-OOO]에 각각 접속되는 것을 확인할 수 있습니다.\n\n~# mysql -h {Load Balancer 접속 도메인} -u {계정} -p\n\n\nMySQL [(none)]&gt; SELECT @@hostname;\n\n\n[test-003-OOO]에 접속된 상태\n\n  \n  \n    \n  \n\n\n[test-004-OOO]에 접속된 상태\n\n  \n  \n    \n  \n\n\nDB 삭제\n테스트를 끝낸 DB를 삭제하려고 할 때 [Slave나 Recovery DB 서버가 있는 경우 Master DB를 삭제할 수 없습니다.]라는 메시지가 나타나는 것을 확인할 수 있습니다.\n\n그래서 DB를 삭제할 때는 [Slave DB]부터 삭제해야 하고, [Slave DB]를 삭제할 때에도 동시에 삭제할 수 없고 1대씩 차례로 삭제해야 합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for MySQL 읽기 부하 분산 설정 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-2\n    \n  \n  VPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 프록시 로드밸런서로 분산시키는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-proxy-lb.html\n    \n  \n  Classic 환경 Cloud DB for MySQL 읽기 부하 로드밸런서로 분산시키는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-mysql-read-load-balancing.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mysql-read-load-balancing-network-proxy-lb-html": {
						"id": "database-ncloud-database-cloud-db-for-mysql-read-load-balancing-network-proxy-lb-html",
						"title": "VPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 프록시 로드밸런서로 분산시키는 방법",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-proxy-lb.html",
						"content": "개요\nMySQL DB서버의 부하를 줄이기 위해 보통 읽기 전용 DB서버를 생성하게 되는데, 읽기 전용 서버를 여러대 생성해서 로드밸런서(Load Balancer)로 연결하면 읽기 부하를 분산 시키고 좀 더 안정적인 서비스가 가능해집니다.\n\n여기서는 Ncloud (네이버 클라우드) VPC 환경에서 관리형 DB인 Cloud DB for MySQL의 읽기 전용 Slave DB를 네트워크 프록시 로드밸런서(Network Proxy Load Balancer)에 연결하고 제대로 부하가 분산되는지 확인해보겠습니다.\n\n사전 준비\nDB 접속과 부하 분산을 테스트할 서버가 필요합니다. 여기서는 CentOS 7.8 서버를 준비했습니다.\n\nDB 서버 생성\n우선 [Cloud DB for MySQL] - [DB Server]에서 DB를 생성합니다.\n\n서버 설정\nDB엔진 버전과 VPC, 그리고 Subnet을 선택합니다.\n\n[고가용성 지원]을 선택하면 [Standby DB]도 추가로 생성되고, [Multi Zone]을 선택하면 Master와 Standby Master DB를 각각 [서로 다른 Zone에 생성]해서 안정성을 높일 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 서버 타입, 스토리지 타입, 스토리지 용량, DB 서버 이름, DB 서비스 이름 등을 입력합니다.\nPrivate Sub 도메인을 선택하고 입력하면 [*.{Private Sub Domain}.vpc-cdb.ntruss.com] 같은 형식으로 도메인이 생성됩니다.\n\n\n  \n  \n    \n  \n\n\nDB 설정\nUSER ID, DB 접근 HOST(IP), USER 암호, 접속 포트, DB명 등을 입력합니다.\n고가용성을 선택한 경우 [Backup]은 기본으로 무조건 사용하게 됩니다.\n\n 접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nSlave DB Server 추가\nDB가 생성되었으면 [Master] DB를 선택하고, [DB 관리]에서 [Slave 추가] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\nSlave DB Server를 추가할 때 설정할 수 있는 것은 Subnet 입니다. 부하 분산을 위해서는 2대 이상을 추가해야 하는데, 여기서는 테스트를 위해 2대를 추가하겠습니다.\n우선 첫번째 Slave DB Server는 KR-2 존에 추가했습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 두번째 Slave DB Server는 KR-1 존에 추가해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n이렇게 Slave DB Server 2대를 추가해서 [Master], [Standy Master] 포함 총 4대의 서버가 생성되었습니다.\n\n[Master] DB 서버와 첫번째 [Slave] DB 서버는 KR-2 존에, [Standy Master] DB 서버와 두번째 [Slave] DB 서버는 KR-1 존에 생성해서 안정성을 높이는 구조를 선택했습니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정\n다음으로 Load Balancer와 Cloud DB for Mysql을 연결할 Target Group을 설정해보겠습니다.\n\nTarget Group 생성\n여기서 중요한 항목은 프로토콜입니다. [Network Proxy Load Balancer]에 사용할 Target Group이므로 [PROXY_TCP]를 선택합니다.\n포트는 Cloud DB for Mysql 생성 시에 사용했던 포트를 입력해야 하는데 여기서는 3306을 사용하겠습니다.\n\n\n  \n  \n    \n  \n\n\nHealth Check 설정\nHealth Check 설정에서는 TCP 프로토콜을 선택합니다. 포트는 마찬가지로 3306을 입력합니다.\n\n\n  \n  \n    \n  \n\n\nTarget 추가\nTarget 추가 화면에 가면 앞에서 생성했던 Slave DB Server 2대를 확인할 수 있는데, 선택 후에 오른쪽으로 이동시킵니다.\n\n\n  \n  \n    \n  \n\n\nLoad Balancer 생성\n여기서는 [네트워크 프록시 로드밸런서 (Network Proxy Load Balancer)]를 선택합니다.\n\n\n애플리케이션 로드밸런서(Application Load Balancer)는 Cloud DB for MySQL의 부하분산에 사용할 수 없습니다.\n\n\n\n  \n  \n    \n  \n\n\n로드밸런서 생성\n안정성을 높이려면 로드밸런서도 멀티존으로 구성할 수 있습니다. KR-1, KR-2 두 곳의 서브넷을 모두 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n리스너 설정\n리스너 프로토콜은 TCP, 포트는 3306으로 설정합니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 선택\n위에서 생성했던 Target Group을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n[Cloud DB for MySQL]에 접근하는 로드밸런서들의 Subnet 대역을 ACG에 추가해야 합니다.\n\nLoad Balancer 서브넷 확인\nACG에 추가할 멀티존으로 구성된 로드밸런서의 서브넷 2가지를 확인합니다.\n그리고, 테스트 시에 접속할 로드밸런서의 접속 정보를 메모해 둡니다.\n\n\n  \n  \n    \n  \n\n\nACG 확인\n[Cloud DB for MySQL]의 [Master] DB를 선택하고 [ACG] 항목 옆의 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[ACG] 리스트에서 해당 ACG를 선택하고 [ACG 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 추가\n필요한 ACG 규칙을 추가합니다.\n\n  Load Balancer (KR-1) -&gt; Cloud DB for MySQL 접근 규칙\n  Load Balancer (KR-2) -&gt; Cloud DB for MySQL 접근 규칙\n\n\n\n  \n  \n    \n  \n\n\n테스트 서버 설정\nDB 부하 분산 테스트에 사용할 서버에 MySQL Client를 설치합니다.\n\n Note: CentOS 7부터는 yum으로 설치하는 MySQL의 기본 데이터베이스가 MariaDB로 변경되었습니다.\n\n~# yum -y install mysql\n\n\n  \n  \n    \n  \n\n\n부하 분산 테스트\n설치된 MySQL Client를 이용해서 Load Balancer 도메인으로 접속한 후에 접속한 DB 서버의 호스트명을 확인하는 쿼리를 실행합니다.\n\n여러 차례 반복해보면 아래와 같이 위에서 추가했던 Slave DB [test-003-OOO], [test-004-OOO]에 각각 접속되는 것을 확인할 수 있습니다.\n\n~# mysql -h {Load Balancer 접속 도메인} -u {계정} -p\n\n\nMySQL [(none)]&gt; SELECT @@hostname;\n\n\n[test-003-OOO]에 접속된 상태\n\n  \n  \n    \n  \n\n\n[test-004-OOO]에 접속된 상태\n\n  \n  \n    \n  \n\n\nDB 삭제\n테스트를 끝낸 DB를 삭제하려고 할 때 [Slave나 Recovery DB 서버가 있는 경우 Master DB를 삭제할 수 없습니다.]라는 메시지가 나타나는 것을 확인할 수 있습니다.\n\n그래서 DB를 삭제할 때는 [Slave DB]부터 삭제해야 하고, [Slave DB]를 삭제할 때에도 동시에 삭제할 수 없고 1대씩 차례로 삭제해야 합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for MySQL 읽기 부하 분산 설정 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-2\n    \n  \n  VPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 로드밸런서로 분산시키는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-lb.html\n    \n  \n  Classic 환경 Cloud DB for MySQL 읽기 부하 로드밸런서로 분산시키는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-mysql-read-load-balancing.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mysql-read-load-balancing-html": {
						"id": "database-ncloud-database-cloud-db-for-mysql-read-load-balancing-html",
						"title": "Classic 환경 Cloud DB for MySQL 읽기 부하 로드밸런서로 분산시키는 방법",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-mysql-read-load-balancing.html",
						"content": "개요\nMySQL DB서버의 부하를 줄이기 위해 보통 읽기 전용 DB서버를 생성하게 되는데, 읽기 전용 서버를 여러대 생성해서 로드밸런서(Load Balancer)로 연결하면 읽기 부하를 분산 시키고 좀 더 안정적인 서비스가 가능해집니다.\n\n여기서는 Ncloud (네이버 클라우드) Classic 환경에서 관리형 DB인 Cloud DB for MySQL의 읽기 전용 Slave DB를 로드밸런서에 연결하고 제대로 부하가 분산되는지 확인해보겠습니다.\n\n사전 준비\nDB 접속과 부하 분산을 테스트할 서버가 필요합니다. 여기서는 CentOS 7.8 서버를 준비했습니다.\n\nDB 서버 생성\n우선 [Cloud DB for MySQL] - [DB Server]에서 DB를 생성합니다.\n\n서버 설정\n서버 설정에서 중요한 부분은 [고가용성 지원] 항목입니다. Slave DB를 추가하기 위해서는 [고가용성 지원] 항목을 체크해야 합니다. \n혹시 고가용성 지원 없이 서버를 생성했을 경우 이후에 [고가용성 지원]을 설정하면 문제 없이 Slave DB를 추가할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 설정\n그 외 필요한 DB 설정을 입력합니다. 여기서 Backup 설정은 고가용성을 선택했을 경우 자동으로 사용하도록 설정됩니다.\n\n\n  \n  \n    \n  \n\n\nSlave DB 추가\nDB 서버 생성이 완료되면 아래와 같이 [Master], [Standy Master] 2대의 서버가 생성된 것을 확인할 수 있습니다.\nMaster 서버를 선택하고 [DB 관리] 메뉴에서 [Slave 추가]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\nSlave DB 정보\nSlave DB 서버 추가 팝업에서는 특별히 수정할 부분 없이 [예] 버튼을 클릭하면 추가 됩니다.\n\nSlave DB Server는 Master DB Server와 동일한 스펙 (DB Server 타입, 스토리지 타입, 스토리지 용량)및 DB Config 설정으로 생성됩니다. Slave DB Server 역시 Master DB Server와 동일한 요금이 청구되며, 사용한 시간으로 과금됩니다.\n\n\n  \n  \n    \n  \n\n\n생성 완료\nSlave DB를 1대 생성했으면 동일한 방법으로 하나 더 생성합니다. \n여기서는 [test-003], [test-004]라는 이름으로 생성되었습니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n다음으로 방화벽 ACG를 미리 설정해야 하는데, Master DB를 선택하고 아래쪽에 있는 [ACG] 항목을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 리스트에서 Cloud DB를 생성할때 자동으로 생성된 [cloud-db-OOOO]라는 이름의 ACG를 선택하고 [ACG 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n규칙 설정\nACG에 설정이 필요한 규칙은 2가지입니다.\n\n  부하 분산을 위한 Load Balancer -&gt; Cloud DB for MySQL로 접근을 허용하는 규칙\n  테스트를 위한 Server -&gt; Cloud DB for MySQL로 접근을 허용하는 규칙\n\n\nLoad Balancer -&gt; Cloud DB for MySQL로 접근을 허용하는 규칙은 Load Balancer 전용 ACG [ncloud-load-balancer]를 [접근 소스] 항목에 추가합니다.\n\nServer -&gt; Cloud DB for MySQL로 접근을 허용하는 규칙은 [접근 소스] 항목에 [Server IP] 또는 [Server에 설정된 ACG]를 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nLoad Balancer 생성\n마지막으로 로드밸런서를 생성해야 하는데, 로드밸런서를 생성할 때 Slave DB와 연결하려면 네트워크 항목을 [Private IP]로 설정해야 합니다.\n그리고 프로토콜은 TCP, 포트는 3306으로 설정하겠습니다.\n\n\n  \n  \n    \n  \n\n\n서버 추가\n[서버 추가] 화면에는 적용할 서버 리스트에 위에서 생성했던 Slave DB 서버가 나타나는데, 모두 선택하고 오른쪽으로 이동 시킵니다.\n\n\n  \n  \n    \n  \n\n\n설정에 이상이 없으면 로드밸런서가 생성되고, 적용 서버의 연결 상태가 모두 [성공]으로 나타납니다.\n\n\n  \n  \n    \n  \n\n\n테스트 서버 설정\n읽기 부하가 제대로 분산되는지 테스트 하기 위해 준비된 서버에 [MySQL Client]를 설치합니다.\n\n Note: CentOS 7부터는 yum으로 설치하는 MySQL의 기본 데이터베이스가 MariaDB로 변경되었습니다.\n\n~# yum -y install mysql\n\n\n\n  \n  \n    \n  \n\n\n부하 분산 테스트\n설치된 MySQL Client를 이용해서 Load Balancer IP로 접속한 후에 접속한 DB 서버의 호스트명을 확인하는 쿼리를 실행합니다.\n\n여러 차례 반복해보면 아래와 같이 위에서 추가했던 Slave DB [test-003], [test-004]에 각각 접속되는 것을 확인할 수 있습니다.\n\n~# mysql -h {Load Balancer IP} -u {계정} -p\n\n\nMySQL [(none)]&gt; SELECT @@hostname;\n\n\n[test-003]에 접속된 상태\n\n  \n  \n    \n  \n\n\n[test-004]에 접속된 상태\n\n  \n  \n    \n  \n\n\nDB 삭제\n테스트를 끝낸 DB를 삭제하려고 할 때 [Slave나 Recovery DB 서버가 있는 경우 Master DB를 삭제할 수 없습니다.]라는 메시지가 나타나는 것을 확인할 수 있습니다.\n\n그래서 DB를 삭제할 때는 [Slave DB]부터 삭제해야 하고, [Slave DB]를 삭제할 때에도 동시에 삭제할 수 없고 1대씩 차례로 삭제해야 합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for MySQL 읽기 부하 분산 설정 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-2\n    \n  \n  VPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 프록시 로드밸런서로 분산시키는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-proxy-lb.html\n    \n  \n  VPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 로드밸런서로 분산시키는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-mysql-read-load-balancing-network-lb.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-postgresql-guide-centos-html": {
						"id": "database-ncloud-database-cloud-db-for-postgresql-guide-centos-html",
						"title": "VPC환경에서 Cloud DB for PostgreSQL 생성하기 | CentOS",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-postgresql-guide-centos.html",
						"content": "지원 클라우드 환경\nNcloud Cloud DB for PostgreSQL이 지원하는 클라우드 환경은 다음과 같습니다.\n\n\n  리전(존): 한국, 싱가포르\n  VPC만\t지원\n  언어: 한국어, 영어, 일본어, 중국어(간체)\n  DB 엔진 버전: PostgreSQL 13.3\n\n\n서버 사양과 요금\n\n(2022-03-30 기준)\n\n  \n    타입제공사양이용 요금\n    vCPU메모리디스크시간당/대\n  \n  \n    High CPU2개4GB50GB158원\n    4개8GB323원\n    8개16GB653원\n    16개32GB1,313원\n    32개64GB2,633원\n    Standard2개8GB50GB250원\n    4개16GB506원\n    8개32GB1,019원\n    16개64GB2,045원\n    32개128GB4,099원\n    High Memory2개16GB50GB302원\n    4개32GB611원\n    8개64GB1,227원\n    16개128GB2,462원\n    32개256GB4,927원\n  \n\n\n서버 사양 변경 시 제약 사항\nCloud DB for PostgreSQL 서버는 타입은 변경할 수 없지만 메모리 크기는 콘솔 PostgreSQL Server 메뉴에서 스펙 변경 기능을 사용하여 언제든지 변경할 수 있습니다. 그 외 제약 사항은 아래와 같습니다.\n\n\n  같은 타입 내에서만 변경 가능\n  2대 이상의 서버로 구성된 경우(고가용성 사용 및 Read Replica 사용) 모두 동일한 사양으로 변경\n  변경 완료 후 서버가 다시 시작되며 이에 따라 서비스 영향 발생 가능성 존재\n\n\n상세 특징\n\n  DB 엔진 버전: PostgreSQL 13.3\n  스토리지: 기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6000GB까지 자동으로 용량이 증가\n  Multi Zone 구성 제공\n  자동 Fail-over 기본 지원\n  최대 5대까지 Read Replica 확장\n  최대 30일까지 자동 백업 및 보관\n\n\n서버 접근 방법\nCloud DB for PostgreSQL은 현재 다음의 3가지 방법으로 접근 가능한데 여기서는 별도의 Linux 서버를 생성해서 PostgreSQL과 Private 통신을 하는 방법으로 진행하겠습니다.\n\n\n⁃ Public Domain으로 접근 (2022-04-21 업데이트) \n⁃ PostgreSQL DB와 Private 통신을 위한 별도의 서버를 생성해서 접근 \n⁃ SSL VPN을 이용해서 접근\n\n\nDB 생성\n[Cloud DB for PostgreSQL] - [DB Server]에서 [DB Server 생성] 버튼을 클릭해 DB를 생성을 시작합니다.\n\n\n  \n  \n    \n  \n\n\n서버 설정\n\n  DB 엔진: 현재 지원되는 DB 엔진 버전은 PostgreSQL 13.3 입니다.\n  고가용성 지원은 기본 선택 사항인데, 필요하지 않을 경우 체크를 해제하면 됩니다.\n  VPC와 Subnet을 선택하고, 미리 생성된 VPC와 Subnet가 없으면 생성 버튼을 클릭합니다.\n  DB Server 타입은 위쪽에서 확인했던 서버 사양 중에서 원하는 vCPU와 메모리를 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  데이터 스토리지 타입과 암호화 적용 여부를 선택합니다.\n  데이터 스토리지는 기본 10GB로 설정되며 최대 6000GB까지 자동으로 증가합니다.\n  DB Server 이름과 DB Service 이름을 입력합니다. DB Service 이름은 DB Server를 역할별로 구분한 그룹의 명칭입니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 설정\n\n  USER ID와 암호를 입력합니다. (ID와 암호는 잊어버리지 않도록 잘 보관해야 합니다.)\n  접근제어는 접근을 허용할 IP 대역을 입력합니다.\n  DB 접속포트는 기본 포트가 5432 입니다.\n  기본 DB명을 입력하고, Backup 설정을 선택합니다.\n\n\n 접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n지금까지 입력한 값이 이상이 없는지 최종 확인하고, 수정할 부분이 없으면 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nDB 상세 정보\nDB 생성이 완료되면 아래와 같이 DB의 상세 정보를 확인할 수 있습니다.\n이 중에서 Private 도메인과 ACG는 이후 설정에서 사용할 중요한 항목입니다.\n\n\n  \n  \n    \n  \n\n\nClient Server 생성 | CentOS\n처음에 설명했 듯이 Cloud DB for PostgreSQL DB Server는 Private 환경에서만 접속 가능하므로 PostgreSQL Client를 설치할 Linux Server를 생성해야 하는데, \n여기서는 CentOS 7.8을 설치했습니다.\n\nVPC 환경에서 Linux Server를 생성하는 방법은 다음 문서를 참고하시기 바랍니다.\n\n  VPC 환경에서 서버 생성하기\n\n\n\n생성된 Client Server의 정보 중에서 비공인 IP는 다음 ACG 설정에서 필요하니 기억해 둡니다.\n마찬가지로 공인 IP는 로컬 PC에서 PostgreSQL Client에 접속할 때 필요하니 기억해 둡니다.\n\n\n\n  \n  \n    \n  \n\n\nACG 설정\n[Server] - [ACG]에서 Cloud DB for PostgreSQL 생성 시에 자동으로 생성된 ACG [cloud-postgresql-ooooo]를 선택하고, [ACG 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정\nACG 규칙 설정 창에서 [Inbound] 탭을 선택하고 [접근 소스]는 위에서 생성한 Client Server의 비공인 IP를 입력하고 허용 포트는 5432를 입력하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\npgAdmin4 설치\nClient용 Linux Server에 PostgreSQL DB의 Client 프로그램인 pgAdmin4를 설치합니다.\n\n~# yum -y install https://ftp.postgresql.org/pub/pgadmin/pgadmin4/yum/pgadmin4-redhat-repo-2-1.noarch.rpm\n\n\n  \n  \n    \n  \n\n\npgAdmin4-Web 설치\n로컬 PC에서 pgAdmin4에 접속하기 위해 pgAdmin4-Web을 설치합니다.\n\n~# yum -y install pgadmin4-web\n\n\n  \n  \n    \n  \n\n\npgAdmin4-Web 환경 설정\nsetup-web.sh 스크립트를 실행 후 pgAdmin4-Web 접속을 위한 이메일 계정과 패스워드를 입력합니다.\n\n~# /usr/pgadmin4/bin/setup-web.sh\n\n\n  \n  \n    \n  \n\n\n오류 상황\n간혹 위에서 진행한 pgAdmin4-Web 환경 설정에서 아래와 같은 오류가 발생하는 경우가 있습니다.\n\n semanage 오류: \n/usr/pgamin4/bin/setup-web.sh: line 87: semanage: command not found\n/usr/pgamin4/bin/setup-web.sh: line 89: semanage: command not found\n\n\n\n  \n  \n    \n  \n\n\n필요한 파일 확인\nsemanage 실행에 필요한 파일을 확인합니다.\n아래 명령어를 실행하면 나오면 결과에 나오는 파일명을 복사합니다.\n\n~# yum provides /usr/sbin/semanage\n\n\n  \n  \n    \n  \n\n\n추가 파일 설치\n위에서 확인한 추가 파일을 설치합니다.\n\n~# yum -y install policycoreutils-python-2.5-34.el7.x86_64\n\n\n  \n  \n    \n  \n\n\npgAdmin4-Web 설정 재 확인\n필요한 파일 설치를 마쳤으면 pgAdmin4-Web 환경 설정 명령어를 다시 실행합니다. 문제가 해결되었으면 오류 메시지가 나타나지 않습니다.\n\n~# /usr/pgadmin4/bin/setup-web.sh\n\n\n  \n  \n    \n  \n\n\npgAdmin4 접속\npgAdmin4 접속 주소는 http://[Client Server 공인IP 주소]/pgadmin4/ 입니다.\n위 주소로 접속하면 아래와 같이 Email Address와 Password 입력 화면이 나오는데 pgAdmin4-Web 환경 설정에서 입력한 이메일과 패스워드를 입력하고 로그인 합니다.\n\n\n  \n  \n    \n  \n\n\n서버 추가\npgAdmin에서 [Add New Server] 버튼을 클릭해서 위에서 생성했던 DB서버를 연결합니다.\n\n\n  \n  \n    \n  \n\n\nName 입력\n등록할 DB의 이름을 편하게 입력합니다.\n\n\n  \n  \n    \n  \n\n\n연결 정보 입력\n\n  Host name/address: Cloud DB for PostgreSQL 생성 후에 확인한 Private 도메인 (pg-oooo-vpc-cdb-kr.ntruss.com)을 입력합니다.\n  Username: Cloud DB for PostgreSQL 생성 시에 입력한 USER ID를 입력합니다.\n  Password: Cloud DB for PostgreSQL 생성 시에 입력한 USER 암호를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\npgAdmin4 대시보드\n연결 정보에 이상이 없고 정상적으로 접속이 되면 아래와 같이 대시보드 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB Service 상세 보기\nDB Service 상세 보기에서는 Database 추가/삭제, Config 관리, User 추가/삭제, Backup 설정 등을 관리할 수 있습니다.\nCloud DB for PostgreSQL을 선택하고 [DB 관리] - [DB Service 상세보기] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nDatabase 관리\nPostgreSQL DB의 Database를 추가/삭제 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB User 관리\nCloud DB for PostgreSQL의 DB User를 추가/삭제 할 수 있습니다.\n\n\n⁃ PostgreSQL은 1개의 DB에 1개 계정만 owner로 지정할 수 있습니다.\n⁃ 1개의 DB를 여러 계정으로 관리해야 하는 경우는 서브 계정을 만들고 \n   owner 계정으로 서브 계정에 별도의 권한을 설정해야 합니다.\n⁃ 이때 계정 생성은 Ncloud 콘솔에서만 가능합니다. (아래 화면의 DB User 관리 기능)\n⁃ 그 외의 권한 설정은 pgAdmin4 웹페이지에서 설정해야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n서브 계정\nsubid라는 서브 계정을 만들었다고 가정했을 때 아래 화면처럼 Superuser 등의 권한 설정을 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 접근 권한 설정\n서브 계정의 특정 DB에 대한 접근 권한을 설정하고자 할 경우는 아래와 같이 DB를 선택하고, 마우스 오른쪽 클릭을 한 후 [Properties] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n[Properties] 설정 화면에서 [Security] 메뉴를 선택하면 계정별로 권한을 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for PostgreSQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbforpostgresql-overview\n    \n  \n  pgAdmin 홈페이지\n    \n      https://www.pgadmin.org/\n    \n  \n  Cloud DB for PostgreSQL Private 도메인 접속 - Ubuntu\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-postgresql-guide-ubuntu.html\n    \n  \n  Cloud DB for PostgreSQL Public 도메인 접속\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-postgresql-public-domain-guide.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-postgresql-guide-ubuntu-html": {
						"id": "database-ncloud-database-cloud-db-for-postgresql-guide-ubuntu-html",
						"title": "VPC환경에서 Cloud DB for PostgreSQL 생성하기 | Ubuntu",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-postgresql-guide-ubuntu.html",
						"content": "지원 클라우드 환경\nNcloud Cloud DB for PostgreSQL이 지원하는 클라우드 환경은 다음과 같습니다.\n\n\n  리전(존): 한국, 싱가포르\n  VPC만\t지원\n  언어: 한국어, 영어, 일본어, 중국어(간체)\n  DB 엔진 버전: PostgreSQL 13.3\n\n\n서버 사양과 요금\n\n(2022-03-30 기준)\n\n  \n    타입제공사양이용 요금\n    vCPU메모리디스크시간당/대\n  \n  \n    High CPU2개4GB50GB158원\n    4개8GB323원\n    8개16GB653원\n    16개32GB1,313원\n    32개64GB2,633원\n    Standard2개8GB50GB250원\n    4개16GB506원\n    8개32GB1,019원\n    16개64GB2,045원\n    32개128GB4,099원\n    High Memory2개16GB50GB302원\n    4개32GB611원\n    8개64GB1,227원\n    16개128GB2,462원\n    32개256GB4,927원\n  \n\n\n서버 사양 변경 시 제약 사항\nCloud DB for PostgreSQL 서버는 타입은 변경할 수 없지만 메모리 크기는 콘솔 PostgreSQL Server 메뉴에서 스펙 변경 기능을 사용하여 언제든지 변경할 수 있습니다. 그 외 제약 사항은 아래와 같습니다.\n\n\n  같은 타입 내에서만 변경 가능\n  2대 이상의 서버로 구성된 경우(고가용성 사용 및 Read Replica 사용) 모두 동일한 사양으로 변경\n  변경 완료 후 서버가 다시 시작되며 이에 따라 서비스 영향 발생 가능성 존재\n\n\n상세 특징\n\n  DB 엔진 버전: PostgreSQL 13.3\n  스토리지: 기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6000GB까지 자동으로 용량이 증가\n  Multi Zone 구성 제공\n  자동 Fail-over 기본 지원\n  최대 5대까지 Read Replica 확장\n  최대 30일까지 자동 백업 및 보관\n\n\n서버 접근 방법\nCloud DB for PostgreSQL은 현재 다음의 3가지 방법으로 접근 가능한데 여기서는 별도의 Linux 서버를 생성해서 PostgreSQL과 Private 통신을 하는 방법으로 진행하겠습니다.\n\n\n⁃ Public Domain으로 접근 (2022-04-21 업데이트) \n⁃ PostgreSQL DB와 Private 통신을 위한 별도의 서버를 생성해서 접근 \n⁃ SSL VPN을 이용해서 접근\n\n\nDB 생성\n[Cloud DB for PostgreSQL] - [DB Server]에서 [DB Server 생성] 버튼을 클릭해 DB를 생성을 시작합니다.\n\n\n  \n  \n    \n  \n\n\n서버 설정\n\n  DB 엔진: 현재 지원되는 DB 엔진 버전은 PostgreSQL 13.3 입니다.\n  고가용성 지원은 기본 선택 사항인데, 필요하지 않을 경우 체크를 해제하면 됩니다.\n  VPC와 Subnet을 선택하고, 미리 생성된 VPC와 Subnet가 없으면 생성 버튼을 클릭합니다.\n  DB Server 타입은 위쪽에서 확인했던 서버 사양 중에서 원하는 vCPU와 메모리를 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  데이터 스토리지 타입과 암호화 적용 여부를 선택합니다.\n  데이터 스토리지는 기본 10GB로 설정되며 최대 6000GB까지 자동으로 증가합니다.\n  DB Server 이름과 DB Service 이름을 입력합니다. DB Service 이름은 DB Server를 역할별로 구분한 그룹의 명칭입니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 설정\n\n  USER ID와 암호를 입력합니다. (ID와 암호는 잊어버리지 않도록 잘 보관해야 합니다.)\n  접근제어는 접근을 허용할 IP 대역을 입력합니다.\n  DB 접속포트는 기본 포트가 5432 입니다.\n  기본 DB명을 입력하고, Backup 설정을 선택합니다.\n\n\n 접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n지금까지 입력한 값이 이상이 없는지 최종 확인하고, 수정할 부분이 없으면 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nDB 상세 정보\nDB 생성이 완료되면 아래와 같이 DB의 상세 정보를 확인할 수 있습니다.\n이 중에서 Private 도메인과 ACG는 이후 설정에서 사용할 중요한 항목입니다.\n\n\n  \n  \n    \n  \n\n\nClient Server 생성 | Ubuntu\n처음에 설명했 듯이 Cloud DB for PostgreSQL DB Server는 Private 환경에서만 접속 가능하므로 PostgreSQL Client를 설치할 Linux Server를 생성해야 하는데, \n여기서는 Ubuntu 18.04을 설치했습니다.\n\nVPC 환경에서 Linux Server를 생성하는 방법은 다음 문서를 참고하시기 바랍니다.\n\n  VPC 환경에서 서버 생성하기\n\n\n\n생성된 Client Server의 정보 중에서 비공인 IP는 다음 ACG 설정에서 필요하니 기억해 둡니다.\n마찬가지로 공인 IP는 로컬 PC에서 PostgreSQL Client에 접속할 때 필요하니 기억해 둡니다.\n\n\n\n  \n  \n    \n  \n\n\nACG 설정\n[Server] - [ACG]에서 Cloud DB for PostgreSQL 생성 시에 자동으로 생성된 ACG [cloud-postgresql-ooooo]를 선택하고, [ACG 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정\nACG 규칙 설정 창에서 [Inbound] 탭을 선택하고 [접근 소스]는 위에서 생성한 Client Server의 비공인 IP를 입력하고 허용 포트는 5432를 입력하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\npgAdmin4 설치\nClient용 Linux Server에 PostgreSQL DB의 Client 프로그램인 pgAdmin4를 설치합니다.\n\nRepository 설정\npgAdmin4 설치하기 위해 Repository를 먼저 설정합니다.\n\n~# curl https://www.pgadmin.org/static/packages_pgadmin_org.pub | sudo apt-key add\n\n\n  \n  \n    \n  \n\n\n~# sh -c 'echo \"deb https://ftp.postgresql.org/pub/pgadmin/pgadmin4/apt/$(lsb_release -cs) pgadmin4 main\" &gt; /etc/apt/sources.list.d/pgadmin4.list &amp;&amp; apt update'\n\n\n  \n  \n    \n  \n\n\n오류 상황\n간혹 위에서 진행한 Repository 설정에서 아래와 같은 오류가 발생하는 경우가 있습니다.\n\n Certificate verification failed: \nThe certificate is NOT trusted. The certificate chain uses expired certificate. Could not handshake: Error in the certificate verification.\n\n\n\n  \n  \n    \n  \n\n\n추가 기능 설치\n위 오류 메시지에 보면 인증서 관련해서 오류가 발생하는 것으로 확인되었기에 인증서 관련 기능을 추가 설치합니다.\n\n~# apt install ca-certificates\n\n\n  \n  \n    \n  \n\n\nRepository 다시 설정\nRepository 설정에서 오류가 발생했던 부분을 다시 설정합니다. 실행해보면 정상적으로 설정되었다는 메시지를 확인할 수 있습니다.\n\n~# sh -c 'echo \"deb https://ftp.postgresql.org/pub/pgadmin/pgadmin4/apt/$(lsb_release -cs) pgadmin4 main\" &gt; /etc/apt/sources.list.d/pgadmin4.list &amp;&amp; apt update'\n\n\n  \n  \n    \n  \n\n\npgAdmin4 설치\n로컬 PC에서 pgAdmin4에 접속하기 위해 pgAdmin4-Web을 설치합니다.\n\n~# apt install pgadmin4\n\n\n⁃ apt install pgadmin4: desktop, web mode 두가지 모두 설치\n⁃ apt install pgadmin4-desktop: desktop mode만 설치\n⁃ apt install pgadmin4-web: web mode만 설치\n\n\n\n  \n  \n    \n  \n\n\npgAdmin4-Web 환경 설정\nsetup-web.sh 스크립트를 실행 후 pgAdmin4-Web 접속을 위한 이메일 계정과 패스워드를 입력합니다.\n\n~# /usr/pgadmin4/bin/setup-web.sh\n\n\n  \n  \n    \n  \n\n\npgAdmin4 접속\npgAdmin4 접속 주소는 http://[Client Server 공인IP 주소]/pgadmin4/ 입니다.\n위 주소로 접속하면 아래와 같이 Email Address와 Password 입력 화면이 나오는데 pgAdmin4-Web 환경 설정에서 입력한 이메일과 패스워드를 입력하고 로그인 합니다.\n\n\n  \n  \n    \n  \n\n\n서버 추가\npgAdmin에서 [Add New Server] 버튼을 클릭해서 위에서 생성했던 DB서버를 연결합니다.\n\n\n  \n  \n    \n  \n\n\nName 입력\n등록할 DB의 이름을 편하게 입력합니다.\n\n\n  \n  \n    \n  \n\n\n연결 정보 입력\n\n  Host name/address: Cloud DB for PostgreSQL 생성 후에 확인한 Private 도메인 (pg-oooo-vpc-cdb-kr.ntruss.com)을 입력합니다.\n  Username: Cloud DB for PostgreSQL 생성 시에 입력한 USER ID를 입력합니다.\n  Password: Cloud DB for PostgreSQL 생성 시에 입력한 USER 암호를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\npgAdmin4 대시보드\n연결 정보에 이상이 없고 정상적으로 접속이 되면 아래와 같이 대시보드 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB Service 상세 보기\nDB Service 상세 보기에서는 Database 추가/삭제, Config 관리, User 추가/삭제, Backup 설정 등을 관리할 수 있습니다.\nCloud DB for PostgreSQL을 선택하고 [DB 관리] - [DB Service 상세보기] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nDatabase 관리\nPostgreSQL DB의 Database를 추가/삭제 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB User 관리\nCloud DB for PostgreSQL의 DB User를 추가/삭제 할 수 있습니다.\n\n\n⁃ PostgreSQL은 1개의 DB에 1개 계정만 owner로 지정할 수 있습니다.\n⁃ 1개의 DB를 여러 계정으로 관리해야 하는 경우는 서브 계정을 만들고 \n   owner 계정으로 서브 계정에 별도의 권한을 설정해야 합니다.\n⁃ 이때 계정 생성은 Ncloud 콘솔에서만 가능합니다. (아래 화면의 DB User 관리 기능)\n⁃ 그 외의 권한 설정은 pgAdmin4 웹페이지에서 설정해야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n서브 계정\nsubid라는 서브 계정을 만들었다고 가정했을 때 아래 화면처럼 Superuser 등의 권한 설정을 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 접근 권한 설정\n서브 계정의 특정 DB에 대한 접근 권한을 설정하고자 할 경우는 아래와 같이 DB를 선택하고, 마우스 오른쪽 클릭을 한 후 [Properties] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n[Properties] 설정 화면에서 [Security] 메뉴를 선택하면 계정별로 권한을 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for PostgreSQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbforpostgresql-overview\n    \n  \n  pgAdmin 홈페이지\n    \n      https://www.pgadmin.org/\n    \n  \n  Cloud DB for PostgreSQL Private 도메인 접속 - CentOS\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-postgresql-guide-centos.html\n    \n  \n  Cloud DB for PostgreSQL Public 도메인 접속\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-postgresql-public-domain-guide.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-postgresql-public-domain-guide-html": {
						"id": "database-ncloud-database-cloud-db-for-postgresql-public-domain-guide-html",
						"title": "Cloud DB for PostgreSQL 생성 후 Public 도메인으로 접속하기",
						"categories": "",
						"url": " /database/ncloud-database-cloud-db-for-postgresql-public-domain-guide.html",
						"content": "지원 클라우드 환경\nNcloud Cloud DB for PostgreSQL이 지원하는 클라우드 환경은 다음과 같습니다.\n\n\n  리전(존): 한국, 싱가포르\n  VPC만\t지원\n  언어: 한국어, 영어, 일본어, 중국어(간체)\n  DB 엔진 버전: PostgreSQL 13.3\n\n\nDB 생성\n[Cloud DB for PostgreSQL] - [DB Server]에서 [DB Server 생성] 버튼을 클릭해 DB를 생성을 시작합니다.\n\n\n  \n  \n    \n  \n\n\n서버 설정\n\n  DB 엔진: 현재 지원되는 DB 엔진 버전은 PostgreSQL 13.3 입니다.\n  고가용성 지원은 기본 선택 사항인데, 필요하지 않을 경우 체크를 해제하면 됩니다.\n  VPC와 Subnet을 선택하고, 미리 생성된 VPC와 Subnet가 없으면 생성 버튼을 클릭합니다.\n  Subnet은 반드시 Public Subnet으로 선택합니다.\n  DB Server 타입은 위쪽에서 확인했던 서버 사양 중에서 원하는 vCPU와 메모리를 선택하면 됩니다.\n\n\n\n⁃ Public 도메인은 Public Subnet에 생성된 DB 서버에서만 이용 신청이 가능합니다. \n⁃ DB 서버 생성 이후에 Subnet 이전은 불가능합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  데이터 스토리지 타입과 암호화 적용 여부를 선택합니다.\n  데이터 스토리지는 기본 10GB로 설정되며 최대 6000GB까지 자동으로 증가합니다.\n  DB Server 이름과 DB Service 이름을 입력합니다. DB Service 이름은 DB Server를 역할별로 구분한 그룹의 명칭입니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 설정\n\n  USER ID와 암호를 입력합니다. (ID와 암호는 잊어버리지 않도록 잘 보관해야 합니다.)\n  접근제어는 접근을 허용할 IP 대역을 입력합니다.\n  DB 접속포트는 기본 포트가 5432 입니다.\n  기본 DB명을 입력하고, Backup 설정을 선택합니다.\n\n\n 접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n지금까지 입력한 값이 이상이 없는지 특히 Public Subnet으로 설정했는지 최종 확인하고, 수정할 부분이 없으면 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nPublic 도메인 설정\nDB 생성이 완료되면 아래와 같이 DB의 상세 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[DB 관리] - [Public 도메인 관리] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[Public 도메인 신청] 팝업에서 [예] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n이제 [Public 도메인]이 생성되었습니다. 생성된 Public 도메인과 ACG 이름이 중요하니 기억해 둡니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n[Server] - [ACG]에서 Cloud DB for PostgreSQL 생성 시에 자동으로 생성된 ACG [cloud-postgresql-ooooo]를 선택하고, [ACG 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정\nACG 규칙 설정 창에서 [Inbound] 탭을 선택하고 [접근 소스]는 [myIp]를 클릭하고 허용 포트는 5432를 입력하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\npgAdmin 4 다운로드\nPostgreSQL에 접속하기 위한 클라이언트 pgAdmin 4를 다운로드 합니다.\n\n\n  pgAdmin 다운로드 페이지: https://www.pgadmin.org/download/\n\n\n\n  \n  \n    \n  \n\n\n다운로드 할 버전은 pgAdmin 4 v6.7 (released March 14, 2022) 입니다.\n\n  \n  \n    \n  \n\n\npgAdmin 4 설치\npgAdmin 4 클라이언트가 설치되는 기본 경로는 다음과 같습니다.\n\nC:\\Users\\{Windows User Account}\\AppData\\Local\\Programs\\pgAdmin 4\\v6\n\n\n\n  \n  \n    \n  \n\n\npgAdmin 4  실행\n\npgAdmin Master Password 입력\npgAdmin 4 접속/관리를 위한 Master Password를 입력합니다. DB와는 관계없고 단지 pgAdmin 클라이언트를 위한 패스워드입니다.\n\n\nMaster Password는 반드시 입력해야 합니다. 여기서 설정하지 않으면 internal server error: crypt key is missing 에러가 발생하면서 서버 관리를 할 수 없게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\npgAdmin Master Password 재설정\n이후에 혹시 Master Password를 잊어버렸을 경우에는 아래와 같이 [Reset Master Password] 기능을 이용해 재설정 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 추가\npgAdmin에서 [Add New Server] 버튼을 클릭해서 위에서 생성했던 DB서버를 연결합니다.\n\n\n  \n  \n    \n  \n\n\nName 입력\n등록할 DB의 이름을 편하게 입력합니다.\n\n\n  \n  \n    \n  \n\n\n연결 정보 입력\n\n  Host name/address: Cloud DB for PostgreSQL 생성 후에 확인한 Public 도메인 (pg-oooo-vpc-pub-cdb-kr.ntruss.com)을 입력합니다.\n  Username: Cloud DB for PostgreSQL 생성 시에 입력한 USER ID를 입력합니다.\n  Password: Cloud DB for PostgreSQL 생성 시에 입력한 USER 암호를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\npgAdmin 4 대시보드\n연결 정보에 이상이 없고 정상적으로 접속이 되면 아래와 같이 대시보드 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB Service 상세 보기\nDB Service 상세 보기에서는 Database 추가/삭제, Config 관리, User 추가/삭제, Backup 설정 등을 관리할 수 있습니다.\nCloud DB for PostgreSQL을 선택하고 [DB 관리] - [DB Service 상세보기] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nDatabase 관리\nPostgreSQL DB의 Database를 추가/삭제 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB User 관리\nCloud DB for PostgreSQL의 DB User를 추가/삭제 할 수 있습니다.\n\n\n⁃ PostgreSQL은 1개의 DB에 1개 계정만 owner로 지정할 수 있습니다.\n⁃ 1개의 DB를 여러 계정으로 관리해야 하는 경우는 서브 계정을 만들고 \n   owner 계정으로 서브 계정에 별도의 권한을 설정해야 합니다.\n⁃ 이때 계정 생성은 Ncloud 콘솔에서만 가능합니다. (아래 화면의 DB User 관리 기능)\n⁃ 그 외의 권한 설정은 pgAdmin4 웹페이지에서 설정해야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n서브 계정\nsubid라는 서브 계정을 만들었다고 가정했을 때 아래 화면처럼 Superuser 등의 권한 설정을 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 접근 권한 설정\n서브 계정의 특정 DB에 대한 접근 권한을 설정하고자 할 경우는 아래와 같이 DB를 선택하고, 마우스 오른쪽 클릭을 한 후 [Properties] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n[Properties] 설정 화면에서 [Security] 메뉴를 선택하면 계정별로 권한을 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상황\npgAdmin 4를 사용할 때 아래와 같은 오류가 발생하는 경우가 있습니다.\n이는 pgAdmin 4 최신 버전인 6.8을 사용할 때 발생하는 것으로 위에서 안내했 듯이 6.7 버전을 사용하면 문제가 없습니다.\n\n Failed to retrieve data from server.: Request failed with status code 500\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Cloud DB for PostgreSQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/clouddbforpostgresql-overview\n    \n  \n  pgAdmin 홈페이지\n    \n      hhttps://www.pgadmin.org/\n    \n  \n  Cloud DB for PostgreSQL Private 도메인 접속 - CentOS\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-postgresql-guide-centos.html\n    \n  \n  Cloud DB for PostgreSQL Private 도메인 접속 - Ubuntu\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-cloud-db-for-postgresql-guide-ubuntu.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-db-migration-from-mariadb-to-mysql80-guide-html": {
						"id": "database-ncloud-database-db-migration-from-mariadb-to-mysql80-guide-html",
						"title": "Ncloud 데이터베이스 마이그레이션 서비스 | From MariaDB To MySQL 8.0",
						"categories": "",
						"url": " /database/ncloud-database-db-migration-from-mariadb-to-mysql80-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 [MariaDB]를 Private 환경의 [Cloud DB for MySQL 8.0]으로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n\n서비스에서 제공하는 기능\n\n  마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화\n  Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능\n  연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행\n  마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능\n\n\n지원 데이터베이스\nDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\n\n\n  Major 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다.\n  Source DB는 MariaDB도 가능합니다.\n  Target DB는 MySQL만 가능합니다.\n\n\n\n⁃ MariaDB도 마이그레이션이 가능하지만 MySQL 8.0과의 호환성 문제로 마이그레이션이 실패할 수도 있습니다. \n⁃ 마이그레이션이 실패했을 경우에는  MariaDB  MySQL 5.7   MySQL 8.0 이렇게 2단계로 마이그레이션 하는 방법을 시도해보시기 바랍니다.\n\n\n\n  \n  \n    \n  \n\n\n상세 설정 지원 여부\nSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n\n지원 항목\n\n  데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원\n  Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원\n\n\n미지원 항목\n\n  TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원\n  사용자 계정 정보, MariaDB Config 항목, Event 마이그레이션 미지원\n\n\n마이그레이션 진행 구조\n마이그레이션은 Target DB Source DB로 접근하여 DB 데이터를 가져오는 방식으로 진행됩니다.\n\n또한 작업 진행 단계는 다음과 같습니다.\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 완료 상태\n  마이그레이션 작업 완료\n\n\n서비스 점검\n마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 상태\n  서비스 점검 시작\n  마이그레이션 작업 완료\n  서비스 점검 종료\n\n\n테스트 환경\nSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\n\n\n  Source DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다.\n  Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다.\n  Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다.\n  Target DB는 NAT Gateway를 통해서 Source DB에 접근한다.\n\n\nDB 버전 정보\n\n  Source DB: CentOS 7.8, MariaDB 10.4.31\n  Target DB: Cloud DB for MySQL 8.0.32\n\n\n\n  \n      \n          Source DB \n      \n  \n      \n          Target DB \n      \n  \n\n\n  \n      \n⁃ Source DB\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Target DB\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 정보 확인\n테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\n\n\n  \n      \n          MariaDB 버전 \n      \n  \n      \n          Database \n      \n  \n      \n          계정 \n      \n  \n      \n          Table \n      \n  \n      \n          Procedure \n      \n  \n\n\n  \n      \n⁃ MariaDB 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MariaDB 5.7.43입니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Database\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ 계정\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Table\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Procedure\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 사전 설정\n\n마이그레이션 전용 DB User 생성\n마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n\n\n  패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` &amp; + \\ “ ‘ / 스페이스 는 패스워드로 사용할 수 없습니다.\n  기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다.\n\n\nCREATE USER 'migration_test'@'%' IDENTIFIED BY '[패스워드]';\nGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\nGRANT SELECT ON mysql.* TO 'migration_test'@'%';\nGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\nFLUSH PRIVILEGES;\n\n\n\n  위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다.\n\n\n\n  \n  \n    \n  \n\n\nCharacter Set 점검\nTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\n\n\n  Character Set 점검 쿼리\n\n\nSELECT character_set_name\nFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\nWHERE CCSA.collation_name = T.table_collation \nAND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\n\nSELECT DEFAULT_CHARACTER_SET_NAME\nFROM information_schema.SCHEMATA T\nWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\n\n\n\n  Character Set 변경 쿼리 예시\n\n\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8;\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8 COLLATE utf8_general_ci;\nALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci;\n\n\nsql_mode 설정 점검\nMariaDB에서 지원하는 sql_mode=’NO_AUTO_CREATE_USER’ 설정은 MySQL 8.0 버전에서는 지원하지 않기 때문에, Source DB에서 사용된 곳이 있으면 찾아서 해당 옵션을 제거해야 합니다.\n\nsql_mode 설정 점검 쿼리\nProcedure, Function 등의 ROUTINE과 TRIGGER에서 사용되므로 아래 쿼리로 [NO_AUTO_CREATE_USER] 옵션이 사용된 곳이 있는지 점검합니다.\n\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\nFROM information_schema.routines\nWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\n\nSELECT TRIGGER_SCHEMA, TRIGGER_NAME, sql_mode\nFROM information_schema.triggers\nWHERE TRIGGER_SCHEMA NOT IN ('sys','mysql');\n\n\n\n  테스트용 Source DB에서 점검 쿼리를 실행해보면 아래와 같이 [testdb2]의 [new_procedure2]에 [NO_AUTO_CREATE_USER] 옵션이 적용되어 있는 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nsql_mode 호환성 이슈 조치 방법\nProcedure, Function, Trigger의 Dump 파일을 생성하고 [NO_AUTO_CREATE_USER] 옵션을 제거한 후 다시 적용하면 됩니다.\n\n\n  Procedure, Function, Trigger 에 대해서만 drop 및 create 구문이 생성된 sql 파일 생성\n\n\n~# mariadb-dump -u {사용자명} -p  --routines --triggers  --no-create-info --no-data --no-create-db --add-drop-trigger --databases {사용자 DB} &gt; backup.sql\n\n\n  \n  \n    \n  \n\n\n\n  backup.sql 파일내 NO_AUTO_CREATE_USER 구문 모두 제거\n해당 옵션을 일일이 찾아서 제거하기 힘드니 vim 에디터에서 [NO_AUTO_CREATE_USER] 문자를 찾아서 제거하는 명령을 실행합니다.\n경우에 따라서는 Dump 파일에 [NO_AUTO_CREATE_USER] 옵션이 포함되지 않는 경우도 있습니다. 이때는 걱정말고 Dump 파일을 그냥 그대로 적용하면 됩니다.\n\n\nvim 명령: %s /NO_AUTO_CREATE_USER,//g\n\n원본 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'  \n수정 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION'\n\n\n  \n  \n    \n  \n\n\n\n  적용하기\n수정된 Dump 파일을 Source DB에 적용합니다.\n\n\n~# mariadb -u {사용자명} -p {사용자 DB} &lt; backup.sql\n\n\n  \n  \n    \n  \n\n\nsql_mode 설정 변경 확인\n설정이 제대로 변경되었는지 점검 쿼리로 다시 확인해보겠습니다.\n\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\nFROM information_schema.routines\nWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\n\n\n\n  아래 스샷처럼 [NO_AUTO_CREATE_USER] 옵션이 사라진 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n바이너리 로그 설정\nSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n\n현재 설정 확인\n아래 쿼리를 사용해 현재 설정 값을 확인합니다.\n\nshow variables like 'server_id';\nshow variables like 'log_bin';\n\n\n\n  현재 테스트용 Source DB는 [server_id]는 설정되어 있고, [log_bin]은 설정되어 있지 않은 상태입니다.\n\n\n\n  \n  \n    \n  \n\n\n설정 변경\nMariaDB의 환경 설정 파일 [server.cnf]를 열어서 아래 값을 추가하고, MariaDB 데몬을 재시작합니다.\n~# vim /etc/my.cnf.d/server.cnf\n\nlog-bin\nlog-basename = mariadb\nbinlog-format = mixed\ncharacter-set-server = utf8\n\n~# systemctl restart mariadb\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n변경 설정 확인\n설정 변경 후에 확인해보면 아래와 같이 [server_id] 값이 설정되어 있고, [log_bin]이 ON 상태로 변경된 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nTarget DB 사전 설정\n위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\n\nDEFINER 계정 확인\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\n\nSELECT DEFINER FROM information_schema.ROUTINES\nWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\n\nSELECT DEFINER FROM information_schema.VIEWS\nWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\n\n\n\n  위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.\n\nDEFINER 계정 추가\n[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  DB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n접근 권한 설정\n[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB Source DB로 접근하게 됩니다.\n\nNAT Gateway 생성\n현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n\n\n  [NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nVPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 NAT Gateway 생성하는 방법\n\n\nRoute Table 설정\n다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Route Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n방화벽(ACG) 설정\nTarget DB Source DB로 접근하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을,  [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\n\nTarget DB ACG 설정\n우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nSource DB 방화벽 설정\n이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\n\n\n  \n    On Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\n  \n  \n    Ncloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n  \n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 서비스 위치\n이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 설정\n[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\n\nEndpoint 설정\n우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\n\n  Endpoint URL: Source DB의 IP 또는 도메인을 입력합니다.\n  DB PORT: Source DB의 Port를 입력합니다.\n  DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다.\n  DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 생성\n[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTest Connection\n[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB Source DB로 접근을 테스트 해봅니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 시작\n[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 진행 상태\n마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n진행 상태 확인 메일\n진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\n\n\n  \n      \n          Export Completed \n      \n  \n      \n          Import Completed \n      \n  \n      \n          Migration Completed \n      \n  \n\n\n  \n      \n⁃ Export Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Import Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Migration Completed\n\n  \n  \n    \n  \n\n\n\n  \n\n\n\n이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다. \n\n\n마이그레이션 완료\n마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  [완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다.\n\n\n\n  \n  \n    \n  \n\n\n최종 완료\n최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\n\n\n  \n  \n    \n  \n\n\nTarget DB 데이터 확인\n마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고,  [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상황\n지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n\n방화벽 설정 오류\n[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정  내용을 다시 확인해주세요.\nSource DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG 를 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nEndpoint DB User 설정 오류\n[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정  내용을 다시 확인해주세요.\nSource DB 에 접속이 되지 않습니다.DB ACL 을 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nDEFINER 계정 생성 오류\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정  내용을 다시 확인해주세요.\nSource DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.Definer 에 사용된 계정은 먼저 생성후 진행해 주세요.필요 Definer 계정 : abcd2@%\n\n\n  \n  \n    \n  \n\n\n바이너리 로그 설정 오류\nSource DB의 바이너리 로그 설정 중에서, [server_id], [log_bin] 관련 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 바이너리 로그 설정  내용을 다시 확인해주세요.\n마이그레이션을 위해서는 Source DB Config 설정이 필요합니다.추가 필요 설정 : log_bin\n\n\n  \n  \n    \n  \n\n\nsql_mode 설정 오류\n[Source DB] 사전 설정에서 sql_mode 관련된 설정을 수정하지 않았을 경우 아래와 같이 마이그레이션 진행 중에 [Importing] 단계에서 실패가 발생하고 [에러 보기] 버튼을 클릭하면 아래와 같은 메시지가 나타납니다. sql_mode 설정  내용을 다시 확인해주세요.\n\n\n  \n  \n    \n  \n\n\nERROR 1234 (42000) at line 98: Variable ‘sql_mode’ can’t be set to the value of ‘NO_AUTO_CREATE_USER’\n\n\n  \n  \n    \n  \n\n\n마이그레이션 재실행\n위와 같이 [sql_mode] 관련 오류로 마이그레이션 작업이 실패했을 경우에는 [재시작] 버튼으로 재시작을 할 경우에는 동일한 오류가 계속 발생하게 됩니다. \n이때는 [sql_mode] 설정을 수정한 후에 마이그레이션 작업을 삭제하고, [Target DB]에 생성된 [Database]을 모두 삭제 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n\n\n  [sql_mode] 설정을 수정한 후에 [삭제] 버튼을 클릭해서 마이그레이션 작업을 삭제합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Target DB]의 [DB 관리] - [DB Server 상세보기] 메뉴를 클릭해서 [Database 관리] 기능으로 이동합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Database 관리]에서 [Source DB]에서 Import한 [Database]을 모두 삭제하고, [저장] 버튼을 클릭합니다.\n그런 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Database Migration Service 개요\n    \n      https://guide.ncloud-docs.com/docs/ko/dms-overview\n    \n  \n  Source DB 및 Target DB 접속 설정\n    \n      https://guide.ncloud-docs.com/docs/dms-connect\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-11-02\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-db-migration-from-mysql57-to-mysql57-guide-html": {
						"id": "database-ncloud-database-db-migration-from-mysql57-to-mysql57-guide-html",
						"title": "Ncloud 데이터베이스 마이그레이션 서비스 | From MySQL 5.7 To MySQL 5.7",
						"categories": "",
						"url": " /database/ncloud-database-db-migration-from-mysql57-to-mysql57-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 MySQL 5.7을 Private 환경의 [Cloud DB for MySQL 5.7]로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n\n서비스에서 제공하는 기능\n\n  마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화\n  Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능\n  연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행\n  마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능\n\n\n지원 데이터베이스\nDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\n\n\n  Major 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다.\n  Source DB는 MariaDB도 가능합니다.\n  Target DB는 MySQL만 가능합니다.\n\n\n\n  \n  \n    \n  \n\n\n상세 설정 지원 여부\nSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n\n지원 항목\n\n  데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원\n  Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원\n\n\n미지원 항목\n\n  TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원\n  사용자 계정 정보, MySQL Config 항목, Event 마이그레이션 미지원\n\n\n마이그레이션 진행 구조\n마이그레이션은 Target DB Source DB로 접근하여 DB 데이터를 가져오는 방식으로 진행됩니다.\n\n또한 작업 진행 단계는 다음과 같습니다.\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 완료 상태\n  마이그레이션 작업 완료\n\n\n서비스 점검\n마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 상태\n  서비스 점검 시작\n  마이그레이션 작업 완료\n  서비스 점검 종료\n\n\n테스트 환경\nSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\n\n\n  Source DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다.\n  Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다.\n  Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다.\n  Target DB는 NAT Gateway를 통해서 Source DB에 접근한다.\n\n\nDB 버전 정보\n\n  Source DB: CentOS 7.8, MySQL 5.7.43\n  Target DB: Cloud DB for MySQL 5.7.40\n\n\n\n  \n      \n          Source DB \n      \n  \n      \n          Target DB \n      \n  \n\n\n  \n      \n⁃ Source DB\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Target DB\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 정보 확인\n테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\n\n\n  \n      \n          MariaDB 버전 \n      \n  \n      \n          Database \n      \n  \n      \n          계정 \n      \n  \n      \n          Table \n      \n  \n      \n          Procedure \n      \n  \n      \n          MySQL 버전 \n      \n  \n\n\n  \n      \n⁃ MariaDB 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MariaDB 5.7.43입니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Database\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ 계정\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Table\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Procedure\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ MySQL 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MySQL 5.7.43입니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 사전 설정\n\n마이그레이션 전용 DB User 생성\n마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n\n\n  패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` &amp; + \\ “ ‘ / 스페이스 는 패스워드로 사용할 수 없습니다.\n  기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다.\n\n\nCREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password'  BY '[패스워드]';\nGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\nGRANT SELECT ON mysql.* TO 'migration_test'@'%';\nGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\nFLUSH PRIVILEGES;\n\n\n\n  위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다.\n\n\n  \n  \n    \n  \n\n\nCharacter Set 점검\nTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\n\n\n  Character Set 점검 쿼리\n\n\nSELECT character_set_name\nFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\nWHERE CCSA.collation_name = T.table_collation \nAND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\n\nSELECT DEFAULT_CHARACTER_SET_NAME\nFROM information_schema.SCHEMATA T\nWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\n\n\n\n  Character Set 변경 쿼리 예시\n\n\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8;\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8 COLLATE utf8_general_ci;\nALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci;\n\n\n바이너리 로그 설정\nSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n\n현재 설정 확인\n아래 쿼리를 사용해 현재 설정 값을 확인합니다.\n\nshow variables like 'server_id';\nshow variables like 'log_bin';\n\n\n\n  현재 테스트용 Source DB는 두 값이 모두 설정되어 있지 않은 상태입니다.\n\n\n\n  \n  \n    \n  \n\n\n설정 변경\nMySQL의 환경 설정 파일 [my.cnf]를 열어서 아래 값을 추가하고, MySQL 데몬을 재시작합니다.\n~# vim /etc/my.cnf\n\nserver_id = 1\nlog_bin = binlog\n\n~# systemctl restart mysqld\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n변경 설정 확인\n설정 변경 후에 확인해보면 아래와 같이 [server_id] 값이 설정되어 있고, [log_bin]이 ON 상태로 변경된 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nTarget DB 사전 설정\n위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\n\nDEFINER 계정 확인\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\n\nSELECT DEFINER FROM information_schema.ROUTINES\nWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\n\nSELECT DEFINER FROM information_schema.VIEWS\nWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\n\n\n\n  위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.\n\nDEFINER 계정 추가\n[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  DB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n접근 권한 설정\n[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB Source DB로 접근하게 됩니다.\n\nNAT Gateway 생성\n현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n\n\n  [NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nVPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 NAT Gateway 생성하는 방법\n\n\nRoute Table 설정\n다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Route Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n방화벽(ACG) 설정\nTarget DB Source DB로 접근하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을,  [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\n\nTarget DB ACG 설정\n우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nSource DB 방화벽 설정\n이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\n\n\n  \n    On Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\n  \n  \n    Ncloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n  \n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 서비스 위치\n이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 설정\n[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\n\nEndpoint 설정\n우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\n\n  Endpoint URL: Source DB의 IP 또는 도메인을 입력합니다.\n  DB PORT: Source DB의 Port를 입력합니다.\n  DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다.\n  DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 생성\n[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTest Connection\n[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB Source DB로 접근을 테스트 해봅니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 시작\n[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 진행 상태\n마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n진행 상태 확인 메일\n진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\n\n\n  \n      \n          Export Completed \n      \n  \n      \n          Import Completed \n      \n  \n      \n          Migration Completed \n      \n  \n\n\n  \n      \n⁃ Export Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Import Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Migration Completed\n\n  \n  \n    \n  \n\n\n\n  \n\n\n\n이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다. \n\n\n마이그레이션 완료\n마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 복제 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  [완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다.\n\n\n\n  \n  \n    \n  \n\n\n최종 완료\n최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\n\n\n  \n  \n    \n  \n\n\nTarget DB 데이터 확인\n마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고,  [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상황\n지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n\n방화벽 설정 오류\n[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정  내용을 다시 확인해주세요.\nSource DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG 를 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nEndpoint DB User 설정 오류\n[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정  내용을 다시 확인해주세요.\nSource DB 에 접속이 되지 않습니다.DB ACL 을 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nDEFINER 계정 생성 오류\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정  내용을 다시 확인해주세요.\nSource DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.Definer 에 사용된 계정은 먼저 생성후 진행해 주세요.필요 Definer 계정 : abcd2@%\n\n\n  \n  \n    \n  \n\n\n바이너리 로그 설정 오류\nSource DB의 바이너리 로그 설정 중에서, [server_id], [log_bin] 관련 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 바이너리 로그 설정  내용을 다시 확인해주세요.\n마이그레이션을 위해서는 Source DB Config 설정이 필요합니다.추가 필요 설정 : log_bin\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Database Migration Service 개요\n    \n      https://guide.ncloud-docs.com/docs/ko/dms-overview\n    \n  \n  Source DB 및 Target DB 접속 설정\n    \n      https://guide.ncloud-docs.com/docs/dms-connect\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-10-23\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-db-migration-from-mysql57-to-mysql80-guide-html": {
						"id": "database-ncloud-database-db-migration-from-mysql57-to-mysql80-guide-html",
						"title": "Ncloud 데이터베이스 마이그레이션 서비스 | From MySQL 5.7 To MySQL 8.0",
						"categories": "",
						"url": " /database/ncloud-database-db-migration-from-mysql57-to-mysql80-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 MySQL 5.7을 Private 환경의 [Cloud DB for MySQL 8.0]으로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n\n서비스에서 제공하는 기능\n\n  마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화\n  Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능\n  연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행\n  마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능\n\n\n지원 데이터베이스\nDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\n\n\n  Major 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다.\n  Source DB는 MariaDB도 가능합니다.\n  Target DB는 MySQL만 가능합니다.\n\n\n\n  \n  \n    \n  \n\n\n상세 설정 지원 여부\nSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n\n지원 항목\n\n  데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원\n  Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원\n\n\n미지원 항목\n\n  TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원\n  사용자 계정 정보, MySQL Config 항목, Event 마이그레이션 미지원\n\n\n마이그레이션 진행 구조\n마이그레이션은 Target DB Source DB로 접근하여 DB 데이터를 가져오는 방식으로 진행됩니다.\n\n또한 작업 진행 단계는 다음과 같습니다.\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 완료 상태\n  마이그레이션 작업 완료\n\n\n서비스 점검\n마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 상태\n  서비스 점검 시작\n  마이그레이션 작업 완료\n  서비스 점검 종료\n\n\n테스트 환경\nSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\n\n\n  Source DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다.\n  Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다.\n  Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다.\n  Target DB는 NAT Gateway를 통해서 Source DB에 접근한다.\n\n\nDB 버전 정보\n\n  Source DB: CentOS 7.8, MySQL 5.7.43\n  Target DB: Cloud DB for MySQL 8.0.32\n\n\n\n  \n      \n          Source DB \n      \n  \n      \n          Target DB \n      \n  \n\n\n  \n      \n⁃ Source DB\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Target DB\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 정보 확인\n테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\n\n\n  \n      \n          MariaDB 버전 \n      \n  \n      \n          Database \n      \n  \n      \n          계정 \n      \n  \n      \n          Table \n      \n  \n      \n          Procedure \n      \n  \n      \n          MySQL 버전 \n      \n  \n\n\n  \n      \n⁃ MariaDB 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MariaDB 5.7.43입니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Database\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ 계정\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Table\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Procedure\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ MySQL 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MySQL 5.7.43입니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 사전 설정\n\n마이그레이션 전용 DB User 생성\n마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n\n\n  패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` &amp; + \\ “ ‘ / 스페이스 는 패스워드로 사용할 수 없습니다.\n  기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다.\n\n\nCREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password'  BY '[패스워드]';\nGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\nGRANT SELECT ON mysql.* TO 'migration_test'@'%';\nGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\nFLUSH PRIVILEGES;\n\n\n\n  위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다.\n\n\n  \n  \n    \n  \n\n\nCharacter Set 점검\nTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\n\n\n  Character Set 점검 쿼리\n\n\nSELECT character_set_name\nFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\nWHERE CCSA.collation_name = T.table_collation \nAND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\n\nSELECT DEFAULT_CHARACTER_SET_NAME\nFROM information_schema.SCHEMATA T\nWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\n\n\n\n  Character Set 변경 쿼리 예시\n\n\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8;\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8 COLLATE utf8_general_ci;\nALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci;\n\n\nsql_mode 설정 점검\nMySQL 5.7 버전에서 Default 값으로 지원하는 sql_mode=’NO_AUTO_CREATE_USER’ 설정은 MySQL 8.0 버전부터는 지원하지 않기 때문에, Source DB에서 사용된 곳이 있으면 찾아서 해당 옵션을 제거해야 합니다.\n\nsql_mode 설정 점검 쿼리\nProcedure, Function 등의 ROUTINE과 TRIGGER에서 사용되므로 아래 쿼리로 [NO_AUTO_CREATE_USER] 옵션이 사용된 곳이 있는지 점검합니다.\n\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\nFROM information_schema.routines\nWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\n\nSELECT TRIGGER_SCHEMA, TRIGGER_NAME, sql_mode\nFROM information_schema.triggers\nWHERE TRIGGER_SCHEMA NOT IN ('sys','mysql');\n\n\n\n  테스트용 Source DB에서 점검 쿼리를 실행해보면 아래와 같이 [testdb2]의 [new_procedure2]에 [NO_AUTO_CREATE_USER] 옵션이 적용되어 있는 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nsql_mode 호환성 이슈 조치 방법\nProcedure, Function, Trigger의 Dump 파일을 생성하고 [NO_AUTO_CREATE_USER] 옵션을 제거한 후 다시 적용하면 됩니다.\n\n\n  Procedure, Function, Trigger 에 대해서만 drop 및 create 구문이 생성된 sql 파일 생성\n\n\n~# mysqldump -u {사용자명} -p --set-gtid-purged=OFF --routines --triggers  --no-create-info --no-data --no-create-db --add-drop-trigger --databases {사용자 DB} &gt; backup.sql\n\n\n  \n  \n    \n  \n\n\n\n  backup.sql 파일내 NO_AUTO_CREATE_USER 구문 모두 제거\n해당 옵션을 일일이 찾아서 제거하기 힘드니 vim 에디터에서 [NO_AUTO_CREATE_USER] 문자를 찾아서 제거하는 명령을 실행합니다.\n경우에 따라서는 Dump 파일에 [NO_AUTO_CREATE_USER] 옵션이 포함되지 않는 경우도 있습니다. 이때는 걱정말고 Dump 파일을 그냥 그대로 적용하면 됩니다.\n\n\nvim 명령: %s /NO_AUTO_CREATE_USER,//g\n\n원본 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'  \n수정 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION'\n\n\n  \n  \n    \n  \n\n\n\n  적용하기\n수정된 Dump 파일을 Source DB에 적용합니다.\n\n\n~# mysql -u {사용자명} -p {사용자 DB} &lt; backup.sql\n\n\n  \n  \n    \n  \n\n\nsql_mode 설정 변경 확인\n설정이 제대로 변경되었는지 점검 쿼리로 다시 확인해보겠습니다.\n\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\nFROM information_schema.routines\nWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\n\n\n\n  아래 스샷처럼 [NO_AUTO_CREATE_USER] 옵션이 사라진 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n바이너리 로그 설정\nSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n\n현재 설정 확인\n아래 쿼리를 사용해 현재 설정 값을 확인합니다.\n\nshow variables like 'server_id';\nshow variables like 'log_bin';\n\n\n\n  현재 테스트용 Source DB는 두 값이 모두 설정되어 있지 않은 상태입니다.\n\n\n\n  \n  \n    \n  \n\n\n설정 변경\nMySQL의 환경 설정 파일 [my.cnf]를 열어서 아래 값을 추가하고, MySQL 데몬을 재시작합니다.\n~# vim /etc/my.cnf\n\nserver_id = 1\nlog_bin = binlog\n\n~# systemctl restart mysqld\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n변경 설정 확인\n설정 변경 후에 확인해보면 아래와 같이 [server_id] 값이 설정되어 있고, [log_bin]이 ON 상태로 변경된 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nTarget DB 사전 설정\n위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\n\nDEFINER 계정 확인\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\n\nSELECT DEFINER FROM information_schema.ROUTINES\nWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\n\nSELECT DEFINER FROM information_schema.VIEWS\nWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\n\n\n\n  위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.\n\nDEFINER 계정 추가\n[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  DB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n접근 권한 설정\n[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB Source DB로 접근하게 됩니다.\n\nNAT Gateway 생성\n현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n\n\n  [NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nVPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 NAT Gateway 생성하는 방법\n\n\nRoute Table 설정\n다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Route Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n방화벽(ACG) 설정\nTarget DB Source DB로 접근하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을,  [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\n\nTarget DB ACG 설정\n우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nSource DB 방화벽 설정\n이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\n\n\n  \n    On Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\n  \n  \n    Ncloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n  \n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 서비스 위치\n이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 설정\n[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\n\nEndpoint 설정\n우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\n\n  Endpoint URL: Source DB의 IP 또는 도메인을 입력합니다.\n  DB PORT: Source DB의 Port를 입력합니다.\n  DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다.\n  DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 생성\n[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTest Connection\n[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB Source DB로 접근을 테스트 해봅니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 시작\n[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 진행 상태\n마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n진행 상태 확인 메일\n진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\n\n\n  \n      \n          Export Completed \n      \n  \n      \n          Import Completed \n      \n  \n      \n          Migration Completed \n      \n  \n\n\n  \n      \n⁃ Export Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Import Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Migration Completed\n\n  \n  \n    \n  \n\n\n\n  \n\n\n\n이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다. \n\n\n마이그레이션 완료\n마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  [완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다.\n\n\n\n  \n  \n    \n  \n\n\n최종 완료\n최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\n\n\n  \n  \n    \n  \n\n\nTarget DB 데이터 확인\n마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고,  [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상황\n지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n\n방화벽 설정 오류\n[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정  내용을 다시 확인해주세요.\nSource DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG 를 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nEndpoint DB User 설정 오류\n[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정  내용을 다시 확인해주세요.\nSource DB 에 접속이 되지 않습니다.DB ACL 을 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nDEFINER 계정 생성 오류\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정  내용을 다시 확인해주세요.\nSource DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.Definer 에 사용된 계정은 먼저 생성후 진행해 주세요.필요 Definer 계정 : abcd2@%\n\n\n  \n  \n    \n  \n\n\n바이너리 로그 설정 오류\nSource DB의 바이너리 로그 설정 중에서, [server_id], [log_bin] 관련 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 바이너리 로그 설정  내용을 다시 확인해주세요.\n마이그레이션을 위해서는 Source DB Config 설정이 필요합니다.추가 필요 설정 : log_bin\n\n\n  \n  \n    \n  \n\n\nsql_mode 설정 오류\n[Source DB] 사전 설정에서 sql_mode 관련된 설정을 수정하지 않았을 경우 아래와 같이 마이그레이션 진행 중에 [Importing] 단계에서 실패가 발생하고 [에러 보기] 버튼을 클릭하면 아래와 같은 메시지가 나타납니다. sql_mode 설정  내용을 다시 확인해주세요.\n\n\n  \n  \n    \n  \n\n\nERROR 1234 (42000) at line 98: Variable ‘sql_mode’ can’t be set to the value of ‘NO_AUTO_CREATE_USER’\n\n\n  \n  \n    \n  \n\n\n마이그레이션 재실행\n위와 같이 [sql_mode] 관련 오류로 마이그레이션 작업이 실패했을 경우에는 [재시작] 버튼으로 재시작을 할 경우에는 동일한 오류가 계속 발생하게 됩니다. \n이때는 [sql_mode] 설정을 수정한 후에 마이그레이션 작업을 삭제하고, [Target DB]에 생성된 [Database]을 모두 삭제 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n\n\n  [sql_mode] 설정을 수정한 후에 [삭제] 버튼을 클릭해서 마이그레이션 작업을 삭제합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Target DB]의 [DB 관리] - [DB Server 상세보기] 메뉴를 클릭해서 [Database 관리] 기능으로 이동합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Database 관리]에서 [Source DB]에서 Import한 [Database]을 모두 삭제하고, [저장] 버튼을 클릭합니다.\n그런 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Database Migration Service 개요\n    \n      https://guide.ncloud-docs.com/docs/ko/dms-overview\n    \n  \n  Source DB 및 Target DB 접속 설정\n    \n      https://guide.ncloud-docs.com/docs/dms-connect\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-10-24\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-db-migration-from-mysql80-to-mysql80-guide-html": {
						"id": "database-ncloud-database-db-migration-from-mysql80-to-mysql80-guide-html",
						"title": "Ncloud 데이터베이스 마이그레이션 서비스 | From MySQL 8.0 To MySQL 8.0",
						"categories": "",
						"url": " /database/ncloud-database-db-migration-from-mysql80-to-mysql80-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 MySQL 8.0을 Private 환경의 [Cloud DB for MySQL 8.0]으로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n\n서비스에서 제공하는 기능\n\n  마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화\n  Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능\n  연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행\n  마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능\n\n\n지원 데이터베이스\nDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\n\n\n  Major 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다.\n  Source DB는 MariaDB도 가능합니다.\n  Target DB는 MySQL만 가능합니다.\n\n\n\n  \n  \n    \n  \n\n\n상세 설정 지원 여부\nSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n\n지원 항목\n\n  데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원\n  Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원\n\n\n미지원 항목\n\n  TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원\n  사용자 계정 정보, MySQL Config 항목, Event 마이그레이션 미지원\n\n\n마이그레이션 진행 구조\n마이그레이션은 Target DB Source DB로 접근하여 DB 데이터를 가져오는 방식으로 진행됩니다.\n\n또한 작업 진행 단계는 다음과 같습니다.\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 완료 상태\n  마이그레이션 작업 완료\n\n\n서비스 점검\n마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n\n\n  [Source DB]에서 [Export]\n  [Target DB]로 [Import]\n  두 DB 간의 Replication 상태\n  서비스 점검 시작\n  마이그레이션 작업 완료\n  서비스 점검 종료\n\n\n테스트 환경\nSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\n\n\n  Source DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다.\n  Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다.\n  Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다.\n  Target DB는 NAT Gateway를 통해서 Source DB에 접근한다.\n\n\nDB 버전 정보\n\n  Source DB: CentOS 7.8, MySQL 8.0.35\n  Target DB: Cloud DB for MySQL 8.0.32\n\n\n\n  \n      \n          Source DB \n      \n  \n      \n          Target DB \n      \n  \n\n\n  \n      \n⁃ Source DB\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Target DB\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 정보 확인\n테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\n\n\n  \n      \n          MariaDB 버전 \n      \n  \n      \n          Database \n      \n  \n      \n          계정 \n      \n  \n      \n          Table \n      \n  \n      \n          Procedure \n      \n  \n      \n          MySQL 버전 \n      \n  \n\n\n  \n      \n⁃ MariaDB 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MariaDB 5.7.43입니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Database\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ 계정\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Table\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Procedure\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ MySQL 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MySQL 8.0.35입니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n\n\nSource DB 사전 설정\n\n마이그레이션 전용 DB User 생성\n마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n\n\n  패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` &amp; + \\ “ ‘ / 스페이스 는 패스워드로 사용할 수 없습니다.\n  반드시 mysql_native_password 형식으로 생성된 패스워드를 사용해야 합니다.\n  기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다.\n  MySQL 8.0.20 이상은 8.0.19 이하 버전과 다르게 ROUTINE Dump를 위한 SHOW_ROUTINE 권한이 필수이니 버전에 맞게 쿼리를 사용해야 합니다.\n\n\n\n  \n      \n          8.0.20 이상 \n      \n  \n      \n          8.0.19 이하 \n      \n  \n\n\n  \n      \n⁃ 위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다.\n\nCREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password'  BY '[패스워드]';\nGRANT SHOW_ROUTINE, RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\nGRANT SELECT ON mysql.* TO 'migration_test'@'%';\nGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\nFLUSH PRIVILEGES;\n\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ 위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다.\n\nCREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password'  BY '[패스워드]';\nGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\nGRANT SELECT ON mysql.* TO 'migration_test'@'%';\nGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\nFLUSH PRIVILEGES;\n\n\n\n  \n  \n    \n  \n\n\n\n  \n\n\nCharacter Set 점검\nTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\n\n\n  Character Set 점검 쿼리\n\n\nSELECT character_set_name\nFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\nWHERE CCSA.collation_name = T.table_collation \nAND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\n\nSELECT DEFAULT_CHARACTER_SET_NAME\nFROM information_schema.SCHEMATA T\nWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) \nAND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\n\n\n\n  Character Set 변경 쿼리 예시\n\n\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8mb4;\nALTER DATABASE [데이터베이스명] CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\nALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\n\n\n바이너리 로그 설정\nSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n\n현재 설정 확인\n아래 쿼리를 사용해 현재 설정 값을 확인합니다.\n\nshow variables like 'server_id';\nshow variables like 'log_bin';\n\n\n\n  MySQL 8.0 부터는 기본적으로 설정이 되어 있으므로, 보통의 경우 특별한 조치 없이 그대로 진행하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nTarget DB 사전 설정\n위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\n\nDEFINER 계정 확인\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\n\nSELECT DEFINER FROM information_schema.ROUTINES\nWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\n\nSELECT DEFINER FROM information_schema.VIEWS\nWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\n\n\n\n  위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.\n\nDEFINER 계정 추가\n[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  DB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n접근 권한 설정\n[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB Source DB로 접근하게 됩니다.\n\nNAT Gateway 생성\n현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n\n\n  [NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nVPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 NAT Gateway 생성하는 방법\n\n\nRoute Table 설정\n다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Route Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n방화벽(ACG) 설정\nTarget DB Source DB로 접근하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을,  [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\n\nTarget DB ACG 설정\n우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nSource DB 방화벽 설정\n이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\n\n\n  \n    On Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\n  \n  \n    Ncloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n  \n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 서비스 위치\n이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 설정\n[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\n\nEndpoint 설정\n우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\n\n  Endpoint URL: Source DB의 IP 또는 도메인을 입력합니다.\n  DB PORT: Source DB의 Port를 입력합니다.\n  DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다.\n  DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 생성\n[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTest Connection\n[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB Source DB로 접근을 테스트 해봅니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 시작\n[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n\n\n  \n  \n    \n  \n\n\n마이그레이션 작업 진행 상태\n마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n진행 상태 확인 메일\n진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\n\n\n  \n      \n          Export Completed \n      \n  \n      \n          Import Completed \n      \n  \n      \n          Migration Completed \n      \n  \n\n\n  \n      \n⁃ Export Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Import Completed\n\n  \n  \n    \n  \n\n\n\n  \n      \n⁃ Migration Completed\n\n  \n  \n    \n  \n\n\n\n  \n\n\n\n이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다. \n\n\n마이그레이션 완료\n마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  [완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다.\n\n\n\n  \n  \n    \n  \n\n\n최종 완료\n최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\n\n\n  \n  \n    \n  \n\n\nTarget DB 데이터 확인\n마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고,  [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상황\n지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n\n방화벽 설정 오류\n[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정  내용을 다시 확인해주세요.\nSource DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG 를 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nEndpoint DB User 설정 오류\n[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정  내용을 다시 확인해주세요.\nSource DB 에 접속이 되지 않습니다.DB ACL 을 점검해 주세요.\n\n\n  \n  \n    \n  \n\n\nDEFINER 계정 생성 오류\n[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정  내용을 다시 확인해주세요.\nSource DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.Definer 에 사용된 계정은 먼저 생성후 진행해 주세요.필요 Definer 계정 : abcd2@%\n\n\n  \n  \n    \n  \n\n\n마이그레이션 재실행\n그 외의 오류로 마이그레이션 작업이 실패했을 경우 아래와 같이 [재시작], [삭제] 버튼이 활성화 되는데, [재시작] 버튼으로 재시작을 할 경우에는 동일한 오류가 계속 발생하는 경우가 있습니다. \n이때는 마이그레이션 작업을 삭제하고, [Target DB]에 생성된 [Database]을 모두 삭제 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n\n\n  [삭제] 버튼을 클릭해서 마이그레이션 작업을 삭제합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Target DB]의 [DB 관리] - [DB Server 상세보기] 메뉴를 클릭해서 [Database 관리] 기능으로 이동합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Database 관리]에서 [Source DB]에서 Import한 [Database]을 모두 삭제하고, [저장] 버튼을 클릭합니다.\n그런 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Database Migration Service 개요\n    \n      https://guide.ncloud-docs.com/docs/ko/dms-overview\n    \n  \n  Source DB 및 Target DB 접속 설정\n    \n      https://guide.ncloud-docs.com/docs/dms-connect\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-10-26\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mariadb-multi-source-replication-html": {
						"id": "database-ncloud-database-mariadb-multi-source-replication-html",
						"title": "MariaDB Multi Source Replication 구성 가이드",
						"categories": "",
						"url": " /database/ncloud-database-mariadb-multi-source-replication.html",
						"content": "개요\n\nn대의 마스터 DB와 1대의 슬레이브 DB를 연결하여 마스터 DB들의 데이터를 슬레이브 DB 한곳에 모아 조회할 수 있는 Multi-Source-Replication(MSR)을 MariaDB에서 구성하는 방법을 정리해보겠습니다.\n\n테스트 준비\n\n\n  마스터 서버 2대, 슬레이브 서버 1대 준비\n  각 서버에 MariaDB 10.3 이상 설치\n  MariaDB 리플리케이션작업 진행 시 마스터 서버의 데이터베이스에 쓰기 작업 금지\n\n\n\n  \n  \n    \n  \n\n\nACG 설정\n서버 준비가 끝났으면 우선 마스터 서버  슬레이브 서버로 디비 백업 파일 복사과 복제 구성에 필요한 22, 3306 포트를 오픈해야 합니다.\n오픈 할 때 규칙은 마스터 서버와 슬레이브 서버의 공통 ACG에 사설 IP 대역 전체를 지정할 수도 있고, 슬레이브 서버 전용 ACG에 마스터 서버 IP만 등록하는 방법도 있습니다.\n\n\n  \n  \n    \n  \n\n\nSlave 장비에 백업 디렉토리 생성\n먼저 Slave 장비에 Master 장비들로 부터 DB 복원용 덤프 파일을 전송 받을 백업 디렉토리를 생성하는 것 부터 시작하겠습니다.\n\n~# mkdir /data\n~# cd /data\n\n\n\n  \n  \n    \n  \n\n\nMaster1 장비 구성\n\nMaster1 설정 추가\n\n  /etc/my.cnf.d/mariadb-server.cnf에 Master1 설정을 추가합니다.\n  MariaDB 버전에 따라서는 /etc/my.cnf.d/server.cnf 인 경우도 있습니다.\n\n\n\n  \n      \n          MySQL 호환 \n      \n  \n      \n          MariaDB 전용 \n      \n  \n\n\n  \n      \n~# vi /etc/my.cnf.d/mariadb-server.cnf\n\nserver-id = 1\nlog-bin = mariadb-bin\nbinlog_format = mixed\ncharacter-set-server = utf8\n\n#MariaDB를 재시작해 변경사항 적용.\n~# systemctl restart mariadb\n\n\n  \n      \n~# vi /etc/my.cnf.d/mariadb-server.cnf\n\nlog-bin\nserver_id = 1\nlog-basename = mariadb\nbinlog-format = mixed\ncharacter-set-server = utf8\n\n#MariaDB을 재시작해 변경사항 적용.\n~# systemctl restart mariadb\n\n\n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 계정 생성\nMariaDB 접속 후 리플리케이션을 진행할 계정 생성\n\n#master1 계정 생성.\nMariaDB [(none)]&gt; create user '리플리케이션 계정명'@'%' identified by '패스워드';\nMariaDB [(none)]&gt; grant replication slave on *.* to '리플리케이션 계정명'@'%';\nMariaDB [(none)]&gt; flush privileges;\n\n\n\n  \n  \n    \n  \n\n\n테스트 DB 생성\n다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\n\nMariaDB [(none)]&gt; CREATE DATABASE testdb1 default CHARACTER SET UTF8;\n\n\n\n  \n  \n    \n  \n\n\nMaster1 정보확인\n이제 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\n\nMariaDB [(none)]&gt; show variables like 'server_id';\nMariaDB [(none)]&gt; show master status;\n\n\n\n[show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 백업 파일 슬레이브 장비로 전송\ntestdb1 DB의 백업파일을 생성하고, 슬레이브 서버로 전송합니다.\n\n~# mkdir /data\n~# cd /data\n~# mysqldump -u root -p --databases testdb1 &gt; /data/test1.sql \n\n#슬레이브 서버에 전송.\n~# scp test1.sql root@10.0.0.8:/data\n\n\n\n  \n  \n    \n  \n\n\nMaster2 장비 구성\n\nMaster2 설정 추가\n\n  /etc/my.cnf.d/mariadb-server.cnf에 Master2 설정을 추가합니다.\n  MariaDB 버전에 따라서는 /etc/my.cnf.d/server.cnf 인 경우도 있습니다.\n\n\n\n  \n      \n          MySQL 호환 \n      \n  \n      \n          MariaDB 전용 \n      \n  \n\n\n  \n      \n~# vi /etc/my.cnf.d/mariadb-server.cnf\n\nserver-id = 2\nlog-bin = mariadb-bin\nbinlog_format = mixed\ncharacter-set-server = utf8\n\n#MariaDB을 재시작해 변경사항 적용.\n~# systemctl restart mariadb\n\n\n  \n      \n~# vi /etc/my.cnf.d/mariadb-server.cnf\n\nlog-bin\nserver_id = 2\nlog-basename = mariadb\nbinlog-format = mixed\ncharacter-set-server = utf8\n\n#MariaDB을 재시작해 변경사항 적용.\n~# systemctl restart mariadb\n\n\n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 계정 생성\nMariaDB 접속 후 리플리케이션을 진행할 계정 생성합니다.\n\n#master2 계정 생성.\nMariaDB [(none)]&gt; create user '리플리케이션 계정명'@'%' identified by '패스워드';\nMariaDB [(none)]&gt; grant replication slave on *.* to '리플리케이션 계정명'@'%';\nMariaDB [(none)]&gt; flush privileges;\n\n\n\n  \n  \n    \n  \n\n\n테스트 DB 생성\n다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\n\nMariaDB [(none)]&gt; CREATE DATABASE testdb2 default CHARACTER SET UTF8;\n\n\n\n  \n  \n    \n  \n\n\nMaster2 정보확인\n마찬가지로 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\n\nMariaDB [(none)]&gt; show variables like 'server_id';\nMariaDB [(none)]&gt; show master status;\n\n\n\n[show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 백업 파일 슬레이브 장비로 전송\ntestdb2 DB의 백업파일 생성하고, 슬레이브 서버로 전송합니다.\n\n~# mkdir /data\n~# cd /data\n~# mysqldump -u root -p --databases testdb2 &gt; /data/test2.sql\n\n~# scp test2.sql root@10.0.0.8:/data\n\n\n\n  \n  \n    \n  \n\n\nSlave 장비 구성\n\nSlave 설정 추가\n\n  /etc/my.cnf.d/mariadb-server.cnf에 Slave 설정을 추가합니다.\n  MariaDB 버전에 따라서는 /etc/my.cnf.d/server.cnf 인 경우도 있습니다.\n\n\n~# vi /etc/my.cnf.d/mariadb-server.cnf\n\nserver-id = 3 \n\n#리플리케이션 대상 디비 설정.\nreplicate-do-db = testdb1\nreplicate-do-db = testdb2\n\n#리플리케이션 제외 디비 설정.\nreplicate-ignore-db = information_schema\nreplicate-ignore-db = mysql\nreplicate-ignore-db = performance_schema\nreplicate-ignore-db = sys\n\nslave-skip-errors = all\n\n#DB를 재시작하여 변경사항 적용.\n~# systemctl restart mariadb\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nDB 복구 진행\n먼저 복구할 DB를 미리 생성하고 Master1, Master2 장비에서 전송 받은 백업 파일을 사용해 DB를 복구합니다.\n#복구할 DB 생성.\nMariaDB [(none)]&gt; create database testdb1;\nMariaDB [(none)]&gt; create database testdb2;\nMariaDB [(none)]&gt; quit\n\n#DB 복구\n~# mysql -u root -p testdb1 &lt; /data/test1.sql\n~# mysql -u root -p testdb2 &lt; /data/test2.sql\n\n\n\n  \n  \n    \n  \n\n\n\n  백업 파일을 전송 받은 디렉토리로 이동해 백업 파일이 정상적으로 전송되었는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\n\n  백업 파일을 사용해 DB를 복구합니다.\n\n\n  \n  \n    \n  \n\n\n리플리케이션 채널 설정\n리플리케이션 채널을 설정하는 쿼리문은 다음과 같은데, MySQL과는 일부 다른 부분이 있으니 잘 확인하고 사용해야 합니다.\n\nMariaDB [(none)]&gt; CHANGE MASTER '커넥션 이름' TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호;\n\n\n여기에 필요한 정보 중에서 [MASTER_LOG_FILE]과 [MASTER_LOG_POS]은 위쪽에서 확인한 Master DB들의 정보에 나타났던 것으로 정리하면 다음과 같습니다.\n\n\n\n\n  \n    \n      DB\n      File\n      Position\n    \n  \n  \n    Master1mariadb-bin.000001939\n    Master2mariadb-bin.000002939\n  \n    \n\n\n\nMaster 서버 정보 입력\n다음의 예시처럼 Slave 서버에 Master 서버 정보를 하나씩 입력합니다.\n\n#Master1 예시\nMariaDB [(none)]&gt; CHANGE MASTER 'ch_testdb1' TO MASTER_HOST='10.0.0.6', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mariadb-bin.000001', MASTER_LOG_POS=939;\n\n#Master2 예시\nMariaDB [(none)]&gt; CHANGE MASTER 'ch_testdb2' TO MASTER_HOST='10.0.0.7', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mariadb-bin.000002', MASTER_LOG_POS=939;\n\nMariaDB [(none)]&gt; FLUSH PRIVILEGES;\n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 채널 시작\n리플리케이션 시작 후 에러가 없는지 확인합니다.\n\n# start slave '커넥션명';\nMariaDB [(none)]&gt; start slave 'ch_testdb1'; \nMariaDB [(none)]&gt; start slave 'ch_testdb2';\n\n# show slave '커넥션명' status\\G\nMariaDB [(none)]&gt; show slave 'ch_testdb1' status\\G \nMariaDB [(none)]&gt; show slave 'ch_testdb2' status\\G\n\n\n\n  Master1\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Master2\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다.\n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 테스트\n리플리케이션 설정을 모두 마친 후에 Master 서버들에서 DB 작업을 진행하고, Slave 서버에 해당 내용이 복제되는지 확인해보겠습니다.\n\n\n  Master1 서버 작업\nMaster1 서버에 테스트를 위한 [sampletable1] Table을 생성합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Slave 서버 확인\nSlave 서버에서 testdb1 DB에 sampletable1 Table이 복제되었는지 확인합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Master2 서버 작업\nMaster2 서버에 테스트를 위한 [sampletable2] Table을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Slave 서버 확인\nSlave 서버에서 testdb2 DB에 sampletable2 Table이 복제되었는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\n리플리케이션 명령어 모음\n\n\n\n  \n    \n      \n      리플리케이션 명령어\n    \n  \n  \n    \n      채널 설정\n      CHANGE MASTER '커넥션 이름' TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호;\n    \n    채널 시작START SLAVE \"커넥션 이름\";\n    채널 중지STOP SLAVE \"커넥션 이름\";\n    채널 상태 확인SHOW SLAVE \"커넥션 이름\" STATUS\\G\n    채널 정보 삭제RESET SLAVE \"커넥션 이름\";\n  \n  \n\n\n참고 URL\n\n  MariaDB Replication 기본 설정 가이드\n    \n      https://mariadb.com/kb/en/setting-up-replication/\n    \n  \n  MariaDB Multi-Source Replication 가이드\n    \n      https://mariadb.com/kb/en/multi-source-replication/"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-57-install-on-rocky-linux-html": {
						"id": "database-ncloud-database-mysql-57-install-on-rocky-linux-html",
						"title": "Rocky Linux 서버에 MySQL 5.7 설치하는 방법",
						"categories": "",
						"url": " /database/ncloud-database-mysql-57-install-on-rocky-linux.html",
						"content": "개요\n록키 리눅스(Rocky Linux)는 기본 데이터베이스가 MariaDB인데, 상황에 따라 MySQL이 필요한 경우가 있습니다. 이번에는 그 중에서 MySQL 5.7 버전을 설치하는 방법을 정리해보겠습니다.\n\n서버 준비\n우선 Rocky Linux 서버를 준비합니다.\n\n\n  \n  \n    \n  \n\n\nRocky Linux 소개\n록키 리눅스에 대한 간략한 소개는 아래 문서에서 확인할 수 있습니다.\n\n\n⁃  Ncloud에서 제공하는 록키 리눅스(Rocky Linux) 서버 소개\n\n\n패키지 업데이트\n우선 패키지 업데이트를 해보겠습니다.\n\n~# dnf -y upgrade-minimal\n\n dnf: Dandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 \nFedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nMySQL Community 패키지 설치\nMySQL 5.7 버전이 포함된 가장 최근의 Repository 설치 패키지는 mysql80-community-release-el7-10.noarch.rpm 입니다.\n\n~# dnf -y install https://dev.mysql.com/get/mysql80-community-release-el7-10.noarch.rpm\n\n\n\n  \n  \n    \n  \n\n\nMySQL 5.7 버전 리포지토리 활성화\n\n버전 활성화 정보 초기화\n\n~# dnf module reset mysql\n\n\n\n  \n  \n    \n  \n\n\n기본 MySQL 버전 비활성화\n\n~# dnf module disable mysql\n\n\n\n  \n  \n    \n  \n\n\nMySQL 버전 확인\n설치된 리포지토리에서 MySQL 버전을 확인해보면 5.7과 8.0이 존재하는 것을 확인할 수 있습니다.\n\n~# dnf repolist all | grep mysql\n\n\n\n  \n  \n    \n  \n\n\nMySQL 5.7 버전 활성화\n설치된 MySQL Community 패키지에서 MySQL 8.0 버전은 비활성화 하고, 5.7 버전을 활성화 합니다.\n\n~# dnf config-manager --disable mysql80-community\n~# dnf config-manager --enable mysql57-community\n\n\n\n  \n  \n    \n  \n\n\nMySQL 5.7 설치\nMySQL 5.7 서버를 설치합니다.\n\n~# dnf -y install mysql-community-server\n\n\n\n  \n  \n    \n  \n\n\nMySQL 초기화\n아래 명령어로 기본 데이터베이스 생성 등의 초기화 작업을 진행합니다. 다만 여기서는 초기화 할 때 –initialize-insecure 옵션으로 비밀번호는 설정하지 않고 아래쪽 MySQL 보안 설정 단계에서 [mysql_secure_installation] 명령으로 설정하도록 하겠습니다.\n\n~# mysqld --initialize-insecure --user=mysql\n\n\n\n  \n  \n    \n  \n\n\nMySQL 데몬 시작\n초기화를 마쳤으면 MySQL 데몬을 시작합니다.\n\n~# systemctl start mysqld\n\n\n\n  \n  \n    \n  \n\n\nMySQL 보안 설정\n[mysql_secure_installation]은 MySQL의 기본 보안을 설정하는 명령으로, 설정되는 항목은 다음과 같습니다.\n\n\n  root 계정 패스워드 설정\n  원격 호스트에서 root 계정 접속 차단\n  익명 계정 삭제\n  테스트 DB 등 삭제\n\n\n~# mysql_secure_installation\n\n\n\n  비밀번호를 설정할 때 비밀번호 유효성 검사 플러그인을 사용할 것인지 선택할 수 있는데 [Y]를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n비밀번호 정책 수준 선택\n제공되는 비밀번호 정책 수준은 [LOW], [MEDIUM], [STRONG]의 3가지가 있습니다.\n\n  LOW: 8자 이상\n  MEDIUM: 8자 이상, 숫자-대소문자-특수문자 포함\n  STRONG: 8자 이상, 숫자-대소문자-특수문자 포함, dictionary file에 포함된 단어 사용 불가\n\n\n여기서는 1을 입력해서 MEDIUM을 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  패스워드를 입력하면 패스워드의 복잡성 강도를 점수로 측정해주는데 이번 테스트에서는 100점을 받았습니다.\n그리고, 방금 입력했던 패스워드를 그대로 사용할 것인지 확인하는데 [Y]를 입력합니다.\n(혹시 입력했던 비밀번호를 변경하고 싶을 경우는 [N]를 입력합니다.)\n\n\n\n  \n  \n    \n  \n\n\n익명 계정 삭제\n다음으로 Anonymous Users 즉, 익명 계정들을 삭제할 것인지 묻는데 [Y]를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n원격 호스트에서 root 계정 접속 차단\n다음은 로컬이 아닌 원격에서 root 계정 로그인을 차단할 것인지 묻는데 [Y]를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n테스트 DB 등 삭제\n테스트 DB 등을 삭제할 것인지 묻는데 여기서도 [Y]를 입력합니다.\n\n  \n  \n    \n  \n\n\n설정 저장\n마지막으로 지금까지 선택한 설정을 모두 적용할 것인지 묻는데 [Y]를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nMySQL 접속\n위에서 설정했던 비번으로 접속해보면 [5.7.43 MySQL Community Server]인 것을 확인할 수 있습니다.\n\n~# mysql -u root -p\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  MySQL Yum Repository 다운로드 페이지\n    \n      https://dev.mysql.com/downloads/repo/yum/\n    \n  \n  Installing MySQL on Linux Using the MySQL Yum Repository\n    \n      https://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html\n    \n  \n  Rocky Linux 서버에 MySQL 8.0 최신 버전 설치하는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-mysql-8-latest-version-install-on-rocky-linux.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-04-10\n          문서 최초 생성\n        \n      \n        \n          2023-09-04\n          Rocky Linux 8.8 적용, MySQL 5.7.43 적용"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-8-latest-version-install-on-rocky-linux-html": {
						"id": "database-ncloud-database-mysql-8-latest-version-install-on-rocky-linux-html",
						"title": "Rocky Linux 서버에 MySQL 8.0 최신 버전 설치하는 방법",
						"categories": "",
						"url": " /database/ncloud-database-mysql-8-latest-version-install-on-rocky-linux.html",
						"content": "개요\n록키 리눅스(Rocky Linux)는 기본 데이터베이스가 MariaDB인데, 상황에 따라 MySQL이 필요한 경우가 있습니다. 이번에는 그 중에서 MySQL 8.0 최신 버전을 설치하는 방법을 정리해보겠습니다.\n\n서버 준비\n우선 Rocky Linux 서버를 준비합니다.\n\n\n  \n  \n    \n  \n\n\nRocky Linux 소개\n록키 리눅스에 대한 간략한 소개는 아래 문서에서 확인할 수 있습니다.\n\n\n⁃  Ncloud에서 제공하는 록키 리눅스(Rocky Linux) 서버 소개\n\n\n패키지 업데이트\n우선 패키지 업데이트를 해보겠습니다.\n\n~# dnf -y upgrade-minimal\n\n dnf: Dandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 \nFedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nMySQL Community 최신 패키지 확인\nMySQL Community Yum(Dnf) 최신 패키지는 아래 주소에서 확인할 수 있습니다.\nRocky Linux는 CentOS 8 기반으로 만들어졌으므로 아래 다운로드 페이지에서 Red Hat Enterprise Linux 8 기반의 mysql80-community-release-el8-{버전}.noarch.rpm 리파지토리 버전을 확인합니다.\n2023-09-04 기준으로는 [mysql80-community-release-el8-8.noarch.rpm] 인것을 확인할 수 있습니다.\n\n\n⁃  https://dev.mysql.com/downloads/repo/yum/\n\n\n\n  \n  \n    \n  \n\n\nMySQL Community 패키지 설치\n위에서 확인한 MySQL 8.0의 최신 Repository 설치 패키지는 [mysql80-community-release-el8-8.noarch.rpm] 입니다.\n\n~# dnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-8.noarch.rpm\n\n\n\n  \n  \n    \n  \n\n\nMySQL 8.0 버전 리포지토리 활성화\n\n버전 활성화 정보 초기화\n\n~# dnf module reset mysql\n\n\n\n  \n  \n    \n  \n\n\n기본 MySQL 버전 비활성화\n\n~# dnf module disable mysql\n\n\n\n  \n  \n    \n  \n\n\nMySQL 8.0 버전 확인\n설치된 MySQL Community 패키지에 포함된 MySQL 버전을 확인해보겠습니다.\nmysql80-community-release-el8-{버전}.noarch.rpm 버전부터는 8.0 버전만 있고, 5.7 버전은 포함되어 있지 않습니다.\n\n~# dnf repolist all | grep mysql\n\n\n\n  \n  \n    \n  \n\n\nMySQL 8.0 설치\nMySQL 8.0 서버를 설치합니다.\n\n~# dnf -y install mysql-community-server\n\n\n\n  \n  \n    \n  \n\n\nMySQL 초기화\n아래 명령어로 기본 데이터베이스 생성 등의 초기화 작업을 진행합니다. 다만 여기서는 초기화 할 때 –initialize-insecure 옵션으로 비밀번호는 설정하지 않고 아래쪽 MySQL 보안 설정 단계에서 [mysql_secure_installation] 명령으로 설정하도록 하겠습니다.\n\n~# mysqld --initialize-insecure --user=mysql\n\n\n\n  \n  \n    \n  \n\n\nMySQL 데몬 시작\n초기화를 마쳤으면 MySQL 데몬을 시작합니다.\n\n~# systemctl start mysqld\n\n\n\n  \n  \n    \n  \n\n\nMySQL 보안 설정\n[mysql_secure_installation]은 MySQL의 기본 보안을 설정하는 명령으로, 설정되는 항목은 다음과 같습니다.\n\n\n  root 계정 패스워드 설정\n  원격 호스트에서 root 계정 접속 차단\n  익명 계정 삭제\n  테스트 DB 등 삭제\n\n\n~# mysql_secure_installation\n\n\n\n  비밀번호를 설정할 때 비밀번호 유효성 검사 플러그인을 사용할 것인지 선택할 수 있는데 [Y]를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n비밀번호 정책 수준 선택\n제공되는 비밀번호 정책 수준은 [LOW], [MEDIUM], [STRONG]의 3가지가 있습니다.\n\n  LOW: 8자 이상\n  MEDIUM: 8자 이상, 숫자-대소문자-특수문자 포함\n  STRONG: 8자 이상, 숫자-대소문자-특수문자 포함, dictionary file에 포함된 단어 사용 불가\n\n\n여기서는 1을 입력해서 MEDIUM을 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  패스워드를 입력하면 패스워드의 복잡성 강도를 점수로 측정해주는데 이번 테스트에서는 100점을 받았습니다.\n그리고, 방금 입력했던 패스워드를 그대로 사용할 것인지 확인하는데 [Y]를 입력합니다.\n(혹시 입력했던 비밀번호를 변경하고 싶을 경우는 [N]를 입력합니다.)\n\n\n\n  \n  \n    \n  \n\n\n익명 계정 삭제\n다음으로 Anonymous Users 즉, 익명 계정들을 삭제할 것인지 묻는데 [Y]를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n원격 호스트에서 root 계정 접속 차단\n다음은 로컬이 아닌 원격에서 root 계정 로그인을 차단할 것인지 묻는데 [Y]를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n테스트 DB 등 삭제\n테스트 DB 등을 삭제할 것인지 묻는데 여기서도 [Y]를 입력합니다.\n\n  \n  \n    \n  \n\n\n설정 저장\n마지막으로 지금까지 선택한 설정을 모두 적용할 것인지 묻는데 [Y]를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nMySQL 접속\n위에서 설정했던 비번으로 접속해보면 [8.0.34 MySQL Community Server]인 것을 확인할 수 있습니다.\n\n~# mysql -u root -p\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  MySQL Yum Repository 다운로드 페이지\n    \n      https://dev.mysql.com/downloads/repo/yum/\n    \n  \n  Installing MySQL on Linux Using the MySQL Yum Repository\n    \n      https://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html\n    \n  \n  Rocky Linux 서버에 MySQL 5.7 설치하는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-mysql-57-install-on-rocky-linux.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-04-11\n          문서 최초 생성\n        \n      \n        \n          2023-09-04\n          Rocky Linux 8.8 적용, MySQL 8.0.43 적용"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-datadir-change-install-guide-html": {
						"id": "database-ncloud-database-mysql-datadir-change-install-guide-html",
						"title": "MySQL 데이터 저장 디렉토리(datadir) 위치를 변경해서 설치하는 방법",
						"categories": "",
						"url": " /database/ncloud-database-mysql-datadir-change-install-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) 서버에 MySQL을 설치할 때 MySQL 데이터 저장 디렉토리(datadir) 위치를 변경해서 설치하는 방법을 정리해보겠습니다.\n\n테스트 환경\n\n  서버: Rocky Linux 8.8\n  DB: MySQL 8.0\n\n\n\n  \n  \n    \n  \n\n\nMySQL 설치\n아래와 같은 순서대로 MySQL 8.0 최신 버전을 설치합니다.\n\n~# dnf -y upgrade-minimal\n~# dnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-9.noarch.rpm\n~# dnf module reset mysql\n~# dnf module disable mysql\n~# dnf -y install mysql-community-server\n\n\n\n  \n  \n    \n  \n\n\n데이터 저장 디렉토리 생성\nDB 데이터를 저장할 임의의 디렉토리를 생성합니다. /database/mysql 과 같이 생성하고 실제 저장되는 디렉토리는 mysql로 하겠습니다.\n\n~# mkdir -p /database/mysql\n\n\n  \n  \n    \n  \n\n\n디렉토리 소유권 변경\n실제 저장되는 디렉토리인 [mysql]에 대한 소유권을 변경해야 하는데, 변경하기 전에 현재 상태를 확인해보면 아래와 같이 root:root로 되어 있는 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n아래 명령으로 mysql 디렉토리에 대한 소유권을 mysql:mysql로 변경합니다.\n~# chown -R mysql:mysql /database/mysql/\n\n\n\n  \n  \n    \n  \n\n\n환경 설정 변경\n환경 설정 파일 my.cnf 파일을 열어서 [mysqld] 항목에 있는 [datadir], [socket] 두가지의 설정을 위에서 생성한 [/database/mysql/] 디렉토리로 변경합니다. 그리고 아래쪽에 로컬에서 접속하기 위한 [client] 항목에 대한 [socket] 설정도 추가합니다.\n\n~# vim /etc/my.cnf\n\n# mysqld용 설정 변경 (위에서 생성한 디렉토리)\n[mysqld]\ndatadir=/database/mysql\nsocket=/database/mysql/mysql.sock\n\n# 선택사항: CharacterSet, Collation 설정 추가\ncharacter-set-server = utf8mb4\ncollation-server = utf8mb4_unicode_ci\ninit-connect='SET NAMES utf8mb4'\nskip-character-set-client-handshake\n\n# 로컬에서 접속하기 위한 client 용 설정 추가\n[client]\nsocket=/database/mysql/mysql.sock\n\n# 선택사항: CharacterSet 설정 추가\ndefault-character-set=utf8mb4\n\n\n  \n  \n    \n  \n\n\nMySQL 초기화\n아래 명령어로 기본 데이터베이스 생성 등의 초기화 작업을 진행합니다. 이때 위에서 생성한 [/database/mysql/] 디렉토리에서 초기화가 진행됩니다.\n초기화 한 후에 디렉토리를 살펴보면 아래와 같이 기본 데이터 베이스 등이 정상적으로 생성된 것을 확인할 수 있습니다.\n\n~# mysqld --initialize-insecure --user=mysql\n~# ls -al /database/mysql\n\n\n\n  \n  \n    \n  \n\n\nMySQL 데몬 시작\n초기화를 마쳤으면 MySQL 데몬을 시작합니다.\n\n~# systemctl start mysqld\n\n\n\n  \n  \n    \n  \n\n\nMySQL 보안 설정\n[mysql_secure_installation]은 MySQL의 기본 보안을 설정하는 명령으로, 설정되는 항목은 다음과 같습니다.\n\n\n  root 계정 패스워드 설정\n  원격 호스트에서 root 계정 접속 차단\n  익명 계정 삭제\n  테스트 DB 등 삭제\n\n\n~# mysql_secure_installation\n\n\n\n  \n  \n    \n  \n\n\nMySQL 접속\n위에서 설정했던 비번으로 접속해보면 [8.0.35 MySQL Community Server]인 것을 확인할 수 있습니다.\n\n[show databases] 명령으로 데이터베이스를 확인해보면 기본 데이터베이스 등 각종 시스템 데이터베이스가 모두 정상적으로 나타나는 것을 알 수 있습니다.\n\n~# mysql -u root -p\n\nmysql&gt; show databases;\n\n\n\n  \n  \n    \n  \n\n\n테스트 DB 생성\n데이터베이스 생성도 문제 없이 잘되는지 확인해보기 위해 [testdb]를 생성하고, 확인해보겠습니다.\n\nmysql&gt; CREATE DATABASE testdb;\nmysql&gt; show databases;\n\n\n\n  \n  \n    \n  \n\n\n디렉토리 확인\n변경해서 설치한 디렉토리에도 [testdb]가 제대로 생성되었는지 확인해보니 아래 화면처럼 정상적으로 생성된 것을 알 수 있습니다.\n\n~# ls -al /database/mysql\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  MySQL Yum Repository 다운로드 페이지\n    \n      https://dev.mysql.com/downloads/repo/yum/\n    \n  \n  Installing MySQL on Linux Using the MySQL Yum Repository\n    \n      https://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html\n    \n  \n  Rocky Linux 서버에 MySQL 8.0 최신 버전 설치하는 방법\n    \n      https://docs.3rdeyesys.com/database/ncloud-database-mysql-8-latest-version-install-on-rocky-linux.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-12-20\n          문서 최초 생성\n        \n      \n        \n          2023-12-21\n          CharacterSet, Collation 설정 내용 추가"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-gtid-replication-html": {
						"id": "database-ncloud-database-mysql-gtid-replication-html",
						"title": "MySQL GTID Replication 생성 상세 가이드",
						"categories": "",
						"url": " /database/ncloud-database-mysql-gtid-replication.html",
						"content": "GTID 란?\nGTID는 Global Transaction Identifier의 약자로 MySQL 복제에서 서버의 각 트랜잭션을 구분하는 고유한 식별자입니다. \nGTID는 모든 트랜잭션과 1:1 관계이며, GTID를 활용하면 복제본으로 장애 조치, 계층적 복제, 특정 시점으로 백업 복구하는 등의 작업을 더 쉽게 구현할 수 있으며, 오류 발생 빈도도 줄일 수 있습니다.\n\nGTID 구성\nGTID는 source_id:transaction_id의 형태로 저장됩니다.\n\n  예시: 2070b9863-4c88-72ef-9fa053db4612:1-12\n\n\nsource_id\n여기서 source_id는 서버의 uuid이며 다음의 방법으로 확인할 수 있습니다.\n\nmysql&gt; SELECT @@server_uuid;\n\n\n\n  \n  \n    \n  \n\n\n테스트 환경\n\n\n⁃ CentOS 7.8\n⁃ MySQL 5.7\n⁃ Master Server IP: 10.0.0.6\n⁃ Slave Server IP: 10.0.0.7\n⁃ VPC 대역: 10.0.0.0/16\n⁃ Subnet 대역: 10.0.0.0/24\n⁃ ACG: test3-vpc-default-acg\n\n\n파라미터 설정\nMaster 서버와 Slave 서버에 각각 파라미터를 설정합니다.\n\n# Master, Slave \n~# vi /etc/my.cnf\n\n\nMaster 서버\n\n# Master \n[mysqld]\nserver-id=1\nlog-bin=binlog\ngtid-mode=ON\nenforce-gtid-consistency=ON\nlog_slave_updates=ON\n\n\n\n  \n  \n    \n  \n\n\nSlave 서버\n\n# Slave\n[mysqld]\nserver-id=2\nlog-bin=binlog\ngtid-mode=ON\nenforce-gtid-consistency=ON\nlog_slave_updates=ON\n\n\n\n  \n  \n    \n  \n\n\ngtid_mode 상태 확인\n위 설정 변경 후 mysql DB를 재시작하고 Master와 Slave모두 gtid_mode가 ON상태인지 확인합니다.\n# Master, Slave \n~# systemctl restart mysqld\n\n/* Master, Slave */\nmysql&gt; show variables like '%gtid_mode%';\n\n\nMaster 서버\n\n  \n  \n    \n  \n\n\nSlave 서버\n\n  \n  \n    \n  \n\n\nReplication 전용 유저 생성\nMaster 서버에서 Replication 전용 유저를 생성합니다.\n\n/* Master */\nmysql&gt; create user '3rd'@'%' identified by 'Test123$';\nmysql&gt; grant replication slave,replication client on *.* to '3rd'@'%';\nmysql&gt; flush privileges;\nmysql&gt; SELECT user,host,authentication_string FROM mysql.user;\n\n\n\n  \n  \n    \n  \n\n\n테스트용 DB 생성\n테스트에 사용할 database를 생성합니다.\n\n/* Master */\nmysql&gt; CREATE DATABASE testdb default CHARACTER SET UTF8;\nmysql&gt; show databases;\n\n\n\n  \n  \n    \n  \n\n\n백업 파일 생성\nMaster 서버에서 백업 파일을 생성합니다.\n\n백업 디렉터리 생성\n\n# Master\n~# mkdir /root/db_backup\n\n\nmysqldump 명령으로 백업 파일 생성\n# Master \n~# mysqldump -u root -p -v --databases testdb \\\n--quick --single-transaction --routines --set-gtid-purged=ON \\\n--triggers --extended-insert --master-data=2 &gt; /root/db_backup/testdb.sql\n\n\n\n  \n  \n    \n  \n\n\n백업 파일 복사\n백업 파일을 Slave 서버로 복사하기 위해 Master 와 Slave 서버 모두 rsync를 설치합니다.\n(백업 파일 복사는 rsync를 사용하지 않고 다른 방법을 사용해도 됩니다.)\n\n~# yum -y install rsync\n\nMaster 서버\n\n  \n  \n    \n  \n\n\nSlave 서버\n\n  \n  \n    \n  \n\n\nACG (방화벽) 설정\n이제 Master, Slave 두 서버간에 동기화, 복제가 가능하도록 ACG (방화벽)를 설정합니다.\n두 서버를 설치할 때 사용하도록 설정한 ACG는 test3-vpc-default-acg이기에 해당 ACG를 선택하고, ACG 규칙 설정에서 접근소스에는 Subnet의 IP 대역인 10.0.0.0/24, 허용포트는 22, 3306를 입력하고 추가합니다.\n\n  접근소스: 10.0.0.0/24\n  허용포트 22: rsync 사용을 위한 포트\n  허용포트 3306: Replication을 위한 포트\n\n\n\n  \n  \n    \n  \n\n\n 접근 소스: 여기서는 테스트를 위해 접근소스에 Subnet IP 전체 대역을 지정했지만, 실제 서비스 환경에서는 해당 Subnet에 DB서버 외에 다른 서버들이 존재하는 경우도 있을 수 있으므로 각 DB서버 IP만 지정하는 것이 보안 측면에서는 더욱 안전할 수 있습니다.\n\n백업 파일 전송\nMaster -&gt; Slave로 DB 백업 파일을 전송합니다.\n전송 과정에서 정말 전송할 것인지 확인하는 단계와 Slave 서버의 root 패스워드를 확인하는 단계가 있습니다.\n\n# rsync -avzr --progress testdb.sql root@슬레이브서버IP:~/\n\n~# cd db_backup/\n~# rsync -avzr --progress testdb.sql root@10.0.0.7:~/\n\n\n\n  \n  \n    \n  \n\n\nSlave 서버에서 DB 복원\nrsync로 전송 받은 DB 백업 파일을 실행해서 DB를 복원합니다.\n\n/* Slave */\nmysql&gt; source testdb.sql;\n\n\n\n  \n  \n    \n  \n\n\nReplication 설정\nSlave 서버에서 Replication을 설정합니다.\n\n/* Slave \nmysql&gt; CHANGE MASTER TO MASTER_HOST='Master 서버 IP',\nMASTER_USER='Replication 계정',MASTER_PASSWORD='Replication 계정 비번', \nMASTER_AUTO_POSITION=1;\n*/\n\nmysql&gt; CHANGE MASTER TO MASTER_HOST='101.0.0.6',\nMASTER_USER='3rd',MASTER_PASSWORD='Test123$', \nMASTER_AUTO_POSITION=1;\n\nmysql&gt; start slave;\n\n\n\n  \n  \n    \n  \n\n\nReplication 대기 상태 확인\nSlave 서버에서 Replication 상태가 어떤지 확인합니다.\n아래 명령어를 실행해보면 Master에서의 이벤트 전송을 대기 중이라는 메시지와 Master 서버의 정보를 확인할 수 있습니다.\n\n/* Slave */\nmysql&gt; show slave status \\G\n\n\n  \n  \n    \n  \n\n\nReplication 테스트\nMaster 서버에서 테스트용 테이블을 생성하고, 데이터를 입력한 후 Slave 서버에도 복제가 되었는지 확인합니다.\n\nMaster 서버에 테스트용 데이터 입력\n/* Master */\nmysql&gt; use testdb;\nmysql&gt; create table 3rd (\n    no int(10) auto_increment , \n    name varchar(10), \n    primary key(no));\nmysql&gt; insert into 3rd values(1,'3rd');\nmysql&gt; commit;\nmysql&gt; select * from 3rd;\n\n\n\n  \n  \n    \n  \n\n\nSlave 서버에서 복제 확인\n/* Slave */\nmysql&gt; use testdb;\nmysql&gt; select * from 3rd;\n\n\n\n  \n  \n    \n  \n\n\n추가 테스트\n추가로 데이터를 다시 입력해보면 정상적으로 복제가 되는 것을 확인할 수 있습니다.\n\nMaster 서버\n\n  \n  \n    \n  \n\n\nSlave 서버\n\n  \n  \n    \n  \n\n\n오류 상황\nMaster 서버에서 데이터를 입력해도 Slave 서버에 제대로 복제되지 않는 등 Replication 기능에 문제가 생겼을 때에는 \n위쪽에서도 사용했었던 다음 명령어로 Replication 상태를 확인해봅니다.\n\n/* Slave */\nmysql&gt; show slave status \\G\n\n\n혹시 Slave_IO_State: Connecting to master 등의 Master 서버에 연결하지 못한다는 메시지가 보이는 경우 ACG (방화벽) 설정에 문제가 있는 것이니\n위쪽에서 설정했던 ACG (방화벽) 설정 을 다시 한번 확인해보시기 바랍니다.\n\n Slave_IO_State: Connecting to master\n\n Slave_IO_Running: Connecting\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  GTID를 이용한 Mysql 복제 가이드\n    \n      https://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-multi-source-replication-html": {
						"id": "database-ncloud-database-mysql-multi-source-replication-html",
						"title": "MySQL Multi Source Replication 구성 가이드",
						"categories": "",
						"url": " /database/ncloud-database-mysql-multi-source-replication.html",
						"content": "개요\n\nn대의 마스터 DB와 1대의 슬레이브 DB를 연결하여 마스터 DB들의 데이터를 슬레이브 DB 한곳에 모아 조회할 수 있는  MySQL Multi-Source-Replication(MSR)을 구성하는 방법을 정리해보겠습니다.\n\n테스트 준비\n\n\n  마스터 서버 2대, 슬레이브 서버 1대 준비\n  각 서버에 MySQL 5.7 이상 설치\n  MySQL 리플리케이션작업 진행 시 마스터 서버의 데이터베이스에 쓰기 작업 금지\n\n\n\n  \n  \n    \n  \n\n\nACG 설정\n서버 준비가 끝났으면 우선 마스터 서버  슬레이브 서버로 디비 백업 파일 복사과 복제 구성에 필요한 22, 3306 포트를 오픈해야 합니다.\n오픈 할 때 규칙은 마스터 서버와 슬레이브 서버의 공통 ACG에 사설 IP 대역 전체를 지정할 수도 있고, 슬레이브 서버 전용 ACG에 마스터 서버 IP만 등록하는 방법도 있습니다.\n\n\n  \n  \n    \n  \n\n\nSlave 장비에 백업 디렉토리 생성\n먼저 Slave 장비에 Master 장비들로 부터 DB 복원용 덤프 파일을 전송 받을 백업 디렉토리를 생성하는 것 부터 시작하겠습니다.\n\n~# mkdir /data\n~# cd /data\n\n\n\n  \n  \n    \n  \n\n\nMaster1 장비 구성\n\nmaster1 설정 추가\n\n  /etc/my.cnf에 Master1 설정을 추가합니다.\n\n\n~# vi /etc/my.cnf\n\nserver-id = 1\nlog-bin = mysql-bin\nbinlog_format = mixed\ncharacter-set-server = utf8\n\n#MySQL을 재시작해 변경사항 적용.\n~# systemctl restart mysqld\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 계정 생성\nMySQL 접속 후 리플리케이션을 진행할 계정 생성\n\n#master1 계정 생성.\nmysql&gt; create user '리플리케이션 계정명'@'%' identified by '패스워드';\nmysql&gt; grant replication slave,replication client on *.* to '리플리케이션 계정명'@'%';\nmysql&gt; flush privileges;\n\n\n\n  \n  \n    \n  \n\n\n테스트 DB 생성\n다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\n\nmysql&gt; CREATE DATABASE testdb1 default CHARACTER SET UTF8;\n\n\n\n  \n  \n    \n  \n\n\nMaster1 정보확인\n이제 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\n\nmysql&gt; show variables like 'server_id';\nmysql&gt; show master status;\n\n\n\n[show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 백업 파일 슬레이브 장비로 전송\ntestdb1 DB의 백업파일을 생성하고, 슬레이브 서버로 전송합니다.\n\n~# mkdir /data\n~# cd /data\n~# mysqldump -u root -p --databases testdb1 &gt; /data/test1.sql \n\n#슬레이브 서버에 전송.\n~# scp test1.sql root@10.0.0.8:/data\n\n\n\n  \n  \n    \n  \n\n\nMaster2 장비 구성\n\nMaster2 설정 추가\n\n  /etc/my.cnf에 Master2 설정을 추가합니다.\n\n\n~# vi /etc/my.cnf\n\nserver-id = 2\nlog-bin = mysql-bin\nbinlog_format = mixed\ncharacter-set-server = utf8\n\n#DB를 재시작하여 변경사항 적용.\n~# systemctl restart mysqld\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 계정 생성\nMySQL 접속 후 리플리케이션을 진행할 계정 생성합니다.\n\n#master2 계정 생성.\nmysql&gt; create user '리플리케이션 계정명'@'%' identified by '패스워드';\nmysql&gt; grant replication slave,replication client on *.* to '리플리케이션 계정명'@'%';\nmysql&gt; flush privileges;\n\n\n\n  \n  \n    \n  \n\n\n테스트 DB 생성\n다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\n\nmysql&gt; CREATE DATABASE testdb2 default CHARACTER SET UTF8;\n\n\n\n  \n  \n    \n  \n\n\nMaster2 정보확인\n마찬가지로 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\n\nmysql&gt; show variables like 'server_id';\nmysql&gt; show master status;\n\n\n\n[show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 백업 파일 슬레이브 장비로 전송\ntestdb2 DB의 백업파일 생성하고, 슬레이브 서버로 전송합니다.\n\n~# mkdir /data\n~# cd /data\n~# mysqldump -u root -p --databases testdb2 &gt; /data/test2.sql\n\n~# scp test2.sql root@10.0.0.8:/data\n\n\n\n  \n  \n    \n  \n\n\nSlave 장비 구성\n\nSlave 설정 추가\n\n  /etc/my.cnf에 Slave 설정을 추가합니다.\nMySQL 8.0 버전 부터는 replicate-do-db 설정에 채널 정보도 추가할 수 있게 업데이트 되었습니다.\n\n\n\n  \n      \n          MySQL 5.7 \n      \n  \n      \n          MySQL 8.0 \n      \n  \n\n\n  \n      \n~# vi /etc/my.cnf\n\n### MySQL5.7 기준 ###\n\nserver-id = 3 \n\n#리플리케이션 대상 디비 설정.\nreplicate-do-db = testdb1\nreplicate-do-db = testdb2\n\n#리플리케이션 제외 디비 설정.\nreplicate-ignore-db = information_schema\nreplicate-ignore-db = mysql\nreplicate-ignore-db = performance_schema\nreplicate-ignore-db = sys\n\nmaster_info_repository = 'TABLE'\nrelay_log_info_repository = 'TABLE'\nslave-skip-errors = all\n\n#DB를 재시작하여 변경사항 적용.\n~# systemctl restart mysqld\n\n\n  \n      \n~# vi /etc/my.cnf\n\n### MySQL 8 기준 ###\n\nserver-id = 3 \n\n# 리플리케이션 대상 디비 설정 (replicate-do-db = 채널명:DB명)\nreplicate-do-db = ch_testdb1:testdb1\nreplicate-do-db = ch_testdb1:testdb2\n\n#리플리케이션 제외 디비 설정.\nreplicate-ignore-db = information_schema\nreplicate-ignore-db = mysql\nreplicate-ignore-db = performance_schema\nreplicate-ignore-db = sys\n\nslave-skip-errors = all\n\n#DB를 재시작하여 변경사항 적용.\n~# systemctl restart mysqld\n\n\n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nDB 복구 진행\n먼저 복구할 DB를 미리 생성하고 Master1, Master2 장비에서 전송 받은 백업 파일을 사용해 DB를 복구합니다.\n#복구할 DB 생성.\nmysql&gt; create database testdb1;\nmysql&gt; create database testdb2;\nmysql&gt; quit\n\n#DB 복구\n~# mysql -u root -p testdb1 &lt; /data/test1.sql\n~# mysql -u root -p testdb2 &lt; /data/test2.sql\n\n\n\n  \n  \n    \n  \n\n\n\n  백업 파일을 전송 받은 디렉토리로 이동해 백업 파일이 정상적으로 전송되었는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 채널 설정\n리플리케이션 채널을 설정하는 쿼리문은 다음과 같습니다.\n채널 설정 구문은 MySQL 버전별로 다르고, 특히 8.0.23 버전부터는 완전히 달라지므로 버전에 맞게 사용하시면 됩니다.\n\n\n  \n      \n          MySQL 5.7 \n      \n  \n      \n          MySQL 8.0 ~ 8.0.22 \n      \n  \n      \n          MySQL 8.0.23 ~ \n      \n  \n\n\n  \n      \n# MySQL 5.7\nmysql&gt; CHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\n\n\n  \n      \n# MySQL 8.0 ~ 8.0.22\nmysql&gt; CHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', GET_MASTER_PUBLIC_KEY=1, MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\n\n\n  \n      \n# MySQL 8.0.23 이후 버전\nmysql&gt; CHANGE REPLICATION SOURCE TO SOURCE_HOST='마스터IP', SOURCE_PORT=포트번호, SOURCE_USER='생성한 리플리케이션 계정명', SOURCE_PASSWORD='패스워드', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='위에서 확인된 File명', SOURCE_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL 'ch_testdb1';\n\n\n  \n\n\n여기에 필요한 정보 중에서 [MASTER_LOG_FILE(SOURCE_LOG_FILE)]과 [MASTER_LOG_POS(SOURCE_LOG_POS)]은 위쪽에서 확인한 Master DB들의 정보에 나타났던 것으로 정리하면 다음과 같습니다.\n\n\n\n\n  \n    \n      DB\n      File\n      Position\n    \n  \n  \n    Master1mysql-bin.0000011321\n    Master2mysql-bin.000002970\n  \n    \n\n\n\nMaster 서버 정보 입력\nSlave 서버에 Master 서버 정보를 하나씩 입력합니다.\n\n\n  \n      \n          MySQL 5.7 \n      \n  \n      \n          MySQL 8.0 ~ 8.0.22 \n      \n  \n      \n          MySQL 8.0.23 ~ \n      \n  \n\n\n  \n      \n#Master1\nmysql&gt; CHANGE MASTER TO MASTER_HOST='10.0.0.6', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=1321 FOR CHANNEL 'ch_testdb1';\n\n#Master2\nmysql&gt; CHANGE MASTER TO MASTER_HOST='10.0.0.7', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=970 FOR CHANNEL 'ch_testdb2';\n\nmysql&gt; FLUSH PRIVILEGES;\n\n\n  \n      \n#Master1\nmysql&gt; CHANGE MASTER TO MASTER_HOST='10.0.0.6', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', GET_MASTER_PUBLIC_KEY=1, MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=1321 FOR CHANNEL 'ch_testdb1';\n\n#Master2\nmysql&gt; CHANGE MASTER TO MASTER_HOST='10.0.0.7', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', GET_MASTER_PUBLIC_KEY=1, MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=970 FOR CHANNEL 'ch_testdb2';\n\nmysql&gt; FLUSH PRIVILEGES;\n\n\n  \n      \n#Master1\nmysql&gt; CHANGE REPLICATION SOURCE TO SOURCE_HOST='10.0.0.6', SOURCE_PORT=3306, SOURCE_USER='testuser', SOURCE_PASSWORD='Test!@123', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='mysql-bin.000001', SOURCE_LOG_POS=1321 FOR CHANNEL 'ch_testdb1';\n\n#Master2\nmysql&gt; CHANGE REPLICATION SOURCE TO SOURCE_HOST='10.0.0.7', SOURCE_PORT=3306, SOURCE_USER='testuser', SOURCE_PASSWORD='Test!@123', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='mysql-bin.000001', SOURCE_LOG_POS=970 FOR CHANNEL 'ch_testdb2';\n\nmysql&gt; FLUSH PRIVILEGES;\n\n\n  \n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 채널 시작\n리플리케이션 시작 후 에러가 없는지 확인합니다.\n\n\n  \n      \n          MySQL 5.7 \n      \n  \n      \n          MySQL 8.0 \n      \n  \n\n\n  \n      \n#MySQL 5.7 기준\nmysql&gt; start slave for channel 'ch_testdb1'; \nmysql&gt; start slave for channel 'ch_testdb2';\n\nmysql&gt; show slave status for channel 'ch_testdb1'\\G \nmysql&gt; show slave status for channel 'ch_testdb2'\\G\n\n\n  \n      \n#MySQL 8 기준\nmysql&gt; start replica for channel 'ch_testdb1'; \nmysql&gt; start replica for channel 'ch_testdb2';\n\nmysql&gt; show replica status for channel 'ch_testdb1'\\G \nmysql&gt; show replica status for channel 'ch_testdb2'\\G\n\n\n  \n\n\n\n  Master1\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Master2\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다.\n\n\n\n  \n  \n    \n  \n\n\n리플리케이션 테스트\n리플리케이션 설정을 모두 마친 후에 Master 서버들에서 DB 작업을 진행하고, Slave 서버에 해당 내용이 복제되는지 확인해보겠습니다.\n\n\n  Master1 서버 작업\nMaster1 서버에 테스트를 위한 [sampletable] Table을 생성합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Slave 서버 확인\nSlave 서버에서 testdb1 DB에 sampletable Table이 복제되었는지 확인합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Master2 서버 작업\nMaster2 서버에 테스트를 위한 [sampletable] Table을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Slave 서버 확인\nSlave 서버에서 testdb2 DB에 sampletable Table이 복제되었는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\n버전별 명령어 비교\n\n\n  \n      \n          MySQL 5.7 \n      \n  \n      \n          MySQL 8.0 ~ 8.0.22 \n      \n  \n      \n          MySQL 8.0.23 ~ \n      \n  \n\n\n  \n      \n\n\n  \n    \n      MySQL 5.7\n      리플리케이션 명령어\n    \n  \n  \n    \n      채널 설정\n      CHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\n    \n    채널 시작START SLAVE FOR CHANNEL \"채널이름\";\n    채널 중지STOP SLAVE FOR CHANNEL \"채널이름\";\n    채널 상태 확인SHOW SLAVE STATUS FOR CHANNEL \"채널이름\";\n    채널 정보 삭제RESET SLAVE ALL FOR CHANNEL \"채널이름\";\n  \n  \n\n\n  \n      \n\n\n  \n    \n      MySQL 5.7\n      리플리케이션 명령어\n    \n  \n  \n    \n      채널 설정\n      CHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', GET_Master_PUBLIC_KEY=1, MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\n    \n    채널 시작START SLAVE FOR CHANNEL \"채널이름\";\n    채널 중지STOP SLAVE FOR CHANNEL \"채널이름\";\n    채널 상태 확인SHOW SLAVE STATUS FOR CHANNEL \"채널이름\";\n    채널 정보 삭제RESET SLAVE ALL FOR CHANNEL \"채널이름\";\n  \n  \n\n\n  \n      \n\n\n  \n    \n      MySQL 8.0\n      리플리케이션 명령어\n    \n  \n  \n    \n      채널 설정\n      CHANGE REPLICATION SOURCE TO SOURCE_HOST='마스터IP', SOURCE_PORT=포트번호, SOURCE_USER='생성한 리플리케이션 계정명', SOURCE_PASSWORD='패스워드', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='위에서 확인된 File명', SOURCE_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL 'ch_testdb1';\n    \n    채널 시작START REPLICA FOR CHANNEL \"채널이름\";\n    채널 중지STOP REPLICA FOR CHANNEL \"채널이름\";\n    채널 상태 확인SHOW REPLICA STATUS FOR CHANNEL \"채널이름\";\n    채널 정보 삭제RESET REPLICA ALL FOR CHANNEL \"채널이름\";\n  \n  \n\n\n  \n\n\n참고 URL\n\n  MySQL 5.7 Multi-Source Replication 가이드\n    \n      https://dev.mysql.com/doc/refman/5.7/en/replication-multi-source.html\n    \n  \n  MySQL 8.0 Multi-Source Replication 가이드\n    \n      https://dev.mysql.com/doc/refman/8.0/en/replication-multi-source.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-postgresql-install-connect-guide-centos-html": {
						"id": "database-ncloud-database-postgresql-install-connect-guide-centos-html",
						"title": "설치형 PostgreSQL DB 설치, 접속 가이드 | CentOS",
						"categories": "",
						"url": " /database/ncloud-database-postgresql-install-connect-guide-centos.html",
						"content": "개요\nPostgreSQL은 설치 후에 DB에 접속할 때 MySQL등 다른 DB와 달리 [OS와 PostgreSQL 양쪽에 동일한 계정을 생성]하거나 \n[인증관련 환경설정 파일을 수정]해야 접속할 수 있는데 이 두가지 방법을 CentOS에서 적용하는 과정을 정리해보겠습니다.\n\n테스트 환경\n\n  CentOS 7.8\n  PostgreSQL 13.8\n\n\n설치\n기본 배포 버전으로 테스트할 수도 있지만, 여기서는 PostgreSQL 13을 설치해보겠습니다.\n\n리포지토리 설치\n[PostgreSQL 13] 설치 정보가 담겨 있는 리포지토리 RPM을 설치합니다.\n\n~# yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm\n\n\n  \n  \n    \n  \n\n\nPostgreSQL 설치\n[PostgreSQL 13]을 설치합니다.\n\n~# yum install -y postgresql13-server\n\n\n  \n  \n    \n  \n\n\n기본 DB 생성\n[initdb] 명령으로 기본 DB를 생성하고 올바르게 생성되었는지 로그를 확인해보겠습니다.\n\n~# cd /usr/pgsql-13/bin/\n~# postgresql-13-setup initdb\n~# cat /var/lib/pgsql/13/initdb.log\n\n\n  \n  \n    \n  \n\n\nPostgreSQL 시작\n~# systemctl enable postgresql-13\n~# systemctl start postgresql-13\n~# systemctl status postgresql-13\n\n\n  \n  \n    \n  \n\n\nDB 접속\n기본 마스터 계정인 [postgres]로 [PostgreSQL]에 접속합니다.\n\n~# su postgres\nbash$ psql\n\n\n  \n  \n    \n  \n\n\n유저 생성\n테스트용 계정 [testuser]를 생성하고 [\\du] 명령으로 생성된 유저를 확인합니다.\n\npostgres=# create user testuser password 'test123$' superuser;\npostgres=# \\du \n\n\n  \n  \n    \n  \n\n\nDB 생성 및 소유자 지정\n테스트용 DB를 생성하고 소유자를 지정한 후에 [\\l] 명령으로 생성된 DB를 확인합니다.\n\npostgres=# create database testdb owner testuser;\npostgres=# \\l\npostgres=# \\q\nbash$\n\n\n  \n  \n    \n  \n\n\n접속 시도 - 인증 오류\n위에서 생성한 계정으로 접속을 시도해보면, 아래와 같이 인증 오류가 발생합니다.\n다음 단계에서는 이 인증 오류를 해결하는 방법 2가지를 확인해보겠습니다.\n\n~# psql -U testuser -d testdb\npsql: error: FATAl: Peer authentication failed for user \"testuser\"\n\n\n  \n  \n    \n  \n\n\n인증 오류 해결\n인증 문제를 해결하고 [PostgreSQL]에 접속하는 방법은 크게 2가지가 있는데 한가지씩 확인해보겠습니다.\n\n방법1 - 동일한 계정 생성\n우선, 처음에 DB 생성 후에 추가했던 [PostgreSQL] 유저 계정과 동일한 계정을 OS 사용자에도 추가하는 방법입니다.\n\n아래와 같이 DB 유저와 동일한 [testuser] 계정을 생성하겠습니다.\n~# adduser testuser\n~# passwd testuser\n\n\n  \n  \n    \n  \n\n\n\n  DB 접속\n새로 생성한 [testuser] 계정으로 전환한 후에 접속을 해보면 문제 없이 접속되는 것을 확인할 수 있습니다.\n\n\n~# su testuser\n~$ psql -U testuser -d testdb\n\n\n  \n  \n    \n  \n\n\n방법2 - 인증 설정 파일 수정\n다음으로 인증 관련 설정 파일인 [pg_hba.conf] 파일을 수정해서 접속하는 방법을 확인해보겠습니다.\n\n[pg_hba.conf] 파일을 열어보면 아래와 같이 DB 접근 설정 항목들이 있는데 [local]과 IPv4용 [host]의 METHOD 항목을 보시면 각각 [peer]과 [scram-sha-256]으로 설정되어 있는 것을 확인할 수 있습니다.\n\n여기서 [peer]는 운영 체제에서 클라이언트의 운영 체제 사용자 이름과 요청한 데이터베이스 사용자 이름이 일치하는지 확인하는 옵션입니다.\n\n이 항목을 [scram-sha-256] 또는 [md5]로 수정합니다.\n\n~# vi /var/lib/pgsql/13/data/pg_hba.conf\n\n\n\n  수정 전\n\n\n  \n  \n    \n  \n\n\n\n  수정 후\n\n\n  \n  \n    \n  \n\n\n\n  DB 재시작 후 접속\n설정 파일을 수정했으면 [PostgreSQL]을 재시작하고 다시 접속해봅니다.\n이번에는 문제 없이 패스워드를 입력하고 접속 가능한 것을 확인할 수 있습니다.\n\n\n~# systemctl restart postgresql-13\n~# psql -U testuser -d testdb\n\n\n  \n  \n    \n  \n\n\n기본 배포 버전 설치\n[PostgreSQL 13] 버전이 아닌 기본 배포 버전을 설치하려면 아래와 같은 방법으로 설치를 하면 됩니다.\n나머지 인증 방법은 위에서 설명한 내용과 동일합니다.\n\n~# yum install postgresql-server\n~# cd /usr/bin/\n~# postgresql-setup --initdb\n~# systemctl enable postgresql\n~# systemctl start postgresql\n~# systemctl status postgresql\n\n\nOS별 배포 버전\n2022년 10월 05일 기준 Red Hat family OS별로 설치되는 배포 버전은 다음과 같습니다.\n\n\n  RHEL / Rocky Linux 9 : 13\n  RHEL / Rocky Linux / OL 8\t: 13, 12, 10 and 9.6 via modules\n  RHEL / CentOS / SL / OL 7\t: 9.2\n  RHEL / CentOS / SL / OL 6\t: 8.4\n  Fedora 36\t: 14\n  Fedora 35\t: 13\n\n\npg_hba.conf 파일 Method 옵션\n[pg_hba.conf] 설정 파일의 Method 옵션 리스트는 아래와 같습니다.\n\n\n  \n    trust: 무조건 접속을 허용합니다. 이 방법을 사용하면 PostgreSQL 데이터베이스 서버에 연결할 수 있는 모든 사람이 암호나 다른 인증 없이 원하는 PostgreSQL 사용자로 로그인할 수 있습니다.\n  \n  \n    reject: 무조건 연결을 거부합니다. 이것은 그룹에서 특정 호스트 를 “ 필터링 “reject 하는 데 유용합니다. 예를 들어 한 라인은 특정 호스트의 연결을 차단할 수 있고 나중 라인은 특정 네트워크의 나머지 호스트가 연결할 수 있도록 합니다.\n  \n  \n    scram-sha-256: SCRAM-SHA-256 인증을 수행해 사용자의 암호를 확인합니다.\n  \n  \n    md5: SCRAM-SHA-256 또는 MD5 인증을 수행해 사용자의 암호를 확인합니다.\n  \n  \n    password: 클라이언트가 인증을 위해 암호화되지 않은 암호를 제공하도록 요구합니다. 암호는 네트워크를 통해 일반 텍스트로 전송되기 때문에 신뢰할 수 없는 네트워크에서는 사용해서는 안 됩니다.\n  \n  \n    gss: GSSAPI를 사용해 사용자를 인증합니다. 이것은 TCP/IP 연결에만 사용할 수 있습니다. GSSAPI 암호화와 함께 사용할 수 있습니다.\n  \n  \n    sspi: SSPI를 사용해 사용자를 인증합니다. 이것은 Windows에서만 사용할 수 있습니다.\n  \n  \n    ident: 클라이언트의 ident 서버에 연결하여 클라이언트의 운영 체제 사용자 이름을 얻고 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. ID 인증은 TCP/IP 연결에서만 사용할 수 있습니다. 로컬 연결에 대해 지정된 경우 피어 인증이 대신 사용됩니다.\n  \n  \n    peer: 운영 체제에서 클라이언트의 운영 체제 사용자 이름을 가져와서 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. 이것은 로컬 연결에만 사용할 수 있습니다.\n  \n  \n    lda: LDAP 서버를 사용해 인증 합니다.\n  \n  \n    radius: RADIUS 서버를 사용해 인증합니다.\n  \n  \n    cert: SSL 클라이언트 인증서를 사용해 인증합니다.\n  \n  \n    pam: 운영 체제에서 제공하는 PAM(Pluggable Authentication Modules) 서비스를 사용해 인증합니다.\n  \n  \n    bsd: 운영 체제에서 제공하는 BSD 인증 서비스를 사용해 인증합니다.\n  \n\n\n참고 URL\n\n  PostgreSQL OS별 다운로드 안내\n    \n      https://www.postgresql.org/download/linux/\n    \n  \n  PostgreSQL pg_hba.conf 파일 옵션 안내\n    \n      https://www.postgresql.org/docs/current/auth-pg-hba-conf.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-postgresql-install-connect-guide-rocky-linux-html": {
						"id": "database-ncloud-database-postgresql-install-connect-guide-rocky-linux-html",
						"title": "설치형 PostgreSQL DB 설치, 접속 가이드 | Rocky Linux",
						"categories": "",
						"url": " /database/ncloud-database-postgresql-install-connect-guide-rocky-linux.html",
						"content": "개요\nPostgreSQL은 설치 후에 DB에 접속할 때 MySQL등 다른 DB와 달리 [OS와 PostgreSQL 양쪽에 동일한 계정을 생성]하거나 \n[인증관련 환경설정 파일을 수정]해야 접속할 수 있는데 이 두가지 방법을 [Rocky Linux]에서 적용하는 과정을 정리해보겠습니다.\n\n테스트 환경\n\n  Rocky Linux 8.8\n  PostgreSQL 13.12\n\n\n설치\n기본 배포 버전으로 테스트할 수도 있지만, 여기서는 PostgreSQL 13 최신 버전을 설치해보겠습니다.\n\n리포지토리 버전 확인\n우선 Rocky Linux에서 지원하는 기본 버전들을 확인해보면 아래와 같이 PostgreSQL [9.6], [10], [12], [13], [15] 인 것을 확인할 수 있습니다.\n\n~# dnf module list postgresql\n\n\n\n  \n  \n    \n  \n\n\n기본 버전 비활성화\nPostgreSQL 13 최신 버전을 사용하기 위해 기본 버전들은 모두 비활성화합니다. 비활성화 처리 후 리스트를 다시 조회해보면 [disabled]를 뜻하는 [X]로 변경된 것을 확인할 수 있습니다.\n\n~# dnf -qy module disable postgresql\n~# dnf module list postgresql\n\n\n\n  \n  \n    \n  \n\n\n리포지토리 설치\n[PostgreSQL 13] 설치 정보가 담겨 있는 리포지토리 RPM을 설치합니다.\n\n~# dnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm\n\n\n  \n  \n    \n  \n\n\nPostgreSQL 설치\n[PostgreSQL 13]을 설치합니다.\n\n~# dnf install -y postgresql13-server\n\n\n  \n  \n    \n  \n\n\n기본 DB 생성\n[initdb] 명령으로 기본 DB를 생성하고 올바르게 생성되었는지 로그를 확인해보겠습니다.\n\n~# cd /usr/pgsql-13/bin/\n~# postgresql-13-setup initdb\n~# cat /var/lib/pgsql/13/initdb.log\n\n\n  \n  \n    \n  \n\n\nPostgreSQL 시작\n~# systemctl enable postgresql-13\n~# systemctl start postgresql-13\n~# systemctl status postgresql-13\n\n\n  \n  \n    \n  \n\n\nDB 접속\n기본 마스터 계정인 [postgres]로 [PostgreSQL]에 접속합니다.\n\n~# su postgres\nbash$ psql\n\n\n  \n  \n    \n  \n\n\n유저 생성\n테스트용 계정 [testuser]를 생성하고 [\\du] 명령으로 생성된 유저를 확인합니다.\n\npostgres=# create user testuser password 'test123$' superuser;\npostgres=# \\du \n\n\n  \n  \n    \n  \n\n\nDB 생성 및 소유자 지정\n테스트용 DB를 생성하고 소유자를 지정한 후에 [\\l] 명령으로 생성된 DB를 확인합니다.\n\npostgres=# create database testdb owner testuser;\npostgres=# \\l\npostgres=# \\q\nbash$\n\n\n  \n  \n    \n  \n\n\n접속 시도 - 인증 오류\n위에서 생성한 계정으로 접속을 시도해보면, 아래와 같이 인증 오류가 발생합니다.\n다음 단계에서는 이 인증 오류를 해결하는 방법 2가지를 확인해보겠습니다.\n\n~# psql -U testuser -d testdb\npsql: error: FATAl: Peer authentication failed for user \"testuser\"\n\n\n  \n  \n    \n  \n\n\n인증 오류 해결\n인증 문제를 해결하고 [PostgreSQL]에 접속하는 방법은 크게 2가지가 있는데 한가지씩 확인해보겠습니다.\n\n방법1 - 동일한 계정 생성\n우선, 처음에 DB 생성 후에 추가했던 [PostgreSQL] 유저 계정과 동일한 계정을 OS 사용자에도 추가하는 방법입니다.\n\n아래와 같이 DB 유저와 동일한 [testuser] 계정을 생성하겠습니다.\n~# adduser testuser\n~# passwd testuser\n\n\n  \n  \n    \n  \n\n\n\n  DB 접속\n새로 생성한 [testuser] 계정으로 전환한 후에 접속을 해보면 문제 없이 접속되는 것을 확인할 수 있습니다.\n\n\n~# su testuser\n~$ psql -U testuser -d testdb\n\n\n  \n  \n    \n  \n\n\n방법2 - 인증 설정 파일 수정\n다음으로 인증 관련 설정 파일인 [pg_hba.conf] 파일을 수정해서 접속하는 방법을 확인해보겠습니다.\n\n[pg_hba.conf] 파일을 열어보면 아래와 같이 DB 접근 설정 항목들이 있는데 [local]과 IPv4용 [host]의 METHOD 항목을 보시면 각각 [peer]과 [scram-sha-256]으로 설정되어 있는 것을 확인할 수 있습니다.\n\n여기서 [peer]는 운영 체제에서 클라이언트의 운영 체제 사용자 이름과 요청한 데이터베이스 사용자 이름이 일치하는지 확인하는 옵션입니다.\n\n이 항목을 [scram-sha-256] 또는 [md5]로 수정합니다.\n\n~# vim /var/lib/pgsql/13/data/pg_hba.conf\n\n\n\n  수정 전\n\n\n  \n  \n    \n  \n\n\n\n  수정 후\n\n\n  \n  \n    \n  \n\n\n\n  DB 재시작 후 접속\n설정 파일을 수정했으면 [PostgreSQL]을 재시작하고 다시 접속해봅니다.\n이번에는 문제 없이 DB 유저 생성 시 입력했던 패스워드를 입력하고 접속 가능한 것을 확인할 수 있습니다.\n\n\n~# systemctl restart postgresql-13\n~# psql -U testuser -d testdb\n\n\n  \n  \n    \n  \n\n\n기본 배포 버전 설치\n[PostgreSQL 13] 최신 버전이 아닌 기본 배포 버전을 설치하려면 아래와 같은 방법으로 설치를 하면 됩니다.\n나머지 인증 방법은 위에서 설명한 내용과 동일합니다.\n\n~# dnf install -y postgresql-server\n~# cd /usr/bin/\n~# postgresql-setup --initdb\n~# systemctl enable postgresql\n~# systemctl start postgresql\n~# systemctl status postgresql\n\n\nOS별 배포 버전\n2023년 9월 13일 기준 Red Hat family OS별로 설치되는 배포 버전은 다음과 같습니다.\n\n\n  RHEL / Rocky Linux 9 : 15, 13\n  RHEL / Rocky Linux / OL 8\t: 15, 13, 12, 10 and 9.6 via modules\n  RHEL / CentOS / SL / OL 7\t: 9.2\n  RHEL / CentOS / SL / OL 6\t: 8.4\n  Fedora 37\t: 14\n  Fedora 36\t: 14\n\n\npg_hba.conf 파일 Method 옵션\n[pg_hba.conf] 설정 파일의 Method 옵션 리스트는 아래와 같습니다.\n\n\n  \n    trust: 무조건 접속을 허용합니다. 이 방법을 사용하면 PostgreSQL 데이터베이스 서버에 연결할 수 있는 모든 사람이 암호나 다른 인증 없이 원하는 PostgreSQL 사용자로 로그인할 수 있습니다.\n  \n  \n    reject: 무조건 연결을 거부합니다. 이것은 그룹에서 특정 호스트 를 “ 필터링 “reject 하는 데 유용합니다. 예를 들어 한 라인은 특정 호스트의 연결을 차단할 수 있고 나중 라인은 특정 네트워크의 나머지 호스트가 연결할 수 있도록 합니다.\n  \n  \n    scram-sha-256: SCRAM-SHA-256 인증을 수행해 사용자의 암호를 확인합니다.\n  \n  \n    md5: SCRAM-SHA-256 또는 MD5 인증을 수행해 사용자의 암호를 확인합니다.\n  \n  \n    password: 클라이언트가 인증을 위해 암호화되지 않은 암호를 제공하도록 요구합니다. 암호는 네트워크를 통해 일반 텍스트로 전송되기 때문에 신뢰할 수 없는 네트워크에서는 사용해서는 안 됩니다.\n  \n  \n    gss: GSSAPI를 사용해 사용자를 인증합니다. 이것은 TCP/IP 연결에만 사용할 수 있습니다. GSSAPI 암호화와 함께 사용할 수 있습니다.\n  \n  \n    sspi: SSPI를 사용해 사용자를 인증합니다. 이것은 Windows에서만 사용할 수 있습니다.\n  \n  \n    ident: 클라이언트의 ident 서버에 연결하여 클라이언트의 운영 체제 사용자 이름을 얻고 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. ID 인증은 TCP/IP 연결에서만 사용할 수 있습니다. 로컬 연결에 대해 지정된 경우 피어 인증이 대신 사용됩니다.\n  \n  \n    peer: 운영 체제에서 클라이언트의 운영 체제 사용자 이름을 가져와서 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. 이것은 로컬 연결에만 사용할 수 있습니다.\n  \n  \n    lda: LDAP 서버를 사용해 인증 합니다.\n  \n  \n    radius: RADIUS 서버를 사용해 인증합니다.\n  \n  \n    cert: SSL 클라이언트 인증서를 사용해 인증합니다.\n  \n  \n    pam: 운영 체제에서 제공하는 PAM(Pluggable Authentication Modules) 서비스를 사용해 인증합니다.\n  \n  \n    bsd: 운영 체제에서 제공하는 BSD 인증 서비스를 사용해 인증합니다.\n  \n\n\n참고 URL\n\n  PostgreSQL OS별 다운로드 안내\n    \n      https://www.postgresql.org/download/linux/\n    \n  \n  PostgreSQL pg_hba.conf 파일 옵션 안내\n    \n      https://www.postgresql.org/docs/current/auth-pg-hba-conf.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-09-13\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-postgresql-install-connect-guide-ubuntu-html": {
						"id": "database-ncloud-database-postgresql-install-connect-guide-ubuntu-html",
						"title": "설치형 PostgreSQL DB 설치, 접속 가이드 | Ubuntu",
						"categories": "",
						"url": " /database/ncloud-database-postgresql-install-connect-guide-ubuntu.html",
						"content": "개요\nPostgreSQL은 설치 후에 DB에 접속할 때 MySQL등 다른 DB와 달리 [OS와 PostgreSQL 양쪽에 동일한 계정을 생성]하거나 \n[인증관련 환경설정 파일을 수정]해야 접속할 수 있는데 이 두가지 방법을 Ubuntu에서 적용하는 과정을 정리해보겠습니다.\n\n테스트 환경\n\n  Ubuntu 20.04\n  PostgreSQL 13.8\n\n\n설치\n기본 배포 버전으로 테스트할 수도 있지만, 여기서는 PostgreSQL 13을 설치해보겠습니다.\n\n리포지토리 설정 파일 생성\n[PostgreSQL 13] 설치 정보가 담겨 있는 리포지토리 설정 파일을 생성합니다.\n\n~# sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\" &gt; /etc/apt/sources.list.d/pgdg.list'\n~# wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\n\n\n  \n  \n    \n  \n\n\nPostgreSQL 설치\n[PostgreSQL 13]을 설치합니다.\n\n~# apt-get update\n~# apt-get -y install postgresql-13\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nPostgreSQL 시작\n~# systemctl enable postgresql\n~# systemctl start postgresql\n~# systemctl status postgresql\n\n\n  \n  \n    \n  \n\n\nDB 접속\n기본 마스터 계정인 [postgres]로 [PostgreSQL]에 접속합니다.\n\n~# sudo -i -u postgres\n~$ psql\n\n\n  \n  \n    \n  \n\n\n유저 생성\n테스트용 계정 [testuser]를 생성하고 [\\du] 명령으로 생성된 유저를 확인합니다.\n\npostgres=# create user testuser password 'test123$' superuser;\npostgres=# \\du \n\n\n  \n  \n    \n  \n\n\nDB 생성 및 소유자 지정\n테스트용 DB를 생성하고 소유자를 지정한 후에 [\\l] 명령으로 생성된 DB를 확인합니다.\n\npostgres=# create database testdb owner testuser;\npostgres=# \\l\npostgres=# \\q\n~$ exit\n\n\n  \n  \n    \n  \n\n\n접속 시도 - 인증 오류\n위에서 생성한 계정으로 접속을 시도해보면, 아래와 같이 인증 오류가 발생합니다.\n다음 단계에서는 이 인증 오류를 해결하는 방법 2가지를 확인해보겠습니다.\n\n~# psql -U testuser -d testdb\npsql: error: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: FATAL:  Peer authentication failed for user \"testuser\"\n\n\n  \n  \n    \n  \n\n\n인증 오류 해결\n인증 문제를 해결하고 [PostgreSQL]에 접속하는 방법은 크게 2가지가 있는데 한가지씩 확인해보겠습니다.\n\n방법1 - 동일한 계정 생성\n우선, 처음에 DB 생성 후에 추가했던 [PostgreSQL] 유저 계정과 동일한 계정을 OS 사용자에도 추가하는 방법입니다.\n\n아래와 같이 DB 유저와 동일한 [testuser] 계정을 생성하겠습니다.\n~# adduser testuser\n\n\n  \n  \n    \n  \n\n\n\n  DB 접속\n새로 생성한 [testuser] 계정으로 전환한 후에 접속을 해보면 문제 없이 접속되는 것을 확인할 수 있습니다.\n\n\n~# sudo -i -u testuser\n~$ psql -U testuser -d testdb\n\n\n  \n  \n    \n  \n\n\n방법2 - 인증 설정 파일 수정\n다음으로 인증 관련 설정 파일인 [pg_hba.conf] 파일을 수정해서 접속하는 방법을 확인해보겠습니다.\n\n[pg_hba.conf] 파일을 열어보면 아래와 같이 DB 접근 설정 항목들이 있는데 [local]과 IPv4용 [host]의 METHOD 항목을 보시면 각각 [peer]과 [md5]으로 설정되어 있는 것을 확인할 수 있습니다.\n\n여기서 [peer]는 운영 체제에서 클라이언트의 운영 체제 사용자 이름과 요청한 데이터베이스 사용자 이름이 일치하는지 확인하는 옵션입니다.\n\n이 항목을 [md5]로 수정합니다.\n\n~# vi /etc/postgresql/13/main/pg_hba.conf\n\n\n\n  수정 전\n\n\n  \n  \n    \n  \n\n\n\n  수정 후\n\n\n  \n  \n    \n  \n\n\n\n  DB 재시작 후 접속\n설정 파일을 수정했으면 [PostgreSQL]을 재시작하고 다시 접속해봅니다.\n이번에는 문제 없이 패스워드를 입력하고 접속 가능한 것을 확인할 수 있습니다.\n\n\n~# systemctl restart postgresql\n~# psql -U testuser -d testdb\n\n\n  \n  \n    \n  \n\n\n기본 배포 버전 설치\n[PostgreSQL 13] 버전이 아닌 기본 배포 버전을 설치하려면 아래와 같은 방법으로 설치를 하면 됩니다.\n2022년 10월 16일 기준 기본 배포 버전은 [12.8]입니다.\n나머지 인증 방법은 위에서 설명한 내용과 동일합니다.\n\n~# apt-get update\n~# apt-get -y install postgresql\n~# systemctl enable postgresql\n~# systemctl start postgresql\n~# systemctl status postgresql\n\n\npg_hba.conf 파일 Method 옵션\n[pg_hba.conf] 설정 파일의 Method 옵션 리스트는 아래와 같습니다.\n\n\n  \n    trust: 무조건 접속을 허용합니다. 이 방법을 사용하면 PostgreSQL 데이터베이스 서버에 연결할 수 있는 모든 사람이 암호나 다른 인증 없이 원하는 PostgreSQL 사용자로 로그인할 수 있습니다.\n  \n  \n    reject: 무조건 연결을 거부합니다. 이것은 그룹에서 특정 호스트 를 “ 필터링 “reject 하는 데 유용합니다. 예를 들어 한 라인은 특정 호스트의 연결을 차단할 수 있고 나중 라인은 특정 네트워크의 나머지 호스트가 연결할 수 있도록 합니다.\n  \n  \n    scram-sha-256: SCRAM-SHA-256 인증을 수행해 사용자의 암호를 확인합니다.\n  \n  \n    md5: SCRAM-SHA-256 또는 MD5 인증을 수행해 사용자의 암호를 확인합니다.\n  \n  \n    password: 클라이언트가 인증을 위해 암호화되지 않은 암호를 제공하도록 요구합니다. 암호는 네트워크를 통해 일반 텍스트로 전송되기 때문에 신뢰할 수 없는 네트워크에서는 사용해서는 안 됩니다.\n  \n  \n    gss: GSSAPI를 사용해 사용자를 인증합니다. 이것은 TCP/IP 연결에만 사용할 수 있습니다. GSSAPI 암호화와 함께 사용할 수 있습니다.\n  \n  \n    sspi: SSPI를 사용해 사용자를 인증합니다. 이것은 Windows에서만 사용할 수 있습니다.\n  \n  \n    ident: 클라이언트의 ident 서버에 연결하여 클라이언트의 운영 체제 사용자 이름을 얻고 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. ID 인증은 TCP/IP 연결에서만 사용할 수 있습니다. 로컬 연결에 대해 지정된 경우 피어 인증이 대신 사용됩니다.\n  \n  \n    peer: 운영 체제에서 클라이언트의 운영 체제 사용자 이름을 가져와서 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. 이것은 로컬 연결에만 사용할 수 있습니다.\n  \n  \n    lda: LDAP 서버를 사용해 인증 합니다.\n  \n  \n    radius: RADIUS 서버를 사용해 인증합니다.\n  \n  \n    cert: SSL 클라이언트 인증서를 사용해 인증합니다.\n  \n  \n    pam: 운영 체제에서 제공하는 PAM(Pluggable Authentication Modules) 서비스를 사용해 인증합니다.\n  \n  \n    bsd: 운영 체제에서 제공하는 BSD 인증 서비스를 사용해 인증합니다.\n  \n\n\n참고 URL\n\n  PostgreSQL OS별 다운로드 안내\n    \n      https://www.postgresql.org/download/linux/\n    \n  \n  PostgreSQL pg_hba.conf 파일 옵션 안내\n    \n      https://www.postgresql.org/docs/current/auth-pg-hba-conf.html"
					}
					
				
			
		
			
				
					,
					
					"dev-tools-ncloud-dev-tools-jenkins-server-install-guide-centos-html": {
						"id": "dev-tools-ncloud-dev-tools-jenkins-server-install-guide-centos-html",
						"title": "Jenkins 서버 설치 가이드 | CentOS",
						"categories": "",
						"url": " /dev-tools/ncloud-dev-tools-jenkins-server-install-guide-centos.html",
						"content": "개요\nNcloud (네이버 클라우드)의 Classic 환경에서는 Jekins 서버 이미지를 제공하고 있지만, VPC 환경에서는 제공하지 않기에 VPC 환경 CentOS 서버에 Jekins 서버를 설치하는 과정을 정리해보겠습니다.\n\nJenkins란\nJenkins는 지속적 통합(Continuous Integration, CI)과 지속적 배포(Continuous Delivery, CD)를 위한 대표적인 도구로 빌드, 테스트, 배포 프로세스를 자동화하여 소프트웨어 품질 향상과 개발 생산성 향상에 도움을 주는 도구입니다.\n\nJenkins 특징\n\n\n  지속적 통합을 사용하여 빌드, 테스트, 배포 과정을 자동화하여 개발 생산성을 향상할 수 있습니다.\n  자동화 테스트를 통하여 소프트웨어 품질을 향상할 수 있습니다.\n  지속적인 통합을 통해 안정적인 릴리즈를 빠르게 배포할 수 있습니다.\n\n\n설치 과정\n\n루트 인증서 설치\nJenkins의 저장소 추가시 인증서 에러가 발생할 경우를 대비해 루트 인증서를 설치 합니다.\n\n~# yum -y install ca-certificates\n\n\n\n  \n  \n    \n  \n\n\n패키지 저장소 추가\n이제 Jenkins의 패키지 저장소를 추가합니다.\n\n~# wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo\n\n\n\n  \n  \n    \n  \n\n\nGPG 키 추카\n그런 다음 Jenkins GPG 키를 다음과 같이 추가 합니다.\n\n~# rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key\n\n\n\n  \n  \n    \n  \n\n\nJAVA 설치\nJenkins를 구동하기 위해서는 JAVA가 필요하고, 추가로 fontconfig도 설치합니다.\n\n※ JAVA의 경우 Jenkins최신버전을 기준으로 8 혹은 11 버전이 필요 합니다.\n\n~# yum -y install fontconfig java-11-openjdk\n\n\n  \n  \n    \n  \n\n\nJenkins 설치\n모든 준비가 끝났으면 Jenkins를 설치합니다.\n\n~# yum -y install jenkins\n\n\n\n  \n  \n    \n  \n\n\nJenkins 서비스 시작\nJekins 서비스를 시작하고 정상 작동을하고 있는지 다음과 같이 확인합니다.\n\n~# systemctl start jenkins\n~# systemctl status jenkins\n\n\n\n  \n  \n    \n  \n\n\n방화벽 ACG 설정\nJekins 서버가 사용하는 기본 포트는 8080 입니다. Ncloud 방화벽 ACG에서 8080 포트를 허용해줍니다.\n\n\n  \n  \n    \n  \n\n\n초기 설정\n\nPort 변경\n\nJenkins의 기본 접속 Port는 8080인데 /etc/sysconfig/jenkins 의 JENKINS_PORT= 항목에서 변경 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n초기 패스워드 확인\n\n설치가 완료 되면 http://{서버 IP주소}:8080 으로 접속하면 아래의 스크린샷처럼 초기 어드민 패스워드를 입력하는 화면이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n초기 어드민 패스워드는 /var/lib/jenkins/secrets/initialAdminPassword 파일에 기록되어 있습니다.\ncat 명령어로 초기 패스워드를 확인합니다.\n\n~# cat /var/lib/jenkins/secrets/initialAdminPassword\n\n\n\n  \n  \n    \n  \n\n\n플러그인 설치\n플러그인 설치는 추천 플러그인을 설치하는 옵션과 직접 선택해서 설치하는 옵션이 있습니다. 일단 여기서는 추천 플러그인을 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n추천 플러그인을 선택하면 아래와 같이 설치과정이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n직접 플러그인을 선택할 경우 아래와 같이 여러 플러그인 중에서 설치하고 싶은 플러그인을 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n어드민 계정 정보 입력\n플러그인 설치를 마치면 아래와 같이 어드민 계정 정보를 입력하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n설치 완료\n필요한 정보를 모두 입력하고 나면 마지막으로 Jekins URL을 확정하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n설치가 모두 끝났습니다.\n\n\n  \n  \n    \n  \n\n\n이제 Jekins에 접속하면 아래와 같은 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Jeins Redhat Packages\n    \n      https://pkg.jenkins.io/redhat-stable/\n    \n  \n  Jenkins User Documentation\n    \n      https://www.jenkins.io/doc/"
					}
					
				
			
		
			
				
					,
					
					"dev-tools-ncloud-dev-tools-jenkins-server-install-guide-rocky-linux-html": {
						"id": "dev-tools-ncloud-dev-tools-jenkins-server-install-guide-rocky-linux-html",
						"title": "Jenkins 서버 설치 가이드 | Rocky Linux",
						"categories": "",
						"url": " /dev-tools/ncloud-dev-tools-jenkins-server-install-guide-rocky-linux.html",
						"content": "개요\nNcloud (네이버 클라우드)의 Classic 환경에서는 Jekins 서버 이미지를 제공하고 있지만, VPC 환경에서는 제공하지 않기에 VPC 환경 록키 리눅스(Rocky Linux) 서버에 Jekins 서버를 설치하는 과정을 정리해보겠습니다.\n\nJenkins란\nJenkins는 지속적 통합(Continuous Integration, CI)과 지속적 배포(Continuous Delivery, CD)를 위한 대표적인 도구로 빌드, 테스트, 배포 프로세스를 자동화하여 소프트웨어 품질 향상과 개발 생산성 향상에 도움을 주는 도구입니다.\n\nJenkins 특징\n\n\n  지속적 통합을 사용하여 빌드, 테스트, 배포 과정을 자동화하여 개발 생산성을 향상할 수 있습니다.\n  자동화 테스트를 통하여 소프트웨어 품질을 향상할 수 있습니다.\n  지속적인 통합을 통해 안정적인 릴리즈를 빠르게 배포할 수 있습니다.\n\n\n설치 과정\n\n패키지 저장소 추가\n먼저 Jenkins의 패키지 저장소를 추가합니다.\n\n~# wget -O /etc/yum.repos.d/jenkins.repo \\\n    https://pkg.jenkins.io/redhat-stable/jenkins.repo\n\n\n\n  \n  \n    \n  \n\n\nGPG 키 추카\n그런 다음 Jenkins GPG 키를 다음과 같이 추가 합니다.\n\n~# rpm --import \\\n    https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\n\n\n\n  \n  \n    \n  \n\n\n패키지 업데이트\n그리고, 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 진행합니다.\n\n~# dnf -y upgrade-minimal\n\n\n\n  \n  \n    \n  \n\n\nJAVA 설치\nJenkins를 구동하기 위해서 필요한 JAVA 11 버전을 설치합니다.\n\n~# dnf -y install java-11-openjdk\n\n\n  \n  \n    \n  \n\n\nJAVA 버전 선택\n현재 시스템에 설치된 JAVA는 기본 설치 버전인 [java-1.8.0]과 좀 전에 설치한 [java-11] 이렇게 2가지인데, Jenkins는 [java-11] 버전을 사용하므로 다음 명령어로 [java-11] 버전이 기본으로 적용되도록 설정을 변경하겠습니다.\n명령어 입력 후 나타난 선택화면에서 [java-11] 버전에 해당하는 2번을 입력합니다. 그리고, 변경이 제대로 되었는지 java 버전을 확인합니다.\n\n~# update-alternatives --config java\n~# java -version\n\n\n\n  \n  \n    \n  \n\n\nJenkins 설치\n모든 준비가 끝났으면 Jenkins를 설치합니다.\n\n~# dnf -y install jenkins\n\n\n\n  \n  \n    \n  \n\n\nJenkins 서비스 시작\nJekins 서비스를 시작하고 정상 작동을하고 있는지 다음과 같이 확인합니다.\n\n~# systemctl daemon-reload\n~# systemctl enable jenkins\n~# systemctl start jenkins\n~# systemctl status jenkins\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n방화벽 ACG 설정\nJekins 서버가 사용하는 기본 포트는 8080 입니다. Ncloud 방화벽 ACG에서 8080 포트를 허용해줍니다.\n\n\n  \n  \n    \n  \n\n\n초기 설정\n\nPort 변경\nJenkins의 기본 접속 Port는 8080인데 /etc/sysconfig/jenkins 의 JENKINS_PORT= 항목에서 변경 할 수 있습니다.\n\n~# vi /etc/sysconfig/jenkins\n\n\n\n  \n  \n    \n  \n\n\n초기 패스워드 확인\n\n설치가 완료 되면 http://{서버 IP주소}:8080 으로 접속하면 아래의 스크린샷처럼 초기 어드민 패스워드를 입력하는 화면이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n초기 어드민 패스워드는 /var/lib/jenkins/secrets/initialAdminPassword 파일에 기록되어 있습니다.\ncat 명령어로 초기 패스워드를 확인합니다.\n\n~# cat /var/lib/jenkins/secrets/initialAdminPassword\n\n\n\n  \n  \n    \n  \n\n\n플러그인 설치\n플러그인 설치는 추천 플러그인을 설치하는 옵션과 직접 선택해서 설치하는 옵션이 있습니다. 일단 여기서는 추천 플러그인을 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n추천 플러그인을 선택하면 아래와 같이 설치과정이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n직접 플러그인을 선택할 경우 아래와 같이 여러 플러그인 중에서 설치하고 싶은 플러그인을 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n어드민 계정 정보 입력\n플러그인 설치를 마치면 아래와 같이 어드민 계정 정보를 입력하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n설치 완료\n필요한 정보를 모두 입력하고 나면 마지막으로 Jekins URL을 확정하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n설치가 모두 끝났습니다.\n\n\n  \n  \n    \n  \n\n\n이제 Jekins에 접속하면 아래와 같은 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상황\n위 순서대로 설치를 진행했다면 문제 없이 설치가 되겠지만, 혹시나 설치 중에 중요한 과정을 빠뜨렸을 경우 아래아 같이 [Jenkins]를 시작하려고 할 때 오류가 발생하게 됩니다.\n\n~# systemctl start jenkins\n\nJob for jenkins.service failed because the control process exited with error code.\nSee \"systemctl status jenkins.service\" and \"journalctl -xe\" for details.\n\n\n  \n  \n    \n  \n\n\n오류 원인 분석\n위 오류 메시지에서 2가지 방법으로 상세한 오류 내용을 확인해보겠습니다.\n\n\n  우선 첫번째 명령 [systemctl status jenkins.service]으로 확인을 해보았으나 별다른 내용은 나오지 않습니다.\n\n\n~# systemctl status jenkins.service\n\n● jenkins.service - Jenkins Continuous Integration Server\n   Loaded: loaded (/usr/lib/systemd/system/jenkins.service; enabled; vendor preset: disabled)\n   Active: failed (Result: exit-code) since Fri 2023-06-30 17:08:01 KST; 1min 25s ago\n  Process: 6494 ExecStart=/usr/bin/jenkins (code=exited, status=1/FAILURE)\n Main PID: 6494 (code=exited, status=1/FAILURE)\n\nJun 30 17:08:01 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\nJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Service RestartSec=100ms expired, scheduling restart\nJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Scheduled restart job, restart counter is at 5.\nJun 30 17:08:01 jenkins-test systemd[1]: Stopped Jenkins Continuous Integration Server.\nJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Start request repeated too quickly.\nJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Failed with result 'exit-code'.\nJun 30 17:08:01 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\nJun 30 17:08:03 jenkins-test systemd[1]: jenkins.service: Start request repeated too quickly.\nJun 30 17:08:03 jenkins-test systemd[1]: jenkins.service: Failed with result 'exit-code'.\nJun 30 17:08:03 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\n\n\n  \n  \n    \n  \n\n\n\n  다음으로 [journalctl -xe] 명령을 입력해보니 상당히 긴 로그가 나오는데, 차근차근 살펴보다 보니 원인을 찾을 수 있었는데, 그 부분만 발췌해보면 아래와 같습니다.\n\n\n~# journalctl -xe\n\n#------------- 중간 생략 --------------#\n-- Unit jenkins.service has begun starting up.\nJun 30 17:37:41 jenkins-test jenkins[7588]: jenkins: invalid Java version: openjdk version \"1.8.0_352\"\nJun 30 17:37:41 jenkins-test jenkins[7588]: OpenJDK Runtime Environment (build 1.8.0_352-b08)\nJun 30 17:37:41 jenkins-test jenkins[7588]: OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\nJun 30 17:37:41 jenkins-test systemd[1]: jenkins.service: Main process exited, code=exited, status=1/FAILURE\nJun 30 17:37:41 jenkins-test systemd[1]: jenkins.service: Failed with result 'exit-code'.\n-- Subject: Unit failed\n-- Defined-By: systemd\n-- Support: https://lists.freedesktop.org/mailman/listinfo/systemd-devel\n--\n-- The unit jenkins.service has entered the 'failed' state with result 'exit-code'.\nJun 30 17:37:41 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\n-- Subject: Unit jenkins.service has failed\n-- Defined-By: systemd\n-- Support: https://lists.freedesktop.org/mailman/listinfo/systemd-devel\n--\n-- Unit jenkins.service has failed.\n--\n-- The result is failed.\n#------------- 중간 생략 --------------#\n\n\n\n오류 로그 중에서 핵심이 되는 부분은 바로 이 문장입니다. \njenkins: invalid Java version: openjdk version '1.8.0_352'\n\n\n\n  \n  \n    \n  \n\n\n오류 해결\n즉, 오류 원인은 JAVA 버전이었습니다. 현재의 Jenkins는 [java-11] 버전을 사용하는데, [java-11]을 설치하지 않았거나 현재 시스템에 JAVA가 [java-11] 뿐만 아니라 [java-1.8.0] 버전도 함께 설치되어 있는데, [java-1.8.0] 버전이 기본 버전으로 설정된 상태여서 생기는 문제입니다.\n\n위쪽 설치 단계에서 확인했던 아래 명령으로 JAVA 기본 버전을 [java-11]로 변경해주고 Jenkins를 시작하면 문제가 없습니다.\n\n\n  JAVA 기본 버전 변경하기 \n\n\n~# update-alternatives --config java\n~# java -version\n\n\n참고 URL\n\n  Jeins Redhat Packages\n    \n      https://pkg.jenkins.io/redhat-stable/\n    \n  \n  Jenkins User Documentation\n    \n      https://www.jenkins.io/doc/"
					}
					
				
			
		
			
				
					,
					
					"dev-tools-ncloud-dev-tools-jenkins-server-install-guide-ubuntu-html": {
						"id": "dev-tools-ncloud-dev-tools-jenkins-server-install-guide-ubuntu-html",
						"title": "Jenkins 서버 설치 가이드 | Ubuntu",
						"categories": "",
						"url": " /dev-tools/ncloud-dev-tools-jenkins-server-install-guide-ubuntu.html",
						"content": "개요\nNcloud (네이버 클라우드)의 Classic 환경에서는 Jekins 서버 이미지를 제공하고 있지만, VPC 환경에서는 제공하지 않기에 VPC 환경 Ubuntu 서버에 Jekins 서버를 설치하는 과정을 정리해보겠습니다.\n\nJenkins란\nJenkins는 지속적 통합(Continuous Integration, CI)과 지속적 배포(Continuous Delivery, CD)를 위한 대표적인 도구로 빌드, 테스트, 배포 프로세스를 자동화하여 소프트웨어 품질 향상과 개발 생산성 향상에 도움을 주는 도구입니다.\n\nJenkins 특징\n\n\n  지속적 통합을 사용하여 빌드, 테스트, 배포 과정을 자동화하여 개발 생산성을 향상할 수 있습니다.\n  자동화 테스트를 통하여 소프트웨어 품질을 향상할 수 있습니다.\n  지속적인 통합을 통해 안정적인 릴리즈를 빠르게 배포할 수 있습니다.\n\n\n설치 과정\n\n루트 인증서 설치\nJenkins의 저장소 추가시 인증서 에러가 발생할 경우를 대비해 루트 인증서를 설치 합니다.\n\n~# apt-get -y install ca-certificates\n\n\n\n  \n  \n    \n  \n\n\n저장소 키 추가\n이제 Jenkins의 패키지 저장소를 추가 하기 위한 저장소 키를 가져옵니다.\n\ncurl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io.key \\\n    | sudo tee /usr/share/keyrings/jenkins-keyring.asc &gt; /dev/null\n\n\n\n  \n  \n    \n  \n\n\n저장소 추가\n그런다음 Jenkins의 패키지 저장소 항목을 추가 합니다.\n\necho deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \\\n    https://pkg.jenkins.io/debian-stable binary/ | sudo tee \\\n    /etc/apt/sources.list.d/jenkins.list &gt; /dev/null\n\n\n\n  \n  \n    \n  \n\n\nJAVA 설치\nJenkins를 구동하기 위해서는 JAVA가 필요하고, 추가로 fontconfig도 설치합니다.\n\n※ JAVA의 경우 Jenkins최신버전을 기준으로 8 혹은 11 버전이 필요 합니다.\n\n~# apt-get update\n~# apt-get -y install fontconfig openjdk-11-jre\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nJenkins 설치\n모든 준비가 끝났으면 Jenkins를 설치합니다.\n\n~# apt-get -y install jenkins\n\n\n\n  \n  \n    \n  \n\n\nJenkins 서비스 시작\nJekins 서비스를 시작하고 정상 작동하고 있는지 다음과 같이 확인합니다.\n\n~# systemctl start jenkins\n~# systemctl status jenkins\n\n\n\n  \n  \n    \n  \n\n\n방화벽 ACG 설정\nJekins 서버가 사용하는 기본 포트는 8080 입니다. Ncloud 방화벽 ACG에서 8080 포트를 허용해줍니다.\n\n\n  \n  \n    \n  \n\n\n초기 설정\n\nPort 변경\n\nJenkins의 기본 접속 Port는 /etc/default/jenkins 의 HTTP_PORT= 항목에서 변경 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n초기 패스워드 확인\n\n설치가 완료된 후 http://{서버 IP주소}:8080 으로 접속하면 아래의 스크린샷처럼 초기 어드민 패스워드를 입력하는 화면이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n초기 어드민 패스워드는 /var/lib/jenkins/secrets/initialAdminPassword 파일에 기록되어 있습니다.\ncat 명령어로 초기 패스워드를 확인합니다.\n\n~# cat /var/lib/jenkins/secrets/initialAdminPassword\n\n\n\n  \n  \n    \n  \n\n\n플러그인 설치\n플러그인 설치는 추천 플러그인을 설치하는 옵션과 직접 선택해서 설치하는 옵션이 있습니다. 일단 여기서는 추천 플러그인을 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n추천 플러그인을 선택하면 아래와 같이 설치과정이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n직접 플러그인을 선택할 경우 아래와 같이 여러 플러그인 중에서 설치하고 싶은 플러그인을 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n어드민 계정 정보 입력\n플러그인 설치를 마치면 아래와 같이 어드민 계정 정보를 입력하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n설치 완료\n필요한 정보를 모두 입력하고 나면 마지막으로 Jekins URL을 확정하고 저장합니다.\n\n\n  \n  \n    \n  \n\n\n설치가 모두 끝났습니다.\n\n\n  \n  \n    \n  \n\n\n이제 Jekins에 접속하면 아래와 같은 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Jeins Debian Packages\n    \n      https://pkg.jenkins.io/debian-stable/\n    \n  \n  Jenkins User Documentation\n    \n      https://www.jenkins.io/doc/"
					}
					
				
			
		
			
				
					,
					
					"dev-tools-ncloud-dev-tools-source-commit-external-repository-copy-html": {
						"id": "dev-tools-ncloud-dev-tools-source-commit-external-repository-copy-html",
						"title": "SourceCommit에서 GitHub Repository 복사해오기 | Ncloud",
						"categories": "",
						"url": " /dev-tools/ncloud-dev-tools-source-commit-external-repository-copy.html",
						"content": "개요\nNcloud SourceCommit에서 GitHub Repository를 복사해서 가져오기 위해서는 [외부 리포지토리 복사] 기능을 이용해야 하는데, Public Repository는 간단하게 가져올 수 있지만, Private Repository는 GitHub에서 생성한 별도의 Personal access token을 사용해야 가져올 수 있어서 그 내용을 정리해보겠습니다.\n\n외부 리포지토리 복사\nSourceCommit에서 [외부 리포지토리 복사] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nPublic Repository\n퍼블릭 리포지토리는 아래와 같이 [복사할 Git URL] 정보를 입력한 후에 [Git 연결 확인] 버튼을 클릭해서 올바른 리포지토리인지 확인 후 [다음] 버튼을 클릭해 이후 과정을 진행하면 완료됩니다.\n\n\n  \n  \n    \n  \n\n\nPrivate Repository\n프라이빗 리포지토리는 [프라이빗 리포지토리 여부] 옵션을 켜고 [ID]와 [Password]를 입력해야 복사해 올 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nPassword 오류\n깃허브 계정과 패스워드를 입력하고 [Git 연결 확인] 버튼을 클릭해 보면 ID 또는 Password가 올바르지 않다는 메시지가 나타납니다.\n올바르게 입력했음에도 이런 오류가 발생하는 것은 2021년 8월부터 외부에서 깃허브에 연결하려고 할 때 계정 패스워드를 사용하지 않고 토큰을 사용하는 방식으로 바뀌었기 때문입니다.\n\n깃허브 공지 내용을 보면 다음과 같습니다.\n\nFrom GitHub Blog “In July 2020, we announced our intent to require the use of token-based authentication (for example, a personal access, OAuth, or GitHub App installation token) for all authenticated Git operations. Beginning August 13, 2021, we will no longer accept account passwords when authenticating Git operations on GitHub.com.”\n\n\n  \n  \n    \n  \n\n\nPersonal Access Token 생성\n그러면 이제 Personal access token을 생성해보겠습니다.\n깃허브 사이트에 접속해서 [계정] - [Settings]를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[Settings] 화면 아래쪽에 [Developer settings] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[Developer settings] 화면에서 [Personal access tokens] 메뉴를 클릭하고, [Generate new token] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nToken 생성\n우선 Personal access token 생성 화면에서 토큰 이름을 입력하고, 만료기간을 설정합니다.\n그리고, 토큰으로 이용 가능한 기능의 범위 즉, 권한 설정을 해야 하는데 단순히 리포지토리를 복사하는 용도라면 [repo] 그룹 항목만 체크하셔도 됩니다.\n설정을 마친 후에 아래쪽에 있는 [Generate token] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nToken 복사\n생성된 Personal access toke을 복사합니다.\n\n 주의: 생성된 Token은 바로 복사해 두셔야 합니다. 이 화면을 벗어나면 두번 다시 토큰 문자열을 확인할 수 없습니다.Make sure to copy your personal access token now. You won’t be able to see it again!\n\n\n  \n  \n    \n  \n\n\nPersonal Access Token 입력\n[Password] 항목에 Personal Access Token을 입력하고, [Git 연결 확인] 버튼을 클릭하면 문제없이 연결되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n보안상품 연동\n리포지토리에 악성코드 필터링 보안 시스템인 [File Safer]를 연동하고 싶은 경우 [File Safer 이용 신청] 링크를 클릭해 먼저 이용신청을 하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n입력한 정보들이 이상이 없는지 최종 확인을 하고 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nRepository 확인\n생성된 리포지토리를 이렇게 확인할 수 있고, 리포지토리 이름을 클릭하면 리포지토리 내용을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n아래와 같이 깃허브에서 복사된 내용을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nPersonal Access Token 분실\nPersonal Access Token이 기억나지 않거나 분실했을 경우에는 다음과 같은 방법으로 재생성 하시면 됩니다.\n[Settings] - [Developer settings] - [Personal access token] 메뉴에서 토큰 이름을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n토큰 수정 메뉴에서 [Regenerate token] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n혹시 만료 기간을 수정려면 수정한 후에 [Regenerate token] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n재 생성된 [Personal access token]을 복사합니다. 마찬가지로 이 화면을 벗어나면 두번 다시 확인할 수 없으니 꼭 복사해서 별도로 저장합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud SourceCommit 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/devtools-devtools-2-1"
					}
					
				
			
		
			
				
					,
					
					"dev-tools-ncloud-dev-tools-source-commit-git-client-clone-guide-html": {
						"id": "dev-tools-ncloud-dev-tools-source-commit-git-client-clone-guide-html",
						"title": "SourceCommit 리포지토리 Git 클라이언트로 로컬PC에 복제하기 | Ncloud",
						"categories": "",
						"url": " /dev-tools/ncloud-dev-tools-source-commit-git-client-clone-guide.html",
						"content": "개요\nNcloud (네이버 클라우드) SourceCommit 리포지토리를 로컬 PC에서 Git 클라이언트를 이용해 복제(Clone)하는 방법을 정리해보겠습니다. \n이때 Git 클라이언트로 접속하는 방법에는 HTTPS와 SSH 2가지 방식이 있는데 여기서는 HTTPS로 접속하는 방법을 사용하겠습니다.\n\nSub Account 생성\nGit 클라이언트로 SourceCommit 리포지토리에 접속하기 위해서는 서브 어카운트를 생성해야 합니다.\nSub Account가 아닌 메인 계정으로 Git 클라이언트 접속에 필요한 계정을 설정하려고 하면 아래와 같은 경고 메시지가 나타납니다.\n\n\n  \n  \n    \n  \n\n\n\nSub Account로 로그인 후 Git 계정을 설정하세요.\n\n고객 계정은 Git 계정을 설정할 수 없습니다. \nGit Client를 사용하여 소스코드 다운로드 및 수정을 하기 위해서는 \nSub Account로 로그인 후 Git 계정 설정을 하셔야 합니다.\n\n\nSub Account 생성 가이드\nSub Account 생성방법은 아래 문서에서 확인할 수 있습니다.\n\n\n  Sub Account 생성 가이드: https://docs.3rdeyesys.com/management/ncloud_management_sub_account_guide.html\n\n\nSub Account 권한 설정\nSub Account를 생성했으면 정책 권한을 부여해야 합니다.\n생성한 Sub Account에 SourceCommit 접속 권한을 부여하려면 여러 가지 정책 권한이 있지만 일반적으로 [NCP_SOURCECOMMIT_MANAGER] 정책을 부여하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nSub Account 로그인\nSub Account를 생성하고 정책 권한을 부여했으면 해당 Sub Account로 로그인합니다.\n\n\n  \n  \n    \n  \n\n\n리포지토리 생성\nSub Account로 로그인 후에 콘솔에 접속한 후 [SourceCommit]에서 [리포지토리 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n기본 설정\n리포지토리 이름과 설명을 입력하고 초기화 설정을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n보안상품 연동\n리포지토리와 악성코드  필터링 시스템인 File Safer 상품을 연동하면 보다 안전하게 리포지토리를 사용할 수 있습니다.\nFile Safer 상품은 별도로 상품 신청을 해야 하는데, 필요할 경우에는 링크를 클릭해 File Safer 이용 신청을 하시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n입력한 정보들에 수정할 부분이 없는지 최종 확인을 한 후에 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nGit 계정 설정\n리포지토리가 생성되었으면 [Git 계정/Git SSH 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n계정 패스워드 입력\nGit 클라이언트에서 사용할 계정 즉 User Name은 Sub Account로 자동 설정 되므로 여기서는 패스워드만 입력합니다.\n\n  \n  \n    \n  \n\n\n\n여기서 설정한 비밀번호는 Git Client를 통한 리포지토리 접근 시 사용되며, \n해당 비밀번호를 사용하여 포털, 콘솔 등 웹을 통한 로그인은 불가능합니다. \n\n비밀번호 규칙은 영문, 숫자, 특수문자 !@#$%^&amp;*+=-_~`() 가 포함된 8~16 길이입니다.\n\n\n리포지토리 Clone URL 확인\n리포지토리 Clone URL은 리포지토리를 선택하고 [코드로 이동] 버튼을 클릭해서 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n상단에 있는 [CLONE URL] 메뉴를 클릭하면 HTTPS와 SSH 두가지 용도의 URL을 확인할 수 있는데 여기서는 HTTPS URL을 복사합니다.\n\n\n  \n  \n    \n  \n\n\nGit 클라이언트 다운로드\nSourceCommit 리포지토리에 접속하기 위한 윈도우용 클라이언트는 아래 경로에서 다운 받을 수 있습니다.\n\n\n  Git for Windows downloads: https://git-scm.com/download/win\n\n\n\n  \n  \n    \n  \n\n\n디렉토리 생성\n설치한 Git 클라이언트에서 [Git Bash]를 실행해 리포지토리를 복제할 디렉토리를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n리포지토리 복제\n위에서 복사한 HTTS용 리포지토리 URL를 입력하여 복제를 시도하면 아래와 같이 패스워드 입력 창이 나타납니다. \n리포지토리 URL을 아래 명령어에 입력할 때는 [https://]와 [도메인(devtools.ncloud.com)] 사이에 [Git계정@]를 입력하면 편하게 패스워드만 입력하면 됩니다.\n\n# git clone 예시\n$ git clone https://{Git 계정}@devtools.ncloud.com/123456789/source-commit-test.git\n\n\n  \n  \n    \n  \n\n\n복제 완료\n패스워드를 입력하고 나면 아래와 같이 리포지토리가 복제됩니다.\n\n\n  \n  \n    \n  \n\n\nGitHub Desktop 사용\n평소에 깃허브를 이용하고 있는 경우에는 GitHub Desktop을 사용해도 됩니다. \n아래와 같이 [Clone a repository] 메뉴를 선택하고 URL 탭에서 리포지토리 URL를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nGitHub Desktop에서는 아래와 같이 Username과 Password를 모두 입력해야 합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud SourceCommit 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/sourcecommit-overview\n    \n  \n  Ncloud SourceCommit Git Client 가이드\n    \n      https://guide.ncloud-docs.com/docs/sourcecommit-use-client"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-cloud-insight-rule-template-guide-html": {
						"id": "management-ncloud-management-cloud-insight-rule-template-guide-html",
						"title": "모니터링 서비스 Cloud Insight Rule Template 설정 가이드",
						"categories": "",
						"url": " /management/ncloud-management-cloud-insight-rule-template-guide.html",
						"content": "개요\nCloud Insight를 설정할 때 매번 서버마다 일일이 설정하는 방법도 있지만 [CPU-메모리-디스크 사용률] 같은 자주 모니터링하는 항목들을 [Template]에 등록해 두면 모니터링을 설정할 때 좀 더 쉽고 정확하게 설정할 수 있는데, 그 방법을 정리해보겠습니다.\n\nCloud Insight 기본 설정 방법\nCloud Insight의 기본적인 설정 방법은 아래 링크 문서에서 확인 가능합니다.\n\n\n⁃ 모니터링 서비스 Cloud Insight 설정 가이드\n\n\nTemplate 설정 항목\nTemplate 설정할 때 서비스 상황에 따라 여러가지를 설정할 수 있는데, 여기서 예시로 설정해 볼 항목은 다음과 같습니다.\n\n  서버 평균 CPU 사용률\n  서버 메모리 사용률\n  서버 디스크 사용률\n\n\nRule Template 설정\n먼저 [Cloud Insight] - [Configuration] - [Template]에서 [Rule Template] 탭을 선택하고, [Rule Template 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nCPU 사용률\n[서버 평균 CPU 사용률]은  [SERVER] 탭에서 [SEVER/avg_cpu_used_rto] 항목을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n메모리 사용률\n[서버 평균 메모리 사용률]은 [Memory] 탭에서 [MEMORY/mem_usert] 항목을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n디스크별 사용 중인 용량\n[디스크별 사용 중인 용량]은  [FILE STSTEM] 탭에서 [FILE STSTEM/fs_usert] 항목을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n- [사용 중인 디스크가 2개 이상인 경우] \n서버를 생성할 때 자동으로 추가되는 OS용 기본 디스크 말고 별도로 디스크를 추가했을 경우에는 기본 / 영역외에 추가 디스크가 마운트된 영역에 대해서도 항목을 추가해야 합니다.\n\n추가 디스크를 /data 디렉토리로 마운트했다고 가정했을 경우 아래 스샷처럼 [FILE STSTEM/fs_usert] 항목 오른쪽에 있는 [+] 버튼을 클릭해서 동일한 \n항목을 하나 더 추가하고, 디멘션에서 [mnt_nm: /data]를 선택합니다. 다른 곳으로 마운트했을 경우에는 그에 맞는 값을 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  3가지 항목을 모두 선택하고, [다음] 버튼을 클릭하면 아래와 같이 각 항목별로 조건을 설정할 수 있습니다.\n여기서는 각 수치가 70% 이상일 경우로 설정했고, 몇 분간의 평균값으로 할 것인가는 사용하는 서비스 상황에 따라 조절하시면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nEvent Rule 설정\n다음으로 [Cloud Insight] - [Configuration] - [Event Rule]에서 [Event Rule 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n감시 상품 선택\nNcloud Cloud Insight에서 모니터링 할 수 있는 상품은 아래와 같은데 그 중에서 여기서는 VPC Server를 선택하겠습니다.\n\n  Classic Load Balancer Monitor\n  Classic Server\n  VPC Load Balancer Monitor\n  VPC Server\n  Object Storage\n\n\n\n  \n  \n    \n  \n\n\n감시 대상 설정\n감시 대상은 미리 설정한 그룹이나 Auto Scaling Group에서 선택할 수도 있는데, 여기서는 [전체 보기]를 선택해서 미리 만들어둔 테스트용 서버를 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n감시 항목 설정\n여기가 이 가이드 문서의 가장 중요한 단계인데, 위에서 설정했던 [Template]인 [template-test]를 감시 항목으로 선택해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n액션 설정\n액션 설정에서 [통보 대상자], [알림 유형], [리마인드 알림 주기], [종료 알림 여부]를 설정합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n지금까지 설정한 내역을 최종 확인한 후에 이상이 없으면 [생성] 버튼을 클릭해서 Event Rule 생성을 완료합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n기타\n\nTarget Group 생성\n위에서는 [Rule Template]만 사용했는데, 여러 대상을 미리 하나의 그룹으로 묶어서 관리할 수도 있습니다.\n[Cloud Insight] - [Configuration] - [Template]에서 [Target Group] 탭을 선택하고, [Target Group 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  그룹 생성화면에서 원하는 [Product Type]을 선택하고, 선택 가능한 감시 대상 중에서 Group으로 묶을 대상을 선택하고 아래 쪽으로 이동 시킨 후에 [생성] 버튼을 클릭하면 됩니다. 이후에 [Event Rule] 생성할 때 [감시 대상 설정] 단계에서 여기서 설정한 Group을 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Cloud Insight 소개\n    \n      https://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightoverview\n    \n  \n  Cloud Insight 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightconsole\n    \n  \n  Cloud Insight 기본 설정 가이드\n    \n      https://docs.3rdeyesys.com/management/ncloud_management_cloud_insight_guide.html"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-cloud-log-analytics-guide-html": {
						"id": "management-ncloud-management-cloud-log-analytics-guide-html",
						"title": "Cloud Log Analytics 설정 가이드",
						"categories": "",
						"url": " /management/ncloud-management-cloud-log-analytics-guide.html",
						"content": "개요\nCloud Log Analytics는 Ncloud(네이버 클라우드)가 제공하는 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석할 수 있는 서비스로, \n검색 기능을 이용해 여러 종류의 로그를 한 곳에서 한번에 조회하고 분석할 수 있어 효과적인 로그 관리가 가능합니다.\n\n로그 템플릿 종류\nCloud Log Analytics는 텍스트 형식으로 생성되는 모든 종류의 로그 데이터 파일을 수집할 수 있는데, 사전에 제공되는 로그 템플릿 종류는 다음과 같습니다.\n\n\n  Server SYSLOG\n  Apache 로그(Access log, Apache Error Log)\n  MySQL 설치형 상품의 로그(Error Log, Slow Log)\n  Microsoft SQL Server 설치형 상품의 Error Log\n  Tomcat 로그(Catalina Log)\n  Windows 서버의 Event Log\n  Windows 서버의 각종 text 형식의 로그\n  Cloud DB for MySQL 로그\n  Cloud DB for MSSQL 로그\n  Cloud DB for MongoDB 로그\n  Cloud DB for PostgreSQL 로그\n  Application Server Launcher 로그\n  Application Load Balancer 로그\n  Search Engine Service 로그\n  Cloud Data Streaming Service 로그\n  Bare Metal Server 로그\n  Ncloud Kubernetes Service Audit 로그\n  그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다\n\n\n지원 운영 체제\n지원하는 운영 체제는 다음과 같습니다.\n\n\n  CentOS/RHEL 6\n  CentOS 7\n  CentOS 8\n  RHEL 8\n  RHEL 9\n  Ubuntu 16.04\n  Ubuntu 18.04\n  Ubuntu 20.04\n  Ubuntu 22.04\n  SLES 15\n  Debian 9\n  Debian 10\n  Debian 11\n  Windows Server 2012\n  Windows Server 2016\n  Windows Server 2019\n  Windows Server2022\n\n\n저장 용량\n\n  최대 100GB까지 저장할 수 있습니다.\n  100GB 용량을 초과했을 경우 추가 저장 용량 확보를 위해 과거부터 전날까지의 데이터가 삭제될 수 있습니다.\n  CLA로 수집되는 로그량이 하루 10GB 이상을 넘거나 천만 건 이상일 경우 저장된 로그 검색시 성능에 제한이 발생할 수 있습니다.\n  저장 용량과 저장 기간을 더 늘리길 원할 경우 고객지원으로 문의해야 합니다.\n  과거 데이터를 보관하려면 [자동 보내기] 기능을 이용하여 과거 데이터를 Object Storage로 백업할 수 있습니다.\n\n\n로그 보관 기간\n\n  Cloud Log Analytics 서비스는 최대 30일 동안 데이터가 보관되며, 검색 및 대시보드에서 확인할 수 있습니다.\n  30일이 지난 데이터는 과거 데이터부터 순차적으로 삭제됩니다.\n  30일이 지나지 않았더라도 저장된 데이터가 100GB를 초과하면 과거부터 전날까지의 데이터가 매일 삭제될 수 있습니다.\n\n\n이용신청\nNcloud(네이버 클라우드) 콘솔 [Cloud Log Analytics] - [Subscription]에서 [이용 신청] 버튼을 클릭합니다. \nCloud Log Analytics는 Classic, VPC 환경 공통 서비스이므로 어느쪽 환경에서 이용신청을 해도 상관없습니다.\n\n\n  \n  \n    \n  \n\n\n설정 - Linux\n먼저 Linux 서버에서 설정하는 방법을 알아보겠습니다.\n[Cloud Log Analytics] - [Management]에서 로그를 수집할 서버를 선택하고, [수집 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nLog 수집 설정 화면에서 수집할 로그 템플릿을 선택하거나, 직접 [Custom Log]를 선택해서 로그 형태를 설정한 후에 [적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 Agent 설치\nLog 수집 설정을 마치면 [로그 수집 Agent] 설치 안내가 나옵니다.\n로그 수집 Agent 설치 명령어에는 URL 뒤쪽에 설치 하려는 서버에 해당하는 설치키(Install Key)가 포함되어 있습니다. 그러므로 URL을 수정해서도 안되고 다른 서버에 사용할 수도 없습니다.\n\n# VPC 환경\n~# curl -s http://cm.vcla.ncloud.com/setUpClaVPC/{설치키(Install Key)} | sudo sh\n\n# Classic 환경\n~# curl -s http://cm.cla.ncloud.com/setUpCla/{설치키(Install Key)} | sudo sh\n\n\n\n  \n  \n    \n  \n\n\n서버에 실제로 설치해보면 아래와 같이 설치 과정이 진행되고,\n설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\n설치된 Agent가 제대로 작동하고 있는지 확인해보면 아래와 같이 active (running) 상태인 것을 확인할 수 있습니다.\n~# systemctl status filebeat\n\n\n  \n  \n    \n  \n\n\n설정 - Windows\n다음으로 Windows 서버에서 설정하는 방법을 살펴보겠습니다.\n마찬가지로 서버를 선택하고 [수집 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 설정에서 Log Template은 [EventLog]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n설정을 마치면 Agent 설치 가이드를 확인할 수 있습니다.\n서버에서 [Windows PowerShell]을 열고, 아래 명령어를 실행합니다. 마찬가지로 마지막에는 설치 서버에 해당하는 설치키가 포함되어 있습니다.\n\n# VPC 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\n\n# Classic 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\n\n\n  \n  \n    \n  \n\n\n설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\n로그 확인\nAgent 설치 후 [Dashboard]를 확인해보면 로그가 수집되고 있을 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[Search] 메뉴에서는 로그 내용을 자세히 검색, 확인할 수 있고, 굳이 서버에 접속하지 않더라도 필요한 로그를 콘솔 화면에서 직접 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n로그 백업\nCloud Log Analytics는 수집된 로그를 Object Storage로 내보내기하거나 Excel 파일로 다운로드 해서 백업할 수 있는 기능을 지원합니다.\n\n수동 백업\n[Search] 메뉴에 [Object Storage로 내보내기]와 [X 다운로드] 버튼이 있습니다.\n\n\n  \n  \n    \n  \n\n\n[Object Storage로 내보내기] 버튼을 클릭하면 내보내기 할 버킷을 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n자동 백업\n[Export Log] 메뉴에서 [자동 내보내기 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n설정 화면에서 내보내기를 할 Object Storage의 버킷을 선택합니다. 혹시 버킷이 생성되지 않았다면 Object Storage로 가서 먼저 버킷을 생성하고 와야 합니다.\n\n\n  \n  \n    \n  \n\n\n내보내기는 하루에 한번 진행되므로 설정 후 다음 날 Object Storage에서 아래와 같이 파일이 저장되어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 해제\n더 이상 로그를 수집할 필요가 없어지면, 로그 수집 설정을 해제하면 됩니다.\n\nLinux 서버 로그 수집 해제\n서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\n\n# VPC 환경\n~# curl -s http://cm.vcla.ncloud.com/removeCla | sudo sh\n\n# Classic 환경\n~# curl -s http://cm.cla.ncloud.com/removeCla | sudo sh\n\n\n  \n  \n    \n  \n\n\nAgent 삭제 명령어를 실행하면 아래와 같이 Success Remove Agent 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\nWindows 서버 로그 수집 해제\n마찬가지로 서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\n\n# VPC 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/removewinCla\"))\n\n# Classic 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/removewinCla\"))\n\n\n  \n  \n    \n  \n\n\nAgent 삭제 명령어를 실행하면 아래와 같이 Remove Agent 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\nWindows 서버 Agent 삭제 오류 상황\nWindows 서버에서 Agent 삭제를 시도할 때 아래와 같이 오류 메시지가 발생하는 경우가 있습니다.\n이때는 당황하지 마시고, Agent 삭제 명령어를 다시 한번 실행하면 됩니다.\n\n Stop-Service: Cannot find any service with service name ‘filebeat’.\n\n로그 수집 설정에서 EventLog만 선택했을 경우 발생합니다.\n\n로그 수집 Agent는 윈도 이벤트 로그 수집을 위한 winlogbeat와 그 외 로그를 수집하기 위한 filebeat 두가지가 설치되는데, EventLog만 수집하도록 설정할 경우 filebeat는 실행되지 않습니다. \n그 상태에서 Agent를 삭제하려고 하면 실행중이 아닌 filebeat를 실행 중지 시키려고 시도하게 되고, 결국 오류가 발생합니다.\n\n그러므로 심각한 오류는 아니고 만약을 위해 Agent 삭제 명령어를 한번 더 실행시키는 것으로 문제는 해결됩니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Cloud Log Analytics 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/cla-overview\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-12-14\n          문서 최초 생성\n        \n      \n        \n          2023-11-14\n          기능 개선 사항 적용, 문서 카테고리 변경\n        \n      \n        \n          2024-02-16\n          지원 운영체제 리스트 추가"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-cloud-log-analytics-template-info-html": {
						"id": "management-ncloud-management-cloud-log-analytics-template-info-html",
						"title": "Cloud Log Analytics에서 수집하는 로그 유형",
						"categories": "",
						"url": " /management/ncloud-management-cloud-log-analytics-template-info.html",
						"content": "개요\nCloud Log Analytics는 네이버 클라우드 플랫폼의 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석하게 해주는 서비스입니다.\n\n로그 템플릿 종류\nCloud Log Analytics에서 수집하는 각 종 서비스의 로그 템플릿 종류는 다음과 같습니다.\n\n\n  Server SYSLOG\n  Apache 로그(Access log, Apache Error Log)\n  MySQL 설치형 상품의 로그(Error Log, Slow Log)\n  Microsoft SQL Server 설치형 상품의 Error Log\n  Tomcat 로그(Catalina Log)\n  Windows 서버의 Event Log\n  Windows 서버의 각종 text 형식의 로그\n  Cloud DB for MySQL 로그\n  Cloud DB for MSSQL 로그\n  Cloud DB for MongoDB 로그\n  Cloud DB for PostgreSQL 로그\n  Application Server Launcher 로그\n  Application Load Balancer 로그\n  Search Engine Service 로그\n  Cloud Data Streaming Service 로그\n  Bare Metal Server 로그\n  Ncloud Kubernetes Service Audit 로그\n  그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다\n\n\n지원 운영 체제\n지원하는 운영 체제는 다음과 같습니다.\n\n\n  CentOS/RHEL 6\n  CentOS 7\n  CentOS 8\n  RHEL 8\n  RHEL 9\n  Ubuntu 16.04\n  Ubuntu 18.04\n  Ubuntu 20.04\n  Ubuntu 22.04\n  SLES 15\n  Debian 9\n  Debian 10\n  Debian 11\n  Windows Server 2012\n  Windows Server 2016\n  Windows Server 2019\n  Windows Server2022\n\n\n로그 보관 기간\n로그 데이터의 보관 기간은 30일로, 30일이 지난 데이터는 자동 삭제되며, 사전에 별도로 통지하지 않습니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/cla-overview\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-12-07\n          문서 최초 생성\n        \n      \n        \n          2023-11-14\n          로그 템플릿 종류 추가, 문서 카테고리 변경\n        \n      \n        \n          2024-02-16\n          지원 운영체제 리스트 추가"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-cloud-log-analytics-windows-iis-log-collect-guide-html": {
						"id": "management-ncloud-management-cloud-log-analytics-windows-iis-log-collect-guide-html",
						"title": "Cloud Log Analytics에서 Windows IIS Log 수집하는 방법",
						"categories": "",
						"url": " /management/ncloud-management-cloud-log-analytics-windows-iis-log-collect-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) Cloud Log Analytics 서비스에서 Windows 웹서버인 IIS 로그를 수집하는 방법에 대해 정리해보겠습니다.\n\n테스트 서버\n\n  Windows Server 2019 (64-bit) English Edition\n\n\n수집 설정\n\n  [Cloud Log Analytics] - [Management]에서 서버를 선택하고 [수집 설정] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n[Log 수집 설정] 화면에서 각 설정 항목을 다음과 같이 입력합니다.\n\n  Log Template: Custom Log를 선택합니다.\n  Log Type: 임의의 값을 입력합니다. (예: iislog)\n  Log 경로: 실제 저장되는 로그파일의 경로를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\nLog 파일 경로 확인\nIIS Log 파일의 경로는 [IIS Manager]를 실행하고, 사이트 정보에서 [Logging] 메뉴를 선택하면 아래와 같이 [Directory] 항목을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n해당 경로를 찾아가면 아래와 같이 로그 파일이 저장되어 있는 것을 확인할 수 있습니다.\n\n# 예시\nC:\\inetpub\\logs\\LogFiles\\W3SVC1\\u_ex231114.log\n\n\n  \n  \n    \n  \n\n\nLog 파일 경로 입력\n실제 Log 파일은 일별 또는 시간 별로 파일명이 다르게 저장되는 경우가 대부분이므로 [Log 경로]에는 다음과 같이 전체 파일을 수집하도록 입력하면 됩니다. 이제 모든 항목을 입력했으면 [추가] 버튼을 클릭합니다.\n\n# 예시\nC:\\inetpub\\logs\\LogFiles\\W3SVC1\\*.log\n\n\n\n  \n  \n    \n  \n\n\n그리고, 입력한 내용에 이상이 없으면 [적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 Agent 설치\n로그 수집 설정을 마치면 [로그 수집 Agent 설치] 방법에 대한 안내 팝업이 나타납니다. 설치 안내 내용 중에서 [로그 수집 agent 설치 명령어] 항목에 있는 [클립보드에 복사하기] 버튼을 클릭해서 설치 명령어를 복사합니다.\n\n\n  \n  \n    \n  \n\n\n서버의 [Windows PowerShell]을 실행시켜서 위에서 복사한 [로그 수집 agent 설치 명령어] 입력합니다. 설치가 정상적으로 완료되면 [Finish Installation] 이라는 메시지를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n수집된 로그 확인\n설치 후 5분 정도 기다렸다 [Cloud Log Analytics] - [Search] 메뉴에 들어가보면 아래와 같이 수집된 로그를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/cla-overview\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-11-16\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-sub-account-api-gateway-access-control-guide-html": {
						"id": "management-ncloud-management-sub-account-api-gateway-access-control-guide-html",
						"title": "Ncloud API Key 접근 제한 설정하는 방법",
						"categories": "",
						"url": " /management/ncloud-management-sub-account-api-gateway-access-control-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)를 이용하다보면 여러 가지 정보를 조회하거나 서버를 생성하는 등의 작업을 위해 API를 활용하게 되는 경우가 많습니다. 그런데 이때 사용하는 API Key를 접근 제한 없이 사용하게 되면 외부에 유출되거나 했을 때 심각한 보안 문제를 일으키게 되므로 사전에 API Key에 대한 권한을 설정하거나 접근 제한을 설정해서 사용하는 것이 권장됩니다.\n\n여기서는 API Key를 최소 권한으로 생성하고, 접근 경로를 제한 하는 등의 방법들을 정리해보겠습니다.\n\n서브 계정 생성\nAPI Key 보안과 관련해서 가장 중요한 원칙은 메인 계정이 아닌 최소 권한을 가진 서브 계정(Sub Account)에서 API Key를 생성하는 것입니다.\n\n : \n메인 계정은 최대 권한을 가지기 때문에 메인 계정으로 생성한 API도 메인 계정과 동일한 최대 권한을 가지게 됩니다. 그러므로 메인 계정으로 API Key를 생성하게 되면 이 Key가 유출되었을 때 심각한 문제가 생기기 때문에 반드시 서브 계정에서 API Key를 생성해야 합니다.\n\n\n\n서브 계정(Sub Account)을 생성하는 방법은 아래 문서를 참고하시기 바랍니다.\n⁃ Ncloud 서브 계정 (Sub Account) 생성 가이드\n\n\n\n\n  테스트를 위해 아래와 같이 서브 계정을 준비하고, 계정을 클릭해서 서브 계정 세부 정보 화면으로 이동합니다.\n\n\n  \n  \n    \n  \n\n\n계정 권한 설정\n서브 계정의 권한은 최소로 설정해야 합니다.\n예를 들어 Object Storage만 접근하는지, VPC Server 관련된 기능만 사용할 것인지, VPC Server 관련된 기능 중에서도 조회 기능만 사용할 것인지, Server 생성 등을 포함한 모든 기능을 사용할 것인지 등의 사용에 필요한 권한을 모두 정리해서 최소한의 권한으로 설정하는 것이 안전합니다.\n\n우선, 서브 계정 세부 정보 화면에서 아래쪽에 있는 [정책] 탭에 있는 [개별 권한 추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 추가 화면에서는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책]과 사용자가 직접 정의하는 [사용자 정의 정책]이 있습니다.\n우선 [관리형 정책]에서 필요한 정책을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  정책이 워낙 많기 때문에 가능하면 위쪽의 검색 기능을 이용해서 정책을 찾는 것을 추천합니다.\n여기서는 테스트를 위해 Function으로 검색해서 [NCP_VPC_CLOUD_FUNCTIONS_MANAGER (VPC 기반 Cloud Functions 서비스 내 모든 기능을 이용할 수 있는 권한)]을 선택했습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nAPI Gateway 접근 권한 설정\n우선, [서브 계정 세부 정보] 화면에서 [수정] 메뉴 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [서브 계정 정보] 수정 화면에서 [접근 권한]에 있는 [API Gateway 접근]을 체크합니다. 그리고, 되도록이면 [지정된 Source에서만 접근 가능] 옵션을 선택하고, 지정된 IP 등을 추가하는 것을 권장합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  위 화면에서 [추가] 버튼을 클릭하면 아래와 같이 [접근 가능 Source 지정] 팝업이 나타나는데, IP를 입력하거나 VPC Server를 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n⁃ [VPC Server]의 경우 IP 주소로는 접근할 수 없습니다.\n⁃ 아래 화면처럼 VPC Server 리스트에서 직접 선택해야 접근 가능합니다.\n⁃ 그러므로 다른 계정의 VPC Server는 접근 가능 리소스에 추가할 수 없습니다.\n\n\n\n  \n  \n    \n  \n\n\nAPI Access Key 추가\n위에서 [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나고 [추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n접근 제한 테스트\n그러면 위에서 설정했던 접근 제한 설정이 제대로 작동하는지 테스트 해보겠습니다.\n\nIP 제한\n위에서 설정한 [접근 가능 Source 지정] 항목에 IP를 설정하지 않거나, 지정되지 않은 IP에서 접근할 경우 아래의 예시와 같은 오류 메시지가 반환됩니다.\n\n\n  호출 API: getProductList\n\n\n&lt;Message&gt;\n  &lt;error&gt;\n      &lt;errorCode&gt;230&lt;/errorCode&gt;\n      &lt;message&gt;Forbidden&lt;/message&gt;\n      &lt;details&gt;IP not allowed for authentication.&lt;/details&gt;\n  &lt;/error&gt;\n&lt;/Message&gt;\n\n\n계정 권한 제한\n계정에 올바른 권한이 설정되지 않았을 경우 아래와 같은 오류 메시지가 반환됩니다.\n\n\n  호출 API: createServerInstances\n\n\n&lt;responseError&gt;\n  &lt;returnCode&gt;802&lt;/returnCode&gt;\n  &lt;returnMessage&gt;You do not have authority about action : [VPCServer:Change/createServerInstance].&lt;/returnMessage&gt;\n&lt;/responseError&gt;\n\n\n\n  호출 API: getDemandCostList\n\n\n&lt;responseError&gt;\n  &lt;returnCode&gt;2210&lt;/returnCode&gt;\n  &lt;returnMessage&gt;You do not have authority about action : [NCP_FINANCE_MANAGER].&lt;/returnMessage&gt;\n&lt;/responseError&gt;\n\n\n주요 API 최소 권한\n\n\n  \n    \n              \n        API\n        설명\n        Classic/VPC\n        최소 권한\n      \n    \n          \n        \n          getProductList\n          Ncloud 상품 리스트 조회\n          공통\n          없음\n         \n         \n          getDemandCostList\n          청구 비용 리스트 조회\n          공통\n          NCP_FINANCE_MANAGER\n        \n        \n          getServerInstanceList\n          서버 인스턴스(VM) 리스트 조회  \n          VPC\n          NCP_VPC_SERVER_VIEWER        \n          \n                  \n          Classic\n          NCP_SERVER_OBSERVER\n        \n        \n          createServerInstances\n          서버 인스턴스(VM) 생성\n          VPC\n          NCP_VPC_SERVER_MANAGER\n         \n        \n          Classic\n          NCP_SERVER_MANAGER\n         \n        \n          Get Action List\n          CloudFunction 액션 리스트 조회\n          VPC\n          NCP_VPC_CLOUD_FUNCTIONS_VIEWER\n         \n        \n          Classic\n          NCP_CLOUD_FUNCTIONS_MANAGER\n            \n        \n          Post Action\n          CloudFunction 액션 실행\n          VPC\n          NCP_VPC_CLOUD_FUNCTIONS_MANAGER\n         \n        \n          Classic\n          NCP_CLOUD_FUNCTIONS_MANAGER\n         \n        \n          ListBuckets\n          ObjectStorage 버킷 리스트 조회\n          공통\n          NCP_OBJECT_STORAGE_VIEWER\n         \n        \n          createAutoScalingGroup\n          Auto Scaling Group 생성\n          VPC\n          NCP_VPC_AUTOSCALING_MANAGER\n        \n        \n          SMS API\n          Simple &amp; Easy Notification Service 내SMS 발신번호 등록 기능을 제외한모든 기능\n          공통\n          NCP_SENS_MANAGER\n        \n        \n          geoLocation\n          지정한 IP의 위치 정보 조회\n          공통\n          NCP_GEOLOCATION_MANAGER\n        \n    \n  \n\n\n참고 URL\n\n  Ncloud Sub Account 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/subaccount-overview\n    \n  \n  Ncloud API 사용 가이드\n    \n      https://api.ncloud-docs.com/docs/api-overview\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-08-14\n          문서 최초 생성\n        \n      \n        \n          2023-12-19\n          VPC Server 접근 리소스 지정 설명 추가, 스샷 업데이트"
					}
					
				
			
		
			
				
					,
					
					"media-ncloud-media-video-player-enhancement-guide-html": {
						"id": "media-ncloud-media-video-player-enhancement-guide-html",
						"title": "Ncloud Video Player Enhancement 사용 가이드",
						"categories": "",
						"url": " /media/ncloud-media-video-player-enhancement-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) [Video Player Enhancement]는 웹/앱에서 비디오 또는 오디오와 같은 미디어 재생을 위한 서비스로, Live Station, VOD Station과 연동을 통해, 다양한 디바이스 환경에서 시청자에게 최고 품질의 경험을 제공합니다.\n\n특징\nVideo Player Enhancement 서비스의 특징은 다음과 같습니다.\n\n\n  Live Station &amp; VOD Station과 손쉽게 연동 가능\n  HTML5 표준 : HTML5 표준에 맞게 제작된 SaaS 기반의 서비스로 별도의 APP 설치 없이 모든 디바이스 및 OS Browser에서 재생 가능\n  사용자가 직접 커스터마이징 : Console 에서 UI &amp; UX 패널 제공하여 고객이 직접 커스터마이징을 할 수 있음 (유료 버전)\n  개발 시간 단축 : 스크립트 코드 예제를 통해 플레이어를 웹페이지 내 손쉽게 임베디드가 가능하며 완성된 코드 제공을 통해 개발 시간을 단축 시킬 수 있음\n\n\n제공 기능\nVOD Station이 제공하는 기능은 다음과 같은 것들이 있습니다.\n\n\n  다양한 재생 옵션 설정을 위한 기능\n  콘텐츠 보안: MultiDRM (FairPlay, Widevine, PlayReady) 및 Visible Watermark 기능 제공\n  모바일 SDK: Native SDK 제공 (AOS - Kotlin, iOS - Swift)\n  커스터마이징: 콘솔에 UI/UX 설정을 위한 기능 제공\n  CMAF LL-HLS 지원\n\n\n사전 준비 사항\n[Video Player Enhancement]을 테스트 하기 위해 [VOD Station]에 스트리밍 가능한 영상 파일을 미리 등록해 두겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  [VOD Station] 사용 방법은 아래 가이드 문서에서 확인할 수 있습니다.\n\n\n\n⁃  VOD Station 생성 가이드\n\n\n서비스 위치\nNcloud Console에서 [Video Player Enhancement] 서비스 위치는 아래와 같이 [Media] - [Video Player Enhancement]에 있습니다.\n\n\n  \n  \n    \n  \n\n\n서비스 신청\n[Video Player Enhancement] 서비스를 사용하기 위해서는 먼저 [서비스 신청] 버튼을 클릭해 서비스를 신청해야 합니다.\n\n\n  \n  \n    \n  \n\n\n서비스 선택\n[Video Player Enhancement] 서비스는 무료 서비스인 Basic 버전과 유료 서비스인 Standard 버전이 있습니다. 각각이 제공하는 기능이 다르므로 잘 살펴보고 선택하시면 됩니다.\n\n 주의: 서비스를 유료로 신청 또는 무료에서 유료로 전환 후에는 다시 무료로 전환이 불가합니다.\n\n\n  \n  \n    \n  \n\n\n\n  서비스 신청이 끝났으면 플레이어를 생성해야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n플레이어 생성\n플레이어 생성 화면에서는 현재 계약된 정보가 표시되며, 무료인 경우 [유료 전환] 버튼도 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n기본 설정\n기본 설정에서는 플레이어를 사용할 [사이트 도메인] 또는 [앱 패키지 ID]를 입력해야 합니다.\n\n\n⁃ 사이트 도메인은 플레이어가 노출될 사이트 도메인에 대한 유효성을 확인하기 위함입니다.\n⁃ 등록된 도메인이 아닐 경우 플레이어가 동작하지 않습니다.\n⁃ 사이트 도메인은 5개까지 입력 가능합니다.\n⁃ 5개 이상 입력이 필요할 경우 네이버 클라우드 영업팀에 별도 문의 부탁 드립니다.\n\n\n\n  \n  \n    \n  \n\n\n플레이어 옵션\n플레이어가 생성되면 플레이어 옵션 미리보기를 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n미리보기\n미리 보기 화면에서 플레이어의 기본 스크립트를 확인할 수 있는데 [복사] 버튼을 클릭해서 스크립트를 가져옵니다.\n\n\n  \n  \n    \n  \n\n\n플레이어 스크립트 기본 템플릿\n위에서 복사해 온 플레이어 스크립트는 기본적으로 다음과 같은 형태로 구성되어 있습니다.\n\n&lt;script type=\"text/javascript\" src=\"https://player.vpe.naverncp.com/ncplayer.js?access_key={Access Key}\"&gt;&lt;/script&gt;\n\n&lt;div id=\"video\"&gt;&lt;/div&gt;\n\n&lt;script&gt;\n  let player = new ncplayer('video',{\t\t\n    playlist:[\n      {\n       file:\"{재생 파일 URL}\",\n        poster:\"{썸네일 이미지 URL}\"    \n      }\t\t\n    ],\t\t\n  });\n&lt;/script&gt;\n\n\n플레이어 샘플 예제\n[VOD Station]에 등록한 스트리밍 파일을 이용한 샘플 스크립트 예제는 다음과 같습니다.\n\n\n⁃  VOD Station 생성 가이드\n\n\n&lt;script type=\"text/javascript\" src=\"https://player.vpe.naverncp.com/ncplayer.js?access_key=1b***d7\"&gt;&lt;/script&gt;\n\n&lt;div id=\"video\"&gt;&lt;/div&gt;\n\n&lt;script&gt;\n  let player = new ncplayer('video',{\n    autostart: true,\n    muted: true,\t\t\t\n    aspectRatio: '16/9',\n    repeat: true,\n    playlist:[\n      {\n        file:\"https://fv***47.cdn.ntruss.com/hls/OS***E8_/test-category/VOD-Station_***_30fps.mp4/index.m3u8\",\n        poster:\"https://kr***08.cdn.ntruss.com/test-category/VOD-Station_02.jpg\",\t\t\t\t\n      }\t\t\t\n    ],\t\t\n  });\n&lt;/script&gt;\n\n\n플레이어 실행 화면\n위 스크립트로 생성한 플레이어를 실행하면 아래와 같이 영상이 플레이 되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n 음소거 옵션: autostart: true 상태에서 muted 옵션과 관계없이 무조건 음소거 상태로 나타나는 경우가 많은데, 이것은 웹브라우저의 자체 정책으로 인해 영상의 자동재생이 차단되는 것을 막기 위해 음소거 상태로 플레이됩니다. \n\n플레이어 상세 옵션\n\n\n  \n    \n      프로퍼티\n      유형\n      설명\n      기본값\n      옵션값\n      라이선스\n      필수여부\n    \n  \n  \n    *playlistarray플레이리스트없음무료O\n    autostartboolean자동재생여부TRUE무료X\n    mutedboolean음소거FALSE무료X\n    keyboardShortcutboolean키보드 단축키TRUE무료X\n    controlsboolean컨트롤바 사용 여부TRUE무료X\n    uistringUI 설정allall, mobile , pc무료X\n    **controlBtnarray컨트롤바 버튼 on/off유료X\n    progressBarColorstring컨트롤바 컬러#4299f5유료X\n    controlActiveTimenumber컨트롤바 활성 시간(ms)3000유료X\n    startMutedInfoNotVisibleboolean음소거 알림FALSE유료X\n    aspectRatiostring화면비16/916/9 , 4/3 , 1/1 , 9/16 , 21/9무료X\n    objectFitstring영상 화면 맞춤containcontain , cover , fill무료X\n    playRateSettingarray배속 선택 옵션[0.5,0.75,1,1.5,2]유료X\n    seekingPreviewboolean영상 구간 이동 미리보기TRUE유료X\n    autoPauseboolean탭 비활성화 시 자동멈춤FALSE무료X\n    repeatboolean영상 반복FALSE무료X\n    touchGesturesboolean터치 제스처TRUE유료X\n    descriptionNotVisibleboolean영상 메타 데이터FALSE유료X\n    langstringUI 언어설정autoauto , ko , en , ja , zh무료X\n    lowLatencyModebooleanCMAF LL-HLSFALSE유료X\n  \n\n\n*playlist 상세 속성\n\n\n  \n    \n      프로퍼티\n      유형\n      설명\n      기본값\n      옵션값\n      라이선스\n      필수여부\n    \n  \n  \n    filestring재생하고자 하는 video 정보\n    \n      sourcesarray\n      \n        video에 여러가지 해상도를 제공하는 경우 사용\n        \n        \n          \n            filestring해상도별 video 파일 경로\n            labelstring해상도 조절 컨트롤에 표시되는 텍스트\n            defaultboolean기본 해상도로 적용\n          \n         \n      \n      file로 대체 가능무료X\n    posterstringvideo 재생 전 표시할 이미지없음무료X\n    \n      descriptionarray\n      \n        Player 상단에 표시할 메타데이터\n        \n                  \n          \n            title string제목 표시\n            created_at string날짜 표시\n            profile_name string채널명 or 업로더 닉네임\n            profile_image string채널이미지 or 업로더 프로필 이미지\n            callback function메타데이터 클릭시 발생시킬 이벤트\n          \n         \n      \n      없음유료X   \n  \n\n\n**controlBtn 상세 속성\n\n\n\n  \n    \n      프로퍼티\n      유형\n      설명\n      기본값\n    \n  \n  \n    playboolean플레이버튼TRUE\n    fullscreenboolean전체화면 전환TRUE\n    volumeboolean볼륨컨트롤TRUE\n    timesboolean시간정보 UITRUE\n    pictureInPictureboolean미니플레이어TRUE\n    settingboolean세팅 버튼TRUE\n  \n    \n\n\n\n통계\n[Player Statistics] 화면에서는 플레이어 사용량 등의 통계를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Video Player Enhancement 개요\n    \n      https://guide.ncloud-docs.com/docs/videoplayerenhancement-overview\n    \n  \n  Ncloud Video Player Enhancement 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/videoplayerenhancement-user-guide"
					}
					
				
			
		
			
				
					,
					
					"media-ncloud-media-vod-station-guide-html": {
						"id": "media-ncloud-media-vod-station-guide-html",
						"title": "Ncloud VOD Station 생성 가이드",
						"categories": "",
						"url": " /media/ncloud-media-vod-station-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) VOD Station은 저장된 영상을 다양한 디바이스에서 시청할 수 있도록 변환하는 인코딩 기능과 동영상 파일을 패킷타이징하여 네트워크를 효율적으로 사용할 수 있는 스트리밍 기능을 제공하는 VOD 전용 서비스입니다.\n\n특징\nVOD Station 서비스의 특징은 다음과 같습니다.\n\n\n  하나의 서비스로 인코딩과 송출 가능: 여러 가지 VOD 서비스를 고민할 필요 없이 VOD Station 하나로 인코딩과 스트리밍이 가능합니다.\n  영상의 길이와 해상도에 따른 합리적 과금: 영상의 길이와 코딩 후 변환된 해상도에 따라 요금이 책정되므로 합리적인 비용으로 서비스를 이용할 수 있습니다.\n  고품질의 안정적인 스트리밍: Progressive Download 방식이 아닌 영상을 패킷타이징하여 송출하는 방식이므로 안정적인 품질로 스트리밍을 제공할 수 있습니다.\n  간편한 CDN 생성: CDN(Content Delivery Network) 선택 옵션을 통해 VOD 스트리밍 서비스에 최적화된 CDN을 쉽게 생성할 수 있습니다.\n  서비스 간의 유연한 연동: 인코딩, 보안, 비디오 플레이어와의 연동 등 VOD 서비스에 필요한 유연한 연동을 제공합니다.\n\n\n제공 기능\nVOD Station이 제공하는 기능은 다음과 같은 것들이 있습니다.\n\n\n  인코딩\n  On-the-fly 패킷타이징\n  템플릿 인코딩 설정\n  DRM\n  썸네일 추출저장\n  최적의 CDN 생성(선택 옵션)\n\n\n사전 준비 사항\nVOD Station을 이용하기 위해서는 반드시 필요한 것이 2가지 있는데 다음과 같습니다.\n\n\n  Object Storage: 원본 미디어 파일과 변환된 영상 파일을 저장하기 위한 공간\n  CDN: 영상 배포를 위한 콘텐츠 스트리밍 플랫폼\n\n\n서비스 위치\nNcloud Console에서 [VOD Station] 서비스 위치는 아래와 같이 [Media] - [VOD Station]에 있습니다.\n\n\n  \n  \n    \n  \n\n\nObject Storage Bucket 생성\nVOD Station을 좀 더 편하게 생성하려면 VOD Station 생성 전에 먼저 Object Storage에 Bucket을 생성하는 것이 좋습니다.\n\nBucket 생성\n예를 들어 아래와 같이 용도별 Bucket 3개를 생성합니다.\n\n\n  vod-station-input: 동영상 원본 파일을 저장할 Bucket\n  vod-station-output: 인코딩이 완료된 동영상을 저장할 Bucket\n  vod-station-thumbnail: 동영상에서 추출한 썸네일 이미지를 저장할 Bucket\n\n\n\n  \n  \n    \n  \n\n\n\n  아래와 같이 Bucket 3개를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n파일 업로드\nBucket 생성 후에 [vod-station-input] Bucket에 테스트할 동영상 파일을 업로드 합니다.\n\n\n  \n  \n    \n  \n\n\n이용 신청\n다음으로 [VOD Station] - [Subscription]에서 이용 신청을 합니다.\n\n\n  \n  \n    \n  \n\n\n이용 신청이 끝나면 [Category]를 생성하라는 안내 팝업이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n카테고리 생성\n카테고리 생성 화면은 다음과 같은데 아래쪽에서 차례대로 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n인코딩 설정\n인코딩 설정 방법은 미리 지정된 템플릿을 이용해서 간편하게 설정할 수도 있고, 원하는 옵션으로 직접 설정할 수도 있는데, 여기서는 [템플릿 간편 설정]으로 진행하겠습니다.\n\n\n  템플릿 간편 설정\n템플릿 간편 설정에는 [실속형 콘텐츠], [비즈니스 콘텐츠], [초고화질 콘텐츠] 등의 3가지 옵션이 있는데, 아래쪽에서 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  인코딩 템플릿\n인코딩 템플릿의 상세 옵션을 확인하려면 [템플릿 간편 설정] 옆에 있는  아이콘을 클릭하면 아래와 같이 자세히 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  직접 설정\n템플릿을 사용하지 않고 상세 옵션을 직접 설정하려면 [설정함] 옵션을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  상세 옵션\n인코딩 옵션을 직접 설정하는 경우 아래와 같이 17개의 Video 옵션과 4개의 Audio 옵션 중에서 최대 5개를 선택할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n파일 경로 설정\n가능하면 썸네일은 설정함을 선택하고, [+ 선택] 버튼을 클릭해 아웃풋 파일 경로와 썸네일 아웃풋 파일 경로를 설정하도록 하겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  아웃풋 파일 경로 설정\n파일 경로 설정 팝업에서 미리 생성해 둔 [vod-station-output] Bucket을 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  썸네일 아웃풋 파일 경로 설정\n마찬가지로 썸네일 경로 설정 팝업에서 미리 생성해 둔 [vod-station-thumbnail] Bucket을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n고급 설정\n고급 설정에서는 [재생구간 설정]과 [워터마크 이미지]를 추가할 수 있는데, 서비스 상황에 맞에 선택하시면 되고, 여기서는 설정하지 않고 완료하겠습니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n위에서 설정한 값들을 최종 확인한 후에 이상이 없으면 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n파일 인코딩\n이제 생성된 카테고리 리스트에서 [신규파일 인코딩] 버튼을 클릭해 인코딩할 파일을 등록합니다.\n\n\n  \n  \n    \n  \n\n\n\n  파일 경로 선택\n인풋 파일 경로는 [오브젝트 스토리지]와 별도의 [HTTP 다운로드 URL]을 선택할 수 있는데 여기서는 앞에서 생성한 오브젝트 스토리지를 선택하겠습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  파일 선택\n오브젝트 스토리지 버킷에서 앞에서 업로드한 인코딩할 파일을 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  인코딩 시작\n선택한 파일이 맞는지 최종 확인하고 이상이 없으면 [확인] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n인코딩 상태 확인\n위에서 선택한 파일의 인코딩 상태 확인은 [VOD Station] - [Status]에서 확인 가능합니다.\n\n\n  \n  \n    \n  \n\n\n썸네일 파일 확인\n썸네일 파일은 앞에서 생성하고 선택했던 오브젝트 스토리지 [vod-station-thumbnail] 버킷에서 아래와 같이 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n채널 생성\n인코딩이 끝났으면, 이제 스트리밍을 위한 채널을 생성해야 합니다.\n[VOD Station] - [Channel]에서 [채널 생성] 버튼을 클릭해 VOD Streaming을 구성하기 위한 새로운 채널을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n채널 생성 구성 항목\n채널 생성 시에 입력 또는 선택이 필요한 항목들을 차례대로 살펴보겠습니다.\n\n\n  \n    Object Storage Bucket 선택\nStreaming할 파일의 위치는 위에서 설정했던 인코딩된 파일의 위치인 [vod-station-output] 버킷을 선택합니다.\n  \n  \n    Object Storage 비공개 파일 접근\nObject Storage 비공개 파일 접근 설정은 [허용]을 선택하는 것을 추천합니다. \nVOD Station은 Object Storage 의 “공개 안함” 권한을 가진 파일도 스트리밍할 수 있는 기능을 제공하므로 Object Storage 에 있는 원본 파일의 권한을 “공개” 대신 “공개 안함” 으로 설정함으로써 컨텐츠의 보안 수준을 높일 수 있습니다.\n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n    Protocol\nProtocol은 [HLS], [DASH] 중에서 선택하거나 두 가지 모두 선택할 수 있습니다.\n  \n  \n    Segment 설정\nSegment 설정도 서비스 상황에 맞에 선택하시면 됩니다.\n  \n\n\n\n  \n  \n    \n  \n\n\n\n  CDN 설정\nVOD Station은 CDN 연동이 필수인 상품으로 [신규 생성]을 선택해 VOD Station에 최적화된 CDN을 자동 생성하거나, 기존 CDN 연동 또는 차후 별도의 CDN을 생성할 수도 있지만, \n가급적 [신규 생성] 옵션을 선택하는 것을 추천드립니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  콘텐츠 보호 설정\nDRM 등의 콘텐츠 보호 설정이 필요할 경우 관련된 설정을 추가할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  채널 생성 완료\n채널은 생성과 함께 운영상태로 전환되고, 그에 따라 과금이 발생하게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  생성된 채널 확인\n채널이 생성되면 아래와 같이 파일리스트와 채널 정보를 확인할 수 있습니다. 자세한 채널 정보는 상단에 있는 [채널 정보] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n채널 정보\n위에서 확인한 채널 리스트에서 [채널 정보] 버튼을 클릭하면 아래와 같은 채널 정보를 확인할 수 있는데, 이 채널 정보 중에서 중요한 항목은 아래에 표시한 3가지 입니다.\n\n\n  Object Storage Bucket (암호화명)\n  Protocol\n  CDN 재생경로\n\n\n\n  \n  \n    \n  \n\n\n재생 경로 URL 확인\nCDN에 위치한 VOD의 재생 경로 URL은 다음과 같은 요소로 구성되어 있습니다.\n\n URL Template: https://[CDN Domain]/[Protocol]/[EncryptedBucketName]/[Path]/[Video Filename]/[Manifest]\n\n\n\n  \n    \n      Domain\n      Protocol\n      BucketName\n      Path\n      FileName\n\t  Manifest\n    \n  \n      \n    \n\t  example.cdn.ntruss.com\n\t  ~aiEihf7l39&#42;&#42;&#42;&#42;&#42;&#42;fs890ilkjlkfts_\n\t  /hls\n\t  /example_category\n\t  /example.mp4\n\t  /index.m3u8\n\t\n\t\n\t\t/dash\n\t\t/manifest.mpd\n\t\n  \n  \n\t\n\t  CDN 도메인\n\t  암호화된 Bucket 이름\n\t  스트리밍프로토콜\n\t  카테고리 이름으로구성된 폴더 경로\n\t  파일명\n\t  스트리밍을 위한Manifest 파일\n\t\n  \n\n\n### URL 예시\nChannel에서 확인했던 파일 하나를 선택해서 재생 URL이 어떻게 구성되는지 예시를 들어보겠습니다.\n\n 파일명 예시: test-category/VOD-Station_AVC_HD_1Pass_30fps.mp4\n\n\n\n\n\n 재생 경로 URL: https://yyvs***46***73.cdn.ntruss.com/hls/~ndO***eX~d1Y***OfE***VRYsO***Mgb***ri24_/test-category/VOD-Station_AVC_HD_1Pass_30fps.mp4/index.m3u8\n\n\n\n\n\n### 재생 URL 빠르게 확인하기\n재생 경로 URL이 복잡하게 구성되어 있다보니 직접 작성하기 쉽지 않은데, 이럴 때는 아래와 같은 방법으로 빠르게 확인할 수 있습니다.  \n사용하시는 웹브라우저(여기서는 크롬을 사용)에 HLS, DASH 프로토콜 파일을 플레이할 수 있는 기능이 설치되어 있으면 보다 간편하게 확인 가능합니다.  \n\n- **웹브라우저 확장 프로그램 설치**  \n혹시 설치되어 있지 않을 경우 크롬 웹스토어 [**확장 프로그램**]에서 **HLS, DASH Player**를 아래와 같이 검색해서 설치합니다.\n\n\n  \n  \n    \n  \n\n\n\n\n- **CDN 재생경로 URL 생성**  \n확장 프로그램이 설치되었으면 [**VOD Station**] - [**Channel**]에서 파일 리스트 오른쪽에 있는 [**HLS URL 생성**] 또는 [**DASH URL 생성**] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n\n- **CDN 재생경로 URL 확인**  \n그러면 아래와 같이 웹브라우저에서 해당 파일이 재생되면서 주소창에서 재생 URL을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n\n\n\n## Video Player Enhancement\n모든 작업이 완료된 영상을 재생하려면 [**Video Player Enhancement**] 서비스를 이용하면 되는데 자세한 사용 방법은 아래 가이드 문서에서 확인할 수 있습니다.\n\n\n⁃  Video Player Enhancement 사용 가이드\n\n\n\n\n\n\n\n  \n  \n    \n  \n\n\n\n\n## 참고 URL\n1. Ncloud VOD Station 가이드\n\t- https://guide.ncloud-docs.com/docs/ko/vodstation-vodstationoverview"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-find-my-ip-address-html": {
						"id": "networking-ncloud-networking-find-my-ip-address-html",
						"title": "내 IP 주소 확인하기",
						"categories": "",
						"url": " /networking/ncloud-networking-find-my-ip-address.html",
						"content": "IPv4\n111.222.333.444처럼 우리가 일반적으로 알고 있는 IPv4는 32비트로 구성된 IP 주소 체계로 이론적으로는 2^32 즉, 4,294,967,296개의 IP주소를 부여할 수 있습니다.\n2011년 전세계 IP주소를 관리하고 있는 IANA(Internet Assigned Numbers Authority)에서 인터넷에 연결되는 기기가 급속도로 증가하면서 할당할 수 있는 IP주소가 고갈되어 감에 따라 IPv4의 신규 할당을 공식 종료했고, 그로 인해 신규 IP주소 체계인 IPv6에 대한 관심이 높아졌습니다.\n\nIPv6\nIPv6는 ae06:2610:122a:2002:1849:2874:27c1:18f6 처럼 128비트로 구성된 신규 IP 주소 체계로 이론적으로는 2^128 개의 IP 주소를 부여할 수 있어 IP 주소의 부족은 없을 것이라고 이야기 되고 있습니다.\n\nPrivate IP (사설 아이피) 대역\n국제 인터넷 표준화 기구(IETF)에서 정한 RFC 1918 표준에 따라  IP 주소, 최상위 도메인 등을 관리하는 단체인 IANA(Internet Assigned Numbers Authority)가 아래의 주소를 사설 IP 대역으로 지정해두고 있습니다.\n\n\n  A Class: 10.0.0.0 - 10.255.255.255 (10.0.0.0/8)\n  B Class: 172.16.0.0 - 172.31.255.255 (172.16.0.0/12)\n  C Class: 192.168.0.0 - 192.168.255.255 (192.168.0.0/16)\n\n\n\nNcloud (네이버 클라우드)의 VPC(Virtual Private Cloud)는 퍼블릭 클라우드 상에 논리적으로 완전하게 분리된 고객전용 네트워크를 제공하는 서비스로, 위에서 설명한 RFC 1918 표준에 따른 최대 /16의 IP 네트워크 공간을 제공하고 있습니다."
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-global-dns-configure-long-txt-record-html": {
						"id": "networking-ncloud-networking-global-dns-configure-long-txt-record-html",
						"title": "DNS 설정에서 255자 이상의 TXT 레코드(SPF, DKIM, DMARC 등) 등록하는 방법",
						"categories": "",
						"url": " /networking/ncloud-networking-global-dns-configure-long-txt-record.html",
						"content": "개요\nDNS 설정할 때 TXT 레코드의 설정 값은 일반적으로 255자로 제한되어 있습니다. 하지만 메일 발신 도메인 인증을 위한 SPF, DKIM 레코드의 설정 값은 255자를 넘는 경우가 많은데 이때 이런 255자 이상의 문자열을 등록할 수 있는 방법에 대해 대표적인 DNS 서비스 업체별로 확인해보겠습니다.\n\nNcloud Global DNS\n우선 Ncloud(네이버 클라우드)의 DNS 서비스인 [Global DNS]는 다른 DNS 제공 업체와 다르게 255자가 넘는 경우에도 자동으로 문자열을 분리해서 등록해줍니다.\n그러므로 Ncloud(네이버 클라우드)에서는 TXT 레코드 값의 길이를 신경쓰지 않고 편하게 등록하시면 됩니다.\n\n레코드 등록 예시\n아래와 같이 예시로 255자가 넘는 DKIM 정보를 [Global DNS]에 등록했습니다. 등록하면서 문자열을 나누지 않고 전체를 하나의 문자열로 등록했습니다.\n\n\n  \n  \n    \n  \n\n\nDNS 레코드 정보 조회 예시\n위에서 예시로 등록한 레코드 정보를 아래와 같이 확인해보면 레코드 문자열이 자동으로 255자 이하로 나누어서 표시되는 것을 확인할 수 있습니다.\nnslookup -q=txt ***._domainkey.조회할도메인\n\n\n\n  \n  \n    \n  \n\n\nAWS Route53\nAWS Route53에서는 255자를 초과하는 값의 경우 각각 255자 이하의 문자열로 나누어서 각 문자열을 큰따옴표로 묶어서 등록해야 합니다. 이때 각 문자열 사이에 줄바꿈을 입력하면 안됩니다.\n\n예시\n\n  원본 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Long_String_Record_ThjBJHkMghJbG”\n  수정 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Lo\" \"ng_String_Record_ThjBJHkMghJbG”\n\n\nGoogle Cloud DNS\nGoogle Cloud Platform의 Cloud DNS에서도 AWS와 마찬가지로 255자를 초과하는 값의 경우 각각 255자 이하의 문자열로 나누어서 각 문자열을 큰따옴표로 묶어서 등록해야 합니다. 이때 각 문자열 사이에 줄바꿈을 입력하면 안됩니다.\n\n예시\n\n  원본 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Long_String_Record_ThjBJHkMghJbG”\n  수정 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Lo\" \"ng_String_Record_ThjBJHkMghJbG”\n\n\n참고 URL\n\n\n  Ncloud Global DNS 가이드\n    \n      https://guide.ncloud-docs.com/docs/globaldns-overview\n    \n  \n  Ncloud Cloud Outbound Mailer 도메인 보안 인증\n    \n      https://guide.ncloud-docs.com/docs/cloudoutboundmailer-use-domain#%EB%8F%84%EB%A9%94%EC%9D%B8-%EB%B3%B4%EC%95%88\n    \n  \n  AWS Route53에서 255자 보다 긴 TXT 레코드 구성하기\n    \n      https://repost.aws/ko/knowledge-center/route-53-configure-long-spf-txt-records\n    \n  \n  GCP Cloud DNS 레코드 추가 가이드\n    \n      https://cloud.google.com/dns/docs/records?hl=ko#record_type\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2024-01-10\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-ipsecvpn-fortigate-setting-guide-html": {
						"id": "networking-ncloud-networking-ipsecvpn-fortigate-setting-guide-html",
						"title": "Ncloud VPC환경 IPsecVPN과 FortiGate 장비 연동 가이드",
						"categories": "",
						"url": " /networking/ncloud-networking-ipsecvpn-fortigate-setting-guide.html",
						"content": "구성 환경\n\n\n  Platform : VPC\n  서버 OS : CentOS 7.8\n  클라이언트 OS : Windows 11 Pro\n  온프레미스 VPN 장비 : FortiGate 30E\n\n\nVPC - IPsecVPN 네이버 클라우드 설정\n\n1. 서버생성\n\nPlatform에서 VPC를 선택 후 서버를 생성합니다. 서버 생성에 대한 자세한 사항은 해당 문서에서 다루지 않습니다. 서버 생성 가이드 참고 부탁드립니다.\n\n(※실습은 VPC, Subnet, 서버 생성이 완료된상태로 진행됩니다.)\n\n2. Virtual Private Gateway 생성\n\n콘솔 → VPC → Virtual Private Gateway\n\n\n  \n  \n    \n  \n\n\n이름입력 및 VPC를 선택하고 생성합니다.\n\n\n  \n  \n    \n  \n\n\n생성 후 현재 상태는 미사용중이 맞습니다. 다음으로 넘어갑니다.\n\n\n  \n  \n    \n  \n\n\n3. Virtual Private Gateway Group 생성\n\n콘솔 → VPC → Virtual Private Gateway → Virtual Private Gateway Group\n\n\n  \n  \n    \n  \n\n\n이름설정 및 VPC, Default 여부 선택하여 추가하고 생성합니다.\n\n\n  \n  \n    \n  \n\n\nGroup생성이 완료되면 2번항목에서 생성한 Virtual Private Gateway도 운영중으로 변경됩니다.\n\n\n  \n  \n    \n  \n\n\n4. Route Table 설정\n\n콘솔 → VPC → Route Table\n\nVPC를 생성하면 아래와같이 default로 해당 VPC의 Public, Private Table이 기본으로 생성되어있습니다.\n\n\n  \n  \n    \n  \n\n\nIPsecVPN 연결을위해 생성한 서버가 소속된 default-table에 목적지인 사무실대역을 추가하여 경로를 지정합니다.\n\n\n  \n  \n    \n  \n\n\n5. IPsec VPN Gateway 생성\n\n콘솔 → IPsec VPN → IPsec VPN Gateway\n\n\n  \n  \n    \n  \n\n\n이름 및 Group를 선택하고 생성합니다.\n\n\n  \n  \n    \n  \n\n\n생성완료되어 상태가 운영중이면 다음으로 넘어갑니다.\n\n\n  \n  \n    \n  \n\n\n6. IPsecVPN Tunnel 생성\n\n콘솔 → IPsecVPN → IPsecVPN Tunnel\n\n\n  \n  \n    \n  \n\n\nVPN 연결 정보 입력 후 다음으로 넘어갑니다.\n\n(※ 아래 입력한 정보는 임의 설정값입니다.)\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n최종 입력 정보를 확인 후 생성합니다.\n\n\n  \n  \n    \n  \n\n\n생성된 정보를 확인하여 상태가 운영중이면 다음으로 넘어갑니다.\n\n\n  \n  \n    \n  \n\n\nFortiGate IPsec VPN 장비설정\n\n1. 가상사설망 생성\n\nFortiGate → 가상사설망 IPsec Wizard → Custom\n\nTemplate Type은 Custom으로 진행합니다.\n\n\n  \n  \n    \n  \n\n\n네이버 클라우드에서 생성한 IPsecVPN Tunnel 정보와 동일하게 설정합니다. 서로의 정보가 하나라도 다를경우 연결에 실패할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n네이버 클라우드 IPseVPN Gateway 공인 IP 확인\n\n콘솔 → IPsec VPN → IPsec VPN Gateway\n\n\n  \n  \n    \n  \n\n\n계속하여 FortiGate VPN 장비 정보 입력하겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n2. 라우팅 설정\n\nFortiGate → 네트워크 → 정적 경로 → 새로 생성\n\n\n  \n  \n    \n  \n\n\nInterface 부분부터 위에서 생성한 test-vpn을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n목적지로 가기위한 정보 입력 후 생성합니다.\n\n\n  \n  \n    \n  \n\n\n3. 정책설정\n\nLocal&gt;VPN, VPN&gt;Local의 접근을 제어하기위한 설정을 합니다.\n\n(가이드에서는 all로 설정하고 진행하겠습니다)\n\nFortiGate → Policy &amp; Objects → IPv4 Policy → 새로 생성\n\n\n  \n  \n    \n  \n\n\nLoca l&gt; VPN 정보 입력 후 생성\n\n\n  \n  \n    \n  \n\n\nVPN &gt; Local 정보 입력 후 생성\n\n\n  \n  \n    \n  \n\n\n4. VPN 모니터링\n\nFortiGate → 모니터 → IPsec 모니터 → Bring UP\n\nBring UP하여 상태가 Down에서 UP 으로 변경되면 정상적으로 연결이 완료되었습니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n\nVPN연결이 되어도 아래와같이 Ping테스트에 실패하게됩니다. 이유는 네이버클라우드 서버는 ACG 정책에 따라 접근이 통제되므로 추가 설정이 필요합니다.\n\n\n  \n  \n    \n  \n\n\n콘솔 → Server → ACG → ACG 선택 → ACG 설정\n\n사무실PC에서 네이버클라우드 서버로 ping 테스트를 위해 서버에 매핑된 ACG에 아래와 같이 사무실의 사설대역을 입력하고 추가합니다.\n\n\n  \n  \n    \n  \n\n\n접근소스에 프로토콜 - ICMP, 접근소스 - 사무실의 사설대역으로 추가합니다.\n\n\n  \n  \n    \n  \n\n\n이후 핑테스트결과 아래와같이 정상적으로 통신이가능합니다.\n\n\n  \n  \n    \n  \n\n\n※ 추가로 프로토콜 - TCP, 접근소스 - 사무실 사설대역, 허용포트 22를추가하면 아래와같이 서버에 접근이 가능합니다."
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-load-balancer-application-lb-access-log-html": {
						"id": "networking-ncloud-networking-load-balancer-application-lb-access-log-html",
						"title": "로드밸런서(Application Load Balancer) 접속 로그 확인하는 방법",
						"categories": "",
						"url": " /networking/ncloud-networking-load-balancer-application-lb-access-log.html",
						"content": "개요\nNcloud (네이버 클라우드) VPC 환경의 대표적인 로드밸런서(Load Balancer)인 애플리케이션 로드밸런서(Application Load Balancer)의 접속 로그를 확인하는 방법에 대해 정리해보겠습니다.\n\n테스트 준비\n\n  서버 생성: 록키 리눅스 (Rocky Linux 8.6)\n  로드밸런서 생성: 애플리케이션 로드밸런서(Application Load Balancer)\n  서버와 로드밸런서 연결\n\n\n서버 생성\n테스트용 서버는 Rocky Linux 8.6 서버로 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n로드밸런서 생성\nApplication Load Balancer를 생성하고 테스트용 서버와 연결까지 마쳤습니다.\n\nApplication Load Blancer 의 생성 가이드는 아래 문서를 참고하시기 바랍니다. \n- VPC 환경에서 Application Load Balancer 생성하기\n\n\n  \n  \n    \n  \n\n\n접속 로그 수집 활성화\n로드밸런서의 접속 로그를 수집하려면 접속 로그 수집 기능을 활성화 해야 합니다. 생성된 로드밸런서를 선택하고 [로드밸런서 설정 변경] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [로드밸런서 설정 변경] 팝업창에서 [액세스 로그 수집] 항목이 [비활성] 상태인 것을 확인할 수 있습니다. 여기서 [설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [액세스 로그 수집]을 활성화할 것인지 한번 더 확인하는 창이 뜨는데 [확인] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [로드밸런서 설정 변경] 팝업창에서 [액세스 로그 수집] 항목이 [활성] 상태로 변경된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n접속 테스트\n웹브라우저에서 로드밸런서 주소로 접속해서 정상 작동하는지 확인했습니다.\n\n\n  \n  \n    \n  \n\n\n로드밸런서 접속 로그 확인\n로드밸런서 접속 로그는 Ncloud 서비스 중에서 [Cloud Log Analytics]에서 확인할 수 있습니다.\n\n[Cloud Log Analytics] - [Search] - [로그 종류 선택]에서 [application_loadbalancer_access] 필드를 선택하고 [Log 발생시간]을 상황에 맞에 선택한 후에 검색을 하면 아래 스샷과 같이 접속로그를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  VPC 환경에서 Application Load Balancer 생성하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud_networking_load_balancer_application_lb.html\n    \n  \n  Cloud Log Analytics 설정 가이드\n    \n      https://docs.3rdeyesys.com/management/ncloud-management-cloud-log-analytics-guide.html"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-load-balancer-certificate-change-html": {
						"id": "networking-ncloud-networking-load-balancer-certificate-change-html",
						"title": "로드밸런서(Load Balancer) 인증서 교체하는 방법",
						"categories": "",
						"url": " /networking/ncloud-networking-load-balancer-certificate-change.html",
						"content": "개요\nNcloud (네이버 클라우드) 로드밸런서(Load Balancer)에는 HTTPS 서비스가 필요할 때 로드밸런서에 인증서를 추가 하여 사용 할 수 있습니다.\n이때 인증서 만료, 멀티도메인 인증서로 교체 등의 여러가지 이유로 로드밸런서에 있는 기존의 인증서를 새로운 인증서로 교체해야 하는 경우가 있는데 VPC, Classic 환경별로 인증서를 교체하는 방법을 정리해보겠습니다.\n\n테스트 인증서 준비\n인증서 교체 테스트를 위한 테스트용 인증서 2개를 미리 준비했습니다.\n\n\n  test1: 현재 적용중인 인증서\n  test2:  새로 교체할 인증서\n\n\n\n  \n  \n    \n  \n\n\nVPC 환경\n우선 VPC 환경에서 로드밸런서 인증서를 교체하는 방법을 정리해보겠습니다.\n\n인증서를 변경 할 로드밸런서를 선택한 후 [리스너 설정 변경] 클릭 합니다.\n\n\n  \n  \n    \n  \n\n\n\n  현재 테스트용 ‘test1’ 인증서가 적용되어 있는 리스너를 선택 한 후 [인증서 변경]을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [default 인증서 선택] 항목에서 교체할 인증서인 test2를 선택한 후 [변경] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  인증서 변경 팝업에서 [변경] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  그런 후에 다시 [리스너 설정 변경] 화면으로 돌아오면 아래와 같이 인증서가 test2로 변경된 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nClassic 환경\n다음으로는 Classic 환경에서 로드밸런서 인증서를 교체하는 방법을 정리해보겠습니다.\n인증서를 변경할 로드밸런서를 선택 후 [로드밸런서 설정 변경]을 클릭 합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [SSL Certificate] 항목을 보면 LB에 적용 되어있는 인증서가 test1임을 확인 할 수가 있습니다.\n이제 새로운 인증서를 적용 하기 위해 [삭제] 버튼을 클릭해 기존에 설정 해두었던 로드밸런서 설정을 삭제 합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  기존 설정을 삭제하고 나면 [SSL Certificate] 항목에 아래와 같이 인증서 정보가 사라진 것을 확인할 수 있습니다.\n다음으로 기존과 동일한 설정(로드밸런서 포트가 443)을 입력하고 [추가] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [추가] 버튼을 클릭하면 [SSL Certificate 입력] 팝업이 나타나는데 여기서 [SSL Certificate 선택] 옵션에서 test2를 선택하고 [확인] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  그러면 아래와 같이 기존에 설정되어 있던 ‘tes1’ 인등서가 ‘test2’ 인증서로 변경 되어 있는 것을 확인 할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  VPC 환경에서 Application Load Balancer 생성하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud_networking_load_balancer_application_lb.html\n    \n  \n  Ncloud Classic 환경에서 Load Balancer 생성하기\n    \n      https://guide.ncloud-docs.com/docs/loadbalancer-classiclb-classic\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-08-30\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-proxy-protocol-client-ip-logging-centos-html": {
						"id": "networking-ncloud-networking-proxy-protocol-client-ip-logging-centos-html",
						"title": "Proxy Protocol을 이용해 Client IP 확인하기 | CentOS",
						"categories": "",
						"url": " /networking/ncloud-networking-proxy-protocol-client-ip-logging-centos.html",
						"content": "개요\nNcloud Load Balancer는 HTTP, HTTPS, TCP, SSL 이렇게 4가지의 프로토콜을 지원합니다.\n그런데, Load Balancer를 사용하면서 Client IP를 확인하려고 할 때 http, https 통신의 경우 X-Forwarded-For 헤더값이 지원되기에 Client IP를 확인할 수 있지만, \nTCP 통신의 경우 X-Forwarded-For 헤더를 사용할 수 없기에 Client IP를 확인하기 위해서는 Proxy Protocol 옵션을 활성화 시켜야 합니다.\n\n여기서는 Ncloud Network Proxy Load Balancer의 TCP 프로토콜을 사용하면서 Proxy Protocol 옵션을 활성화시켜 CentOS 서버에서 Client IP를 기록하는 방법을 소개하겠습니다.\n\n테스트 환경\n\n  VPC 환경\n  CentOS 7.8\n  Apache 2.4.6\n  Network Proxy Load Balancer\n  Protocol/Port: TCP/80\n\n\nCentOS 서버 설치\n서버를 생성하고 Apache 웹서버와 개발용 추가 모듈이 포함된 httpd-devel 패키지를 설치하고 간단한 웹페이지를 만들어 접속해 보았습니다.\n\n\n⁃ VPC 환경에서 서버 생성하는 방법\n\n\n~# yum -y install httpd httpd-devel\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정\n우선 Load Balancer를 생성하기 전에 Load Balancer에서 사용할 Target Group을 [Load Balancer] - [Target Group]에서 생성합니다.\n\n\n  Target Group 생성\nTarget Group의 이름를 입력하고 Target 유형은 [VPC Server]를 선택, 다음으로 VPC 대역을 선택합니다.\n그리고, 프로토콜은 PROXY_TCP를 선택하고, 포트는 80포트를 사용하겠습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Health Check 설정\nHealth Check 할 프로토콜은 TCP를 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Target 추가\n앞에서 생성했던 서버 2대를 선택하고 [적용 Target]쪽으로 이동시킵니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  설정 확인\n설정 정보를 최종 확인하고 이상이 없으면 Target Group을 생성합니다.\n\n\n\n  \n  \n    \n  \n\n\n생성된 Target Group를 확인할 수 있습니다.\n\n  \n  \n    \n  \n\n\nNetwork Proxy Load Balancer 생성\n[Load Balancer]에서 [로드밸런서 생성] 버튼을 클릭하고  [네트워크 프록시 로드밸런서]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  로드밸런서 설정\n필요한 로드밸런서 설정을 선택하는데, 그 중에서 서브넷은 혹시 생성되어 있지 않으면 [서브넷 생성] 버튼을 클릭해 로드밸런서 전용 서브넷을 생성한 후에 다시 돌아옵니다. 여기서는 [10.0.4.0/24] 대역으로 설정했습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  리스너 설정\n리스너는 TCP 프로토콜에 80 포트를 선택하고 추가합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  **Target Group 선택\nTarget Group는 위쪽에서 생성한 [Proxy-Protocol-TG] 을 선택합니다. 선택하면 해당 Target Group 설정 내용을 바로 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  설정 확인\n선택한 설정을 최종 확인하고 이상이 없으면 [로드밸런서 생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  생성 확인\n생성된 로드밸런서의 정보를 확인합니다. 특히 접속 정보와 서브넷은 이후 테스트에 사용되므로 꼭 기억하거나 메모해 두는 것이 좋습니다.\n\n\n\n  \n  \n    \n  \n\n\nACG 설정\n로드밸런서 → 서버 접속이 가능하도록 서버 ACG에 규칙을 추가합니다.\n서버에 적용된 ACG의 규칙 설정 화면에서 프로토콜은 TCP,  접근소스는 로드밸런서 IP 대역인 10.0.4.0/24, 포트는 80을 입력하고 추가합니다.\n\n\n  \n  \n    \n  \n\n\n로드밸런서 접속 테스트\n위에서 생성된 로드밸런서 접속 주소로 접속을 해보면 아래와 같은 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  Apache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하지만, 저희는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해보겠습니다.\n  CentOS Apache 로그파일 위치 : /var/log/httpd/access_log\n\n\n\n⁃ Cloud Log Analytics 설정 가이드\n\n\nCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 Load Balancer의 IP 대역 (10.0.4.xx)이 기록된 것을 확인할 수 있습니다.\n\n다음에는 로드밸런서 IP가 아닌 실제 Client IP가 기록되도록 설정을 변경해 보겠습니다.\n\n\n  \n  \n    \n  \n\n\nProxy Protocol 설정\n이제 실제 Client IP가 기록되도록 Proxy Protocol을 설정해보겠습니다.\n[Load Balancer] - [Target Group]에서 위에서 생성했던 Target Group를 선택하고 [TargetGroup 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정 화면에서 [ProxyProtocol] 옵션을 체크하고 확인 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n위에서 정상적으로 접속이 되었던 로드밸런서 주소로 접속하면 [Bad Request] 메시지가 뜨는 것을 확인할 수 있습니다.\n다음으로는 서버 설정을 변경해야 합니다.\n\n\n  \n  \n    \n  \n\n\nApache 모듈 설치\nProxy Protocol을 사용할 때 필요한 Apache 모듈을 CentOS 서버에 설치하겠습니다.\n\n\n  mod_myfixip 모듈 다운로드\n아래 명령어로 mod_myfixip.c 파일을 다운로드 받습니다. 정상적으로 다운로드가 완료되면 ‘mod_myfixip.c’ saved 라는 메시지를 확인할 수 있습니다.\n\n\n~# wget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache24-modules/master/mod_myfixip.c\n\n\n\n  \n  \n    \n  \n\n\n\n  모듈 설치\n이어서 /{아파치가 설치된 경로}/bin/apxs -c -i mod_myfixip.c 명령어로 모듈을 설치합니다.\n\n\n~# /usr/bin/apxs -c -i mod_myfixip.c\n\n\n  \n  \n    \n  \n\n\n\n  httpd.conf 설정 변경\n모듈 설치가 완료된 후에 httpd.conf 파일을 열어서 제일 아래쪽에 아래 코드를 추가합니다.\nRewriteIPAllow 항목에는 로드밸런서 IP 대역 (ex: 192.168.0.0/16, 10.31.0.0/16 등)을 입력합니다.\n여기서는 위에서 설정했던 로드밸런서 IP 대역인 10.0.4.0/24를 입력했습니다.\n\n\n~# vi /etc/httpd/conf/httpd.conf\n\nLoadModule myfixip_module modules/mod_myfixip.so\n\n&lt;IfModule mod_myfixip.c&gt;\n  RewriteIPResetHeader off\n  RewriteIPAllow 10.0.4.0/24\n&lt;/IfModule&gt;\n\n\n\n  \n  \n    \n  \n\n\n\n  Apache 재시작\n설정을 마친 후에 Apache를 재시작합니다.\n\n\n~# systemctl restart httpd\n\n\n  \n  \n    \n  \n\n\n최종 접속 테스트\n모든 설정을 모두 마친 후에 서버에 접속해봅니다.\n\n\n  \n  \n    \n  \n\n\n최종 접속 로그 확인\n접속 로그를 다시 확인해보면 이번에는 로드밸런서 IP가 아닌 Client IP가 기록된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n\n  Ncloud Proxy Protocol 설정하기 가이드\n    \n      https://guide.ncloud-docs.com/docs/loadbalancer-targetgroup-vpc#proxy-protocol-%EC%84%A4%EC%A0%95\n    \n  \n  Ubuntu 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud-networking-proxy-protocol-client-ip-logging-ubuntu.html\n    \n  \n  Rocky Linux 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud-networking-proxy-protocol-client-ip-logging-rocky-linux.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-08-22\n          참고 URL 링크 수정"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-proxy-protocol-client-ip-logging-rocky-linux-html": {
						"id": "networking-ncloud-networking-proxy-protocol-client-ip-logging-rocky-linux-html",
						"title": "Proxy Protocol을 이용해 Client IP 확인하기 | Rocky Linux",
						"categories": "",
						"url": " /networking/ncloud-networking-proxy-protocol-client-ip-logging-rocky-linux.html",
						"content": "개요\nNcloud Load Balancer는 HTTP, HTTPS, TCP, SSL 이렇게 4가지의 프로토콜을 지원합니다.\n그런데, Load Balancer를 사용하면서 Client IP를 확인하려고 할 때 http, https 통신의 경우 X-Forwarded-For 헤더값이 지원되기에 Client IP를 확인할 수 있지만, \nTCP 통신의 경우 X-Forwarded-For 헤더를 사용할 수 없기에 Client IP를 확인하기 위해서는 Proxy Protocol 옵션을 활성화 시켜야 합니다.\n\n여기서는 Ncloud Network Proxy Load Balancer의 TCP 프로토콜을 사용하면서 Proxy Protocol 옵션을 활성화시켜 Rocky Linux 서버에서 Client IP를 기록하는 방법을 소개하겠습니다.\n\n테스트 환경\n\n  VPC 환경\n  Rocky Linux 8.6\n  Apache 2.4.6\n  Network Proxy Load Balancer\n  Protocol/Port: TCP/80\n\n\nRocky Linux 서버 설치\n서버를 생성하고 Apache 웹서버와 개발용 추가 모듈이 포함된 httpd-devel 패키지를 설치하고 간단한 웹페이지를 만들어 접속해 보겠습니다.\n\n\n⁃ VPC 환경에서 서버 생성하는 방법\n\n\n~# dnf -y install httpd httpd-devel\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정\n우선 Load Balancer를 생성하기 전에 Load Balancer에서 사용할 Target Group을 [Load Balancer] - [Target Group]에서 생성합니다.\n\n\n  Target Group 생성\nTarget Group의 이름를 입력하고 Target 유형은 [VPC Server]를 선택, 다음으로 VPC 대역을 선택합니다.\n그리고, 프로토콜은 PROXY_TCP를 선택하고, 포트는 80포트를 사용하겠습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Health Check 설정\nHealth Check 할 프로토콜은 TCP를 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Target 추가\n앞에서 생성했던 서버를 선택하고 [적용 Target]쪽으로 이동시킵니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  설정 확인\n설정 정보를 최종 확인하고 이상이 없으면 Target Group을 생성합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  생성된 Target Group를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nNetwork Proxy Load Balancer 생성\n[Load Balancer]에서 [로드밸런서 생성] 버튼을 클릭하고  [네트워크 프록시 로드밸런서]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  로드밸런서 설정\n필요한 로드밸런서 설정을 선택하는데, 그 중에서 서브넷은 혹시 생성되어 있지 않으면 [서브넷 생성] 버튼을 클릭해 로드밸런서 전용 서브넷을 생성한 후에 다시 돌아옵니다. 여기서는 [10.0.4.0/24] 대역으로 설정했습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  리스너 설정\n리스너는 TCP 프로토콜에 80 포트를 선택하고 추가합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Target Group 선택\nTarget Group는 위쪽에서 생성한 [Proxy-Protocol-TG] 을 선택합니다. 선택하면 해당 Target Group 설정 내용을 바로 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  설정 확인\n선택한 설정을 최종 확인하고 이상이 없으면 [로드밸런서 생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  생성 확인\n생성된 로드밸런서의 정보를 확인합니다. 특히 접속 정보와 서브넷은 이후 테스트에 사용되므로 꼭 기억하거나 메모해 두는 것이 좋습니다.\n\n\n\n  \n  \n    \n  \n\n\nACG 설정\n로드밸런서 → 서버 접속이 가능하도록 서버 ACG에 규칙을 추가합니다.\n서버에 적용된 ACG의 규칙 설정 화면에서 프로토콜은 TCP,  접근소스는 로드밸런서 IP 대역인 10.0.4.0/24, 포트는 80을 입력하고 추가합니다.\n\n\n  \n  \n    \n  \n\n\n로드밸런서 접속 테스트\n위에서 생성된 로드밸런서 접속 주소로 접속을 해보면 아래와 같은 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n    Apache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하고, 원래는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해아야 하지만, \nRocky Linux는 아직 Cloud Log Analytics Agent를 지원하지 않아 서버에서 직접 로그를 확인해보았습니다.\n  \n  \n    Rocky Linux Apache 로그파일 위치 : /var/log/httpd/access_log\n  \n\n\nApache 접속 로그를 확인해보면 위에서 설정했던 Load Balancer의 IP 대역 (10.0.4.xx)이 기록된 것을 확인할 수 있습니다.\n\n다음에는 로드밸런서 IP가 아닌 실제 Client IP가 기록되도록 설정을 변경해 보겠습니다.\n\n~# cat /var/log/httpd/access_log\n\n\n  \n  \n    \n  \n\n\nProxy Protocol 설정\n이제 실제 Client IP가 기록되도록 Proxy Protocol을 설정해보겠습니다.\n[Load Balancer] - [Target Group]에서 위에서 생성했던 Target Group를 선택하고 [TargetGroup 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정 화면에서 [ProxyProtocol] 옵션을 체크하고 확인 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n위에서 정상적으로 접속이 되었던 로드밸런서 주소로 접속하면 [Bad Request] 메시지가 뜨는 것을 확인할 수 있습니다.\n다음으로는 서버 설정을 변경해야 합니다.\n\n\n  \n  \n    \n  \n\n\nApache 모듈 설치\nProxy Protocol을 사용할 때 필요한 Apache 모듈을 Rocky Linux 서버에 설치하겠습니다.\n\n\n  mod_myfixip 모듈 다운로드\n아래 명령어로 mod_myfixip.c 파일을 다운로드 받습니다. 정상적으로 다운로드가 완료되면 ‘mod_myfixip.c’ saved 라는 메시지를 확인할 수 있습니다.\n\n\n# Apache 2.4\n~# wget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache24-modules/master/mod_myfixip.c\n\n# Apache 2.2\n# wget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache22-modules/master/mod_myfixip.c\n\n\n\n  \n  \n    \n  \n\n\n\n  모듈 설치\n이어서 /{아파치가 설치된 경로}/bin/apxs -c -i mod_myfixip.c 명령어로 모듈을 설치합니다.\n\n\n~# /usr/bin/apxs -c -i mod_myfixip.c\n\n\n  \n  \n    \n  \n\n\n\n  httpd.conf 설정 변경\n모듈 설치가 완료된 후에 httpd.conf 파일을 열어서 제일 아래쪽에 아래 코드를 추가합니다.\nRewriteIPAllow 항목에는 로드밸런서 IP 대역 (ex: 192.168.0.0/16, 10.31.0.0/16 등)을 입력합니다.\n여기서는 위에서 설정했던 로드밸런서 IP 대역인 10.0.4.0/24를 입력했습니다.\n\n\n~# vim /etc/httpd/conf/httpd.conf\n\nLoadModule myfixip_module modules/mod_myfixip.so\n\n&lt;IfModule mod_myfixip.c&gt;\n  RewriteIPResetHeader off\n  RewriteIPAllow 10.0.4.0/24\n&lt;/IfModule&gt;\n\n\n\n  \n  \n    \n  \n\n\n\n  Apache 재시작\n설정을 마친 후에 Apache를 재시작합니다.\n\n\n~# systemctl restart httpd\n\n\n  \n  \n    \n  \n\n\n최종 접속 테스트\n모든 설정을 모두 마친 후에 서버에 접속해봅니다.\n\n\n  \n  \n    \n  \n\n\n최종 접속 로그 확인\nApache 접속 로그를 다시 확인해보면 이번에는 로드밸런서 IP가 아닌 Client IP가 기록된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n\n  Proxy Protocol 설정하기\n    \n      https://guide.ncloud-docs.com/docs/loadbalancer-targetgroup-vpc#proxy-protocol-%EC%84%A4%EC%A0%95\n    \n  \n  Ubuntu 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud-networking-proxy-protocol-client-ip-logging-ubuntu.html\n    \n  \n  CentOS 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud-networking-proxy-protocol-client-ip-logging-centos.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-08-23\n          문서 최초 생성"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-proxy-protocol-client-ip-logging-ubuntu-html": {
						"id": "networking-ncloud-networking-proxy-protocol-client-ip-logging-ubuntu-html",
						"title": "Proxy Protocol을 이용해 Client IP 확인하기 | Ubuntu",
						"categories": "",
						"url": " /networking/ncloud-networking-proxy-protocol-client-ip-logging-ubuntu.html",
						"content": "개요\nNcloud Load Balancer는 HTTP, HTTPS, TCP, SSL 이렇게 4가지의 프로토콜을 지원합니다.\n그런데, Load Balancer를 사용하면서 Client IP를 확인하려고 할 때 http, https 통신의 경우 X-Forwarded-For 헤더값이 지원되기에 Client IP를 확인할 수 있지만, \nTCP 통신의 경우 X-Forwarded-For 헤더를 사용할 수 없기에 Client IP를 확인하기 위해서는 Proxy Protocol 옵션을 활성화 시켜야 합니다.\n\n여기서는 Ncloud Network Proxy Load Balancer의 TCP 프로토콜을 사용하면서 Proxy Protocol 옵션을 활성화시켜 Ubuntu 서버에서 Client IP를 기록하는 방법을 소개하겠습니다.\n\n테스트 환경\n\n  VPC 환경\n  Ubuntu 18.04\n  Apache 2.4.6\n  Network Proxy Load Balancer\n  Protocol/Port: TCP/80\n\n\nUbuntu 서버 설치\n서버를 생성하고 Apache 웹서버와 개발용 추가 모듈이 포함된 apache2-dev 패키지를 설치하고 간단한 웹페이지를 만들어 접속해 보았습니다.\n\n\n⁃ VPC 환경에서 서버 생성하는 방법\n\n\n~# apt-get update\n~# apt-get -y install apache2 apache2-dev\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정\n우선 Load Balancer를 생성하기 전에 Load Balancer에서 사용할 Target Group을 [Load Balancer] - [Target Group]에서 생성합니다.\n\n\n  Target Group 생성\nTarget Group의 이름를 입력하고 Target 유형은 [VPC Server]를 선택, 다음으로 VPC 대역을 선택합니다.\n그리고, 프로토콜은 PROXY_TCP를 선택하고, 포트는 80포트를 사용하겠습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Health Check 설정\nHealth Check 할 프로토콜은 TCP를 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Target 추가\n앞에서 생성했던 서버 2대를 선택하고 [적용 Target]쪽으로 이동시킵니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  설정 확인\n설정 정보를 최종 확인하고 이상이 없으면 Target Group을 생성합니다.\n\n\n\n  \n  \n    \n  \n\n\n생성된 Target Group를 확인할 수 있습니다.\n\n  \n  \n    \n  \n\n\nNetwork Proxy Load Balancer 생성\n[Load Balancer]에서 [로드밸런서 생성] 버튼을 클릭하고  [네트워크 프록시 로드밸런서]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  로드밸런서 설정\n필요한 로드밸런서 설정을 선택하는데, 그 중에서 서브넷은 혹시 생성되어 있지 않으면 [서브넷 생성] 버튼을 클릭해 로드밸런서 전용 서브넷을 생성한 후에 다시 돌아옵니다. 여기서는 [10.0.4.0/24] 대역으로 설정했습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  리스너 설정\n리스너는 TCP 프로토콜에 80 포트를 선택하고 추가합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  Target Group 선택\nTarget Group는 위쪽에서 생성한 [Proxy-Protocol-TG] 을 선택합니다. 선택하면 해당 Target Group 설정 내용을 바로 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  설정 확인\n선택한 설정을 최종 확인하고 이상이 없으면 [로드밸런서 생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  생성 확인\n생성된 로드밸런서의 정보를 확인합니다. 특히 접속 정보와 서브넷은 이후 테스트에 사용되므로 꼭 기억하거나 메모해 두는 것이 좋습니다.\n\n\n\n  \n  \n    \n  \n\n\nACG 설정\n로드밸런서 → 서버 접속이 가능하도록 서버 ACG에 규칙을 추가합니다.\n서버에 적용된 ACG의 규칙 설정 화면에서 프로토콜은 TCP,  접근소스는 로드밸런서 IP 대역인 10.0.4.0/24, 포트는 80을 입력하고 추가합니다.\n\n\n  \n  \n    \n  \n\n\n로드밸런서 접속 테스트\n위에서 생성된 로드밸런서 접속 주소로 접속을 해보면 아래와 같은 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  Apache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하지만, 저희는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해보겠습니다.\n  Ubuntu Apache 로그파일 위치 : /var/log/apache2/access.log\n\n\n\n⁃ Cloud Log Analytics 설정 가이드\n\n\nCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 Load Balancer의 IP 대역 (10.0.4.xx)이 기록된 것을 확인할 수 있습니다.\n\n다음으로는 로드밸런서 IP가 아닌 실제 Client IP가 기록되도록 설정을 변경해 보겠습니다.\n\n\n  \n  \n    \n  \n\n\nProxy Protocol 설정\n이제 실제 Client IP가 기록되도록 Proxy Protocol을 설정해보겠습니다.\n[Load Balancer] - [Target Group]에서 위에서 생성했던 Target Group를 선택하고 [TargetGroup 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 설정 화면에서 [ProxyProtocol] 옵션을 체크하고 확인 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n위에서 정상적으로 접속이 되었던 로드밸런서 주소로 접속하면 [Bad Request] 메시지가 뜨는 것을 확인할 수 있습니다.\n다음으로는 서버 설정을 변경해야 합니다.\n\n\n  \n  \n    \n  \n\n\nApache 모듈 설치\nProxy Protocol을 사용할 때 필요한 Apache 모듈을 Ubuntu 서버에 설치하겠습니다.\n\n\n  mod_myfixip 모듈 다운로드\n아래 명령어로 mod_myfixip.c 파일을 다운로드 받습니다. 정상적으로 다운로드가 완료되면 ‘mod_myfixip.c’ saved 라는 메시지를 확인할 수 있습니다.\n\n\n~# wget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache24-modules/master/mod_myfixip.c\n\n\n\n  \n  \n    \n  \n\n\n\n  모듈 설치\n이어서 apxs2 -c -i mod_myfixip.c 명령어로 모듈을 설치합니다.\n\n\n~# apxs2 -c -i mod_myfixip.c\n\n\n\n  \n  \n    \n  \n\n\n\n  myfixip.load 파일 생성\nmod_myfixip 모듈을 로드하기 위한 파일을 생성하고, LoadModule 관련 코드를 추가합니다.\n\n\n~# vi /etc/apache2/mods-available/myfixip.load\n\nLoadModule myfixip_module /usr/lib/apache2/modules/mod_myfixip.so\n\n\n\n  \n  \n    \n  \n\n\n\n  myfixip.conf 파일 생성\nmod_myfixip 모듈 환경 설정 파일을 생성하고 모듈 관련 코드를 추가합니다.\nRewriteIPAllow 항목에는 로드밸런서 IP 대역 (ex: 192.168.0.0/16, 10.31.0.0/16 등)을 입력합니다.\n여기서는 위에서 설정했던 로드밸런서 IP 대역인 10.0.4.0/24를 입력했습니다.\n\n\n~# vi /etc/apache2/mods-available/myfixip.conf\n\n&lt;IfModule mod_myfixip.c&gt;\n  RewriteIPResetHeader off\n  RewriteIPAllow 10.0.4.0/24\n&lt;/IfModule&gt;\n\n\n  \n  \n    \n  \n\n\n\n  모듈 설치, Apache 재시작\n다음 명령으로 myfixip 모듈을 설치하고 Apache를 재시작합니다.\n\n\n~# a2enmod myfixip\n~# systemctl restart apache2\n\n\n  \n  \n    \n  \n\n\n최종 접속 테스트\n모든 설정을 모두 마친 후에 서버에 접속해봅니다.\n\n\n  \n  \n    \n  \n\n\n최종 접속 로그 확인\n접속 로그를 다시 확인해보면 이번에는 로드밸런서 IP가 아닌 Client IP가 기록된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고URL\n\n\n  Ncloud Proxy Protocol 설정하기 가이드\n    \n      https://guide.ncloud-docs.com/docs/loadbalancer-targetgroup-vpc#proxy-protocol-%EC%84%A4%EC%A0%95\n    \n  \n  CentOS 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud-networking-proxy-protocol-client-ip-logging-centos.html\n    \n  \n  Rocky Linux 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n    \n      https://docs.3rdeyesys.com/networking/ncloud-networking-proxy-protocol-client-ip-logging-rocky-linux.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-08-22\n          참고 URL 링크 수정"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-acg-setting-sample-html": {
						"id": "security-ncloud-security-acg-setting-sample-html",
						"title": "Ncloud 방화벽 ACG 권장설정과 Custom ACG 설정 예시",
						"categories": "",
						"url": " /security/ncloud-security-acg-setting-sample.html",
						"content": "개요\nNcloud (네이버 클라우드)의 IP/Port 기반 필터링 방화벽 서비스인 ACG(Access Control Group) 권장설정과 Custom ACG 설정할 때 참고할 만한 예시를 몇가지 정리해보겠습니다.\n\nInboud 기본 규칙 삭제\n\n서버 생성 시에 기본으로 생성되는 Default ACG에는 아래처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 접근이 허용되어 있는데 보안을 위해 이 항목을 삭제하고 지정된 IP에서만 접속하도록 수정하는 것을 적극 권장합니다.\n\nVPC 화면\n\n아래는 Default ACG가 생성되면서 설정된 전체 접근 허용 상태입니다. 여기서 X버튼을 클릭해서 [0.0.0.0/0] 대역의 설정 2가지를 모두 삭제합니다.\n\n  \n  \n    \n  \n\n\n위에서 기본 설정을 삭제하고 특정 IP만 접근 허용 상태입니다.\n일반적으로 [myip] 버튼을 클릭해서 현재 접속한 PC의 IP를 허용하게 됩니다.\n\n  \n  \n    \n  \n\n\nClassic 화면\n\n아래도 Default ACG가 생성되면서 설정된 전체 접근 허용 상태입니다. 여기서 X버튼을 클릭해서 [0.0.0.0/0] 대역의 설정 2가지를 모두 삭제합니다.\n\n  \n  \n    \n  \n\n\n위에서 기본 설정을 삭제하고 특정 IP만 접근 허용한 상태입니다.\n일반적으로 [myip] 버튼을 클릭해서 현재 접속한 PC의 IP를 허용하게 됩니다.\n\n  \n  \n    \n  \n\n\n용도별 ACG 구분\nACG는 사용하는 서버들을 용도별로 구분해서 기본 ACG외에 별도의 Custom ACG를 아래의 예시처럼 그룹별로 생성해서 적용하는 것이 좋습니다.\n\nVPC 환경에서 ACG 생성\n[Server] - [ACG]에서 생성할 수 있으며 이름 규칙은 최소 3자, 최대 30자, 소문자만, 숫자와 하이픈(-) 사용 가능합니다.\n그리고, ACG를 적용할 VPC도 선택해야 합니다.\n\n\n  \n  \n    \n  \n\n\nClassic 환경에서 ACG 생성\n[Server] - [ACG]에서 생성할 수 있으며 이름 규칙은 최소 6자, 최대 30자, 소문자만, 숫자와 하이픈(-) 사용 가능합니다.\n\n\n  \n  \n    \n  \n\n\n용도별 Custom ACG 생성 예시\n아래의 Custom ACG 명칭은 임의로 작성한 것이며, 어떤 규칙으로 이름을 정할 것인가는 각자 자체 기준에 따라 편하신대로 정하시면 됩니다.\n\n\n  DB-ACG\n  APP-ACG\n  WAS-ACG\n  WEB-ACG\n  BILL-ACG\n  Jenkins-ACG\n  Login-Server-ACG\n  Lobby-Server-ACG\n  Chat-Server-ACG\n  PVP-Server-ACG\n  Live-Streaming-ACG\n  VOD-Server-ACG\n  API-Server-ACG\n  Bill-DB-ACG\n  Bill-APP-ACG\n  Admin-Tool-ACG\n  Live-Service-ACG\n  Dev-System-ACG\n  QA-System-ACG\n  Home-Access-ACG\n  External-Developer-ACG\n  Partner-Company-ACG\n\n\n복수의 ACG 적용\n1개 서버에 허용이 필요한 설정을 모두 추가한 1개의 ACG만 무리하게 적용하려 하기 보다는 위의 예시처럼 용도별로 구분한 ACG를 여러 개 적용하는 것을 추천합니다.\n예를 들어 아래와 같이 각각의 용도별 서버들에는 이런 식으로 ACG를 구분해서 적용할 수도 있습니다.\n\n예를 들어 채팅 서버에 ACG를 적용할 때의 예시는 다음과 같습니다.\n\n  적용 ACG: APP-ACG, Chat-Server-ACG\n\n\n마찬가지로 QA 빌링 DB에 ACG를 적용할 때의 예시는 다음과 같습니다.\n\n  적용 ACG: DB-ACG, BILL-ACG, QA-System-ACG\n\n\nCustom ACG 적용 순서\n\n\n  ACG 생성\n    \n      우선 위의 방법대로 ACG를 용도별로 구분해서 생성합니다.\n    \n  \n  ACG 적용\n    \n      다음으로 생성한 ACG를 서버에 적용하는 단계입니다. 아래쪽에서 VPC, Classic 각각의 환경별로 살펴보겠습니다.\n    \n  \n\n\nVPC 환경\nVPC 환경은 NIC에 ACG가 적용되는 구조이므로 NIC당 최대 3개까지 할당할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nClassic 환경\nClassic 환경에서는 서버에 적용되는 구조이고, 최대 5개까지 선택 가능합니다.\n\n이때 Classic 환경 ACG는 서버를 생성하는 단계에서만 적용할 수 있습니다. 서버 생성이 완료된 후에는 추가로 ACG를 적용할 수 없습니다.\n\n\n  \n  \n    \n  \n\n\nCustom ACG 추가 적용-제거\nClassic 환경과 달리 VPC 환경에서는 ACG가 서버가 아닌 NIC에 적용되는 구조이며, 기존에 적용된 ACG외에 추가로 ACG를 적용하거나 제거할 수 있습니다.\n\n아래와 같이 서버 상세정보 NIC 항목에서 [ACG 수정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 추가 적용\nACG 수정 화면에서 왼쪽 창에서 적용하려는 ACG를 선택하고 오른쪽 창으로 이동시키면 됩니다.\n\n\n  \n  \n    \n  \n\n\nACG 제거\nACG 수정 화면에서 오른쪽 창에서 제거하려는 ACG를 선택하고 왼쪽 창으로 이동시키면 됩니다.\n\n이때 ACG는 최소 1개가 적용되어 있어야 하므로 마지막 ACG 1개는 제거할 수 없습니다.\n\n\n  \n  \n    \n  \n\n\n접근소스를 Load Balancer로 설정\nACG를 설정할 때 접근 소스 항목은 보통 IP주소를 입력하게 됩니다. \n하지만 특수한 경우로 Load Balancer를 지정하거나 ACG를 직접 지정하는 경우도 있습니다.\n\n먼저 로드밸런서를 생성하고 서버와 연결한 후에 서버측 ACG에 로드밸런서의 접근을 허용하는 방법에 대해 알아보겠습니다.\n\nVPC 환경\nVPC 환경에서 아래와 같이 로드밸런서의 서브넷 네트워크가 [10.0.4.0/24] 대역이라고 가정해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n서버의 ACG 규칙 설정 화면에서 아래와 같이 접근소스에 위에서 확인한 로드밸런서의 서브넷 네트워크 [10.0.4.0/24]를 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\nVPC 환경에서 로드밸런서와 서버를 연결할 때에는 ACG 설정 외에도 Network ACL 등 추가로 설정해야 하는 것들이 많이 있습니다. 자세한 설정 방법은 아래 문서를 참고하시기 바랍니다. \n⁃ VPC 환경에서 Application Load Balancer 생성하기\n\n\nClassic 환경\nClassic 환경에서는 아래와 같이 로드밸런서의 ACG 소스 명칭이 [ncloud-load-balancer]로 고정되어 있습니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정 화면에서 접근소스에 로드밸런서의 ACG 소스 [ncloud-load-balancer]를 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n접근소스를 ACG로 설정\n다음으로 다른 ACG를 접근소스로 지정하는 경우도 있습니다. 이것은 해당 ACG가 적용된 서버들이 접근할 수 있도록 규칙을 설정하는 것인데, 아래 설정 방법과 예시를 통해 자세히 알아보겠습니다.\n\nVPC 환경\nACG 규칙 설정에서 접근 소스 항목에 지정하려는 ACG 이름을 일부 입력하면 아래와 같이 적용 가능한 ACG 리스트가 나타는데 그 중에서 지정하려는 ACG를 선택하면 됩니다.\n\nVPC 환경에서 ACG를 접근소스를 설정할 때는 동일한 VPC에 생성된 ACG만 접근소스로 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nClassic 환경\nClassic도 마찬가지로 ACG 규칙 설정에서 접근 소스 항목에 지정하려는 ACG 이름을 일부 입력하면 아래와 같이 적용 가능한 ACG 리스트가 나타는데 그 중에서 지정하려는 ACG를 선택하면 됩니다. Classic은 VPC와 달리 특별한 제한이 없습니다.\n\n\n  \n  \n    \n  \n\n\n예시\n아래와 같이 SVR-1, SVR-2, SVR-3 서버에 각각 ACG-1, ACG-2가 적용되어 있다고 가정해보겠습니다.\n\n[ACG-1]\n\n  적용서버 : SVR-1, SVR-2\n\n\n[ACG-2]\n\n  적용서버 : SVR-3\n\n\n[ACG-2 적용 규칙]\n\n  프로토콜 :  TCP\n  접근소스 :  ACG-1\n  허용포트 : 80\n\n\n Note: 위와 같은 경우 ACG-1이 적용된 SVR-1, SVR-2 서버에서 ACG-2가 적용된 SVR-3 서버로 80포트를 이용한 접근을 허용한다는 의미입니다.\n\nACG 삭제\nCustom ACG는 VPC, Classic 환경 모두 [Console] - [Server] - [ACG] 메뉴에서 삭제할 수 있습니다.\n\n삭제하려는 ACG를 선택하고 [ACG 삭제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 삭제 팝업에서 [예] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n삭제 불가\n아직 적용된 서버나 NIC가 존재하는 ACG는 삭제할 수 없습니다.\n\nVPC 환경\nVPC 환경에서 삭제를 시도하면 [ACG에 속해 있는 Network Interface가 존재합니다. 해당 Network Interface에서 ACG를 삭제 후 다시 시도해주세요]라는 메시지가 나타납니다.\n\n  \n  \n    \n  \n\n\nClassic 환경\nClassic 환경에서 삭제를 시도하면 [서버가 한대라도 ACG 에 적용되어 있는 상태이면, 해당 ACG 는 삭제할 수 없습니다]라는 메시지가 나타납니다.\n\n\n  \n  \n    \n  \n\n\nDefault ACG 삭제 불가\n기본적으로 생성된 Default ACG는 삭제할 수 없습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  VPC 환경 ACG 설정\n    \n      https://guide.ncloud-docs.com/docs/compute-compute-2-3-vpc\n    \n  \n  Classic 환경 ACG 설정\n    \n      https://guide.ncloud-docs.com/docs/compute-compute-2-3"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-certificate-manager-register-ssl-certificate-guide-html": {
						"id": "security-ncloud-security-certificate-manager-register-ssl-certificate-guide-html",
						"title": "Ncloud Certificate Manager SSL 인증서 등록 가이드",
						"categories": "",
						"url": " /security/ncloud-security-certificate-manager-register-ssl-certificate-guide.html",
						"content": "개요\nNcloud (네이버 클라우드)에는 인증서를 관리할 수 있는 Certificate Manager 서비스가 있는데, 여기에 SSL 인증서를 등록해두면 Load Balancer 등을 생성할 때 간단하게 인증서를 적용할 수 있습니다.\n\nCertificate Manager 특징\n\n\n  인증서 등록 및 서비스 연동: 공인 SSL 인증서를 등록하여 연계 서비스(Load Balancer, CDN+ 등)에 적용 가능\n  인증서 정보 제공: 등록된 인증서의 다양한 정보를 제공하여 인증서의 효율적 관리 가능\n  인증서 만료 알림: 등록된 인증서의 만료 예정일 30일 전부터 5일 단위로 알림(SMS/Email) 발송\n\n\n조회 가능한 인증서 정보\n아래와 같은 인증서 정보를 조회할 수 있습니다.\n\n\n  \n    \n      항목\n      내용\n    \n  \n  \n    \n      인증서 이름\n      고객이 설정한 인증서 이름\n    \n    \n      도메인\n      인증서 대표 도메인(DN)\n    \n    \n      추가도메인\n      인증서에 포함된 하위 도메인(SAN)\n    \n    \n      상태\n      정상, 만료\n    \n    \n      인증 시작일\n      인증 개시일\n    \n    \n      인증 종료일\n      인증 종료일\n    \n    \n      발급기관\n      인증서 발급 기관 정보(Certificate Authority)\n    \n    \n      일련번호\n      인증서의 고유 번호\n    \n    \n      PK 정보\n      퍼블릭 키 정보\n    \n    \n      사용 서비스\n      연동된 서비스 및 인스턴스 번호\n    \n  \n\n\n대표적인 인증서 발급 사이트\n여러 인증서 발급 사이트 중에서 대표적인 몇 곳을 정리하면 다음과 같습니다.\n\n\n  \n    https://www.sslcert.co.kr/ (SecureSign)\n  \n  \n    https://cert.crosscert.com/ (한국전자인증)\n  \n  \n    https://hosting.whois.co.kr/new/ssl.php (후이즈)\n  \n\n\n인증서 파일 준비\n인증서 발급 업체에서 인증서를 발급 받으면 업체별로 제공하는 파일을 확인할 수 있습니다.\n대표적인 업체들이 제공하는 파일 형태를 4가지 정도의 예시를 통해 확인해보겠습니다.\n\n예시 1\n예시 1과 같은 형태의 경우 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 3가지 파일이니 기억해 두시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\n예시 2\n예시 2와 같은 형태도 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 3가지 파일이니 기억해 두시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\n예시 3\n예시 3과 같은 형태는 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 4가지 파일이니 기억해 두시기 바랍니다.\n\n\n  \n  \n    \n  \n\n\n예시 4\n예시 4과 같은 형태는 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 5가지 파일이니 기억해 두시기 바랍니다.\n예시 4와 유사한 형태의 경우는, 특히 CA 파일들과 Root CA 파일들이 모두 분리되어 제공되는 경우입니다.\n\n\n  \n  \n    \n  \n\n\n이용 신청\n인증서 파일을 준비했으므로 인증서를 [Certificate Manager]에 등록할 차례인데, [Certificate Manager]를 이용하려면 먼저 서비스 이용 신청을 해야 합니다.\n[Certificate Manager] - [Subscription]에서 [이용 신청] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n인증서 등록\n신청이 끝났으면, [Certificate Manager] - [Certificate List]에서 [외부 인증서 등록] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n인증서를 등록할 때는 아래와 같이 3가지 항목을 입력해야 하는데 각각의 항목에는 위에서 확인했던 3개의 인증서 파일의 내용을 복사해서 붙여넣기하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n아래와 같이 각각의 파일의 내용을 텍스트 편집기로 열어서 전체 내용을 각 항목에 입력하면 되는데, 위에서 살펴본 인증서 예시별로 확인해보겠습니다.\n\n예시 1\n\n  Private Key : [인증서 파일명].key.pem , 인증서에 대한 Private Key\n  Certificate Body : [인증서 파일명].crt.pem, 도메인에 대한 인증서\n  Certificate Chain : ca-chain-bundle.pem, CA와 Root CA 인증서를 합쳐 놓은 파일\n\n\n\n  \n  \n    \n  \n\n\n예시 2\n\n  Private Key : [인증서 파일명].key , 인증서에 대한 Private Key\n  Certificate Body : [인증서 파일명].crt , 도메인에 대한 인증서\n  Certificate Chain : chainca.crt (또는 chain.pem) , CA와 Root CA 인증서를 합쳐 놓은 파일\n\n\n\n  \n  \n    \n  \n\n\n예시 3\n\n  Private Key : [인증서 파일명]_key1.pem , 인증서에 대한 Private Key\n  Certificate Body : [인증서 파일명].crt , 도메인에 대한 인증서\n  Certificate Chain : (상위)chain.cer + (최상위)chain1.cer , CA와 Root CA 인증서 파일\n\n\n Certificate Chain: \n예시 3과 같은 형태의 인증서 파일을 제공 받았을 경우에는 \n(상위)chain.cer = CA이며, (최상위)chain1.cer = Root CA 파일입니다. \n두개의 파일을 텍스트 편집기로 열어서 각각의 파일 내용을 복사해서 Certificate Chain 항목에 두 파일의 내용을 모두 붙여 넣기 하시면 됩니다. \n주의할 점은, 두 파일의 내용 사이 또는 마지막에 줄바꿈 문자 즉, Enter 키는 1번까지만 가능하며 2번이상 들어가면 오류 메시지가 표시됩니다.\n\n\n\n  \n  \n    \n  \n\n\n예시 4\n\n  Private Key : [인증서 파일명]_key.pem , 인증서에 대한 Private Key\n  Certificate Body : [인증서 파일명].crt.pem , 도메인에 대한 인증서\n  Certificate Chain : chain1.crt.pem + chain2.crt.pem + root chain.crt.pem , CA와 Root CA 인증서 파일들\n\n\n Certificate Chain: \n예시 4과 같은 형태의 인증서 파일을 제공 받았을 경우에는 \nCA 파일이 chain1.crt.pem, chain2.crt.pem 처럼 2개 이상 제공되며, root chain.crt.pem = Root CA 파일입니다. \n제공되는 Chain 3개 또는 그 이상 개수의 파일을 텍스트 편집기로 열어서 각각의 파일 내용을 복사해 Certificate Chain 항목에 내용을 모두 붙여 넣기 하시면 됩니다. \n주의할 점은, 각각의 파일의 내용 사이 또는 마지막에 줄바꿈 문자 즉, Enter 키는 1번까지만 가능하며 2번이상 들어가면 오류 메시지가 표시됩니다.\n\n\n\n  \n  \n    \n  \n\n\n등록 완료\n인증서가 문제 없이 등록되면 아래와 같이 [정상]으로 표시가 되고 인증서의 각종 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n주의 사항\n\n  \n    파일 등록: 인증서 파일은 -----BEGIN RSA PRIVATE KEY----- 중간 생략  -----END RSA PRIVATE KEY----- 또는 -----BEGIN CERTIFICATE----- 중간 생략 -----END CERTIFICATE----- 와 같은 형식으로 구성되어 있는데, 인증서를 등록할 때는 인증서 파일을 수정하지 말고 파일의 처음부터 끝까지 모두 복사해서 등록하셔야 합니다.\n  \n  \n    체인 인증서 추출: 간혹 일부 업체의 경우 도메인 인증서 파일은 제공해주지만, CA 파일과 Root CA 파일은 제공해주지 않는 경우가 있습니다. 이럴 때는 아래에 있는 Ncloud 가이드 중에서 인증서 파일 추출 부분을 참고해서 CA 파일과 Root CA 파일을 추출한 다음에 등록하시면 됩니다.\n  \n\n\n참고 URL\n\n  Ncloud Certificate Manager 전체 가이드\n    \n      https://guide.ncloud-docs.com/docs/security-security-15-1\n    \n  \n  Ncloud Certificate Manager 인증서 파일 추출 가이드\n    \n      https://guide.ncloud-docs.com/docs/certificatemanager-use-list#CertificateChain%EB%93%B1%EB%A1%9D"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-security-monitoring-waf-price-info-html": {
						"id": "security-ncloud-security-security-monitoring-waf-price-info-html",
						"title": "Ncloud Security Monitoring WAF 서비스 요금 정보",
						"categories": "",
						"url": " /security/ncloud-security-security-monitoring-waf-price-info.html",
						"content": "개요\nNcloud (네이버 클라우드) Security Monitoring 서비스는 무료인 Basic 서비스와 유료인 Managed 서비스가 있고, 그 중에서 유료 서비스인 Managed 서비스는 IDS, Anti-DOS, WAF, Anti-Virus, IPS 등 4가지 서비스를 모두 제공하고 있는데 그 중에서 WAF(Web Application Firewall) 서비스의 이용 요금 구성과 신청 시 주의 사항에 대해 정리해보겠습니다.\n\n구성\nWAF 서비스 장비는 [WAF VM + WAF LB]로 구성되어 있습니다. 따라서 사용 요금도 WAF VM 요금과 WAF LB 요금이 별도로 청구됩니다.\n\n\n  \n  \n    \n  \n\n\n요금\n\n\n  \n    \n      상품명\n      과금 구간 (Mbps)\n      가격 (월 요금, VAT별도)\n      비고\n    \n  \n  \n    \n        MultiWAF VM\n        0 ~ 300 이하\n        974,800 원\n        리전 단위 판매이중화 기본 제공(요금은 이중화 가격)\n    \n            \n        300 초과 ~ 500 이하\n        1,474,800 원        \n    \n            \n        500 초과 ~ 1,000 이하\n        2,274,800 원        \n    \n    \n        SingleWAF VM\n        0 ~ 300 이하\n        624,800 원\n        리전 단위 판매\n    \n            \n        300 초과 ~ 500 이하\n        924,800 원        \n    \n            \n        500 초과 ~ 1,000 이하\n        1,299,800 원        \n      \n    \n        WAF LB\n        WAF LB 1개당\n        25,200 원\n        WAF LB개수는 WAF 모니터링을 신청하려는도메인 개수 또는 인증서 개수를 의미\n     \n  \n  \n\n\n과금 구간 기준\n과금 구간을 결정, 변경하게 되는 기준은 월 기준 in/out 트래픽 중에서 Peak 트래픽입니다. 그러므로 월 기준으로 단 한번이라도 신청 구간을 초과할 경우 과금 기준이 변경될 수 있습니다.\n\n추가 도메인\n여러 개의 도메인을 추가할 경우 도메인 개수 만큼 WAF LB 요금이 추가 됩니다.\n\n서브 도메인의 요금\n\n  개별 인증서를 사용하는 서브 도메인은 인증서 개수 만큼 WAF LB 요금이 추가 됩니다.\n  Wildcard 인증서를 사용하는 서브 도메인은 추가 요금 없이, 개수 제한 없이 사용 가능합니다.\n  다만, 서브 도메인 개수나 트래픽에 따라 WAF LB 또는 WAF VM이 추가 되어 요금이 증가할 수 있습니다.\n\n\n요금 예시\n\nMulti WAF\n\n\n  \n    \n      해당 월 Peak 트래픽   \n      도메인 또는인증서 개수   \n      WAF VM 요금 (VAT 별도)      \n      WAF LB 요금 (VAT 별도)\n      합계 (VAT 별도)(WAF VM 요금 + WAF LB 요금)\n    \n  \n      \n    \n        90 Mbps        \n        1개\n        974,800 원        \n        25,200 원\n        1,000,000 원\n    \n    \n        90 Mbps        \n        2개\n        974,800 원        \n        50,400 원\n        1,025,200 원\n    \n    \n        300 Mbps        \n        1개\n        974,800 원        \n        25,200 원\n        1,000,000 원\n     \n    \n        301 Mbps        \n        1개\n        1,474,800 원        \n        25,200 원\n        1,500,000 원\n    \n  \n  \n\n\nSingle WAF\n\n\n  \n    \n      해당 월 Peak 트래픽   \n      도메인 또는인증서 개수   \n      WAF VM 요금 (VAT 별도)      \n      WAF LB 요금 (VAT 별도)\n      합계 (VAT 별도)(WAF VM 요금 + WAF LB 요금)\n    \n  \n      \n    \n        90 Mbps        \n        1개\n        624,800 원        \n        25,200 원\n        650,000 원\n    \n    \n        90 Mbps        \n        2개\n        624,800 원        \n        50,400 원\n        675,200 원\n    \n    \n        300 Mbps        \n        1개\n        624,800 원        \n        25,200 원\n        650,000 원\n     \n    \n        301 Mbps        \n        1개\n        924,800 원        \n        25,200 원\n        950,000 원\n    \n  \n  \n\n\nWAF 이용 요금은 고객 서비스의 서버 정지와 무관하게 청구됩니다. 서버 정지와 함께 Security Monitoring 서비스의 WAF 계약도 함께 해지해야 과금되지 않습니다.\n\nWAF 신청 시 주의 사항\n\nVPC\n\n\n  Application Load Balancer 사용 필수: WAF는 Reverse Proxy 방식으로 사용자별 별도의 WAF 플랫폼을 구성하여 제공하고, HTTP/HTTPS 트래픽에 대한 보안 모니터링을 제공합니다. 따라서 Application Load Balancer를 사용하는 HTTP/HTTPS 서비스에만 제공이 가능합니다.\n  서비스 도메인 필수: WAF 서비스를 사용하려면 사용자 서비스 도메인의 CNAME을 WAF Load Balancer 도메인 정보로 수정하여 트래픽이 WAF를 향하도록 설정해야 합니다. 그러므로 서비스 도메인이 있어야 서비스를 신청할 수 있습니다.\n  서비스 인증서 전달: HTTPS 서비스 모니터링을 위해 WAF Load Balancer에 인증서를 설치해야 하며, 서비스 신청 시 사용자 서비스의 인증서도 함께 전달해야 합니다.\n  HTTP 80 리스너 설정: WAF VM과 사용자 서비스 Application Load Balancer 간의 통신은 HTTP 80 port 공인 통신을 사용합니다. 그러므로 사용자 서비스 Application Load Balancer에 HTTP 80 리스너를 기본으로 구성해야 합니다.\n  리다이렉션 설정: WAF Load Balancer에서 80 포트에 대한 443 리다이렉트 설정도 기본으로 지원하고 있습니다. 따라서 WAF 서비스를 정상적으로 사용하려면 사용자의 Application Load Balancer나 서버에서 HTTP -&gt; HTTPS 리다이렉트가 있는 경우 삭제해야 합니다.\n  HTTP 프로토콜 설정: HTTPS 모니터링 신청 시, 신청한 Application Load Balancer 리스너에 HTTP 프로토콜 설정이 필요합니다.\n  CNAME 설정: WAF(V2) 제공을 위해서 고객 대상 도메인에 CNAME 설정을 해야 합니다. 고객 대상 도메인이 Base 도메인인 경우, CNAME 설정이 불가능하오니 A레코드에 WAF VIP로 설정합니다. 그리고, WAF 구성 후 고객에게 CNAME에 등록할 WAF Load Balancer 도메인 설정 정보 전달 예정입니다.\n\n\nClassic\n\n  HTTP/HTTPS 표준 프로토콜 사용 필수: WAF는 HTTP/HTTPS 표준 프로토콜을 사용하는 웹 서비스에 대한 보안 모니터링을 제공합니다. 따라서 네이버 클라우드 플랫폼의 Load Balancer를 사용 중인 서비스에 대한 모니터링을 하려면 Load Balancer Protocol을 반드시 HTTP, HTTPS로 설정해야 합니다. 만약 TCP, SSL로 설정하는 경우 WAF 서비스를 사용할 수 없습니다.\n\n\n참고 URL\n\n  Ncloud Security Monitoring 서비스 안내\n    \n      https://www.ncloud.com/product/security/securityMonitoring\n    \n  \n  Ncloud Security Monitoring 가이드\n    \n      https://guide.ncloud-docs.com/docs/securitymonitoring-overview\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-09-18\n          문서 최초 생성\n        \n      \n        \n          2023-11-03\n          서브 도메인 요금 관련 내용 추가\n        \n      \n        \n          2023-12-07\n          요금 변경 내역 업데이트\n        \n      \n        \n          2024-02-19\n          Single WAF 요금 안내 추가"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-backup-service-basic-guide-html": {
						"id": "storage-ncloud-storage-backup-service-basic-guide-html",
						"title": "Ncloud 백업 서비스 기본 가이드",
						"categories": "",
						"url": " /storage/ncloud-storage-backup-service-basic-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 기존에 별도의 신청서를 작성해서 사용하던 Managed Backup의 대체 상품으로 출시된 콘솔에서 바로 이용할 수 있는 Backup 상품의 기본 가이드를 알아보도록 하겠습니다.\n\n서비스 특징\n\n\n  다양한 플랫폼 및 데이터베이스 지원: Linux, Windows 계열 등 다양한 버전의 운영 체제를 지원하며 OS의 데이터 영역 및 서버에 설치된 데이터베이스의 온라인 백업이 가능합니다.\n  간편한 설치와 백업 단위 선택: 네이버 클라우드 웹 콘솔에서 간단한 설정을 통해 백업을 받고자 하는 리소스에 에이전트의 설치부터 백업 정책 구성까지 완료할 수 있습니다.\n  소산 백업 지원: 기존에 수행한 백업 데이터를 지리적으로 떨어진 다른 존으로 이중화하여 데이터 안정성을 더욱 향상시킬 수 있습니다.\n  리포트 기능 제공: 백업 혹은 복구에 대한 작업 결과를 일간/월간 단위 보고서로 확인할 수 있고 이메일로 리포팅을 받을 수 있습니다.\n\n\n제약 사항\nBackup 서비스의 제약 사항은 다음과 같습니다.\n\n백업 가능 대상\n\n  서버: Data 영역\n  DB: 서버 설치형DB (MSSQL, MySQL, PostgreSQL)\n\n\n백업 가능한 데이터 크기\n\n  계정당 1TB\n\n\n이용 요금\nBackup 서비스는 유료 서비스로 이용 요금은 기본료, 데이터 저장량, 복원 요금, 네트워크 전송 요금을 합산해 부과됩니다.\n\n\n  기본료: 백업 대상 소스 서버 대수당 요금 부과\n  데이터 저장량: 백업된 데이터 저장량에 대해 월 평균 사용량에 대한 스토리지 요금 부과\n  복구 요금: 백업본 복구시 복구대상이 되는 원본 데이터 전체 용량에 대한 요금 부과\n  네트워크 전송 요금: 백업 및 복구간 발생한 존간/리전간 네트워크 전송 요금 부과\n\n\n\n⁃ 데이터 저장량은 월 평균 사용량 기준입니다. \n⁃ 복구 요금은 원본(소스) 용량 기준으로 당월 수행한 전체 복구 작업에 대한 총량 기준으로 요금이 부과됩니다. \n⁃ 동일 존 내에서 백업 수행 및 복구 시 네트워크 전송 요금은 무료입니다.\n\n\n백업 서비스 지원 버전\n\n    \n        구분\n        지원 범위\n        비고\n    \n    \n        \n            MSSQL Server\n            2005, 2008, 2008R2, 2012, 2014, 2016, 2017, 2019\n            x86, x64\n        \n        \n            MySQL\n            5.5, 5.6, 5.7, 8.x\n                Maria DB 5.5, 10.0, 10.1~10.6\n            \n            Redhat/CentOS 6.x~8.x : x86, x64\n                Ubuntu 14.0 ~ 20.04 : x64\n            \n        \n        \n            PostgreSQL\n            9.2 ~ 14.x\n            Redhat/CentOS 5.x : x86, x64\n                Redhat/CentOS 6.x ~ 8.x : x64\n                Ubuntu 12.04 ~ 22.04 : x86, x64\n            \n        \n        \n            Windows File System\n            7, 8, 8.1, 10, 2008, 2008 R2, 2016, 2019, 2022\n            x86, x64\n        \n        \n            Linux File System\n            Redhat/CentOS : 5.x ~ 8.x\n                Ubuntu 8.04 ~ 21.04\n            \n            Redhat/CentOS 5.x ~ 7.x : x86, x64\n                Redhat/CentOS 8.x : x64\n            \n        \n    \n\n\n상세 가이드\n\n  Linux Data 백업 가이드\n\n\n참고 URL\n\n  Ncloud 백업 상품 가이드\n    \n      https://guide.ncloud-docs.com/docs/backup-overview"
					}
					
				
			
		
			
				
			
		
			
				
					,
					
					"storage-ncloud-storage-backup-service-linux-data-guide-html": {
						"id": "storage-ncloud-storage-backup-service-linux-data-guide-html",
						"title": "Ncloud 백업 서비스 사용 가이드 - Linux Data",
						"categories": "",
						"url": " /storage/ncloud-storage-backup-service-linux-data-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Backup 상품은 기존에 별도의 신청서를 작성해서 사용하던 [Managed Backup]의 대체 상품으로 출시된, 콘솔에서 바로 이용할 수 있는 상품으로 이 백업 상품을 이용해 리눅스 파일 데이터를 백업하는 방법을 알아보도록 하겠습니다.\n\n상품위치\nBackup 상품은 [Console] - [Services] - [Storage]에 있습니다.\n\n\n  \n  \n    \n  \n\n\n테스트 서버\n백업을 테스트할 리눅스 서버를 아래와 같이 미리 준비했습니다.\n\n그리고, 백업과 복원에 필요한 디렉토리를 다음과 같이 생성했습니다.\n\n  백업할 디렉토리: /backup-data\n  복원할 디렉토리: /restore\n\n\n\n  \n  \n    \n  \n\n\n리소스 생성\n먼저 백업 혹은 복구를 수행할 대상 서버를 설정합니다.\nBackup 탭에서 [Backup] - [Resource]로 이동해서 [리소스 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n리소스 생성 방법\n\n\n  리소스 이름을 입력합니다.\n  백업 서버가 소속된 존(zone)을 선택합니다.\n  백업 대상이 되는 서버를 리소스에 등록합니다.\n  서버가 위치한 zone 선택 및 대상 서버를 선택하며 파일백업 및 데이터베이스 백업 여부에 따라 체크박스를 선택합니다.\n  에이전트 설치에 사용될 아이디 및 비밀번호를 입력합니다.\n\n\n 주의: 아이디는 백업 대상 서버의 root 계정 또는 백업 및 리스토어가 진행되는 디렉터리와 파일에 대한 소유권한을 가진 계정을 입력해야 합니다.\n\n아이디와 비밀번호는 에이전트 설치를 위해 백업 대상 서버 접속 시 일회성으로 사용하며, 별도로 저장되지 않습니다.\n\n\n  \n  \n    \n  \n\n\n내용 최종 확인 후 리소스 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n백업 에이전트 설치 확인\n리소스가 생성 되면서 백업 에이전트가 설치되는데 정상적으로 설치가 완료되면 [생성 완료]라는 메시지가 나타납니다.\n(에이전트 설치는 대략 5분 정도의 시간이 걸리며, 상단의 [새로 고침] 버튼을 클릭하면 확인할 수 있습니다.)\n\n\n  \n  \n    \n  \n\n\n에이전트 설치 실패\n아이디/비번을 잘못 입력했거나 기타의 이유로 에이전트 설치가 실패했을 경우에는 [추가] 버튼을 클릭해서 다시 설치하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n저장소 생성\n다음으로 백업 데이터를 저장할 저장소를 만들고 관리합니다.\nBackup 탭에서 [Backup] - [Storage]로 이동하여 저장소 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n저장소 이름과 백업 저장소가 위치할 존(zone)을 지정 후 다음을 클릭해서 저장소를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n소산 백업용 스토리지 추가 생성\n추후 Remote Backup 메뉴에서 소산 백업(이중화 백업)에 사용할 스토리지를 미리 추가로 생성하도록 하겠습니다.\n현재 KR-2존에 생성한 스토리지는 그대로 두고 KR-1존에 test2-backup-storage라는 이름으로 추가 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n정책 생성\n다음은 저장소에 대한 정책을 설정 및 관리합니다.\nBackup 탭에서 [Backup] - [Policy]로 이동하여 정책 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 생성\n정책 이름, 보관 주기, 생성한 저장소가 위치한 존을 선택한 후 [연결 저장소]가 맞는지 확인 후 정책을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n보관 기간은 백업 주기의 최소 2배 이상으로 설정해야 합니다. \n⁃ 일간 백업 : 최소 7일 이상\n⁃ 주간 백업 : 최소 14일 이상\n⁃ 월간 백업 : 최소 60일 이상\n\n\n작업 생성\n다음으로 에이전트가 설치된 리소스와 사전에 설정한 저장소 및 정책 등을 활용하여 실제 백업을 수행하는 작업을 생성하고 관리합니다.\n\nBackup 탭에서 [Backup] - [Job]으로 이동하여 작업 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n작업 이름과 대상 리소스(서버) 백업 유형 및 백업 대상 디렉터리 지정을 한 후  Policy 메뉴에서 생성한 백업 정책을 선택합니다.\n\n 주의: Job과 Policy는 1:1 매핑만 가능합니다.\n\n\n  \n  \n    \n  \n\n\n일정 생성\n마지막으로 작업을 수행하는 일정에 대해 계획하고 관리합니다.\nBackup 탭에서 [Backup] - [Schedule]로 이동하여 일정 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n일정 이름과 job에서 등록한 서버 백업 작업을 선택 후 백업 방식, 주기, 시작 요일과 시간을 구성한 후 일정을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n소산 백업 (이중화 백업)\n백업 상품의 소산 백업을 이용해 기존에 수행한 백업 데이터를 지리적으로 떨어진 다른 존으로 이중화할 수 있습니다.\n\nBackup 탭에서 [Backup] - [Remote Backup] 으로 이동하여 소산 설정을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n소산 이름, job에서 등록한 작업 선택, 소산 저장소가 위치한 존 선택, 보관 주기, 소산 백업 주기를 설정 후 소산 백업 일정을 등록합니다.\n\n\n  \n  \n    \n  \n\n\n소산 일정에 백업 작업이 완료되어 있지 않은 경우, 다음 소산 일정에 소산이 수행됩니다.\n\n\n  \n  \n    \n  \n\n\n백업 완료 확인\n기본 백업과 소산 백업까지 모두 완료되면 아래와 같이 [Report] 메뉴에서 결과를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n복원\n복원 기능을 이용하면 위에서 백업한 데이터를 Restore 메뉴에서 원하는 시점의 특정 데이터를 선택해서 원하는 리소스에 복원할 수 있습니다.\n\n[Job]에서 설정한 /backup-data 디렉터리에 저장되어 있는 파일들을 /restore 디렉터리로 복원을 진행해 보겠습니다. 현재 /restore 디렉터리는 비어있는 상태입니다.\n\n\n  \n  \n    \n  \n\n\nBackup 탭에서 [Restore]로 이동하여 복원 설정을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n복원 설정에서는 백업된 데이터 중 어떤 데이터로 복원할 것인지에 대한 세부항목을 선택합니다.\n복원 시점은 [가장 최근 백업 시점] 또는 백업된 데이터들 중에서 [직접 지정]도 가능합니다.\n복원 대상은 Job에서 설정한 디렉터리를 선택하고 [다음]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n타깃 설정에서는 백업한 데이터를 복원할 서버와 디렉터리를 지정하고 다음을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n최종 내용을 확인 후 복원 시작을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n복원 시작 후 복원 상태 확인이 가능합니다.\n\n\n  \n  \n    \n  \n\n\n작업이 종료되면 /restore 경로에 데이터가 정상적으로 복원된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nReport\n\n백업 혹은 복구에 대한 작업 결과를 일간/월간 단위의 보고서로 확인할 수 있습니다.\n\nBackup 탭에서 [Report] 로 이동하여 확인합니다.\n\nBackup Report에서 발생하는 이벤트는 이메일 수신 신청으로 메일로 알림을 받도록 설정이 가능합니다.\n\n\n  \n  \n    \n  \n\n\n항목에서 담당자 이름 및 메일 주소를 확인하고 [추가] 버튼을 클릭한 후 저장합니다.\n\n\n  \n  \n    \n  \n\n\n등록이 완료되면 아래와 같이 메일로 리포트를 받아보실 수 있으며 매일 오전 10시 일간 리포트와 매월 1일 월간 리포트가 전송됩니다.\n\n\n  \n  \n    \n  \n\n\n백업 리소스 삭제\n더 이상 백업 서비스를 이용하지 않게 되어 백업 리소스를 삭제하려면 위에서 생성했던 순서의 반대로 삭제를 진행해야 합니다.\n\n우선, [Backup] - [Resource]에서 해당 리소스를 선택하고 [리소스 삭제] 버튼을 클릭해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n그러면 다음과 같이 리소스와 함께 설치-생성되었던 [Agent], [Job], [Schedule], [Remote Backup]를 먼저 삭제해야 한다는 안내 메시지가 나타납니다.\n\n\n⁃ 백업 리소스 삭제는 아래와 같이 생성 순서와 반대로 삭제해야 합니다. \n⁃ \n[Remote Backup] \n[Schedule] \n[Job] \n[Agent] \n[Resource]\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud 백업 상품 가이드\n    \n      https://guide.ncloud-docs.com/docs/backup-overview"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-backup-service-windows-data-guide-html": {
						"id": "storage-ncloud-storage-backup-service-windows-data-guide-html",
						"title": "Ncloud 백업 서비스 사용 가이드 - Windows Data",
						"categories": "",
						"url": " /storage/ncloud-storage-backup-service-windows-data-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Backup 상품은 기존에 별도의 신청서를 작성해서 사용하던 [Managed Backup]의 대체 상품으로 출시된, 콘솔에서 바로 이용할 수 있는 상품으로 이 백업 상품을 이용해 Windows 파일 데이터를 백업하는 방법을 알아보도록 하겠습니다.\n\n상품위치\nBackup 상품은 [Console] - [Services] - [Storage]에 있습니다.\n\n\n  \n  \n    \n  \n\n\n테스트 서버\n백업을 테스트할 리눅스 서버를 아래와 같이 미리 준비했습니다.\n\n그리고, 백업과 복원에 필요한 디렉토리를 다음과 같이 생성했습니다.\n\n  백업할 디렉토리: C:\\Backup-Data\n  복원할 디렉토리: C:\\Restore\n\n\n\n  \n  \n    \n  \n\n\n리소스 생성\n먼저 백업 혹은 복구를 수행할 대상 서버를 설정합니다.\nBackup 탭에서 [Backup] - [Resource]로 이동해서 [리소스 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n리소스 생성 방법\n\n\n  리소스 이름을 입력합니다.\n  백업 서버가 소속된 존(zone)을 선택합니다.\n  백업 대상이 되는 서버를 리소스에 선택합니다.\n  호스트 이름에는 백업 대상 서버의 이름을 입력합니다.\n  서버가 위치한 zone 선택 및 대상 서버를 선택하며 파일백업 및 데이터베이스 백업 여부에 따라 체크박스를 선택합니다.\n  에이전트 설치에 사용될 아이디 및 비밀번호를 입력합니다.\n\n\n 주의: 아이디는 백업 대상 서버의 Administrator 계정 또는 백업 및 리스토어 수행 시 해당 디렉터리와  파일에 대한 접근 권한을 가지고 있는 user 계정을 입력해야합니다.\n\n아이디와 비밀번호는 에이전트 설치를 위해 백업 대상 서버 접속 시 일회성으로 사용하며, 별도로 저장되지 않습니다.\n\n\n  \n  \n    \n  \n\n\n내용 최종 확인 후 리소스 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n백업 에이전트 설치 확인\n리소스가 생성 되면서 백업 에이전트가 설치되는데 정상적으로 설치가 완료되면 [생성 완료]라는 메시지가 나타납니다.\n(에이전트 설치는 대략 5분 정도의 시간이 걸리며, 상단의 [새로 고침] 버튼을 클릭하면 확인할 수 있습니다.)\n\n\n  \n  \n    \n  \n\n\n에이전트 설치 실패\n아이디/비번을 잘못 입력했거나 기타의 이유로 에이전트 설치가 실패했을 경우에는 [추가] 버튼을 클릭해서 다시 설치하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n저장소 생성\n다음으로 백업 데이터를 저장할 저장소를 만들고 관리합니다.\nBackup 탭에서 [Backup] - [Storage]로 이동하여 저장소 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n저장소 이름과 백업 저장소가 위치할 존(zone)을 지정 후 다음을 클릭해서 저장소를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n소산 백업용 스토리지 추가 생성\n추후 Remote Backup 메뉴에서 소산 백업(이중화 백업)에 사용할 스토리지를 미리 추가로 생성하도록 하겠습니다.\n현재 KR-2존에 생성한 스토리지는 그대로 두고 KR-1존에 test2-backup-storage라는 이름으로 추가 생성했습니다.\n\n\n  \n  \n    \n  \n\n\n정책 생성\n다음은 저장소에 대한 정책을 설정 및 관리합니다.\nBackup 탭에서 [Backup] - [Policy]로 이동하여 정책 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 생성\n정책 이름, 보관 주기, 생성한 저장소가 위치한 존을 선택한 후 [연결 저장소]가 맞는지 확인 후 정책을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n보관 기간은 백업 주기의 최소 2배 이상으로 설정해야 합니다. \n⁃ 일간 백업 : 최소 7일 이상\n⁃ 주간 백업 : 최소 14일 이상\n⁃ 월간 백업 : 최소 60일 이상\n\n\n작업 생성\n다음으로 에이전트가 설치된 리소스와 사전에 설정한 저장소 및 정책 등을 활용하여 실제 백업을 수행하는 작업을 생성하고 관리합니다.\n\nBackup 탭에서 [Backup] - [Job]으로 이동하여 작업 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n작업 이름과 대상 리소스(서버) 백업 유형 및 백업 대상 디렉터리 지정을 한 후  Policy 메뉴에서 생성한 백업 정책을 선택합니다.\n\n 주의: Job과 Policy는 1:1 매핑만 가능합니다.\n\n\n  \n  \n    \n  \n\n\n일정 생성\n마지막으로 작업을 수행하는 일정에 대해 계획하고 관리합니다.\nBackup 탭에서 [Backup] - [Schedule]로 이동하여 일정 생성을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n일정 이름과 job에서 등록한 서버 백업 작업을 선택 후 백업 방식, 주기, 시작 요일과 시간을 구성한 후 일정을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n소산 백업 (이중화 백업)\n백업 상품의 소산 백업을 이용해 기존에 수행한 백업 데이터를 지리적으로 떨어진 다른 존으로 이중화할 수 있습니다.\n\nBackup 탭에서 [Backup] - [Remote Backup] 으로 이동하여 소산 설정을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n소산 이름, job에서 등록한 작업 선택, 소산 저장소가 위치한 존 선택, 보관 주기, 소산 백업 주기를 설정 후 소산 백업 일정을 등록합니다.\n\n\n  \n  \n    \n  \n\n\n소산 일정에 백업 작업이 완료되어 있지 않은 경우, 다음 소산 일정에 소산이 수행됩니다.\n\n\n  \n  \n    \n  \n\n\n백업 완료 확인\n기본 백업과 소산 백업까지 모두 완료되면 아래와 같이 [Report] 메뉴에서 결과를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n복원\n복원 기능을 이용하면 위에서 백업한 데이터를 Restore 메뉴에서 원하는 시점의 특정 데이터를 선택해서 원하는 리소스에 복원할 수 있습니다.\n\n[Job]에서 설정한 C:\\Backup-Data 디렉터리에 저장되어 있는 파일들을 C:\\Restore 디렉터리로 복원을 진행해 보겠습니다. 현재 /Restore 디렉터리는 비어있는 상태입니다.\n\n\n  \n  \n    \n  \n\n\nBackup 탭에서 [Restore]로 이동하여 복원 설정을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n복원 설정에서는 백업된 데이터 중 어떤 데이터로 복원할 것인지에 대한 세부항목을 선택합니다.\n복원 시점은 [가장 최근 백업 시점] 또는 백업된 데이터들 중에서 [직접 지정]도 가능합니다.\n복원 대상은 Job에서 설정한 디렉터리를 선택하고 [다음]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n타깃 설정에서는 백업한 데이터를 복원할 서버와 디렉터리를 지정하고 다음을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n최종 내용을 확인 후 복원 시작을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n복원 시작 후 복원 상태 확인이 가능합니다.\n\n\n  \n  \n    \n  \n\n\n작업이 종료되면 /restore 경로에 데이터가 정상적으로 복원된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nReport\n\n백업 혹은 복구에 대한 작업 결과를 일간/월간 단위의 보고서로 확인할 수 있습니다.\n\nBackup 탭에서 [Report] 로 이동하여 확인합니다.\n\nBackup Report에서 발생하는 이벤트는 이메일 수신 신청으로 메일로 알림을 받도록 설정이 가능합니다.\n\n\n  \n  \n    \n  \n\n\n항목에서 담당자 이름 및 메일 주소를 확인하고 [추가] 버튼을 클릭한 후 저장합니다.\n\n\n  \n  \n    \n  \n\n\n등록이 완료되면 아래와 같이 메일로 리포트를 받아보실 수 있으며 매일 오전 10시 일간 리포트와 매월 1일 월간 리포트가 전송됩니다.\n\n\n  \n  \n    \n  \n\n\n백업 리소스 삭제\n더 이상 백업 서비스를 이용하지 않게 되어 백업 리소스를 삭제하려면 위에서 생성했던 순서의 반대로 삭제를 진행해야 합니다.\n\n우선, [Backup] - [Resource]에서 해당 리소스를 선택하고 [리소스 삭제] 버튼을 클릭해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n그러면 다음과 같이 리소스와 함께 설치-생성되었던 [Agent], [Job], [Schedule], [Remote Backup]를 먼저 삭제해야 한다는 안내 메시지가 나타납니다.\n\n\n⁃ 백업 리소스 삭제는 아래와 같이 생성 순서와 반대로 삭제해야 합니다. \n⁃ \n[Remote Backup] \n[Schedule] \n[Job] \n[Agent] \n[Resource]\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud 백업 상품 가이드\n    \n      https://guide.ncloud-docs.com/docs/backup-overview"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-bucket-cors-setting-api-sdk-guide-html": {
						"id": "storage-ncloud-storage-object-storage-bucket-cors-setting-api-sdk-guide-html",
						"title": "Object Storage에서 CORS를 SDK for S3 API로 설정하기",
						"categories": "",
						"url": " /storage/ncloud-storage-object-storage-bucket-cors-setting-api-sdk-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Object Storage Bucket CORS를 AWS S3에서 제공하는 [SDK for S3 API]로 설정하는 방법을 소개합니다. 여기서 소개할 SDK는 [Python용 SDK for S3 API]와 [PHP용 SDK for S3 API] 두가지입니다.\n\nCORS 설정 기본 방법\nObject Storage Bucket에 CORS를 설정하는 기본 방법인 CLI와 외부 Client Tool에 대한 것은 아래 문서에서 확인 가능합니다.\n\n\n⁃ Object Storage Bucket에 CORS 설정하기 - CLI &amp; Client Tool\n\n\nPython용 SDK for S3 API\n\nSDK 설치\nPython용 SDK를 설치하는 방법은 기본 설치방법과 특정 버전을 설치하는 방법이 있습니다.\n\n# 기본 설치\npip install boto3\n\n# 특정 버전 설치\npip install boto3==1.6.19\n\n\n예제 코드\n아래 예제 코드는 버킷에 CORS를 설정하는 방법과 설정된 CORS를 조회하는 방법입니다.\n\nimport boto3\n\nservice_name = 's3'\nendpoint_url = 'https://kr.object.ncloudstorage.com'\nregion_name = 'kr-standard'\naccess_key = '{ACCESS_KEY_ID}'\nsecret_key = '{SECRET_KEY}'\n\nif __name__ == \"__main__\":\n    s3 = boto3.client(service_name, endpoint_url=endpoint_url,\n                         aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n                      \n    bucket_name = '{버킷명}'\n\n# Define the configuration rules\n    cors_configuration = {\n        'CORSRules': [{\n            'AllowedHeaders': ['*'],\n            'AllowedMethods': ['GET', 'PUT'],\n            'AllowedOrigins': ['http://cors-test.com'],\n            'MaxAgeSeconds': 3000\n        }]\n    }\n\n    # Set CORS configuration\n    response = s3.put_bucket_cors(Bucket=bucket_name, CORSConfiguration=cors_configuration)\n    print(response['ResponseMetadata'])\n\n    # Get CORS configuration\n    response = s3.get_bucket_cors(Bucket=bucket_name)\n    print(response['CORSRules'])\n\n\n예제 코드 실행 결과\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nPHP용 SDK for S3 API\nPHP용 SDK는 아래 2가지 방법 중에서 한가지를 선택해서 사용할 수 있습니다.\n\n1. SDK 설치\n우선 composer를 이용해서 설치하는 방법입니다.\n\ncomposer require aws/aws-sdk-php\n\n\n\n  설치 후에 아래 코드를 추가해서 SDK를 불러옵니다.\n\n\n&lt;?php\n   require '{경로}/vendor/autoload.php';\n?&gt;\n\n\n2. SDK 다운로드\n2번째 방법은 SDK Zip파일을 다운로드 받아 사용하는 방법입니다.\n\n\n⁃ PHP용 SDK Zip 파일 다운로드\n\n\n\n  압축을 풀고 필요한 경로에 복사한 후 아래 코드를 추가해서 SDK를 불러옵니다.\n\n\n&lt;?php \n    require '{경로}/aws-autoloader.php';\n?&gt;\n\n\n예제 코드\n아래 예제 코드는 버킷에 CORS를 설정하는 방법과 설정된 CORS를 조회하는 방법입니다.\n\n&lt;?php\n    use Aws\\S3\\S3Client;\n    use Aws\\Exception\\AwsException;\n    \n    $s3Client = new S3Client ([\n        'endpoint' =&gt; 'https://kr.object.ncloudstorage.com',\n        'region'   =&gt; 'kr-standard',\n        'credentials' =&gt; array(\n            'key'      =&gt; '{ACCESS_KEY_ID}',\n            'secret'   =&gt; '{SECRET_KEY}'\n        ),\n        'version' =&gt; 'latest'\n    ]);\n\n\n    $bucketName = \"{버킷명}\";\n\n    # Set CORS configuration\n    try \n    {\n        $result = $s3Client-&gt;putBucketCors([\n            'Bucket' =&gt; $bucketName, // REQUIRED\n            'CORSConfiguration' =&gt; [ // REQUIRED\n                'CORSRules' =&gt; [ // REQUIRED\n                    [\n                        'AllowedHeaders' =&gt; ['*'],\n                        'AllowedMethods' =&gt; ['GET', 'PUT'], // REQUIRED\n                        'AllowedOrigins' =&gt; ['http://cors-test.com'], // REQUIRED\n                        'ExposeHeaders' =&gt; [],\n                        'MaxAgeSeconds' =&gt; 3000\n                    ],\n                ],\n            ]\n        ]);\n\n        var_dump($result[\"@metadata\"]);\n    } \n    catch (AwsException $e) \n    {   // output error message if fails\n        error_log($e-&gt;getMessage());\n    }\n\n    echo(\"&lt;hr /&gt;\");\n\n    # Get CORS configuration\n    try \n    {\n        $result = $s3Client-&gt;getBucketCors([\n            'Bucket' =&gt; $bucketName, // REQUIRED\n        ]);\n\n        var_dump($result[\"CORSRules\"]);\n    } \n    catch (AwsException $e) \n    {   // output error message if fails\n        error_log($e-&gt;getMessage());\n    }\n\n?&gt;\n\n\n예제 코드 실행 결과\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Python용 AWS SDK (Boto3) 가이드\n    \n      https://guide.ncloud-docs.com/docs/storage-storage-8-2\n    \n  \n  PHP용 AWS SDK 가이드\n    \n      https://aws.amazon.com/ko/sdk-for-php/\n    \n  \n  Object Storage Bucket에 CORS 설정하는 기본 방법\n    \n      https://docs.3rdeyesys.com/storage/ncloud-storage-object-storage-bucket-cors-setting-guide.html"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-bucket-cors-setting-guide-html": {
						"id": "storage-ncloud-storage-object-storage-bucket-cors-setting-guide-html",
						"title": "Object Storage Bucket에 CORS 설정하기",
						"categories": "",
						"url": " /storage/ncloud-storage-object-storage-bucket-cors-setting-guide.html",
						"content": "개요\nObject Storage를 이용해 서비스 개발을 하다 보면 CORS 와 관련된 오류와 종종 마주치게 되는데, 테스트 버킷과 사이트를 생성해서 해결 방법을 알아보겠습니다.\n그리고, Ncloud(네이버 클라우드) Object Storage의 CORS 설정은 콘솔이 아닌, CLI와 외부 Client Tool 등을 사용해야 하는데 각각의 방법을 차례로 소개합니다.\n\n CORS: CORS(Cross-Origin Resource Sharing)는 웹 애플리케션이 서비스되는 도메인에서 다른 도메인에 있는 리소스를 접근해야 할 때 리소스에 대한 접근 허용, 제한 등에 대한 방법을 정의합니다.\n\n테스트 방법\n\n  Object Storage에 cors-test 라는 이름의 버킷 생성\n  http://cors-test.com 라는 테스트 사이트 준비\n  버킷에 http://cors-test.com 도메인에서 접속 가능하도록 CORS 설정\n  Javascript를 이용해 cors-test 버킷에 있는 파일이 호출되는지 확인\n  버킷 CORS 설정을 변경하여 http://cors-test.com 도메인에서는 접속하지 못하게 설정\n  cors-test 버킷에 있는 파일 호출이 차단되는지 확인\n\n\nCORS 구성 요소\nCORS는 아래와 같은 요소들로 구성되어 있습니다.\n\n\n  AllowedHeader : 리소스를 요청할 때 사용할 수 있는 Header\n  AllowedMethod : 리소스를 요청할 때 허용된 Method\n  AllowedOrigin : 접근 허용된 Origin 도메인\n  ExposeHeader : 응답에서 접근이 허용된 Header\n  MaxAgeSeconds : 지정한 리소스에 해당하는 프리플라이트(pre-flight) OPTIONS 요청에 대한 최대 응답 시간\n\n\nCLI 사용\nNcloud는 Object Storage CLI 접속 시 AWS CLI를 이용해 접속하게 되는데, 자세한 사용 방법은 아래 링크 문서에서 확인 가능합니다.\n\n\n⁃ AWS CLI를 이용한 Object Storage 접속 방법\n\n\njson 파일 생성\nCLI를 사용하기 위해 먼저 간단하게 GET, PUT Method로 접근가능 하게 하는 CORS 설정을 입력한 별도의 json 파일을 생성 합니다. 여기서는 cors-test.json 이라는 이름으로 저장하겠습니다.\n\n{\n  \"CORSRules\": \n  [\n    {\n      \"AllowedHeaders\": [\n        \"*\"\n      ],\n      \"AllowedMethods\": [\n        \"GET\",\n        \"PUT\"\n      ],\n      \"AllowedOrigins\": [\n        \"http://cors-test.com\"\n      ],           \n      \"MaxAgeSeconds\": 3000\n    }\n  ]\n}\n\n\njson 형식에 대해서는 아래의 링크를 참조 합니다.\n\n\n⁃ AWS - CORS 구성\n\n\njson파일을 생성 하였으면 아래와 같은 형식으로 CORS 규칙 설정을 버킷에 적용하는 명령어를 입력 합니다. 여기서는 테스트를 위해 미리 [cors-test] 라는 이름의 버킷을 생성해두었습니다.\n\n# CORS 설정 입력 명령어 형식\naws --endpoint-url=https://kr.object.ncloudstorage.com s3api put-bucket-cors --bucket &lt;버킷이름&gt; --cors-configuration file://&lt;json파일 경로&gt;\n\n# 예제\naws --endpoint-url=https://kr.object.ncloudstorage.com s3api put-bucket-cors --bucket cors-test --cors-configuration file://cors-test.json\n\n\n그런 다음 제대로 적용되었는지 확인 하기 위해 버킷의 CORS 설정을 확인하는 명령어를 실행합니다.\n\n# CORS 설정 조회 명령어 형식\naws --endpoint-url=https://kr.object.ncloudstorage.com s3api get-bucket-cors --bucket &lt;버킷이름&gt;\n\n# 예제\naws --endpoint-url=https://kr.object.ncloudstorage.com s3api get-bucket-cors --bucket cors-test\n\n\n  \n  \n    \n  \n\n\nS3 Browser 사용\n외부 Client Tool중에서 CORS 설정이 가능한 것은 S3 Browser 이며, 자세한 사용 방법은 아래의 링크 문서를 참고하시기 바랍니다.\n\n\n⁃ Object Storage 접속용 Windows Client Tool - S3 Browser\n\n\nS3 브라우저에 접속 하신다음 CORS 설정 대상의 버킷에서 오른쪽 마우스 버튼을 클릭 합니다.\n\n\n  \n  \n    \n  \n\n\nCORS Configuration 클릭하여 CORS 설정을 오픈하면 처음에는 아무 값도 설정되어 있지 않습니다.\n\n\n  \n  \n    \n  \n\n\nXML 형식의 설정 준비\n마찬가지로 GET, PUT Method로 접근 가능한 설정을 이번에는 XML 형식으로 입력하고 [Apply] 버튼을 클릭해서 적용합니다.\n\n&lt;CORSConfiguration&gt;\n  &lt;CORSRule&gt;\n    &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt;\n    &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt;\n    &lt;AllowedMethod&gt;PUT&lt;/AllowedMethod&gt;    \n    &lt;AllowedOrigin&gt;http://cors-test.com&lt;/AllowedOrigin&gt;        \n    &lt;MaxAgeSeconds&gt;3000&lt;/MaxAgeSeconds&gt;\n  &lt;/CORSRule&gt;\n&lt;/CORSConfiguration&gt;\n\n\n\n  \n  \n    \n  \n\n\n접속 테스트\n\n정상 접속 확인\n설정을 마친 후 Javascript를 사용해서 cors-test 버킷에 있는 파일을 호출해보면 아래와 같이 문제 없이 접속되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nCORS 변경\n접속 차단을 테스트 하기 위해 CORS 설정에서 AllowedOrigin 값을 임의의 http://example.com 으로 변경하겠습니다.\n\n\n  \n  \n    \n  \n\n\n접속 차단 확인\n설정을 변경한 후에 접속을 해보면 이전과는 다르게 아래와 같은 메시지가 나타나면서 접속이 차단된 것을 확인할 수 있습니다.\n\n error: \nAccess to XMLHttpRequest at ‘https://kr.object.ncloudstorage.com/cors-test/cors-test.txt’ from origin ‘http://cors-test.com’ has been blocked by CORS policy: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.\n\n\n\n  \n  \n    \n  \n\n\nCORS 예시\n\n예시 1\n아래 예시는 http://*.cors-test.com 즉, cors-test.com 도메인을 가진 모든 하위 도메인에 대해 허용할 요청 Method와 허용할 응답 헤더 값을 정의했습니다.\n\n{\n  \"CORSRules\": \n  [\n    {    \n      \"AllowedHeaders\": [\n        \"*\"\n      ],\n      \"AllowedMethods\": [\n        \"PUT\",\n        \"POST\",\n        \"DELETE\"\n      ],\n      \"AllowedOrigins\": [\n        \"http://*.cors-test.com\"\n      ],\n      \"ExposeHeaders\": [\n        \"x-amz-server-side-encryption\",\n        \"x-amz-request-id\",\n        \"x-amz-id-2\"\n      ],\n      \"MaxAgeSeconds\": 3000\n    }\n  ]\n}\n\n\n&lt;CORSConfiguration&gt;\n  &lt;CORSRule&gt;\n    &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt;   \n    &lt;AllowedMethod&gt;PUT&lt;/AllowedMethod&gt;\n    &lt;AllowedMethod&gt;POST&lt;/AllowedMethod&gt;\n    &lt;AllowedMethod&gt;DELETE&lt;/AllowedMethod&gt;\n    &lt;AllowedOrigin&gt;http://*.cors-test.com&lt;/AllowedOrigin&gt;   \n    &lt;ExposeHeader&gt;x-amz-server-side-encryption&lt;/ExposeHeader&gt;\n    &lt;ExposeHeader&gt;x-amz-request-id&lt;/ExposeHeader&gt;\n    &lt;ExposeHeader&gt;x-amz-id-2&lt;/ExposeHeader&gt;\n    &lt;MaxAgeSeconds&gt;3000&lt;/MaxAgeSeconds&gt;\n  &lt;/CORSRule&gt;\n&lt;/CORSConfiguration&gt;\n\n\n예제 2\n아래 예제 2는 2가지 도메인에 대해 각각 다른 규칙을 정의했습니다.\n먼저 http로 접속하는 www.cors-test.com 도메인에 대해서는 GET 방식의 요청만 허용하고,\n다음 https로 접속하는 api.cors-test.com 도메인에 대해서는 PUT, POST, DELETE 요청을 허용하는 규칙입니다.\n\n{\n  \"CORSRules\": \n  [\n    {\n      \"AllowedHeaders\": [\n        \"*\"\n      ],\n      \"AllowedMethods\": [\n        \"PUT\",\n        \"POST\",\n        \"DELETE\"\n      ],\n      \"AllowedOrigins\": [\n        \"https://api.cors-test.com\"\n      ]\n    },\n    {\n      \"AllowedMethods\": [\n        \"GET\"\n      ],\n      \"AllowedOrigins\": [\n        \"http://www.cors-test.com\"\n      ]\n    }\n  ]\n}\n\n\n&lt;CORSConfiguration&gt;\n  &lt;CORSRule&gt;\n    &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt;\n    &lt;AllowedMethod&gt;PUT&lt;/AllowedMethod&gt;\n    &lt;AllowedMethod&gt;POST&lt;/AllowedMethod&gt;\n    &lt;AllowedMethod&gt;DELETE&lt;/AllowedMethod&gt;\n    &lt;AllowedOrigin&gt;http://api.cors-test.com&lt;/AllowedOrigin&gt;\n  &lt;/CORSRule&gt;\n  &lt;CORSRule&gt;\n    &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt;\n    &lt;AllowedOrigin&gt;http://www.cors-test.com&lt;/AllowedOrigin&gt;\n  &lt;/CORSRule&gt;\n&lt;/CORSConfiguration&gt;\n\n\n참고 URL\n\n  Object Storage CLI 가이드\n    \n      https://cli.ncloud-docs.com/docs/guide-objectstorage\n    \n  \n  AWS CLI를 이용한 Object Storage 접속 방법\n    \n      https://docs.3rdeyesys.com/storage/ncloud_storage_object_storage_aws_cli_connect.html\n    \n  \n  Object Storage 접속용 Windows Client Tool - S3 Browser\n    \n      https://docs.3rdeyesys.com/storage/ncloud_storage_object_storage_s3_client_s3browser.html"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-contenttype-bulk-change-guide-html": {
						"id": "storage-ncloud-storage-object-storage-contenttype-bulk-change-guide-html",
						"title": "Object Storage 파일의 Content-Type 일괄 적용, 변경하는 방법",
						"categories": "",
						"url": " /storage/ncloud-storage-object-storage-contenttype-bulk-change-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) Object Storage에서 업로드하는 파일의 Content-Type을 업로드 시에 일괄 적용하거나, 이미 업로드된 다수의 파일의 Content-Type을 일괄 변경하는 방법을 정리해보겠습니다.\n\n테스트 순서\n일괄 적용, 변경 테스트는 다음과 같은 순서로 진행보겠습니다.\n\n\n1. 다수의 txt 파일을 업로드 하면서 [Content-Type]을 [application/octet-stream]으로 일괄 설정 \n2. 업로드된 파일의 [Content-Type]이 [application/octet-stream]인지 확인 \n3. AWS CLI를 이용해서 파일들의 [Content-Type]을 [text/plain]으로 일괄 변경 \n4. 파일의 [Content-Type]이 [text/plain]으로 변경되었는지 확인 \n5. CloudBerry Explorer를 이용해 파일들의 [Content-Type]을 [application/octet-stream]으로 일괄 변경 \n6. 파일의 [Content-Type]이 [application/octet-stream]으로 변경되었는지 확인\n\n\n업로드 시에 일괄 적용\n[Console] - [Object Storage] - [Bucket Management]에서 버킷을 선택하고 [파일 올리기] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n업로드 팝업에서 파일을 선택하기 전에 먼저 [권한 및 메타 데이터 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n메타 데이터 설정\n[권한 및 메타 데이터 설정] 팝업에서 [메타 데이터 관리] 탭을 선택하고 [Content-Type] 키워드에 테스트용으로 [application/octet-stream]을 입력하고 [메타데이터 추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n파일 업로드\n[Content-Type] 설정을 마쳤으면 업로드할 파일을 선택하고 [전송 시작] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nContent-Type 확인\n변경된 [Content-Type]을 확인하기 위해 파일 하나를 선택하고, [편집] - [메타 데이터 변경] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n메타 데이터 관리 팝업에서 [Content-Type]이 [application/octet-stream]으로 적용된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nAWS CLI로 일괄 변경\nNcloud Object Storage는 AWS S3와 호환되는 스토리지이므로 AWS CLI로 관리 가능합니다.\nAWS CLI를 이용해서 Object Storage를 관리하는 방법은 아래 문서에서 확인할 수 있습니다.\n\n AWS CLI: \nAWS CLI를 이용한 Object Storage 접속 방법\n\n\n파일 리스트 조회\n먼저 현재 Object Storage 버킷에 존재하는 파일 리스트를 조회하면 위에서 업로드 했던 5개의 파일을 확인할 수 있습니다.\n\naws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls s3://content-type-test/ --recursive  --human-readable\n\n\n  \n  \n    \n  \n\n\nContent-Type 변경\n이제 [Content-Type]을 [text/plain]으로 변경해보겠습니다.\n\naws --endpoint-url=https://kr.object.ncloudstorage.com s3 cp s3://content-type-test/test/ s3://content-type-test/test/ --recursive --content-type text/plain --metadata-directive REPLACE \n\n\n  \n  \n    \n  \n\n\nContent-Type 확인\n위에서 확인했던 방법대로 [Console]에서 파일을 선택하고 [Content-Type]을 확인해보면 [text/plain]인 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nCloudBerry Explorer를 사용해 일괄 변경\nObject Storage를 관리하기 편한 여러가지 Client Tool중에서 [CloudBerry Explorer]를 사용해서 [Content-Type]을 변경해보겠습니다.\n[CloudBerry Explorer] 사용방법은 아래 문서에서 확인 가능합니다.\n\n CloudBerry Explorer: \nObject Storage 접속용 Windows Client Tool - CloudBerry Explorer 사용 방법\n\n\n\n[CloudBerry Explorer]로 Object Storage에 접속한 후 위에서 업로드 했던 파일들을 모두 선택하고 마우스 오른쪽 버튼을 클릭하면 나타나는 메뉴에서 [Set HTTP Headers]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\nContent-Type 일괄 변경\n[Http Headers] 설정 팝업에서 [Add] 버튼을 클릭하고 [Http Header]에서는 [Content-Type]을, [Value]에서는 [application/octet-stream]을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n선택한 값을 확인하고, 아래쪽 옵션에서는 기본값 그대로 두고, [OK] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nContent-Type 확인\n위에서 확인했던 방법대로 [Console]에서 파일을 선택하고 [Content-Type]을 확인해보면 [application/octet-stream]인 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nCyberduck을 사용해 일괄 변경\n또 다른 Client Tool중의 하나인 [Cyberduck]을 사용할 경우는 아래와 같이 파일을 모두 선택하고, 상단의 [정보 가져오기] 버튼을 클릭하고, [메타데이터] 탭에서 [Content-Type]을 변경할 수 있습니다.\n\n Cyberduck: \nObject Storage 접속용 Windows, MacOS Client Tool - Cyberduck 사용 방법\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Object Storage 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/storage-storage-6-1\n    \n  \n  MIME Type 안내\n    \n      https://developer.mozilla.org/ko/docs/Web/HTTP/Basics_of_HTTP/MIME_types\n    \n  \n  Object Storage에서 html, 이미지 파일이 다운로드되는 문제 해결 방법\n    \n      https://docs.3rdeyesys.com/storage/ncloud-storage-object-storage-mimetype-contenttype-change-guide.html"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-log-management-guide-html": {
						"id": "storage-ncloud-storage-object-storage-log-management-guide-html",
						"title": "Object Storage 버킷 접근 로그 확인하는 방법",
						"categories": "",
						"url": " /storage/ncloud-storage-object-storage-log-management-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) Object Storage에 존재하는 오브젝트, 즉 파일을 호출, 접근한 기록이나 오브젝트를 업로드한 로그를 확인하는 방법을 정리해보겠습니다.\n\n버킷 생성\n우선, 테스트에 사용할 버킷과 로그를 저장할 버킷을 생성하고, 테스트용 버킷에는 파일 몇개를 업로드 해두었습니다.\n\n\n  object-bucket-test: 테스트용 버킷\n  object-bucket-test-log: 로그를 저장할 버킷\n\n\n\n  \n  \n    \n  \n\n\n로그 설정\n로그를 설정하는 방법은 버킷을 선택하고, 옆에 있는 [  ] 아이콘을 클릭하면 나타나는 메뉴에서 [로그 관리]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n로그 관리 설정\n[로그 관리] 설정 팝업에서 로그를 저장할 버킷을 선택하고, 로그 파일의 Prefix를 입력한 후 [+ 추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  설정 항목이 추가 되었으면 [확인] 버튼을 클릭해서 설정을 저장합니다.\n\n\n\n  \n  \n    \n  \n\n\n로그 생성 규칙\n\n\n⁃ 접근 로그 관리를 설정하면 매시간 15~55분에 이전 1시간 동안의 로그가 생성됩니다. \n⁃ 예시: 17시 00분 00초~17시 59분 59초의 로그는 18시 15~55분에 생성\n\n\n로그 생성\n위에서 확인한 로그 생성 규칙처럼 일정한 시간이 지난 후에 아래와 같이 로그가 생성된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n로그 예시\n생성된 로그를 다운로드 받아서 확인해보면 아래와 같은 JSON 형식으로 구성된 것을 확인할 수 있습니다.\n(로그 내용이 길이서 중요한 부분만 표시하고 나머지는 생략했습니다.)\n\n{\n    \"container_id\": \"5d3******e-9****-***2-a***0-54******f9b\", \n    \"container_name\": \"object-bucket-test\", \n    \"container_region\": \"KR\", \n    \"format\": 1, \n    \"headers\": { \"Accept-Encoding\": [\"gzip, deflate, br\"] }, \n    \"https\": \n    {\n        \"cipher_suite\": \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\", \n        \"protocol\": \"TLSv1.2\"\n    }, \n    \"object_name\": \"3rdeyesys-1.png\",   \n    \"remote_address\": \"123.123.123.123\", \n    \"stat\": {    }, \n    \"status\": 200, \n    \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML) Chrome/115.0.0.0\"\n}\n\n\n\n  \n  \n    \n  \n\n\n로그 통합 저장\n또한, 여러 버킷의 접근 로그를 하나의 버킷에 통합해서 저장할 수도 있습니다.\n\n아래와 같이 또 다른 버킷에서 [로그 관리] 설정을 추가하면서 로그를 저장할 버킷은 위에서 설정했던 버킷과 동일한 버킷으로 지정했습니다.\n\n\n  \n  \n    \n  \n\n\n\n  그리고 일정 시간이 지난 후에 확인해보면 아래와 같이 2개의 다른 버킷의 접근 로그가 저장된 것을 확인할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n로그 설정 삭제\n접근 로그를 더 이상 기록하고 싶지 않을 경우에는 아래와 같이 로그 관리 설정에서 [삭제] 버튼을 클릭해서 설정을 모두 지우시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n일본 리전\n일본 리전의 경우 다른 리전과 몇가지 내용들이 다르게 설정, 저장됩니다.\n\n\n  로그가 기록되는데에는 10분 ~ 수시간까지 소요될 수 있습니다.\n  로그에 저장되는 항목 개수가 다른 리전보다 적습니다.\n\n\n참고 URL\n\n  Ncloud Object Storage 버킷 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/objectstorage-use-bucket\n    \n  \n  Ncloud Object Storage 버킷 로그 관리 상세 가이드\n    \n      https://guide.ncloud-docs.com/docs/objectstorage-use-bucket#%EB%A1%9C%EA%B7%B8-%EA%B4%80%EB%A6%AC"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-mimetype-contenttype-change-guide-html": {
						"id": "storage-ncloud-storage-object-storage-mimetype-contenttype-change-guide-html",
						"title": "Object Storage에서 html, 이미지 파일이 다운로드되는 문제 해결 방법",
						"categories": "",
						"url": " /storage/ncloud-storage-object-storage-mimetype-contenttype-change-guide.html",
						"content": "개요\nNcloud(네이버 클라우드) Object Storage에 html 파일이나 이미지 파일을 올려두고 사용하는 경우가 많습니다.\n그런데 간혹, 웹브라우저나 앱에서 해당 파일을 호출 했을 때 html 페이지나 이미지 파일이 화면에 표시되지 않고 다운로드 되는 현상이 발생하기도 합니다.\n\n이것은 Object Storage에 파일이 등록될 때 파일의 속성을 나타내는 메타 데이터 중에서 파일의 종류를 구분하기 위한 MIME Type에 대한 정보를 담고 있는 Content-Type 항목이 제대로 설정되지 않아서 발생하는 문제입니다. 아래에서 이에 대한 내용을 자세히 정리해보겠습니다.\n\n메타 데이터\n메타 데이터는 파일의 속성이나 정보를 나타내는 값으로 Ncloud Object Storage에서는 파일 수정 날짜, 파일 크기 등의 기본으로 설정되는 시스템 메타 데이터와 사용자가 임의로 정의하는 유저 메타 데이터로 구분할 수 있으며 아래와 같이 Console 화면에서 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nMIME Type (Media Type)\nMIME은 [Multipurpose Internet Mail Extensions]의 약자로 이메일 전송을 위해 만들어진 인터넷 표준 형식으로, MIME Type이란 이메일로 전송되는 컨텐츠나 파일의 종류를 구분하기 위해 정의된 형식입니다. 최근에는 Media Type으로 표현하는 경우도 있습니다.\n\nContent-Type\n[Content-Type]은 MIME Type으로 정의된 컨텐츠나 파일을 전송할 때 프로토콜의 Header 값에 정의되는 속성입니다.\nContent-Type Header와 MIME Type은 이메일에 사용하기 위해 정의되었으나, 지금은 HTTP와 같은 다른 인터넷 프로토콜에서 널리 사용하고 있으며, MIME Type 등록은 IANA(Internet Assigned Numbers Authority)에서 관리하고 있습니다.\n\nNcloud Object Storage에서도 업로드 된 파일의 종류에 대한 정보를 Content-Type 속성으로 정의하고 있습니다.\n\n오류 상황\n예를 들어 Object Storage에 등록된 이미지 파일에 대한 Content-Type 속성이 제대로 정의되지 않았을 경우 아래와 같이 이미지 파일을 호출했을 때 이미지가 화면에 표시되지 않고 다운로드 되는 현상이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n메타 데이터 변경\n문제를 해결하기 위해서는 메타 데이터에 있는 [Content-Type]을 변경해야 하므로, 아래와 같이 콘솔 [Object Storage] - [Bucket Management]에서 해당 파일을 선택하고 [편집] - [메타 데이터 변경] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n[메타 데이터 관리] 팝업창에서 [Content-Type] 항목에 있는 [수정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n이미지나 html 문서에 맞는 값을 입력합니다. 여기서는 png 이미지 파일이므로 [image/png]를 입력했습니다.\nhtml의 경우는 [text/html]이며 기타 다양한 파일들의 MIME Type은 문서의 아래쪽에서 정리해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n[Content-Type] 값 변경 후에 브라우저의 캐시를 지우고 다시 호출해보면 아래와 같이 이미지가 정상적으로 나타나는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nMIME Type 종류\n전체 MIME Type 중에서 자주 사용되는 Type을 정리해보면 다음과 같습니다.\n\n\n  \n    \n      파일 종류\n      MIME Type\n    \n  \n  \n    \n      . aac\n      audio/aac\n    \n    \n      . avi\n      video/x-msvideo\n    \n    \n      . bin\n      application/octet-stream\n    \n    \n      . csh\n      application/x-csh\n    \n    \n      . css\n      text/css\n    \n    \n      . csv\n      text/csv\n    \n    \n      . doc\n      application/msword\n    \n    \n      . docx\n      application/vnd.openxmlformats-officedocument.wordprocessingml.document\n    \n    \n      . gif\n      image/gif\n    \n    \n      . html\n      text/html\n    \n    \n      . ico\n      image/x-icon\n    \n    \n      . ics\n      text/calendar\n    \n    \n      . jar\n      application/java-archive\n    \n    \n      . jpg\n      image/jpeg\n    \n    \n      . js\n      text/javascript\n    \n    \n      . json\n      application/json\n    \n    \n      . md\n      text/markdown\n    \n    \n      . oga\n      audio/ogg\n    \n    \n      . ogv\n      video/ogg\n    \n    \n      . pdf\n      application/pdf\n    \n    \n      . png\n      image/png\n    \n    \n      . ppt\n      application/vnd.ms-powerpoint\n    \n    \n      . pptx\n      application/vnd.openxmlformats-officedocument.presentationml.presentation\n    \n    \n      . rar\n      application/x-rar-compressed\n    \n    \n      . sh\n      application/x-sh\n    \n    \n      . svg\n      image/svg+xml\n    \n    \n      . tar\n      application/x-tar\n    \n    \n      . ttf\n      application/x-font-ttf\n    \n    \n      . txt\n      text/plain\n    \n    \n      . wav\n      audio/x-wav\n    \n    \n      . webp\n      image/webp\n    \n    \n      . woff\n      application/x-font-woff\n    \n    \n      . xls\n      application/vnd.ms-excel\n    \n    \n      . xlsx\n      application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n    \n    \n      . xml\n      application/xml\n    \n    \n      . zip\n      application/zip\n    \n  \n\n\n참고 URL\n\n  Ncloud Object Storage 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/storage-storage-6-1\n    \n  \n  MIME Type 안내\n    \n      https://developer.mozilla.org/ko/docs/Web/HTTP/Basics_of_HTTP/MIME_types\n    \n  \n  Object Storage 파일의 Content-Type 일괄 적용, 변경하는 방법\n    \n      https://docs.3rdeyesys.com/storage/ncloud-storage-object-storage-contenttype-bulk-change-guide.html"
					}
					
				
			
		
			
				
					,
					
					"analytics-ncloud-analytics-cloud-log-analytics-guide-html": {
						"id": "analytics-ncloud-analytics-cloud-log-analytics-guide-html",
						"title": "Cloud Log Analytics 설정 가이드",
						"categories": "",
						"url": " /analytics/ncloud_analytics_cloud_log_analytics_guide.html",
						"content": "개요\nCloud Log Analytics는 Ncloud(네이버 클라우드)가 제공하는 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석할 수 있는 서비스로, \n검색 기능을 이용해 여러 종류의 로그를 한 곳에서 한번에 조회하고 분석할 수 있어 효과적인 로그 관리가 가능합니다.\n\n로그 템플릿 종류\nCloud Log Analytics는 텍스트 형식으로 생성되는 모든 종류의 로그 데이터 파일을 수집할 수 있는데, 사전에 제공되는 로그 템플릿 종류는 다음과 같습니다.\n\n\n  Server syslog\n  Apache 로그(Access log, Apache Error Log)\n  MySQL 설치형 상품의 로그(Error Log, Slow Log)\n  Microsoft SQL Server 설치형 상품의 Error Log\n  Tomcat 로그(Catalina Log)\n  Windows 서버의 Event Log\n  Windows 서버의 각종 text 형식의 로그\n  Cloud DB for MySQL 로그\n  Cloud DB for MSSQL 로그\n  Cloud DB for MongoDB 로그\n  Application Server Launcher 로그\n  Application Load Balancer 로그\n  Search Engine Service 로그\n  Cloud Data Streaming Service 로그\n  Bare Metal Server 로그\n  그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다\n\n\n저장 용량\n\n  최대 100GB까지 저장할 수 있습니다.\n  100GB 용량을 초과했을 경우 추가 저장 용량 확보를 위해 과거부터 전날까지의 데이터가 삭제될 수 있습니다.\n  CLA로 수집되는 로그량이 하루 10GB 이상을 넘거나 천만 건 이상일 경우 저장된 로그 검색시 성능에 제한이 발생할 수 있습니다.\n  저장 용량과 저장 기간을 더 늘리길 원할 경우 고객지원으로 문의해야 합니다.\n  과거 데이터를 보관하려면 [자동 보내기] 기능을 이용하여 과거 데이터를 Object Storage로 백업할 수 있습니다.\n\n\n로그 보관 기간\n\n  Cloud Log Analytics 서비스는 최대 30일 동안 데이터가 보관되며, 검색 및 대시보드에서 확인할 수 있습니다.\n  30일이 지난 데이터는 과거 데이터부터 순차적으로 삭제됩니다.\n  30일이 지나지 않았더라도 저장된 데이터가 100GB를 초과하면 과거부터 전날까지의 데이터가 매일 삭제될 수 있습니다.\n\n\n이용신청\nNcloud(네이버 클라우드) 콘솔 [Cloud Log Analytics] - [Subscription]에서 [이용 신청] 버튼을 클릭합니다. \nCloud Log Analytics는 Classic, VPC 환경 공통 서비스이므로 어느쪽 환경에서 이용신청을 해도 상관없습니다.\n\n\n  \n  \n    \n  \n\n\n설정 - Linux\n먼저 Linux 서버에서 설정하는 방법을 알아보겠습니다.\n[Cloud Log Analytics] - [Management]에서 로그를 수집할 서버를 선택하고, [수집 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nLog 수집 설정 화면에서 수집할 로그 템플릿을 선택하거나, 직접 [Custom Log]를 선택해서 로그 형태를 설정한 후에 [적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 Agent 설치\nLog 수집 설정을 마치면 [로그 수집 Agent] 설치 안내가 나옵니다.\n로그 수집 Agent 설치 명령어에는 URL 뒤쪽에 설치 하려는 서버에 해당하는 설치키(Install Key)가 포함되어 있습니다. 그러므로 URL을 수정해서도 안되고 다른 서버에 사용할 수도 없습니다.\n\n# VPC 환경\n~# curl -s http://cm.vcla.ncloud.com/setUpClaVPC/{설치키(Install Key)} | sudo sh\n\n# Classic 환경\n~# curl -s http://cm.cla.ncloud.com/setUpCla/{설치키(Install Key)} | sudo sh\n\n\n\n  \n  \n    \n  \n\n\n서버에 실제로 설치해보면 아래와 같이 설치 과정이 진행되고,\n설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\n설치된 Agent가 제대로 작동하고 있는지 확인해보면 아래와 같이 active (running) 상태인 것을 확인할 수 있습니다.\n~# systemctl status filebeat\n\n\n  \n  \n    \n  \n\n\n설정 - Windows\n다음으로 Windows 서버에서 설정하는 방법을 살펴보겠습니다.\n마찬가지로 서버를 선택하고 [수집 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 설정에서 Log Template은 [EventLog]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n설정을 마치면 Agent 설치 가이드를 확인할 수 있습니다.\n서버에서 [Windows PowerShell]을 열고, 아래 명령어를 실행합니다. 마찬가지로 마지막에는 설치 서버에 해당하는 설치키가 포함되어 있습니다.\n\n# VPC 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\n\n# Classic 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\n\n\n  \n  \n    \n  \n\n\n설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\nWindows Server 2019 지원 여부\n현재 Windows Server 2019는 지원하지 않고, 2022년 상반기 지원 예정입니다.\nWindows Server 2019는 아래와 같이 선택을 해도 [수집 설정] 버튼을 활성화되지 않습니다.\n\n\n  \n  \n    \n  \n\n\n로그 확인\nAgent 설치 후 [Dashboard]를 확인해보면 로그가 수집되고 있을 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[Search] 메뉴에서는 로그 내용을 자세히 검색, 확인할 수 있고, 굳이 서버에 접속하지 않더라도 필요한 로그를 콘솔 화면에서 직접 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n로그 백업\nCloud Log Analytics는 수집된 로그를 Object Storage로 내보내기하거나 Excel 파일로 다운로드 해서 백업할 수 있는 기능을 지원합니다.\n\n수동 백업\n[Search] 메뉴에 [Object Storage로 내보내기]와 [X 다운로드] 버튼이 있습니다.\n\n\n  \n  \n    \n  \n\n\n[Object Storage로 내보내기] 버튼을 클릭하면 내보내기 할 버킷을 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n자동 백업\n[Export Log] 메뉴에서 [자동 내보내기 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n설정 화면에서 내보내기를 할 Object Storage의 버킷을 선택합니다. 혹시 버킷이 생성되지 않았다면 Object Storage로 가서 먼저 버킷을 생성하고 와야 합니다.\n\n\n  \n  \n    \n  \n\n\n내보내기는 하루에 한번 진행되므로 설정 후 다음 날 Object Storage에서 아래와 같이 파일이 저장되어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 해제\n더 이상 로그를 수집할 필요가 없어지면, 로그 수집 설정을 해제하면 됩니다.\n\nLinux 서버 로그 수집 해제\n서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\n\n# VPC 환경\n~# curl -s http://cm.vcla.ncloud.com/removeCla | sudo sh\n\n# Classic 환경\n~# curl -s http://cm.cla.ncloud.com/removeCla | sudo sh\n\n\n  \n  \n    \n  \n\n\nAgent 삭제 명령어를 실행하면 아래와 같이 Success Remove Agent 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\nWindows 서버 로그 수집 해제\n마찬가지로 서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\n\n# VPC 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/removewinCla\"))\n\n# Classic 환경\nInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/removewinCla\"))\n\n\n  \n  \n    \n  \n\n\nAgent 삭제 명령어를 실행하면 아래와 같이 Remove Agent 메시지가 출력됩니다.\n\n\n  \n  \n    \n  \n\n\nWindows 서버 Agent 삭제 오류 상황\nWindows 서버에서 Agent 삭제를 시도할 때 아래와 같이 오류 메시지가 발생하는 경우가 있습니다.\n이때는 당황하지 마시고, Agent 삭제 명령어를 다시 한번 실행하면 됩니다.\n\n Stop-Service: Cannot find any service with service name ‘filebeat’.\n\n로그 수집 설정에서 EventLog만 선택했을 경우 발생합니다.\n\n로그 수집 Agent는 윈도 이벤트 로그 수집을 위한 winlogbeat와 그 외 로그를 수집하기 위한 filebeat 두가지가 설치되는데, EventLog만 수집하도록 설정할 경우 filebeat는 실행되지 않습니다. \n그 상태에서 Agent를 삭제하려고 하면 실행중이 아닌 filebeat를 실행 중지 시키려고 시도하게 되고, 결국 오류가 발생합니다.\n\n그러므로 심각한 오류는 아니고 만약을 위해 Agent 삭제 명령어를 한번 더 실행시키는 것으로 문제는 해결됩니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Cloud Log Analytics 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/cla-cla-1-1"
					}
					
				
			
		
			
				
					,
					
					"analytics-ncloud-analytics-cloud-log-analytics-info-html": {
						"id": "analytics-ncloud-analytics-cloud-log-analytics-info-html",
						"title": "Cloud Log Analytics에서 수집하는 로그 유형",
						"categories": "",
						"url": " /analytics/ncloud_analytics_cloud_log_analytics_info.html",
						"content": "개요\nCloud Log Analytics는 네이버 클라우드 플랫폼의 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석하게 해주는 서비스입니다.\n\n로그 템플릿 종류\nCloud Log Analytics에서 수집하는 각 종 서비스의 로그 템플릿 종류는 다음과 같습니다.\n\n\n  Server syslog\n  Apache 로그(Access log, Apache Error Log)\n  MySQL 설치형 상품의 로그(Error Log, Slow Log)\n  Microsoft SQL Server 설치형 상품의 Error Log\n  Tomcat 로그(Catalina Log)\n  Windows 서버의 Event Log\n  Windows 서버의 각종 text 형식의 로그\n  Cloud DB for MySQL 로그\n  Cloud DB for MSSQL 로그\n  Cloud DB for MongoDB 로그\n  Application Server Launcher 로그\n  Application Load Balancer 로그\n  Search Engine Service 로그\n  Cloud Data Streaming Service 로그\n  Bare Metal Server 로그\n  그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다\n\n\n로그 보관 기간\n로그 데이터의 보관 기간은 30일로, 30일이 지난 데이터는 자동 삭제되며, 사전에 별도로 통지하지 않습니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/cla-cla-1-1.html"
					}
					
				
			
		
			
				
					,
					
					"api-ncloud-api-call-csharp-sample-html": {
						"id": "api-ncloud-api-call-csharp-sample-html",
						"title": "C#으로 Ncloud API를 호출하는 샘플 예제",
						"categories": "",
						"url": " /api/ncloud_api_call_csharp_sample.html",
						"content": "개요\n네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 C#으로 호출하는 샘플 예제중에서 핵심인 인증을 위한 암호화 문자열 생성 코드를 정리해보겠습니다.\n\n암호화 샘플 코드\n\npublic string unixTimeStamp;\npublic string ncpAccessKey = \"네이버 클라우드 AccessKey\";\npublic string ncpSecretKey = \"네이버 클라우드 SecretKey\";\t\npublic string apiCallMethod = \"GET\";\npublic string apiServer = \"https://billingapi.apigw.ntruss.com\";\npublic string apiUrl = \"네이버 클라우드 API URL\";\n\npublic string MakeSignature()\n{\n\tstring msgSignature;\n\tstring space = \" \";\n\tstring newLine = \"\\n\";\n\t\n\t// 13자리 유닉스 타임스탬프 설정\n\tDateTime now = DateTime.Now;\n\tDateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0);\n\tdouble totalMilliSeconds = now.Subtract(unixOriginalTime).TotalMilliseconds;\n\tunixTimeStamp = Math.Round(totalMilliSeconds).ToString();\n\n\t// hmac으로 암호화할 문자열 설정\n\tstring message = new StringBuilder()\n\t\t.Append(apiCallMethod)\n\t\t.Append(space)\n\t\t.Append(apiUrl)\n\t\t.Append(newLine)\n\t\t.Append(unixTimeStamp)\n\t\t.Append(newLine)\n\t\t.Append(ncpAccessKey)\n\t\t.ToString();\n\n\t// hmac_sha256 암호화\n\tbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\n\tbyte[] bytes = Encoding.UTF8.GetBytes(message);\n\tusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\n\t{\n\t\tbyte[] hash = sha256.ComputeHash(bytes);\n\t\tmsgSignature = Convert.ToBase64String(hash);\n\t}\n\treturn msgSignature;\n}\n\n\n코드 상세 설명\n\n네이버 클라우드 인증키\npublic string ncpAccessKey = \"네이버 클라우드 AccessKey\";\npublic string ncpSecretKey = \"네이버 클라우드 SecretKey\";\t\n\n\n네이버 클라우드 인증키는 네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\n\n유닉스 타임스탬프\nDateTime now = DateTime.Now;\nDateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0);\ndouble totalMilliSeconds = now.Subtract(unixOriginalTime).TotalMilliseconds;\nunixTimeStamp = Math.Round(totalMilliSeconds).ToString();\n\n네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요하므로 TotalMilliseconds 값을 가져와서 소수점 아래는 반올림해서 정수값만 취합니다.\n여기서 전달하는 타임스탬프값이 네이버 클라우드 API Gateway의 시간과 5분 이상 차이가 나면 인증 실패가 됩니다.\n그런데 API Gateway는 UTC 기준으로 설정되어 있기 때문에 C#으로 만든 애플리케이션을 로컬PC등의 UTC+9 시간으로 설정된 곳에서 1970년 1월 1일 00시 기준으로 계산하면 9시간의 시간차가 발생해 인증이 실패하게 됩니다.\n정리하면 다음과 같습니다.\n\n  API Gateway 타임스탬프 : UTC 현재시간 - 1970년 1월 1일 00시\n  로컬PC 타임스탬프 : UTC+9 현재시간 - 1970년 1월 1일 09시\n\n\n즉, 로컬PC 등은 API Gateway보다 9시간 빠르기 때문에 동일한 타임스탬프 값을 얻으려면 1970년 1월 1일 09시 기준으로 계산해야 한다는 것입니다. \n그래서 위의 코드에서 DateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0); 이렇게 적용했습니다.\n\nhmac으로 암호화할 문자열 설정\npublic string apiCallMethod = \"GET\";\n\nstring space = \" \";\nstring newLine = \"\\n\";\n\n암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\n\nstring message = new StringBuilder()\n\t.Append(apiCallMethod)\n\t.Append(space)\n\t.Append(apiUrl)\n\t.Append(newLine)\n\t.Append(unixTimeStamp)\n\t.Append(newLine)\n\t.Append(ncpAccessKey)\n\t.ToString();\n\n네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\n\n API 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\n\nhmac_sha256 방식으로 암호화\nbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\nbyte[] bytes = Encoding.UTF8.GetBytes(message);\nusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\n{\n\tbyte[] hash = sha256.ComputeHash(bytes);\n\tmsgSignature = Convert.ToBase64String(hash);\n}\n\nhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\n\n응답 예시\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;getProductPriceListResponse&gt;\n  &lt;requestId&gt;9a6b9f7c-f688-4cec-841f-634d355cef1e&lt;/requestId&gt;\n  &lt;returnCode&gt;0&lt;/returnCode&gt;\n  &lt;returnMessage&gt;success&lt;/returnMessage&gt;\n  &lt;totalRows&gt;2&lt;/totalRows&gt;\n  &lt;productPriceList&gt;\n    &lt;productPrice&gt;\n      &lt;productItemKind&gt;\n        &lt;code&gt;VSVR&lt;/code&gt;\n        &lt;codeName&gt;Server (VPC)&lt;/codeName&gt;\n      &lt;/productItemKind&gt;\n      &lt;productItemKindDetail&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productItemKindDetail&gt;\n     ''' 중략 '''\n      &lt;softwareType/&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productTypeDetail/&gt;\n      &lt;gpuCount&gt;0&lt;/gpuCount&gt;\n      &lt;cpuCount&gt;24&lt;/cpuCount&gt;\n      &lt;memorySize&gt;137438953472&lt;/memorySize&gt;\n      &lt;baseBlockStorageSize&gt;4123168604160&lt;/baseBlockStorageSize&gt;\n      &lt;dbKind/&gt;\n      &lt;osInfomation/&gt;\n      &lt;platformType/&gt;\n      &lt;osType/&gt;\n      &lt;platformCategoryCode/&gt;\n      &lt;diskType&gt;\n        &lt;code&gt;LOCAL&lt;/code&gt;\n        &lt;codeName&gt;Local storage&lt;/codeName&gt;\n      &lt;/diskType&gt;\n      &lt;diskDetailType&gt;\n        &lt;code&gt;SSD&lt;/code&gt;\n        &lt;codeName&gt;SSD&lt;/codeName&gt;\n      &lt;/diskDetailType&gt;\n      &lt;generationCode&gt;G1&lt;/generationCode&gt;     \n    ''' 중략 '''\n  &lt;/productPriceList&gt;\n&lt;/getProductPriceListResponse&gt;\n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ko/home/"
					}
					
				
			
		
			
				
					,
					
					"api-ncloud-api-call-php-sample-html": {
						"id": "api-ncloud-api-call-php-sample-html",
						"title": "PHP로 Ncloud API를 호출하는 샘플 예제",
						"categories": "",
						"url": " /api/ncloud_api_call_php_sample.html",
						"content": "개요\n네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 PHP로 호출하는 샘플 예제를 정리해봅니다.\n네이버 클라우드 API는 RESTful API 방식으로 제공되며, XML와 JSON 형식으로 응답합니다\n우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\nAPI 호출 샘플 코드\n\n&lt;?php\n\t\n\t// 기본 데이터 설정\n\t$unixtimestamp =  round(microtime(true) * 1000);\n\n\t$ncp_accesskey = \"네이버 클라우드 AccessKey\";\n\t$ncp_secretkey = \"네이버 클라우드 SecretKey\";\t\n\n\t$api_server = \"https://billingapi.apigw.ntruss.com\";\n\n\t// API URL 예시 : 상품별 가격 리스트 호출 api\n\t$api_url = \"/billing/v1/product/getProductPriceList\";\n\t$api_url = $api_url.\"?regionCode=KR&amp;productItemKindCode=VSVR\";\n\n\t$apicall_method = \"GET\";\n\t$space = \" \";\n\t$new_line = \"\\n\";\n\n\t$is_post = false;\n\n\t// hmac으로 암호화할 문자열 설정\n\t$message = \n\t\t$apicall_method\n\t\t.$space\n\t\t.$api_url\n\t\t.$new_line\n\t\t.$unixtimestamp\n\t\t.$new_line\n\t\t.$ncp_accesskey;\t\n\t\n\t// hmac_sha256 암호화\n\t$msg_signature = hash_hmac(\"sha256\", $message, $ncp_secretkey, true);\n\t$msg_signature = base64_encode($msg_signature);\n\n\t// http 호출 헤더값 설정\n\t$http_header = array();\n\t$http_header[0] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\n\t$http_header[1] = \"x-ncp-iam-access-key:\".$ncp_accesskey.\"\";\n\t$http_header[2] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\n\n\t// api 호출\n\t$ch = curl_init();\n\tcurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n\tcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n\tcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n\tcurl_setopt($ch, CURLOPT_POST, $is_post);\n\tcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n\n\t$response = curl_exec($ch);\n\n\tcurl_close($ch);\n\n?&gt;\n\n\n코드 상세 설명\n\n유닉스 타임 스탬프\n$unixtimestamp =  round(microtime(true) * 1000);\n\n네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요합니다.\nPHP에서 일반적으로 사용하는 time()함수는 10자리 형식이기 때문에 여기서는 microtime()을 사용합니다.\nmicrotime(true)은 float 형식의 값을 리턴하므로 1000을 곱하고 정수로 반올림합니다.\n\n$val1 = time();\n$val2 = microtime(true);\n$val3 = round(microtime(true) * 1000);\n\n/*\n$val1 : 1617699570\n$val2 : 1617699570.1146\n$val3 : 1617699570115\n*/\n\n\n네이버 클라우드 인증키\n$ncp_accesskey = \"네이버 클라우드 AccessKey\";\n$ncp_secretkey = \"네이버 클라우드 SecretKey\";\t\n\n\n네이버 클라우드 인증키는 네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nhmac으로 암호화할 문자열 설정\n$apicall_method = \"GET\";\n$space = \" \";\n$new_line = \"\\n\";\n\n암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\n\n$message = \n\t$apicall_method\n\t.$space\n\t.$api_url\n\t.$new_line\n\t.$unixtimestamp\n\t.$new_line\n\t.$ncp_accesskey;\t\n\n네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\n\n API 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\n\nhmac_sha256 방식으로 암호화\n$msg_signature = hash_hmac(\"sha256\", $message, $ncp_secretkey, true));\n$msg_signature = base64_encode($msg_signature);\n\nhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 $message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\n\nhttp 호출 헤더값 설정\n$http_header = array();\n$http_header[0] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\n$http_header[1] = \"x-ncp-iam-access-key:\".$ncp_accesskey.\"\";\n$http_header[2] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\n\nAPI를 호출할 때는 http 헤더값에 다음 3가지를 추가해서 호출합니다.\n\n  유닉스 타임스탬프\n  네이버 클라우드 API AccessKey\n  hmac_256 으로 암호화한 문자열\n\n\n여기서 전송하는 타임스탬프는 위에서 $message를 암호화할 때 사용한 타임스탬프와 동일한 값이어야 합니다.\n\napi 호출\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\ncurl_setopt($ch, CURLOPT_POST, $is_post);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n\n$response = curl_exec($ch);\n\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\n리턴값은 호출하는 용도별로 json 또는 xml 형태로 반환됩니다.\n\n응답 예시\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;getProductPriceListResponse&gt;\n  &lt;requestId&gt;9a6b9f7c-f688-4cec-841f-634d355cef1e&lt;/requestId&gt;\n  &lt;returnCode&gt;0&lt;/returnCode&gt;\n  &lt;returnMessage&gt;success&lt;/returnMessage&gt;\n  &lt;totalRows&gt;2&lt;/totalRows&gt;\n  &lt;productPriceList&gt;\n    &lt;productPrice&gt;\n      &lt;productItemKind&gt;\n        &lt;code&gt;VSVR&lt;/code&gt;\n        &lt;codeName&gt;Server (VPC)&lt;/codeName&gt;\n      &lt;/productItemKind&gt;\n      &lt;productItemKindDetail&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productItemKindDetail&gt;\n     ''' 중략 '''\n      &lt;softwareType/&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productType&gt;\n        &lt;code&gt;BM&lt;/code&gt;\n        &lt;codeName&gt;BareMetal&lt;/codeName&gt;\n      &lt;/productType&gt;\n      &lt;productTypeDetail/&gt;\n      &lt;gpuCount&gt;0&lt;/gpuCount&gt;\n      &lt;cpuCount&gt;24&lt;/cpuCount&gt;\n      &lt;memorySize&gt;137438953472&lt;/memorySize&gt;\n      &lt;baseBlockStorageSize&gt;4123168604160&lt;/baseBlockStorageSize&gt;\n      &lt;dbKind/&gt;\n      &lt;osInfomation/&gt;\n      &lt;platformType/&gt;\n      &lt;osType/&gt;\n      &lt;platformCategoryCode/&gt;\n      &lt;diskType&gt;\n        &lt;code&gt;LOCAL&lt;/code&gt;\n        &lt;codeName&gt;Local storage&lt;/codeName&gt;\n      &lt;/diskType&gt;\n      &lt;diskDetailType&gt;\n        &lt;code&gt;SSD&lt;/code&gt;\n        &lt;codeName&gt;SSD&lt;/codeName&gt;\n      &lt;/diskDetailType&gt;\n      &lt;generationCode&gt;G1&lt;/generationCode&gt;     \n    ''' 중략 '''\n  &lt;/productPriceList&gt;\n&lt;/getProductPriceListResponse&gt;\n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ko/home/"
					}
					
				
			
		
			
				
					,
					
					"api-ncloud-api-call-python-sample-html": {
						"id": "api-ncloud-api-call-python-sample-html",
						"title": "Python으로 Ncloud API를 호출하는 샘플 예제",
						"categories": "",
						"url": " /api/ncloud_api_call_python_sample.html",
						"content": "개요\nNcloud (네이버 클라우드) 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 Python으로 호출하는 샘플 예제를 정리해봅니다.\nNcloud API는 RESTful API 방식으로 제공되며, XML와 JSON 형식으로 응답합니다\n우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\nAPI 호출 샘플 코드\n\nimport sys\nimport os\nimport hashlib\nimport hmac\nimport base64\nimport requests\nimport time\n\n# unix timestamp 설정\ntimestamp = int(time.time() * 1000)\ntimestamp = str(timestamp)\n\n# Ncloud API Key 설정\nncloud_accesskey = \"네이버 클라우드 AccessKey\"\nncloud_secretkey = \"네이버 클라우드 SecretKey\"\n\n# 암호화 문자열 생성을 위한 기본값 설정\napicall_method = \"GET\"\nspace = \" \"\nnew_line = \"\\n\"\n\n# API 서버 정보\napi_server = \"https://billingapi.apigw.ntruss.com\"\n\n# API URL 예시 : 상품별 가격 리스트 호출 api\napi_url = \"/billing/v1/product/getProductPriceList\"\napi_url = api_url +\"?regionCode=KR&amp;productCode=SPCF000000000001&amp;responseFormatType=json\"\n\n# hmac으로 암호화할 문자열 생성\nmessage = apicall_method + space + api_url + new_line + timestamp + new_line + ncloud_accesskey\nmessage = bytes(message, 'UTF-8')\n\n# hmac_sha256 암호화\nncloud_secretkey = bytes(ncloud_secretkey, 'UTF-8')\nsigningKey = base64.b64encode(hmac.new(ncloud_secretkey, message, digestmod=hashlib.sha256).digest())\n\n# http 호출 헤더값 설정\nhttp_header = {\n    'x-ncp-apigw-timestamp': timestamp,\n    'x-ncp-iam-access-key': ncloud_accesskey,\n    'x-ncp-apigw-signature-v2': signingKey\n}\n\n# api 호출\nresponse = requests.get(api_server + api_url, headers=http_header)\n\nprint (response.text)\n\n\n코드 상세 설명\n\n유닉스 타임 스탬프\nNcloud API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요합니다.\ntime.time()은 float 형식의 값을 리턴하므로 1000을 곱하고 정수로 반올림하고, 문자열로 변환합니다.\n\ntimestamp = int(time.time() * 1000)\ntimestamp = str(timestamp)\n\n\nNcloud API 인증키 설정\n\nncloud_accesskey = \"네이버 클라우드 AccessKey\"\nncloud_secretkey = \"네이버 클라우드 SecretKey\"\n\n\nNcloud API 인증키는 Ncloud 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\n API 인증키 사용 중지: 발급된 API 인증키는 사용중지/삭제가 가능하므로, 사용하지않는 API 인증키는 사용중지 또는 삭제하는것을 권장합니다.\n\nhmac으로 암호화할 문자열 설정\n암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\nAPI 호출 방식은 GET과 POST 둘 다 가능한데, 일반적으로 많이 사용되는 GET 방식으로 소개하고, POST 방식은 아래쪽에 코드만 정리해두었습니다.\n\napicall_method = \"GET\"\nspace = \" \"\nnew_line = \"\\n\"\n\n\nAPI 서버와 URL 정보\nAPI 서버와 URL 정보를 설정하면서 API 호출 후 리턴되는 결과값을 \njson, xml 어떤 형태로 받을 것인지를 responseFormatType=json, responseFormatType=xml 형식으로 설정할 수 있습니다. \n기본 값은 xml로 값을 설정하지 않으면 xml로 리턴됩니다.\n\n# API 서버 정보\napi_server = \"https://billingapi.apigw.ntruss.com\"\n\n# API URL 예시 : 상품별 가격 리스트 호출 api\napi_url = \"/billing/v1/product/getProductPriceList\"\napi_url = api_url +\"?regionCode=KR&amp;productCode=SPCF000000000001&amp;responseFormatType=json\"\n\n\n API URL 설정: API 서버와 URL 정보를 설정할 때 2가지를 구분해서 설정하는 것이 좋습니다. 암호화 문자열을 설정할 때 도메인에 해당하는 API 서버 정보를 제외한 뒤쪽의 API URL만 사용하는데, https://로 시작하는 API 서버 정보까지 포함하면 API 호출 시에 오류가 발생하기 때문입니다.\n\n API 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\n\n암호화 문자열 생성\nNcloud API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\n\nmessage = apicall_method + space + api_url + new_line + timestamp + new_line + access_key\nmessage = bytes(message, 'UTF-8')\n\n\nhmac_sha256 방식으로 암호화\nhmac sha256 방식으로 Ncloud API SecretKey를 이용하여 message를 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\n\nncloud_secretkey = bytes(ncloud_secretkey, 'UTF-8')\nsigningKey = base64.b64encode(hmac.new(ncloud_secretkey, message, digestmod=hashlib.sha256).digest())\n\n\nhttp 호출 헤더값 설정\nAPI를 호출할 때는 http 헤더값에 다음 3가지를 추가해서 호출합니다.\n\n  유닉스 타임스탬프\n  Ncloud API AccessKey\n  hmac_256 으로 암호화한 문자열\n\n\nhttp_header = {\n    'x-ncp-apigw-timestamp': timestamp,\n    'x-ncp-iam-access-key': ncloud_accesskey,\n    'x-ncp-apigw-signature-v2': signingKey\n}\n\n\n timestamp: 이때 전송하는 timestamp는 위에서 message를 암호화할 때 사용한 timestamp와 동일한 값이어야 합니다. 그리고, API Gateway 서버와 시간 차가 5분 이상 인 경우 유효하지 않은 요청으로 간주되어 호출 오류가 발생합니다.\n\napi 호출\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\n리턴값은 호출하는 용도별로 json 또는 xml 형태로 반환됩니다.\n\nresponse = requests.get(api_server + api_url, headers=http_header)\n\n\n응답 예시\n\n{\"getProductPriceListResponse\": {\n  \"requestId\": \"3e4fa6**-f967-4***-a8a9-9dd75****2d65\",\n  \"returnCode\": \"0\",\n  \"returnMessage\": \"success\",\n  \"totalRows\": 1,\n  \"productPriceList\": [\n    {\n      \"productItemKind\": {\n        \"code\": \"CF\",\n        \"codeName\": \"Cloud Functions\"\n      },\n      \"productItemKindDetail\": {},\n      \"productCode\": \"SPCF000000000001\",\n      \"productName\": \"Cloud Functions\",\n      \"productDescription\": \"Cloud Functions\",\n      \"softwareType\": {},\n      \"productTypeDetail\": {},\n      \"gpuCount\": 0,\n      \"cpuCount\": 0,\n      \"memorySize\": 0,\n      \"baseBlockStorageSize\": 0,\n      \"dbKind\": {},\n      \"osInfomation\": \"\",\n      \"platformType\": {},\n      \"osType\": {},\n      \"platformCategoryCode\": \"\",\n      \"diskType\": {},\n      \"diskDetailType\": {},\n      \"generationCode\": \"\",\n      \"priceList\": [\n        {\n          \"priceNo\": \"3870\",\n          \"priceType\": {\n            \"code\": \"MTRAT\",\n            \"codeName\": \"Meter rate\"\n          },\n          \"chargingUnitType\": {\n            \"code\": \"QUERY\",\n            \"codeName\": \"Query\"\n          },\n          \"ratingUnitType\": {\n            \"code\": \"SECT\",\n            \"codeName\": \"Period unit\"\n          },\n          \"chargingUnitBasicValue\": \"1000000\",\n          \"productRatingType\": {\n            \"code\": \"CFREQ\",\n            \"codeName\": \"Cloud Functions Request\"\n          },\n          \"unit\": {\n            \"code\": \"REQ_CNT\",\n            \"codeName\": \"Number of requests (per month)\"\n          },\n          \"price\": 0,\n          \"conditionType\": {},\n          \"conditionPrice\": 0,\n          \"priceDescription\": \"Number of requests (1000000) * Price\",\n          \"freeUnit\": {},\n          \"freeValue\": 0,\n          \"meteringUnit\": {\n            \"code\": \"REQ_CNT\",\n            \"codeName\": \"Number of requests (per month)\"\n          },\n          \"startDate\": \"2018-04-10T00:00:00+0900\",\n          \"periodUnitList\": [\n            {\n              \"startValue\": 0,\n              \"endValue\": 1000000,\n              \"price\": 0\n            },\n            {\n              \"startValue\": 1000000,\n              \"endValue\": -1,\n              \"price\": 200\n            }\n          ],\n          \"countryUnitList\": [],\n          \"packageUnitList\": []\n        }\n      ]\n    }\n  ]\n}}\n\n\nPOST 방식 호출 코드\nNcloud API는 일반적으로 GET 방식으로 호출하지만, POST 방식으로 호출하는 경우는 다음처럼 구성할 수 있습니다.\n\nimport sys\nimport os\nimport hashlib\nimport hmac\nimport base64\nimport requests\nimport time\n\n# unix timestamp 설정\ntimestamp = int(time.time() * 1000)\ntimestamp = str(timestamp)\n\n# Ncloud API Key 설정\nncloud_accesskey = \"네이버 클라우드 AccessKey\"\nncloud_secretkey = \"네이버 클라우드 SecretKey\"\n\n# 암호화 문자열 생성을 위한 기본값 설정\napicall_method = \"POST\"\nspace = \" \"\nnew_line = \"\\n\"\n\n# API 서버 정보\napi_server = \"https://billingapi.apigw.ntruss.com\"\n\n# API URL 예시 : 상품별 가격 리스트 호출 api\napi_url = \"/billing/v1/product/getProductPriceList\"\n\n# hmac으로 암호화할 문자열 생성\nmessage = apicall_method + space + api_url + new_line + timestamp + new_line + access_key\nmessage = bytes(message, 'UTF-8')\n\n# hmac_sha256 암호화\nncloud_secretkey = bytes(ncloud_secretkey, 'UTF-8')\nsigningKey = base64.b64encode(hmac.new(ncloud_secretkey, message, digestmod=hashlib.sha256).digest())\n\n# http 호출 헤더값 설정\nhttp_header = {\n    'x-ncp-apigw-timestamp': timestamp,\n    'x-ncp-iam-access-key': ncloud_accesskey,\n    'x-ncp-apigw-signature-v2': signingKey\n}\n\n# POST 파라미터\npost_data =(\n    ('regionCode','KR'),\n    ('productCode','SPCF000000000001'),    \n    ('responseFormatType','json')\n)\n\n# api 호출\nresponse = requests.post(api_server + api_url, headers=http_header, data=post_data)\n\nprint (response.text)\n\n\n오류 상황\nPython으로 코드를 작성할 때 발생할 수 있는 오류를 정리해보겠습니다.\n\nimport requests 오류\nrequests는 Python에서 http 호출에 필요한 라이브러리입니다. 설치되어 있지 않으면 다음과 같은 오류가 발생할 수 있습니다.\n\n ModuleNotFoundError: No module named ‘requests’\n\n다음과 같이 requests 라이브러리를 설치하면 해결 됩니다.\n\nD:\\python&gt; pip install requests\n\nCollecting requests\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n     |████████████████████████████████| 63 kB 790 kB/s\nCollecting urllib3&lt;1.27,&gt;=1.21.1\n  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n     |████████████████████████████████| 138 kB ...\nCollecting idna&lt;4,&gt;=2.5\n     |████████████████████████████████| 61 kB ...\nCollecting certifi&gt;=2017.4.17\n  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n     |████████████████████████████████| 149 kB 6.4 MB/s\nCollecting charset-normalizer~=2.0.0\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nInstalling collected packages: urllib3, idna, charset-normalizer, certifi, requests\nSuccessfully installed certifi-2021.10.8 charset-normalizer-2.0.12 idna-3.3 requests-2.27.1 urllib3-1.26.8f\n\n\npip upgrade 오류\nPython 코드 작성과 직접 관계가 있는 것은 아니지만 Windows 환경에서 pip 버전을 업그레이드 하라는 메시지가 나타나서 아래와 같이 업그레이드를 하려고 할 때 오류 메시지가 발생하는 경우가 있습니다.\n\nD:\\python&gt; pip install --upgrade pip\n\n\n ERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다\n\n이럴 때는 Command Prompt를 관리자 권한으로 실행하시면 해결 됩니다.\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ko/home/"
					}
					
				
			
		
			
				
					,
					
					"application-service-ncloud-application-service-cloud-outbound-mailer-bulk-mail-send-html": {
						"id": "application-service-ncloud-application-service-cloud-outbound-mailer-bulk-mail-send-html",
						"title": "Cloud Outbound Mailer로 대량 메일 발송하는 방법",
						"categories": "",
						"url": " /application-service/ncloud_application_service_cloud_outbound_mailer_bulk_mail_send.html",
						"content": "개요\n네이버 클라우드 서비스 중에서 각 종 공지나 이벤트, 마케팅으로 회원들에게 대량의 메일을 발송해야 할 때 사용할 수 있는 것이 Cloud Outbound Mailer 입니다.\n대량 메일을 발송하는 방법은 여러가지 있지만, 그 중에서도 가장 자주, 간편하게 사용하는 것이 Excel 등의 파일을 업로드 해서 발송하는 방법입니다.\n\n이용 신청\nCloud Outbound Mailer는 먼저 이용신청을 하셔야 합니다.\n[Console] - [Cloud Outbound Mailer] - [Mailing list] 에서 [이용 신청] 버튼을 클릭하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 서비스 이용약관에 동의하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n도메인 인증\n\n 도메인 인증: \nGmail에서는 2024년 2월부터 새로운 이메일 발신자 가이드라인을 적용하면서 도메인 인증을 받지 않은 경우 메일이 스팸처리되거나 제대로 전송되지 않을 수 있다고 공지하고 있습니다. 그래서 Ncloud에서도 도메인 인증을 받아야만 Gmail로 메일 발송할 수 있도록 하고 있습니다. 그러므로 메일 발송 전에 도메인 인증을 받는 것을 권장합니다.\n- Cloud Outbound Mailer 도메인 인증 방법 3가지(SPF, DKIM, DMARC) 안내 바로 가기\n\n\n메일 작성\n메일링 리스트 화면에서 발송하기 버튼을 클릭합니다.\n\n  \n  \n    \n  \n\n\n메일 작성-발송하기 화면입니다.\n이중에서 보내는 메일주소, 제목, 내용, 받는 사람은 필수 입력 사항입니다.\n\n\n  \n  \n    \n  \n\n\n[대량 발송용 입력양식 파일다운로드]와 [대량 발송용 파일 선택]은 [보내는 메일 주소]와 [제목], [내용] 을 입력해야 활성화 됩니다.\n\n\n  \n  \n    \n  \n\n\n대량메일 발송용 입력양식\nCloud Outbound Mailer에서 제공하는 대량메일 발송용 입력양식을 다운 받아서 보면, [수신자 Email 주소], [NAME] 이렇게 2가지 항목으로 구성되어 있습니다.\n\n\n  \n  \n    \n  \n\n\n그 외에도 필요한 항목들을 추가해서 사용할 수 있습니다. 여기서는 [GRADE], [GIFT\t] 항목을 추가해서 테스트 해보겠습니다. \n추가 항목의 이름은 어떤 것이든 상관없습니다. 실제 메일 내용에서 동일한 이름을 사용하기만 하면 문제 없습니다.\n\n\n  \n  \n    \n  \n\n\n보내는 이름, 보내는 메일주소, 제목 입력\n우선, 보내는 이름과 보내는 메일주소, 제목을 입력합니다.\n제목에는 대량 메일 수신자들의 이름이 들어가도록 위에서 확인한 입력 양식에 있던 이름에 해당하는 [NAME] 필드가 들어갈 수 있게 ${NAME} 코드를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n내용 입력\n내용은 직접 입력해도 되고 별도로 제작된 html 파일을 이용할 수도 있는데 Cloud Outbound Mailer에서는 html 파일 업로드는 지원하지 않습니다.\n그러므로 html 소스를 직접 복사해서 화면에 입력해야 합니다.  다음과 같은 샘플용 html을 준비해서 &lt;body&gt;와 &lt;/body&gt;태그 사이에 있는 내용을 복사해서 에디터의 html모드에 붙여넣습니다.\n\n Tip: 스타일은 css 파일이나 style태그를 사용하지 말고 가급적 태그 안에 inline으로 적용하는 것이 좋습니다. \n메일 서비스 별로 head 태그만 없애는 곳도 있고, style태그를 모두 없애거나, body태그 안쪽의 내용만 남기고 모두 없애는 곳도 있기 때문에 inline 형식으로 적용하는 것이 가장 안전합니다.\n\n\n  \n  \n    \n  \n\n\n복사한 html을 Editor 모드로 바꾸면 다음과 같이 보입니다.\n여기서 위에서 준비한 입력양식 Excel 파일에 있던 ${NAME}, ${GRADE}, ${GIFT} 항목을 적절하게 배치해서 입력해두었습니다.\n\n\n  \n  \n    \n  \n\n\n대량메일 수신자 파일 등록, 확인 후 발송\n위에서 준비했던 대량메일 수신자 정보가 들어있는 Excel 파일을 등록하고 [확인 후 발송] 버튼을 클릭합니다.\n바로 발송을 해도 되지만 그것보다는 메일 내용이 제대로 표시되는지, 수신자 목록은 문제 없이 로딩되었는지 확인 한 후에 발송하는 것이 안전합니다.\n\n\n  \n  \n    \n  \n\n\n발송 준비\n확인 후 발송을 선택하면 이렇게 [발송 준비] 상태로 리스트에 나타납니다.\n이 상태에서 수신자와 메일 내용이 올바르게 설정되었는지 확인하기 위해 [수신자별 목록] 탭을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n수신자별 목록\n수신자별 목록을 살펴보면 다음과 같이 나옵니다.  Excel 파일에 등록해 두었던 이름과 이메일 주소가 문제없이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n메일 내용 확인\n수신자별 목록에서 하나를 선택하면 상세 내용이 나오는데, 그 중에서 아래쪽에 있는 [내용보기] 버튼을 클릭해서 메일 본문 내용도 문제가 없는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\n내용 보기를 하시면 아래와 같이 Excel 파일에 등록해 두었던  [NAME], [GRADE], [GIFT] 항목들이 문제없이 설정되어 표시된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n메일 발송\n이제 다시 [요청별 목록]으로 돌아와서 [즉시 발송] 버튼을 클릭해 메일을 발송합니다.\n\n\n  \n  \n    \n  \n\n\n메일 도착 확인\n실제 존재하는 메일 주소로 발송해보면 이렇게 메일이 잘 들어온 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n메일 발송 도메인\n메일 발송은 잘되었고, 도착도 잘했는데 궁금한 것이 한가지 생깁니다.\n과연 메일 발송 도메인은 어떤 것일까?  그래서 구글 계정으로 보낸 메일에서 발송 도메인을 확인해보았습니다.\n도메인은 email.ncloud.com 인 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/email-email-1-2\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-05-12\n          문서 최초 생성\n        \n      \n        \n          2024-02-02\n          도메인 인증 안내 추가"
					}
					
				
			
		
			
				
					,
					
					"application-service-ncloud-application-service-nshorturl-php-sample-html": {
						"id": "application-service-ncloud-application-service-nshorturl-php-sample-html",
						"title": "PHP로 nShortURL 서비스 이용하기 샘플 예제",
						"categories": "",
						"url": " /application-service/ncloud_application_service_nshorturl_php_sample.html",
						"content": "개요\nSNS를 사용하거나 SMS를 보낼 때 길고 복잡한 URL은 무척 불편하기에 짧게 바꿔주는 서비스들이 인기를 얻었습니다.\n대표적으로 goo.gl, bit.ly 등이 있는데 현재 구글의 goo.gl는 서비스가 종료되었습니다.\n그래서 이를 대신해서 네이버 클라우드에 있는 길고 복잡한 URL을 간단하고 짧게 바꿔주는 API 서비스 nShortURL 서비스를 추천합니다.\nnShortURL은 OpenAPI 형태로 제공되는데 여기서는 PHP로 호출하는 방식을 살펴볼텐데, 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\n이용 요금\nnShortURL은 무료로 제공되는 서비스이며, 일 25,000건, 월 750,000건 내에서 사용 가능하며 상향이 필요한 경우 고객지원으로 문의하면 됩니다.\n\nAPI 이용 신청\nnShortURL을 이용하기 위해서는 [네이버 클라우드 콘솔] - [AI·NAVER API] -  [Application]에서 등록을 해야 합니다.\n아래와 같이 NAVER 서비스에서 nShortURL을 선택하고, 이름과 사용할 서비스 환경을 입력하고 등록하면 됩니다.\nnShortURL은 웹페이지, 모바일앱 어디서든 사용 가능하며 URL이나 앱 패키지이름, Bundle ID 등을 입력하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\nApplication 등록을 하고 나면 다음과 같은 화면을 볼 수 있는데 여기서 인증 정보를 확인해야 합니다.\n\n\n  \n  \n    \n  \n\n\n인증키 확인\nnShortURL API를 호출하려면 Client ID와 Client Secret 로 이루어진 Application Key를 사용해야 하는데 아래와 같이 [인증 정보] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nAPI 호출 샘플 코드\n\n&lt;?php\n\t\n\t$long_url = \"변환할 URL\";\t\n\t\t\n\t$client_id = \"Client ID\";\n\t$client_secret = \"Client Secret\";\n\t$api_url = \"https://naveropenapi.apigw.ntruss.com/util/v1/shorturl\";\n\t$enc_url = urlencode($long_url);\n\t$postvars = \"url=\".$enc_url;\t\n\t$is_post = true;\n\n\t$ch = curl_init();\n\tcurl_setopt($ch, CURLOPT_URL, $api_url);\n\tcurl_setopt($ch, CURLOPT_POST, $is_post);\n\tcurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n\tcurl_setopt($ch, CURLOPT_POSTFIELDS, $postvars);\n\n\t$headers = array();\n\t$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n\t$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\n\tcurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n\n\t$json_response = curl_exec ($ch);\n\n\t$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n\n\tcurl_close ($ch);\n\n\tif($status_code == 200) \n\t{\n\t\t$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n\t\t$rows_result = $rows_response[\"result\"];\n\t\t$short_url = $rows_result[\"url\"];\n\t\t$hash_val = $rows_result[\"hash\"];\n\t\t$org_url = $rows_result[\"orgUrl\"];\n\t} \n\telse \n\t{\n\t\t$short_url = \"Error 내용:\".$json_response;\n\t}\n\n?&gt;\n\n\n코드 상세 설명\n\nApplication Key\n$client_id = \"Client ID\";\n$client_secret = \"Client Secret\";\n\n네이버 클라우드 콘솔에서 nShortURL 서비스를 등록하고 인증 정보에서 확인한 [Client ID] 와 [Client Secret]를 가져와서 사용하면 됩니다.\n\nAPI URL\n$api_url = \"https://naveropenapi.apigw.ntruss.com/util/v1/shorturl\";\n\n\nnShortURL의 API URL은 위와 같습니다.\n\n파라미터 설정\n$enc_url = urlencode($long_url);\n$postvars = \"url=\".$enc_url;\t\n$is_post = true;\n\n변환할 URL을 urlencode로 인코딩하고, POST 방식으로 호출하면서 넘겨줄 변수에 할당합니다.\n\nhttp 호출 헤더값 설정\n$headers = array();\n$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\n위에서 가져온 Application Key를 호출할 API에 헤더값으로 설정해서 호출하게 됩니다.\n\n결과값 반환\n$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n$rows_result = $rows_response[\"result\"];\n$short_url = $rows_result[\"url\"];\n$hash_val = $rows_result[\"hash\"];\n$org_url = $rows_result[\"orgUrl\"];\n\nnShortURL에서 json형태로 반환된 값을 배열에 담아 사용하면 됩니다.\n반환되는 값은 짧게 변환된 URL와 해시값, 그리고 원본 URL입니다.\n\n사용 한도 및 알람 설정\nnShortURL 서비스는 과도한 사용을 방지하기 위해 일별 25,000회, 월별 750,000회의 제한이 있습니다.\n그리고 지정된 한도 내에서 일정한 사용을 초과하면 알람을 받도록 설정할 수 있습니다.\n아래처럼 Application 등록 화면에서 [한도 및 알람 설정] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ai-naver-nshorturl"
					}
					
				
			
		
			
				
					,
					
					"application-service-ncloud-application-service-papago-korean-name-romanizer-php-sample-html": {
						"id": "application-service-ncloud-application-service-papago-korean-name-romanizer-php-sample-html",
						"title": "Papago Korean Name Romanizer 서비스 이용하기 PHP 샘플 예제",
						"categories": "",
						"url": " /application-service/ncloud_application_service_papago_korean_name_romanizer_php_sample.html",
						"content": "개요\nPapago Korean Name Romanizer는 한글로 된 이름을 로마자 표기로 변환해주는 서비스로, 현행 로마자 표기법을 따라 변환한 이름과 통계적으로 많이 사용되는 로마자 이름도 함께 제안 받을 수 있습니다.\nPapago Korean Name Romanizer는 OpenAPI 형태로 제공되며 여기서는 PHP로 호출하는 방식을 살펴볼텐데, 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\n이용 요금\nPapago Korean Name Romanizer는 무료로 제공되는 서비스이며, 일 25,000자, 월 750,000자 내에서 사용 가능하며 상향이 필요한 경우 고객지원으로 문의하면 됩니다.\n\nAPI 이용 신청\nPapago Korean Name Romanizer를 이용하기 위해서는 [네이버 클라우드 콘솔] - [AI·NAVER API] -  [Application]에서 등록을 해야 합니다.\n아래와 같이 NAVER 서비스에서 Papago Korean Name Romanizer를 선택하고, 이름과 사용할 서비스 환경을 입력하고 등록하면 됩니다.\nPapago Korean Name Romanizer는 웹페이지, 모바일앱 어디서든 사용 가능하며 URL이나 앱 패키지이름, Bundle ID 등을 입력하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\nApplication 등록을 하고 나면 다음과 같은 화면을 볼 수 있는데 여기서 인증 정보를 확인해야 합니다.\n\n\n  \n  \n    \n  \n\n\n인증키 확인\nPapago Korean Name Romanizer API를 호출하려면 Client ID와 Client Secret 로 이루어진 Application Key를 사용해야 하는데 아래와 같이 [인증 정보] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nAPI 호출 샘플 코드\n\n&lt;?php\n\t\n    $korean_name = \"변환할 한글 이름\";\t\n\t\n    $client_id = \"Client ID\";\n    $client_secret = \"Client Secret\";\n    $enc_korean_name = urlencode($korean_name);\n    $getvars = \"query=\".$enc_korean_name;\n    $api_url = \"https://naveropenapi.apigw.ntruss.com/krdict/v1/romanization?\".$getvars;\n    $is_post = false;\n\n    $ch = curl_init();\n    curl_setopt($ch, CURLOPT_URL, $api_url);\n    curl_setopt($ch, CURLOPT_POST, $is_post);\n    curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n\n    $headers = array();\n    $headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n    $headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\n    curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n\n    $json_response = curl_exec ($ch);\n\n    $status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n\n    curl_close ($ch);\n\n    if($status_code == 200){\n    \t$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n    \tif (count($rows_response[\"aResult\"]) &gt; 0){\n    \t\t$rows_result = $rows_response[\"aResult\"][0];\n\t\t    $sFirstName = $rows_result[\"sFirstName\"];\n\t\t    $aItems = $rows_result[\"aItems\"];\n\t    }else{\n    \t\t$roman_name = \"변환할 수 없는 이름입니다\";\n    \t}\n    }else{\n    \t$roman_name = \"Error 내용:\".$json_response;\n    }\n?&gt;\n\n\n코드 상세 설명\n\nApplication Key\n$client_id = \"Client ID\";\n$client_secret = \"Client Secret\";\n\n네이버 클라우드 콘솔에서 Papago Korean Name Romanizer 서비스를 등록하고 인증 정보에서 확인한 [Client ID] 와 [Client Secret]를 가져와서 사용하면 됩니다.\n\n파라미터 설정\n$enc_korean_name = urlencode($korean_name);\n$getvars = \"query=\".$enc_korean_name;\n$is_post = false;\n\n변환할 한글 이름을 urlencode로 인코딩하고, GET 방식으로 호출하면서 넘겨줄 변수에 할당합니다.\n\nAPI URL\n$api_url = \"https://naveropenapi.apigw.ntruss.com/krdict/v1/romanization?\".$getvars;\n\n\nPapago Korean Name Romanizer의 API URL은 위와 같고, GET 방식으로 호출하므로 url 뒤에 파라미터를 붙여서 전송합니다.\n\nhttp 호출 헤더값 설정\n$headers = array();\n$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\n$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\n\n위에서 가져온 Application Key를 호출할 API에 헤더값으로 설정해서 호출하게 됩니다.\n\n결과값 반환\n$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\nif (count($rows_response[\"aResult\"]) &gt; 0){\n\t$rows_result = $rows_response[\"aResult\"][0];\n\t$sFirstName = $rows_result[\"sFirstName\"];\n\t$aItems = $rows_result[\"aItems\"];\n\n\tforeach ($aItems as $item){\n\t\t$roman_name = $item[\"name\"];\n\t\t$score = $item[\"score\"];\n\t}\n}else{\n\t$roman_name = \"변환할 수 없는 이름입니다\";\n}\n\nPapago Korean Name Romanizer에서 json형태로 반환된 값을 배열에 담아 사용하면 됩니다.\n반환되는 값은 한글 성과 변환된 로마자 이름과 빈도수가 담긴 배열입니다.\nPapago Korean Name Romanizer에서 변환할 수 없는 이름일 경우 상태코드는 정상이지만 배열에 정보가 없기 때문에 예외처리를 해주어야 합니다.\n\n사용 한도 및 알람 설정\nPapago Korean Name Romanizer 서비스는 과도한 사용을 방지하기 위해 일별 25,000자, 월별 750,000자의 제한이 있습니다.\n그리고 지정된 한도 내에서 일정한 사용을 초과하면 알람을 받도록 설정할 수 있습니다.\n아래처럼 Application 등록 화면에서 [한도 및 알람 설정] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://api.ncloud-docs.com/docs/ai-naver-papagokoreannameromanizer"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-autoscaling-classic-guide-html": {
						"id": "compute-ncloud-compute-autoscaling-classic-guide-html",
						"title": "Classic 환경에서 AutoScaling 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_autoscaling_classic_guide.html",
						"content": "개요\nAutoScaling 서비스는 미리 등록한 설정에 따라 서버 수를 자동으로 증가 또는 감소시켜 안정적인 서비스를 유지하면서 비용을 절감할 수 있도록 해주는 서비스입니다.\n여기서는 네이버 클라우드 Classic 환경에서 AutoScaling 설정하는 방법을 정리해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n기본 설정\nAuto Scaling 설정은 우선 [Auto Scaling] - [Launch Configuration]에서\n[Launch Configuration 생성] 버튼을 클릭하는 것으로 시작합니다.\n\n\n  \n  \n    \n  \n\n\n서버 이미지 선택\n서버 이미지는 네이버 클라우드에서 제공하는 기본 이미지를 선택할 수도 있고, 기존 서버로 만들어 둔 [내 서버 이미지]를 사용할 수도 있습니다. 여기서는 기본 이미지를 사용하는 것으로 하겠습니다.\n\n현재 Classic 환경 AutoScaling에서 지원하는 Linux 서버 이미지 버전은 다음과 같습니다. \n⁃ CentOS 7.3, 7.8 \n⁃ Ubuntu 18.04\n\n\n\n  \n  \n    \n  \n\n\n서버 설정\n스토리지 종류와 서버 타입 등을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n이름 설정\nLaunch Configuration의 이름을 입력합니다.\n\n\n  \n  \n    \n  \n\n\n인증키 설정\n인증키는 기존에 보유하고 있던 인증키를 이용해도 되고, 새로운 인증키를 설정해도 됩니다.\n\n\n  \n  \n    \n  \n\n\n네트워크 접근 설정 (ACG)\nACG 설정도 기존에 보유하고 있던 ACG 중에서 선택해도 되고, 새로운 ACG를 생성해도 됩니다. 여기서는 새로운 ACG를 생성하는 방법으로 진행하겠습니다.\n\n\n  \n  \n    \n  \n\n\nACG 이름을 입력하고, [myIp]를 클릭, 허용할 포트를 입력한 후 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n지금까지 설정한 정보를 마지막으로 확인 한 후에 이상이 없으면 [Launch Configuration 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nGroup 생성\n다음으로 Auto Scaling Group을 생성합니다. [Auto Scaling] - [Auto Scaling Group]에서 [Auto Scaling Group 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nLaunch Configuration 선택\n위에서 생성했던 Launch Configuration을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n그룹 설정\n여기서는 생성될 서버들의 이름과 최소, 최대 개수 등을 설정합니다.\nAuto Scaling Group당 최대 30대의 서버를 생성할 수 있고, Zone, NAT Gateway 설정은 생성 후 변경할 수 없으며, 변경이 필요하면 새로 생성하여 사용해야 합니다.\n\n\n  \n  \n    \n  \n\n\n\n  서버이름 Prefix : 최대7자까지 지정할 수 있고, 나머지 이름의 뒷부분은 영문,숫자의 조합으로 무작위로 자동 생성됩니다.\n  서버 용량 : 최소, 최대, 기대 용량은 서버 대수를 의미하며 각각 0~30까지 입력 가능합니다.\n  \n    쿨다운 기본값 : 새로운 서버가 생성되었다고 해도, init script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. \n즉, 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 반응하지 않고 무시하도록 설정한 기간입니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n  \n  헬스체크 보류기간 : 서버 인스턴스가 생성되어 상태가 ‘운영 중’으로 바뀌었더라도, 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. \n이런 경우 헬스 체크 보류 기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버에 이상이 있다고 판단하지 않습니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n\n\n\n\n정책/일정 설정\n정책과 일정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있습니다. 여기서는 [나중에 설정]으로 선택하고 아래쪽에서 다시 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n통보 설정\n통보 설정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있습니다. 여기서는 [나중에 설정]으로 선택하고 아래쪽에서 다시 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n최종확인\n생성된 Group 설정값들을 마지막으로 확인하고 [Auto Scaling Group 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서버 생성 확인\n위에서 Auto Scaling Group을 생성하면 아래와 같이 즉시 서버가 생성되는 것을 확인할 수 있습니다. 처음에는 [기대용량]에 입력한 개수만큼 서버가 생성됩니다.\n\n\n  \n  \n    \n  \n\n\n설정 관리 - 정책\n위에서 나중에 설정하기로 하고 넘어갔던 Auto Scaling Group의 정책, 일정, 이력, 통보 설정 등을 확인해보겠습니다.\n[Auto Scaling Group]에서 해당 그룹을 선택하고, [설정 및 관리] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 설정\n먼저 [정책] 탭을 선택하고, [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n우선 서버를 증가시킬 정책으로 increase라는 이름을 입력하고, 증가시킬 서버 개수를 입력 후 [추가] 옵션을 선택하고 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 서버를 감소시킬 정책으로 decrease라는 이름을 입력하고, 감소시킬 서버 개수를 입력 후 [반납] 옵션을 선택하고 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서버 증가, 감소를 위한 정책 2가지가 생성된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n그룹 이벤트 설정\n위에서 설정한 정책이 언제 실행되게할 것인가 즉, 서버에 어떤 이벤트가 발생했을 때 정책을 실행할 것인가를 결정하는 그룹 이벤트를 설정합니다.\n그룹 이벤트 설정은 [Classic] - [Monitoring] - [Group Event Setting]에서 할 수 있으며, 위에서 만든 Auto Scaling 그룹을 선택하고 [그룹 이벤트 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n그룹 이벤트 설정 화면에 들어가면 위에서 만든 increase, decrease 2가지 정책이 리스트에 나타나는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n정책이 발동되게 하는 이벤트는 여러가지가 있는데, 가장 많이 선택하는 것이 CPU 사용률입니다.\n여기서는 CPU 사용률(used)이 60% 이상일 때 increase 정책, CPU 사용률(used)이 30% 이하일 때 decrease 정책이 실행되도록 이벤트를 추가했습니다.\n\n\n  \n  \n    \n  \n\n\n설정 관리 - 일정\n위에서는 서버에 설정한 이벤트가 발생했을 때 정책이 발동되도록 했지만, 그 외에도 특정한 시간대에 사용자가 몰리는 피크 타임이 일정하다면 해당 시간 전후로 서버를 늘리거나 감소시키는 방법도 가능합니다.\n여기 [일정] 탭에서 해당 내용을 설정해두면 피크 타임에 미리 서버를 증가시켜서 좀 더 안정적인 서비스가 가능하게 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n설정 관리 - 이력\n[이력] 탭에서는 서버가 생성되고 반납된 기록을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n설정 관리 - 통보\n[통보] 탭에서는 서버가 생성되거나 반납될 때 지정한 담당자에게 SMS나 Email로 통보하도록 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n설정 관리 - 서버\n[서버] 탭은 현재 작동중인 서버 리스트를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n중지 - 서버삭제\n마지막으로, Auto Scaling을 중지하고, 작동중인 서버를 한번에 모두 삭제하는 방법을 확인해보겠습니다.\n\n[Auto Scaling] - [Auto Scaling Group]에서 해당 그룹을 선택하고 상단에 있는 [수정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n여기서 [최소 용량], [최대 용량], [기대 용량] 항목의 값을 모두 0으로 설정하면, 현재 작동중인 서버가 모두 반납되고, 더 이상 서버가 추가로 생성되지 않아서 Auto Scaling이 중지되게 됩니다.\n사실 [최소 용량], [기대 용량] 2가지 항목만 0으로 설정해도 되지만, 혹시나 모르는 상황을 위해서 깔끔하게 3가지 항목 모두 0으로 설정합니다.\n\n\n  \n  \n    \n  \n\n\n서비스 제한사항\nAuto Scaling 설정과 서버 스펙 등에 대한 제한 사항을 정리해보겠습니다.\n\n스펙 및 서비스 환경 제한 사항\n\n  총 디스크 사이즈 150GB 이하 서버만 가능\n  Windows OS는 Windows 2016. 2019만 지원\n  내 서버 이미지의 경우, 원본 서버의 부팅 디스크 크기가 50GB인 경우만 지원(100GB 디스크에 대해서는 추후 지원 예정)\n\n\n설정 제한 사항\n\n  고객별 생성 가능한 Auto Scaling Group 최대 수: 10\n  고객별 생성 가능한 Launch Configuration 최대 수: 100\n  Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100\n  Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10\n  Auto Scaling Group당 생성 가능한 최대 서버 수: 30대\n  Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10\n\n\n용어 정리\nAuto Scaling에서 사용되는 주요 용어들을 정리해보겠습니다.\n\n\n  \n    \n      용어\n       \n      설명\n    \n  \n  \n    \n      Scale-in / Scale-out\n       \n      Auto Scaling Group을 생성하여 고객이 설정한 Policy에 따라 사용하고 있는 가상 서버의 자동 확장(Scale-out) 및 자동 축소(Scale-in)하도록 제공합니다.\n    \n    \n      Auto Scaling Group\n       \n      여러 개의 서버 인스턴스들을 Auto Scaling Group 이라는 하나의 그룹으로 묶어 놓게 됩니다.\n    \n    \n      Launch Configuration\n       \n      Auto Scaling Group에서 가상 서버를 시작 구성하는 데 사용하는 템플릿입니다. Auto Scaling Group을 생성할 때는 Launch Configuration을 지정해야 합니다.\n    \n    \n      Auto Scaling Group의 최소 용량/최대 용량\n       \n      Auto Scaling Group의 최소/최대 서버 수를 말합니다. 최소 서버 수의 경우, 항상 이 값과 같거나 이 값보다 더 큰 서버 수가 유지됩니다. 서버를 한 대도 보유하지 않을 수 있게 하려면 0으로 설정합니다.\n    \n    \n      기대 용량 (Desired Capacity)\n       \n      서버의 수는 기대 용량값에 따라서 조정됩니다. 이 값은 최소 용량 이상, 최대 용량 이하여야 합니다. 이 값이 지정되어 있지 않으면 초기에 최소 용량만큼 서버를 생성합니다.\n    \n    \n      쿨다운 기본값(초) (Default Cooldown)\n       \n      Default Cooldown(초) 새로운 서버가 생성되었다고 해도, Init-Script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 무시하도록 설정한 기간입니다.\n    \n    \n      헬스체크\n       \n      Auto Scaling Group의 가상 서버에 주기적인 상태 확인을 수행하여 상태가 비정상인 가상 서버를 식별하도록 Health Check를 합니다.\n    \n    \n      헬스체크 보류 기간\n       \n      서버가 생성되어 ‘운영중’으로 변경되었더라도 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. 이런 경우 헬스 체크 보류기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버 헬스에 이상이 있다고 판단하지 않습니다.\n    \n    \n      헬스체크 유형\n       \n      서버와 Load Balancer 둘 중에 선택할 수 있습니다. Auto Scaling Group 설정에서 Load Balancer 이름을 지정한 경우에는 헬스 체크 유형 역시 Load Balancer로 설정합니다. 이런 경우 Auto Scaling은 Load Balancer 헬스 체크 방식과 기준에 따라 서버의 상태를 판단합니다.\n    \n    \n      반납 정책\n       \n      Auto Scaling 과정에서 추가된 서버에 대한 Scale-in 작업에 대해, 고객이 API 질의 형식으로먼저 반납할 서버를 지정할 수 있습니다. 기본 설정은 먼저 생성된 서버부터 반납합니다.\n    \n    \n      Policy\n       \n      Auto Scaling이 일어나는 방식을 정의하고 있는데, 이를 ‘Policy’로 정의하고 있습니다. Auto Scale-out 이 발생할 때, 몇 대의 가상 서버를 늘릴 것인지, 반대로 Scale-in이 발생할 때 몇 대의 가상서버를 줄일 것인지를 정의합니다. 대수로 정의할 수 도 있고, %로 정의할 수도 있습니다.\n    \n  \n\n\n참고 URL\n\n  Ncloud Auto Scaling 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview\n    \n  \n  VPC 환경에서 Auto Scaling 설정하기\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-autoscaling-vpc-guide.html\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2022-06-17\n          문서 최초 생성\n        \n      \n        \n          2023-09-06\n          지원하는 서버 이미지 정보 업데이트"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-autoscaling-event-setting-html": {
						"id": "compute-ncloud-compute-autoscaling-event-setting-html",
						"title": "AutoScaling 이벤트 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_autoscaling_event_setting.html",
						"content": "개요\n네이버 클라우드에서 AutoScaling을 설정할 때 중요한 것이 이벤트 설정입니다.\n예를 들어 CPU 사용률이 70%가 넘는 상태가 1분 이상 지속되면 서버를 늘리는 작업이 진행되도록 설정한다고 할 때, CPU가 70% 이상인 상태가 1분 이상 지속되는 이벤트가 발생하는지 체크하는 것을 말합니다.\n현재 네이버 클라우드 Console에서는 AutoScaling 그룹을 생성한 후에 바로 이 이벤트 설정을 하는 방법에 대한 메뉴나 링크가 없어서 그에 대한 내용을 정리해보겠습니다.\n\nAutoScaling Group 생성\nAutoScaling 이벤트를 설정하려면 우선 AutoScaling Group을 생성해야 합니다.\nConsole - Auto Scaling - Auto Scaling Group 메뉴에서 설정할 수 있습니다.\nAutoScaling Group을 설정한 후에는 AutoScaling Group Event를 설정해야 하니 해당 기능이 있는 메뉴로 이동할 수 있도록 버튼이나 링크가 생겼으면 합니다.\n\n\n  \n  \n    \n  \n\n\nAutoScaling Group Event 설정\nAutoScaling의 그룹 이벤트를 설정하는 곳은 Monitoring 메뉴에 있습니다.\nCPU 사용량 등의 서버 상태를 확인해야 하는 것이다 보니 Console - Monitoring - Group Event Setting 메뉴에서 관련된 이벤트 설정을 할 수 있습니다.\n아래 스샷에서 확인할 수 있듯이 앞에서 생성한 AutoScaling Group이 나타납니다. 만약 AutoScaling Group을 생성하지 않았다면 여기서는 아무런 설정도 할 수 없습니다.\n혹시 AutoScaling Group이 생성되지 않은 상태에서 이 메뉴에 들어오는 경우에는 AutoScaling Group 생성 페이지로 이동하는 버튼이나 링크가 추가되길 바랍니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/management-management-1-1.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-autoscaling-limit-html": {
						"id": "compute-ncloud-compute-autoscaling-limit-html",
						"title": "Auto Scaling 서비스 제한사항",
						"categories": "",
						"url": " /compute/ncloud_compute_autoscaling_limit.html",
						"content": "개요\n모든 클라우드 서비스의 핵심 중의 하나가 Auto Scaling이라고 할 수 있습니다.\n네이버 클라우드도 예외가 아닌데, Auto Scaling을 설정할 때 몇가지 제한사항이 있어서 정리해보았습니다.\n\n스펙 및 서비스 환경 제한 사항\n서버 스펙이나 서비스 환경과 관련한 제한 사항은 다음과 같습니다.\n\n\n  총 디스크 사이즈 150GB 이하 서버만 가능\n  Micro 서버는 불가\n  GPU 서버는 불가\n  베어메탈 서버는 불가\n\n\n따라서 서버타입 기준으로  Auto Scaling 설정이 가능한 서버타입은 다음과 같습니다.\n\n  Classic : Compact, Standard\n  VPC : High CPU, Standard, High Memory\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n현재 [Auto Scaling] - [Launch Configuration] 화면과 가이드에 나오는 [High Memory 타입은 지원되지 않습니다]는 예전 메시지로 조만간 삭제될 예정이라고 합니다.\n\nOS 서버 이미지 제한 사항\ncentos-7.8-64, ubuntu-18.04 이 2가지 OS 이미지는 개인 회원은 KR-1 1세대 서버에서 생성이 불가능한 이미지입니다. 2세대 서버를 선택하시거나 KR-2에서 생성해야 합니다.\n\n설정 제한 사항\n다음으로 Auto Scaling 설정을 할 때 생성 가능한 최대 서버 수 등의 설정 제한 사항은 다음과 같습니다.\n\n\n  고객별 생성 가능한 Auto Scaling Group 최대 수: 100\n  고객별 생성 가능한 Launch Configuration 최대 수: 100\n  Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100\n  Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10\n  Auto Scaling Group당 생성 가능한 최대 서버 수: 30대\n  Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10\n\n\n계정당 생성 가능한 최대 서버 대수 : 네이버 클라우드에서 한 계정당 생성할 수 있는 최대 서버 수 기본 50대입니다. 서버 수 한도를 조정하려면 고객지원으로 문의해야 합니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-autoscaling-vpc-guide-html": {
						"id": "compute-ncloud-compute-autoscaling-vpc-guide-html",
						"title": "VPC 환경에서 AutoScaling 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud-compute-autoscaling-vpc-guide.html",
						"content": "개요\nNcloud(네이버 클라우드)  VPC 환경에서 AutoScaling 설정하는 방법을 정리해보겠습니다.\n\nAutoScaling 서비스는 미리 등록한 설정에 따라 서버 수를 자동으로 증가 또는 감소시켜 안정적인 서비스를 유지하면서 비용을 절감할 수 있도록 해주는 서비스입니다.\n\n그런데, 언제 서버 수를 증가, 감소 시킬 것인 가에 대한 이벤트 설정이 Classic 환경의 경우 오토스케일 그룹에 속한 서버들의 평균값을 기준으로 하지만, \nVPC 환경의 경우 이 방법 말고도 특정 서버를 지정해서 해당 서버를 기준으로 이벤트 설정을 할 수도 있습니다.\n\n그래서 여기서는 사전에 준비된 서버를 기준으로 AutoScaling이 작동되는 것을 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n기준 서버 생성\nAutoScaling 이벤트 설정의 기준이 되는 서버 1대를 아래와 같이 미리 생성하겠습니다.\n\n\n  \n  \n    \n  \n\n\n설정 순서\nAuto Scaling 설정 순서를 요약하면 다음과 같습니다.\n\n\n1. Auto Scaling Launch Configuration 설정 \n2. Auto Scaling Group 설정 \n3. Cloud Insight Monitoring Event Rule 설정 \n\n\nLaunch Configuration 설정\nAuto Scaling 설정은 우선 [Auto Scaling] - [Launch Configuration]에서 [Launch Configuration 생성] 버튼을 클릭하는 것으로 시작합니다.\n\n\n  \n  \n    \n  \n\n\n서버 이미지 선택\n서버 이미지는 Ncloud(네이버 클라우드) 에서 제공하는 기본 이미지를 선택할 수도 있고, 기존에 사용하던 서버로 만들어 둔 [내 서버 이미지]를 사용할 수도 있습니다. 여기서는 기본 이미지를 사용하는 것으로 하겠습니다.\n\n현재 VPC 환경 AutoScaling에서 지원하는 Linux 서버 이미지 버전은 다음과 같습니다. \n⁃ CentOS 7.3, 7.8 \n⁃ Rocky Linux 8.6, 8.8 \n⁃ Ubuntu 16.04, 18.04, 20.04\n\n\n\n  \n  \n    \n  \n\n\nWindows 서버 이미지 버전\n\n현재 AutoScaling에서 지원하는 Windows 서버 이미지 버전은 다음과 같습니다. \n⁃ Windows Server 2016 64bit English Edition \n⁃ Windows Server 2019 64bit English Edition\n\n\n\n  \n  \n    \n  \n\n\n서버 설정\n스토리지 종류와 서버 타입 등을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n이름 설정\nLaunch Configuration의 이름을 입력합니다.\n\n\n  \n  \n    \n  \n\n\n인증키 설정\n인증키는 기존에 보유하고 있던 인증키를 이용해도 되고, 새로운 인증키를 설정해도 됩니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n지금까지 설정한 내용이 이상 없는지 최종 확인을 하고 이상 없으면 [Launch Configuration 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nAuto Scaling Group 설정\n다음으로 Auto Scaling Group을 생성합니다. [Auto Scaling] - [Auto Scaling Group]에서 [Auto Scaling Group 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nLaunch Configuration 선택\n위에서 생성했던 Launch Configuration을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n그룹 설정\n여기서는 VPC와 Subnet 등의 네트워크 환경을 선택하고,  생성될 서버들의 이름과 최소, 최대 개수 등을 설정합니다.\n\n\n  \n  \n    \n  \n\n\n\n  서버이름 Prefix : 최대7자까지 지정할 수 있고, 나머지 이름의 뒷부분은 영문,숫자의 조합으로 무작위로 자동 생성됩니다.\n  서버 용량 : 최소, 최대, 기대 용량은 서버 대수를 의미하며 각각 0~30까지 입력 가능합니다.\n  \n    쿨다운 기본값 : 새로운 서버가 생성되었다고 해도, init script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. \n즉, 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 반응하지 않고 무시하도록 설정한 기간입니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n  \n  헬스체크 보류기간 : 서버 인스턴스가 생성되어 상태가 ‘운영 중’으로 바뀌었더라도, 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. \n이런 경우 헬스 체크 보류 기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버에 이상이 있다고 판단하지 않습니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n  헬스체크 유형 : 헬스체크 유형은 [서버]와 [로드밸런서] 중에서 선택할 수 있습니다.\n\n\n로드밸런서 연결\n\n\nAuto Scaling으로 생성된 서버가 로드밸런서에 자동으로 연결되도록 하려면 [헬스 체크 유형]을 [로드밸런서]로 선택하고 [Target Group] 항목에서 원하는 로드밸런서의 Target Group을 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  VPC 환경에서 로드밸런서를 생성하는 방법은 아래 문서를 참고하시면 됩니다.\n\n\n\n⁃ VPC 환경에서 Application Load Balancer 생성하는 방법\n\n\n네트워크 접근 설정\n네트워크 접근에 필요한 ACG를 설정하고 선택합니다.\n\n\n  \n  \n    \n  \n\n\n정책/일정 설정\n정책과 일정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있는데, \n우선은 [정책 설정]에서 [서버 수 증가 정책]과 [서버 수 감소 정책]을 설정합니다.\n\n\n  \n  \n    \n  \n\n\n통보 설정\n서버가 생성될 때 또는 서버가 반납될 때 언제 통보를 받을 것인지 선택하고, 누가 언제 통보 받을 것인지 설정합니다.\n\n\n  \n  \n    \n  \n\n\n통보 대상 설정\n먼저 [통보대상 관리 그룹]을 선택하고, 다음으로 관리자와 통보 방법을 선택합니다.\n[통보대상 관리 그룹]이 설정되지 않았을 경우에는 [통보대상관리] 버튼을 클릭해 통보를 받을 대상의 그룹을 설정합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n지금까지 설정한 Auto Scaling Group 내역을 확인하고 이상이 없으면 [Auto Scaling Group 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nEvent Rule 설정\n지정한 서버를 모니터링 하다가 설정한 조건에 해당되면 즉, 지정한 Event가 발생하면 Auto Scaling 설정을 적용해 서버를 증가시키거나 감소시키기 위한 감시 규칙인 [Event Rule]을 설정합니다.\n\n서버 증가 Event Rule 생성\nVPC에서는 [Cloud Insight]로 모니터링을 하게 되므로 Event Rule 설정도 [Cloud Insight(Monitoring)] - [Configuration] - [Event Rule]에서 [Event Rules 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n감시 상품 선택\nCloud Insight는 Server 뿐만 아니라 Load Balancer, Object Storage도 감시할 수 있는데 여기서는 처음에 생성했던 서버를 감시할 것이니 [Server(VPC)]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n감시 대상 설정\n맨 처음에 생성했던 서버를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n감시 항목 및 조건 설정\n감시 항목 설정에서 [전체 보기]를 선택하고, [SERVER] 탭에서 [Metric ID]를 [cpu]로 검색한 후 평균 CPU 사용률 항목인 [SERVER/avg_cpu_used_rto]에서 [Level]과 [Condition], [Method], [Duration]을 선택합니다.\n\n먼저 서버를 증가시키는 경우에 해당하는 감시 항목을 설정하겠습니다.\n아래의 설정 내용은 “평균 CPU 사용률이 1분간 50% 이상일 경우 경고 수준으로 이벤트 통보를 한다“라는 설정입니다.\n\n\n  \n  \n    \n  \n\n\n액션 설정\n앞에서 설정한 이벤트가 발생했을 경우 어떤 액션을 취할 것인지 설정하게 되는데 앞에서 [Auto Scaling Group] 설정에서 생성했던 정책을 선택하면 됩니다.\n여기서는 [CPU 사용률 50% 이상]인 경우이므로 서버를 증가시키는 정책을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n설정한 내용이 이상 없는지 최종 확인하고, 규칙 이름을 입력한 후에 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서버 감소 Event Rule 생성\n앞에서 생성한 [서버 증가 Event Rule]과 같은 방식으로 [서버 감소 Event Rule]을 생성합니다.\n\n아래의 설정 내용은 “평균 CPU 사용률이 1분간 10% 이하일 경우 정보 알림 수준으로 이벤트 통보를 한다“라는 설정입니다.\n\n\n  \n  \n    \n  \n\n\n액션 설정\n여기서는 [CPU 사용률 10% 이하]인 경우이므로 서버를 감소시키는 정책을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n설정한 내용이 이상 없는지 최종 확인하고, 규칙 이름을 입력한 후에 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nEvent Rule 생성 완료\n서버 증가과 감소에 대한 Event Rule 2가지가 모두 생성된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nStress Tool 설정\nCPU 사용률에 따른 Auto Scaling 작동 여부를 테스트 하기 위해 서버에 Stress Tool을 설치해보겠습니다.\n\nEPEL 리포지토리 설정\nStress Tool을 설치하기 위해서는 다음 명령어로 [EPEL 리포지토리]를 설정해야 합니다.\n\n~# yum -y install epel-release\n\n\n  \n  \n    \n  \n\n\nStress Tool 설치\n\n~# yum -y install stress\n\n\n  \n  \n    \n  \n\n\nStress Tool 실행\n\nCPU 코어 개수 확인\nCPU에 강제로 부하를 발생 시키기 위해서는 서버의 CPU 코어 개수를 확인해서 모든 코어에 부하를 발생시키는 것이 좋습니다.\nCPU 코어 개수를 확인하는 방법은 아래 명령어를 입력하면 됩니다.\n\n~# grep -c processor /proc/cpuinfo\n\n\n  \n  \n    \n  \n\n\n명령어 테스트\nCPU에 부하를 주는 명령어를 테스트 해보겠습니다.\n\n~# stress --cpu 2 --timeout 60 --verbose\n\n\n위 옵션의 내용은 다음과 같습니다.\n\n\n  cpu: 몇 개의 코어에 부하를 발생 시킬 것인가\n  timeout: 몇 초 동안 부하를 발생 시킬 것인가\n  verbose: 상세 로그를 표시\n\n\n\n  \n  \n    \n  \n\n\nCPU 부하 발생\n부하 발생 테스트를 마쳤으니 실제 Auto Scaling 테스트를 위해 300초 즉, 5분 동안 부하를 발생 시켜보겠습니다.\n\n~# stress --cpu 2 --timeout 300 --verbose\n\n\n  \n  \n    \n  \n\n\n서버 증가 확인\nStress Tool로 부하를 발생 시키고 서버 리스트를 확인해보면 아래와 같이 Auto Scaling 설정에서 지정한 대로 서버가 생성되고 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nCPU 사용률 확인\n[Cloud Insight]에서 서버 사용률을 확인해 보면 아래와 같이 5분간 CPU 사용률이 100%까지 올라간 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 반납 확인\nStress Tool로 부하를 발생 시키도록 설정한 5분이 지난 후에 서버 리스트를 보면 Auto Scaling으로 생성되었던 서버가 반납되고 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n이벤트 발생 확인\n[Cloud Insight] - [Event]에서 서버 증가, 감소 관련 이벤트가 제대로 발생했는지 아래와 같이 그래프와 리스트로 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n이벤트 통보 확인\n이벤트 통보에서 설정한 대로 아래와 같이 Email로 Auto Scaling 이벤트 발생과 완료에 대한 통보 메일이 도착한 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서비스 제한사항\nAuto Scaling 설정과 서버 스펙 등에 대한 제한 사항을 정리해보겠습니다.\n\n스펙 및 서비스 환경 제한 사항\n\n  총 디스크 사이즈 150GB 이하 서버만 가능\n  Windows OS는 Windows 2016. 2019만 지원\n  내 서버 이미지의 경우, 원본 서버의 부팅 디스크 크기가 50GB인 경우만 지원(100GB 디스크에 대해서는 추후 지원 예정)\n\n\n설정 제한 사항\n\n  고객별 생성 가능한 Auto Scaling Group 최대 수: 10\n  고객별 생성 가능한 Launch Configuration 최대 수: 100\n  Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100\n  Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10\n  Auto Scaling Group당 생성 가능한 최대 서버 수: 30대\n  Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10\n\n\n상세 모니터링\nNcloud(네이버 클라우드) 에서는 기본 모니터링 외에 [상세 모니터링]도 지원하는데, [상세 모니터링]에서는 좀 더 자세하고 다양한 모니터링 항목 (Extended Metric)을 지원합니다.\n\n예를 들어 CPU 사용과 관련한 모니터링 항목에서도 아래와 같이 [CPU idle ratio average] 항목들도 확인할 수 있습니다.\n\n  \n  \n    \n  \n\n\n또한, 위와 같이 [Server] 탭에서는 CPU들의 평균 값을 모니터링할 수 있는 것에 비해, 상세 모니터링을 적용하면 아래와 같이 [CPU] 탭에서 CPU 코어별로 각각 모니터링을 할 수도 있습니다.\n\n  \n  \n    \n  \n\n\n상세 모니터링 설정\n상세 모니터링을 적용하는 방법은 서버를 선택하고 [서버 관리 및 설정 변경] 메뉴에서 [상세 모니터링 설정 변경] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n상세 모니터링 신청\n상세 모니터링 신청 팝업에서 [예] 버튼을 클릭하면 상세 모니터링이 적용됩니다. 상세 모니터링 신청 후 실제 데이터가 수집되기까지는 약간의 시간이 소요되므로 잠시 기다렸다 확인해보면 됩니다.\n\n\n  \n  \n    \n  \n\n\n용어 정리\nAuto Scaling에서 사용되는 주요 용어들을 정리해보겠습니다.\n\n\n  \n    \n      용어\n       \n      설명\n    \n  \n  \n    \n      Scale-in / Scale-out\n       \n      Auto Scaling Group을 생성하여 고객이 설정한 Policy에 따라 사용하고 있는 가상 서버의 자동 확장(Scale-out) 및 자동 축소(Scale-in)하도록 제공합니다.\n    \n    \n      Auto Scaling Group\n       \n      여러 개의 서버 인스턴스들을 Auto Scaling Group 이라는 하나의 그룹으로 묶어 놓게 됩니다.\n    \n    \n      Launch Configuration\n       \n      Auto Scaling Group에서 가상 서버를 시작 구성하는 데 사용하는 템플릿입니다. Auto Scaling Group을 생성할 때는 Launch Configuration을 지정해야 합니다.\n    \n    \n      Auto Scaling Group의 최소 용량/최대 용량\n       \n      Auto Scaling Group의 최소/최대 서버 수를 말합니다. 최소 서버 수의 경우, 항상 이 값과 같거나 이 값보다 더 큰 서버 수가 유지됩니다. 서버를 한 대도 보유하지 않을 수 있게 하려면 0으로 설정합니다.\n    \n    \n      기대 용량 (Desired Capacity)\n       \n      서버의 수는 기대 용량값에 따라서 조정됩니다. 이 값은 최소 용량 이상, 최대 용량 이하여야 합니다. 이 값이 지정되어 있지 않으면 초기에 최소 용량만큼 서버를 생성합니다.\n    \n    \n      쿨다운 기본값(초) (Default Cooldown)\n       \n      Default Cooldown(초) 새로운 서버가 생성되었다고 해도, Init-Script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 무시하도록 설정한 기간입니다.\n    \n    \n      헬스체크\n       \n      Auto Scaling Group의 가상 서버에 주기적인 상태 확인을 수행하여 상태가 비정상인 가상 서버를 식별하도록 Health Check를 합니다.\n    \n    \n      헬스체크 보류 기간\n       \n      서버가 생성되어 ‘운영중’으로 변경되었더라도 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. 이런 경우 헬스 체크 보류기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버 헬스에 이상이 있다고 판단하지 않습니다.\n    \n    \n      헬스체크 유형\n       \n      서버와 Load Balancer 둘 중에 선택할 수 있습니다. Auto Scaling Group 설정에서 Load Balancer 이름을 지정한 경우에는 헬스 체크 유형 역시 Load Balancer로 설정합니다. 이런 경우 Auto Scaling은 Load Balancer 헬스 체크 방식과 기준에 따라 서버의 상태를 판단합니다.\n    \n    \n      반납 정책\n       \n      Auto Scaling 과정에서 추가된 서버에 대한 Scale-in 작업에 대해, 고객이 API 질의 형식으로먼저 반납할 서버를 지정할 수 있습니다. 기본 설정은 먼저 생성된 서버부터 반납합니다.\n    \n    \n      Policy\n       \n      Auto Scaling이 일어나는 방식을 정의하고 있는데, 이를 ‘Policy’로 정의하고 있습니다. Auto Scale-out 이 발생할 때, 몇 대의 가상 서버를 늘릴 것인지, 반대로 Scale-in이 발생할 때 몇 대의 가상서버를 줄일 것인지를 정의합니다. 대수로 정의할 수 도 있고, %로 정의할 수도 있습니다.\n    \n    \n      Basic Metric\n       \n      기본적으로 제공되는 모니터링 항목\n    \n    \n      Extended Metric\n       \n      상세모니터링을 신청하면 제공되는 모니터링 항목\n    \n  \n\n\n참고 URL\n\n  Ncloud(네이버 클라우드) Auto Scaling 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview\n    \n  \n  Classic 환경에서 Auto Scaling 설정하기\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_autoscaling_classic_guide.html\n    \n  \n  Cloud Insight Basic/Extended Metric 정리\n    \n      https://api.ncloud-docs.com/docs/management-cloudinsight-productinfo\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2022-06-20\n          문서 최초 생성\n        \n      \n        \n          2023-09-05\n          로드밸런서 연결하는 방법 안내 추가, 지원하는 서버 이미지 정보 업데이트"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-cloud-functions-dotnet-csharp-cmd-html": {
						"id": "compute-ncloud-compute-cloud-functions-dotnet-csharp-cmd-html",
						"title": "Cloud Functions Action을 .Net (C#)을 사용하여 윈도우 명령프롬프트(cmd)에서 만드는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_cloud_functions_dotnet_csharp_cmd.html",
						"content": "개요\n네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어로는 Node.js, Python, Java, Swift, PHP, .Net, Go Language 등이 있는데\n다른 언어들은 네이버 클라우드 콘솔에서 직접 코드를 입력하면 되지만, Java는 로컬에서 작업 후 jar 파일로 .Net은 zip 파일로 압축해서 따로 등록해야 합니다.\n여기서는 윈도우 명령프롬프트(cmd)에서 .Net 그 중에서도 C#으로 Action을 만들고 zip 파일로 압축 후에 콘솔에 등록하고 테스트 하는 과정까지 정리해보겠습니다.\n\n.Net 설치\n네이버 클라우드 Cloud Functions는 .Net Standard 2.0 규격을 요구하는데, 이 규격을 지원하는 버전을 설치하려면 .Net 5.0 또는 .Net Core 2.1 이상을 설치하면 됩니다.\n가장 간단한 방법은 Visual Studio를 설치하는 방법이고 그 외에는 .Net 또는 .Net Core SDK만 별도로 설치하는 방법이 있습니다.\n\n\n  Visual Studio 무료버전 : https://visualstudio.microsoft.com/ko/free-developer-offers/\n  .Net, .Net Core SDK : https://dotnet.microsoft.com/download\n\n\n프로젝트 생성\nCloudFunctionsTestConsole 라는 이름의 Class Library 프로젝트를 생성하면서 언어는 C#, 타겟 프레임워크는 .Net Standard 2.0으로 지정하는 명령어입니다.\n다음으로 생성된 프로젝트 폴더로 이동해서 Newtonsoft.Json이라는 Json 패키지를 설치합니다.\n\n:: 프로젝트 생성\nD:\\&gt;dotnet new classlib -n CloudFunctionsTestConsole -lang \"C#\" -f netstandard2.0\n\n:: 폴더 이동\nD:\\&gt;cd CloudFunctionsTestConsole\n\n:: Json 패키지 설치\nD:\\CloudFunctionsTestConsole&gt;dotnet add package Newtonsoft.Json\n\n\n실제 명령프롬프트(cmd)에서 위 명령을 실행해본 화면은 다음과 같습니다.\n\n\n  \n  \n    \n  \n\n\nHello.cs 작성\n이제 name이라는 파라미터를 json 형태로 받아서 출력해주는 Hello.cs 스크립트를 작성합니다.\n\nusing System;\nusing Newtonsoft.Json.Linq;\n\nnamespace CloudFunctionsTestConsole\n{\n    public class Hello\n    {\n        public JObject Main(JObject args)\n        {\n            string name = \"no name\";\n            if (args.ContainsKey(\"name\")) {\n                name = args[\"name\"].ToString();\n            }\n            JObject message = new JObject();\n            message.Add(\"greeting\", new JValue($\"Hello, {name}!\"));\n            return (message);\n        }\n    }\n}\n\n\n\n  \n  \n    \n  \n\n\n프로젝트 게시\n이제 위에서 작성한 스크립트를 publish폴더로 게시하고, zip 파일로 압축합니다.\n여기서 만든 zip 파일을 네이버 클라우드 콘솔에서 등록하게 됩니다.\n\n:: 프로젝트 게시\nD:\\CloudFunctionsTestConsole&gt;dotnet publish -c Release -o publish\n\n:: 폴더 이동\nD:\\CloudFunctionsTestConsole&gt;cd publish\n\n:: 파일 압축\nD:\\CloudFunctionsTestConsole\\publish&gt;zip -r -0 CloudFunctionsTestConsole.zip *\n\n:: zip 명령이 실행되지 않을 경우 아래와 같이 윈도우 탐색기에서 직접 압축해도 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n Tip: zip 명령이 실행되지 않을 경우 아래와 같이 윈도우 탐색기에서 직접 압축해도 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nCF 이용신청\n네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\n\n\n  \n  \n    \n  \n\n\nCF Action 생성\n\n액션 생성\n버튼을 선택해 액션을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n트리거 선택\n액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n이름 입력\n액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n소스코드 언어 선택\n소스코드 언어 중에서 저희는 dotnet:2.2를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n소스코드 업로드\n소스코드 타입은 코드와 파일이 있지만, java와 .Net은 파일 업로드만 가능합니다.\n앞에서 만든 소스코드를 선택하고 업로드 합니다.\n\n\n  \n  \n    \n  \n\n\n\n소스코드가업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\nVPC 연결 정보 선택\nVPC 환경에서는 연결할 VPC와 Subnet을 선택해야 합니다. Classic 환경에서는 다음 단계로 바로 이동하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n옵션 설정\n실행할 Main 함수의 이름을 {Assembly}::{Class Full Name}::{Method} 형태의 풀네임으로 입력합니다. \n위에서 만든 Hello.cs에서는 CloudFunctionsTestConsole::CloudFunctionsTestConsole.Hello::Main 으로 입력합니다.\n\n액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n입력할 Main 함수 이름을 어떻게 적으면 되는지 한번 더 살펴보겠습니다.\n아래 소스코드 화면에서 보시면 namespace, class, Main 이렇게 이름이 적혀 있는 곳에서\n{ 1 }::{ 1 }.{ 2 }::{ 3 } 이렇게 연결해서 적으면 CloudFunctionsTestConsole::CloudFunctionsTestConsole.Hello::Main 이렇게 완성이 되고\n이 이름을 Main 함수 이름 칸에 입력하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n생성 완료\n디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\n\n\n  \n  \n    \n  \n\n\nCF Action 실행\n이제 생성된 액션을 실행해보겠습니다.\n액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고,\n오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n\n\n  \n  \n    \n  \n\n\n\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다.  파라미터는 json 형태로 입력하면 됩니다.\n왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n\n\n  \n  \n    \n  \n\n\n\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n\n\n  \n  \n    \n  \n\n\n오류 메시지\n위의 순서대로 진행을 하면 문제 없이 사용 가능한데, 이미 다른 방법으로 진행해보면서 오류 메시지를 경험하는 경우도 있을 듯하여 가장 많이 겪게 되는 오류 상황 2가지를 정리해보겠습니다.\n\nMain 함수 이름 입력 오류\n위에서 설명한 액션 Main 함수 이름을 올바르게 입력하지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\n\"error\" : \"main required format is \\\"Assembly::Type::Function\\\".\"\n\n\n\n  \n  \n    \n  \n\n\n\n상단에 설명한 [CF Action 생성] - [옵션 설정]에서 Main 함수 입력하는 부분을 참고하셔서 정확하게 입력하시면 문제가 해결됩니다.\n\n.Net 대상 프레임워크 오류\n네이버 클라우드 Cloud Functions은 .Net Standard 2.0 규약을 지원하고 있습니다.\n그런데 이 대상 프레임워크가 맞지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\n\"error\" : \"Unable to locate requested type (\\\"CloudFunctionsTestConsole.Hello\\\").\"\n\n\n\n  \n  \n    \n  \n\n\n\n위 [프로젝트 생성]에서 설명한 것처럼 프로젝트 생성할 때 -f netstandard2.0 옵션을 반드시 넣어주셔어야 합니다.\n\n:: 프로젝트 생성\nD:\\&gt;dotnet new classlib -n CloudFunctionsTestConsole -lang \"C#\" -f netstandard2.0\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-15-2-6.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-cloud-functions-dotnet-csharp-vs-html": {
						"id": "compute-ncloud-compute-cloud-functions-dotnet-csharp-vs-html",
						"title": "Cloud Functions Action을 .Net (C#)을 사용하여 Visual Studio에서 만드는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_cloud_functions_dotnet_csharp_vs.html",
						"content": "개요\n네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어로는 Node.js, Python, Java, Swift, PHP, .Net, Go Language 등이 있는데 \n다른 언어들은 네이버 클라우드 콘솔에서 직접 코드를 입력하면 되지만, Java는 로컬에서 작업 후 jar 파일로 .Net은 zip 파일로 압축해서 따로 등록해야 합니다.\n여기서는 Visual Studio에서 .Net 그 중에서도 C#으로 Action을 만들고 zip 파일로 압축 후에 콘솔에 등록하고 테스트 하는 과정까지 정리해보겠습니다.\n\n.Net 설치\n네이버 클라우드 Cloud Functions는 .Net Standard 2.0 규격을 요구하는데, 이 규격을 지원하는 버전을 설치하려면 .Net 5.0 또는 .Net Core 2.1 이상을 설치하면 됩니다.\n가장 간단한 방법은 Visual Studio를 설치하는 방법이고 그 외에는 .Net 또는 .Net Core SDK만 별도로 설치하는 방법이 있습니다.\n여기서는 Visual Studio를 이용할 것이기 때문에 Visual Studio를 설치하면 됩니다.\n\n\n  Visual Studio 무료버전 : https://visualstudio.microsoft.com/ko/free-developer-offers/\n  .Net, .Net Core SDK : https://dotnet.microsoft.com/download\n\n\n프로젝트 생성\n\n프로젝트 템플릿 선택\nVisual Studio에서 제공하는 템플릿 중에서 C# Class library를 선택하니다.\n\n\n  \n  \n    \n  \n\n\n프로젝트 구성\n프로젝트 이름과 저장 위치 등을 입력합니다. \n여기서는 CloudFunctionsTestVisualStudio 라는 이름으로 시작합니다.\n\n\n  \n  \n    \n  \n\n\n대상 프레임워크 지정\n대상 프레임워크는 .NET Standard 2.0으로 지정합니다.\n\n\n  \n  \n    \n  \n\n\n프로젝트 생성 후에 CloudFunctionsTestVisualStudio.csproj 파일을 열어보면 TargetFramework 값이 netstandard2.0으로 되어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\njson 패키지 설치\n네이버 클라우드 Cloud Functions은 json 형식으로 파라미터를 입력받고 결과를 출력하기 때문에 NuGet 패키지 관리자를 이용해서 json 패키지를 설치합니다.\n\n프로젝트 선택하고 마우스 오른쪽 버튼을 클릭해서 NuGet 패키지 관리 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\nNuGet 패키지 관리자 화면에서 json을 검색하고 Newtonsoft.Json 패키지를 선택, 설치를 합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n패키지 설치가 완료된 상태입니다.\n\n\n  \n  \n    \n  \n\n\nHello.cs 작성\n이제 name이라는 파라미터를 json 형태로 받아서 출력해주는 Hello.cs 스크립트를 작성합니다.\n\nusing System;\nusing Newtonsoft.Json.Linq;\n\nnamespace CloudFunctionsTestConsole\n{\n    public class Hello\n    {\n        public JObject Main(JObject args)\n        {\n            string name = \"no name\";\n            if (args.ContainsKey(\"name\")) {\n                name = args[\"name\"].ToString();\n            }\n            JObject message = new JObject();\n            message.Add(\"greeting\", new JValue($\"Hello, {name}!\"));\n            return (message);\n        }\n    }\n}\n\n\n\n  \n  \n    \n  \n\n\n프로젝트 게시\n이제 위에서 작성한 스크립트를 게시하고, zip 파일로 압축합니다.\n여기서 만든 zip 파일을 네이버 클라우드 콘솔에서 등록하게 됩니다.\n\n[빌드]-[게시] 메뉴를 선택합니다.\n\n  \n  \n    \n  \n\n\n게시 대상은 폴더를 선택합니다.\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n게시할 준비가 되었고 게시를 시작합니다.\n\n  \n  \n    \n  \n\n\n게시가 완료되었습니다.\n\n  \n  \n    \n  \n\n\n게시된 폴더에 가보면 .nupkg 파일이 생성되는데 저희는 이것을 이용하지 않고 상위 폴더에 있는 dll 파일을 사용합니다.\n\n\n  \n  \n    \n  \n\n\npublish 상위 폴더에 가면 .deps.json, .dll, .pdb 이렇게 3개 파일이 생성되어 있는 것을 확인할 수 있는데 Cloud Functions에서는 이 파일을 사용합니다.\n\n\n  \n  \n    \n  \n\n\n파일 압축\n탐색기에서 3개의 파일을 선택하고 압축합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nCF 이용신청\n네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\n\n\n  \n  \n    \n  \n\n\nCF Action 생성\n\n액션 생성\n버튼을 선택해 액션을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n트리거 선택\n액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n이름 입력\n액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n소스코드 언어 선택\n소스코드 언어 중에서 저희는 dotnet:2.2를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n소스코드 업로드\n소스코드 타입은 코드와 파일이 있지만, java와 .Net은 파일 업로드만 가능합니다.\n앞에서 만든 소스코드를 선택하고 업로드 합니다.\n\n\n  \n  \n    \n  \n\n\n\n소스코드가업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\nVPC 연결 정보 선택\nVPC 환경에서는 연결할 VPC와 Subnet을 선택해야 합니다. Classic 환경에서는 다음 단계로 바로 이동하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n옵션 설정\n실행할 Main 함수의 이름을 {Assembly}::{Class Full Name}::{Method} 형태의 풀네임으로 입력합니다. \n위에서 만든 Hello.cs에서는 CloudFunctionsTestVisualStudio::CloudFunctionsTestVisualStudio.Hello::Main 으로 입력합니다.\n\n액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n\nMain 함수 이름 작성 방법\n입력할 Main 함수 이름을 어떻게 적으면 되는지 한번 더 살펴보겠습니다.\n아래 소스코드 화면에서 보시면 namespace, class, Main 이렇게 이름이 적혀 있는 곳에서\n{ 1 }::{ 1 }.{ 2 }::{ 3 } 이렇게 연결해서 적으면 CloudFunctionsTestVisualStudio::CloudFunctionsTestVisualStudio.Hello::Main 이렇게 완성이 되고\n이 이름을 Main 함수 이름 칸에 입력하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n생성 완료\n디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\n\n\n  \n  \n    \n  \n\n\nCF Action 실행\n이제 생성된 액션을 실행해보겠습니다.\n액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고,\n오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n\n\n  \n  \n    \n  \n\n\n\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다.  파라미터는 json 형태로 입력하면 됩니다.\n왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n\n\n  \n  \n    \n  \n\n\n\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n\n\n  \n  \n    \n  \n\n\n오류 메시지\n위의 순서대로 진행을 하면 문제 없이 사용 가능한데, 이미 다른 방법으로 진행해보면서 오류 메시지를 경험하는 경우도 있을 듯하여 가장 많이 겪게 되는 오류 상황 2가지를 정리해보겠습니다.\n\n Main 함수 이름 입력 오류: 액션 Main 함수 이름을 올바르게 입력하지 않으면 다음과 같은 오류 메시지가 나타납니다.“error” : “main required format is \\“Assembly::Type::Function\\”.”\n\n\n  \n  \n    \n  \n\n\n상단에 설명한 [CF Action 생성] - [옵션 설정]에서 Main 함수 입력하는 부분을 참고하셔서 정확하게 입력하시면 문제가 해결됩니다.\n\n\n .Net 대상 프레임워크 오류: 네이버 클라우드 Cloud Functions은 .Net Standard 2.0 규약을 지원하고 있습니다.\n그런데 이 대상 프레임워크가 맞지 않으면 다음과 같은 오류 메시지가 나타납니다.“error” : “Unable to locate requested type (\\“CloudFunctionsTestVisualStudio.Hello\\”).”\n\n\n  \n  \n    \n  \n\n\n위 [프로젝트 생성]에서 설명한 것처럼 프로젝트 생성할 때 대상 프레임워크를 .NET Standard 2.0으로 지정해야 합니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-15-2-6.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-cloud-functions-php-smtp-via-gmail-with-phpmailer-html": {
						"id": "compute-ncloud-compute-cloud-functions-php-smtp-via-gmail-with-phpmailer-html",
						"title": "Cloud Functions에서 PHPMailer를 사용하여 gmail을 통해 SMTP로 메일 발송하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_cloud_functions_php_smtp_via_gmail_with_phpmailer.html",
						"content": "개요\n네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어중에서 PHP를 이용하여 SMTP로 메일을 발송하는 방법을 소개하려고 합니다.\n메일 발송을 위한 솔루션은 PHPMailer를 이용하고, 발송 서버는 gmail을 이용하는 과정을 정리해보겠습니다.\n\nPHPMailer 다운로드\nPHP에서 SMTP를 이용한 메일을 발송하려고 할 때 흔히 사용하는 것이 PHPMailer입니다.\nPHPMailer는 GitHub에 있는 사이트로 가서 Code를 선택하고 Download ZIP을 클릭하면 다운받을 수 있습니다.\n일반적인 Linux서버에서 사용하는 경우라면 composer를 이용해서 설치하면 되겠지만 Cloud Functions에는 zip 파일로 소스코드를 업로드 해야 하기에 다운로드 받겠습니다.\n\nhttps://github.com/PHPMailer/PHPMailer\n\n\n  \n  \n    \n  \n\n\n다운받은 zip파일을 압축해제하면 아래와 같은 파일과 폴더를 확인할 수 있는데 여기서는 src, language 두 폴더만 사용합니다.\n\n\n  \n  \n    \n  \n\n\n메일발송 코드 작성\nPHPMailer에서 제공하는 샘플코드를 참고해서 꼭 필요한 코드만 적었습니다. 파일은 index.php로 저장합니다.\n\n추가로 필요한 코드가 있으면 아래 링크에 있는 PHPMailer 샘플코드를 참고하시면 되겠습니다.\n\nhttps://github.com/PHPMailer/PHPMailer/blob/master/examples/gmail.phps\n\n&lt;?php\n\n\tuse PHPMailer\\PHPMailer\\PHPMailer;\n\tuse PHPMailer\\PHPMailer\\SMTP;\n\tuse PHPMailer\\PHPMailer\\Exception;\n\n\trequire 'src/Exception.php';\n\trequire 'src/PHPMailer.php';\n\trequire 'src/SMTP.php';\n\n\tfunction main(array $args) : array\n\t{\n\t\t$gmail_user_name = 'gmail 계정';\n\t\t$gmail_app_password = '앱 비밀번호';\n\n\t\t$from_name = '발신자 이름';\t\n\t\t$from_email = '발신자 메일주소';\n\t\t\n\t\t$to_name = $args[\"to_name\"] ?? $from_name;  //수신자 이름\n\t\t$to_email = $args[\"to_email\"] ?? $from_email;  //수신자 메일주소\n\t\t\n\t\t$result = \"\";\n\t\t$result_msg = \"\";\n\n\t\ttry \n\t\t{\n\t\t\t$mail = new PHPMailer();\n\n\t\t\t$mail-&gt;isSMTP();\n\n\t\t\t$mail-&gt;SMTPDebug = SMTP::DEBUG_SERVER;\n\t\t\t$mail-&gt;Host = 'smtp.gmail.com';\n\t\t\t$mail-&gt;Port = 587;\n\t\t\t$mail-&gt;SMTPSecure = PHPMailer::ENCRYPTION_STARTTLS;\n\t\t\t$mail-&gt;SMTPAuth = true;\n\t\t\t\n\t\t\t$mail-&gt;setLanguage(\"ko\", \"language/\");\n\t\t\t$mail-&gt;CharSet = PHPMailer::CHARSET_UTF8;\n\n\t\t\t$mail-&gt;Username = $gmail_user_name;\n\t\t\t$mail-&gt;Password = $gmail_app_password;\n\n\t\t\t$mail-&gt;setFrom($from_email, $from_name);\n\t\t\t$mail-&gt;addAddress($to_email, $to_name);\n\t\t\t$mail-&gt;Subject = 'PHPMailer GMail SMTP test';\n\t\t\t$mail-&gt;Body = 'Cloud Functions에서 PHPMailer로 발송한 메일';\n\n\t\t\tif (!$mail-&gt;send()) \n\t\t\t{\t\t\t\t\t\n\t\t\t\t$result = \"fail\";\n\t\t\t\t$result_msg = $mail-&gt;ErrorInfo;\t\t\n\t\t\t} \n\t\t\telse \n\t\t\t{\n\t\t\t\t$result = \"success\";\n\t\t\t\t$result_msg = 'Message sent!';\t\t\t\t\t\n\t\t\t}\n\t\t}\n\t\tcatch(Exception $e)\n\t\t{\n\t\t\t$result = \"error\";\n\t\t\t$result_msg = $e-&gt;getMessage();\n\t\t}\n\n\t\treturn [$result =&gt; $result_msg];\n\t}\n?&gt;\n\n\n 보안 이슈: 위 소스코드에서 알아보기 쉽게 password 라는 변수명을 사용하기는 했지만, \n여러 상황에서 해킹 관련 이슈(예: grep 명령어를 사용해 password 정보가 포함된 파일 검색)가 발생할 수 있으니 실제 서비스에서는 password 라는 단어 대신에 다른 단어를 사용하기를 추천 드립니다. \n$gmail_app_password 뿐만 아니라 $mail-&gt;Password 가 포함된 PHPMailer.php 소스도 함께 수정하시면 더욱 안전할 수 있습니다\n\n\n앱 비밀번호\n위 소스코드에서 gmail에 로그인할 계정과 비밀번호를 적는 부분에서 앱 비밀번호를 관심있게 보셔야 합니다.\n\n$gmail_user_name = 'gmail 계정';\n$gmail_app_password = '앱 비밀번호';\n\n외부앱이나 서버에서 gmail 즉 google 계정에 로그인 인증을 하려면 2단계 인증을 설정하고, 앱 비밀번호를 생성해서 사용해야 합니다. \n예전에는 보안 수준이 낮은 앱의 액세스 허용 옵션으로 가능했었지만, 지금은 그렇게 하면 인증이 실패하는 경우가 많습니다. \n앱 비밀번호 설정하는 방법 문서를 참고하시면 되겠습니다.\n\nCloud Functions 함수와 파라미터\n이번 메일 발송 기능 함수는 메일 수신자 이름과 메일 주소를 json 형식의 파라미터로 전달 받고, 결과를 json 형식으로 리턴하는 구조로 되어 있습니다. \n아래와 같이 만약 파라미터가 없을 경우에는 발신자 이름과 메일주소와 동일한 기본값으로 설정했습니다.\n\nfunction main(array $args) : array\n{\n\t$to_name = $args[\"to_name\"] ?? $from_name;  //수신자 이름\n\t$to_email = $args[\"to_email\"] ?? $from_email;  //수신자 메일주소\n\n\treturn [$result =&gt; $result_msg];\n}\n\n\n디버깅 레벨 설정\n메일 발송 코드가 실행되는 과정에 여러 오류가 발생할 수 있는데, 오류가 발생했을 때 오류 메시지를 확인할 수 있도록 디버깅 레벨을 다음 코드로 설정하고 있습니다.\n테스트가 끝나고 실제 서비스에 사용할 때는 DEBUG_OFF 옵션으로 변경하시기 바랍니다.\n\n$mail-&gt;SMTPDebug = SMTP::DEBUG_SERVER;\n\n//SMTP::DEBUG_OFF = off (for production use)\n//SMTP::DEBUG_CLIENT = client messages\n//SMTP::DEBUG_SERVER = client and server messages\n//SMTP::DEBUG_CONNECTION =  As DEBUG_SERVER plus connection status\n//SMTP::DEBUG_LOWLEVEL = Low-level data output, all messages\n\n\n언어와 CharSet 설정\n코드가 실행되면서 나타날 수 있는 각 종 오류메시지를 표시할 언어와 메일 내용의 CharSet을 설정하는 코드입니다.\n\n$mail-&gt;setLanguage(\"ko\", \"language/\");\n$mail-&gt;CharSet = PHPMailer::CHARSET_UTF8;\n\n\n소스코드 Zip 파일로 압축\n위에서 작성한 소스코드를 index.php로 저장하고 클래스 파일들이 들어있는 src 폴더와 언어 파일이 들어있는 laguage 파일과 함께 zip 파일로 압축합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nCF 이용신청\n네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\n\n\n  \n  \n    \n  \n\n\nCF Action 생성\n\n액션 생성\n버튼을 선택해 액션을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n트리거 선택\n액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n이름 입력\n액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n소스코드 언어 선택\n소스코드 언어 중에서 php는 7.1, 7.3이 있는데 둘 중에 편하신대로 선택하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n소스코드 업로드\n소스코드 타입은 코드 직접 입력과 파일 업로드가 가능한데, 앞에서 만든 소스코드를 선택하고 업로드 합니다.\n\n\n  \n  \n    \n  \n\n\n\n소스코드가 업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\n네트워크 환경 설정\nVPC 환경에서는 NAT Gateway를 이용해야 하기 때문에 네트워크 환경을 설정해야 합니다.\nClassic 환경에서는 다음 단계인 옵션 설정으로 바로 이동하시면 됩니다.\n\nVPC 연결 정보 선택\n연결할 VPC와 Subnet을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nVPC 생성\n혹시 VPC를 생성하지 않았거나 새로운 VPC에서 실행하려고 할 경우에는 VPC생성 버튼을 클릭해서 새 창에서 VPC를 생성합니다.\nVPC는 논리적으로 격리된 네트워크 공간을 뜻하며, IP 주소 범위는, private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n\nhttps://console.ncloud.com/vpc-network/vpc\n\n\n  \n  \n    \n  \n\n\nSubnet 생성\n사용할 수 있는 Subnet이 없거나 새로 생성할 경우 Subnet 생성 버튼을 클릭합니다.\n이름은 알아보기 쉽게 [ cf-phpmailer-smtp-subnet ]으로 입력했습니다.\nSubnet의 IP 주소 범위는 VPC 주소 범위 이하로만 지정이 가능하며, private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n위에서 VPC IP주소 범위가 [ 192.168.0.0/16 ]이었기에 Subnet IP주소 범위는 [ 192.168.0.0/24 ]로 설정했습니다.\n\n여기서 중요한 것이 [Ineteget Gateway 전용여부] 항목입니다. \nCloud Functions는 Private Subnet에서만 작동하므로 N (Private)을 선택하셔야 합니다.\n용도는 일반으로 선택하시면 됩니다.\n\nhttps://console.ncloud.com/vpc-network/subnet\n\n\n  \n  \n    \n  \n\n\nNAT Gateway 생성\n위에서 생성한 Subnet이 Private이기 때문에 Cloud Functions으로 메일을 발송 즉, 외부와 통신을 하기 위해서는 NAT Gateway를 만들고 적용해주어야 합니다.\n이름은 [ cf-phpmailer-smtp-natgateway ]로 입력했습니다.\n\nhttps://console.ncloud.com/vpc-network/natgw\n\n\n  \n  \n    \n  \n\n\nRoute Table 설정\n이제 Cloud Functions이 속한 Subnet이 NAT Gateway를 거쳐서 외부로 나갈 수 있도록 Route Table을 설정합니다.\nVPC를 만들때 자동으로 생성된 2개의 Route Table중에서 private table을 선택하고 연관 Subnet 탭을 보시면 위에서 생성했던 [ cf-phpmailer-smtp-subnet ]을 확인할 수 있습니다.\n\nhttps://console.ncloud.com/vpc-network/routeTable\n\n\n  \n  \n    \n  \n\n\n이제 Routes 생성 버튼을 클릭하고 설정 값들을 입력, 선택하고 생성 버튼을 클릭합니다.\n\n  Destination : 0.0.0.0/0 입력\n  Target Type : NATGW 선택\n  Target Name : cf-phpmailer-smtp-natgateway 선택\n\n\n\n  \n  \n    \n  \n\n\n생성 버튼을 클릭하고 나면 설정이 추가된 것을 확인할 수 있습니다. 이제 확인 버튼을 클릭해서 창을 닫습니다.\n\n  \n  \n    \n  \n\n\n창을 닫고 나면 설정이 추가된 것을 Routes 탭에서 확인할 수 있습니다.\n\n  \n  \n    \n  \n\n\nVPC관련 설정이 끝났으면 이전 창으로 돌아가서 다음 단계인 [ 옵션 설정 ]을 확인하시면 됩니다.\n\n옵션 설정\n실행할 Main 함수의 이름은 main으로 그대로 두시고, 액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n생성 완료\n디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\n\n\n  \n  \n    \n  \n\n\nCF Action 실행\n이제 생성된 액션을 실행해보겠습니다.\n액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고,\n오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n\n\n  \n  \n    \n  \n\n\n\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다.  파라미터는 json 형태로 입력하면 됩니다.\n왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n\n\n  \n  \n    \n  \n\n\n\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n\n\n  \n  \n    \n  \n\n\n발송메일 확인\n메일함에서 확인해보면 이렇게 메일이 무사히 도착한 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 메시지\n위에서 앱 비밀번호를 사용해야 한다고 했는데 혹시 앱 비밀번호를 사용하지 않았을 경우 다음과 같은 오류 메시지가 나타나는 경우가 있습니다.\n\nThe SMTP server requires a secure connection or the client was not authenticated.\nThe server response was: 5.7.0 Authentication Required.\n\n\n이 문제, 인증 오류 메시지를 해결하려면 앱 비밀번호 설정하는 방법 문서 내용대로 설정을 하시면 해결됩니다.\n\n참고 URL\n\n  https://guide.ncloud-docs.com/docs/compute-compute-15-2-6.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-kubernetes-service-start-guide-html": {
						"id": "compute-ncloud-compute-kubernetes-service-start-guide-html",
						"title": "Kubernetes Service 클러스터 생성 및 제어 가이드",
						"categories": "",
						"url": " /compute/ncloud_compute_kubernetes_service_start_guide.html",
						"content": "개요\nNcloud (네이버 클라우드) VPC 환경에서 Kubernetes(쿠버네티스) 서비스를 생성하고 제어하는 방법에 대해 소개합니다.\n\n쿠버네티스란?\n쿠버네티스(Kubernetes, K8S)는 배포, 스케일링, 그리고 컨테이너화된 애플리케이션의 관리를 자동화 해주는 오픈 소스 컨테이너 오케스트레이션 엔진으로 \n구글에서 처음 개발하기 시작했으나 현재는 구글이 오픈소스 프로젝트로 공개한 상태입니다.\n\n특징\n쿠버네티스는 다음과 같은 특징이 있으며, 자세한 내용은 쿠버네티스 공식 페이지를 참고하시기 바랍니다.\n\nhttps://kubernetes.io/ko/docs/home/\n\n\n  서비스 디스커버리와 로드 밸런싱\n  스토리지 오케스트레이션\n  자동화된 롤아웃과 롤백\n  자동화된 빈 패킹(bin packing)\n  자동화된 복구(self-healing)\n  시크릿과 구성 관리\n\n\n사전 준비\n먼저 쿠버네티스 클러스터에 사용할 전용 VPC와 Private 또는 Public Subnet 그리고, Load Balancer용 Subnet이 필요합니다.\n\n\n  \n  \n    \n  \n\n\nIP 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /17~/26 범위의 Private 또는 Public Subnet, 로드밸런서 전용 Subnet이 필요합니다.\nDocker Bridge 대역의 충돌을 방지하기 위해 172.17.0.0/16 범위 내의 Private Subnet, 로드밸런서 전용Subnet은 선택할 수 없습니다.\n\n클러스터 생성\n\nVPC와 Subnet이 준비되었다면, 다음으로 [Kubernetes Sevice] - [Cluster]에서 생성하기를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n클러스터 설정\n생성할 클러스터의 정보를 설정해줍니다. (ACG는 자동으로 생성 됩니다.)\n네트워크 타입은 Private과 Public 중에서 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n현재 지원되고 있는 Kubenetes 버전은 [1.21.9], [1.22.9] 입니다.\n\nNAT Gateway 생성\nPrivate Subnet을 선택했을 경우에는 아래와 같이 NAT Gateway 생성 안내 팝업이 나타나는데,\nNAT Gateway를 생성해야 아웃바운드 트래픽을 활성화할 수 있기 때문입니다.\n\n\n  \n  \n    \n  \n\n\n팝업에서 링크를 클릭해서 NAT Gateway 화면으로 이동해 NAT Gateway를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n노드풀 설정\n노드풀 이름을 입력하고, 서버 이미지와 서버 타입을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n현재 지원되고 있는 OS는 [ubuntu16.04], [ubuntu18.04] 입니다.\n\n로그인키 설정\n다음으로 워커노드의 로그인키를 설정 합니다.\n\n\n  \n  \n    \n  \n\n\n최종 확인\n설정 정보를 최종적으로 확인한 후 생성버튼을 클릭하여 클러스터를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n쿠버네티스 클러스터 생성은 20분 정도 소요되므로 여유를 갖고 기다리시면 됩니다.\n\nkubectl 설치\n\n사용자 로컬PC에서 클러스터를 제어하기 위해 kubectl을 설치합니다.\nkubctl의 최신 릴리즈 버전은 아래  링크에서 다운받을 수 있습니다.\n\n\n  kubctl v1.21.0 :  https://dl.k8s.io/release/v1.21.0/bin/windows/amd64/kubectl.exe\n\n\n또는 windows에서 cmd 창에서 curl 을 이용하해 다운로드 받을 수도 있습니다.\n&gt; curl -LO https://dl.k8s.io/release/v1.21.0/bin/windows/amd64/kubectl.exe\n\n\nkubectl의 버전 확인이 필요한 경우 다음 명령어를 사용하시면 됩니다.\n&gt; kubectl version --client\n\n\n\n다른 OS 환경에서 설치하는 방법은 아래 링크에서 확인할 수 있습니다.\n\n\n  Linux kubectl 설치 : https://kubernetes.io/ko/docs/tasks/tools/install-kubectl-linux/\n  macOS kubectl 설치 : https://kubernetes.io/ko/docs/tasks/tools/install-kubectl-macos/\n\n\n접속-제어\n\n클러스터를 제어하기 위해서는 네이버 클라우드 쿠버네티스 서비스에서 제공해주는 접속을 위한 인증정보가 있는 설정파일이 필요합니다. \n[설정파일] - [다운로드] 버튼을 클릭해 설정 파일을 다운로드 받습니다.\n\n\n  \n  \n    \n  \n\n\nkubectl을 실행해 Kubernetes에 접속하고 제어하는 방법은 [가이드 보기] 버튼 클릭하면\n아래와 같이 [설치 가이드 바로가기]와 [IAM 인증 가이드] 링크에서 자세히 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다운로드한 설정 파일경로를 %KUBE_CONFIG% 환경변수에 지정합니다.\n\n&gt; SET KUBE_CONFIG=%USERPROFILE%\\Downloads\\kubeconfig-7349***-8***-4***-a***-99e***.yaml\n\n\n이제 –kubeconfig 옵션을 사용하여 쿠버네티스의 클러스터를 제어할수 있습니다.\n\n&gt; kubectl --kubeconfig %KUBE_CONFIG% get nodes\nNAME                 STATUS   ROLES   AGE    VERSION\nnks-pool-1865-w2zy   Ready    node    4d5h   v1.16.6\nnks-pool-1865-w2zz   Ready    node    4d5h   v1.16.6\n\n\n참고 URL\n\n  쿠버네티스 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8soverview\n    \n  \n  클러스터 이용 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8suse-cluster\n    \n  \n  kubectl 설치 가이드\n    \n      https://guide.ncloud-docs.com/docs/k8s-k8sstart#Kubectl"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lamp-config-basic-html": {
						"id": "compute-ncloud-compute-lamp-config-basic-html",
						"title": "Ncloud LAMP 기본 환경 설정 정보",
						"categories": "",
						"url": " /compute/ncloud_compute_lamp_config_basic.html",
						"content": "LAMP 기본설정\n\nNcloud(네이버 클라우드 플랫폼, 이하 네이버 클라우드)에서 제공하는 Application중에서 가장 대표적인 LAMP(Linux + Apache, Mysql, PHP)의 기본설정입니다.\n\n 제공 환경: 2022-01-14 현재 LAMP를 포함한 Application 이미지들은 Classic 환경에서만 이용 가능합니다.  VPC 환경에서는 아직 지원하지 않고 향후 업데이트 예정입니다\n\nLAMP 홈디렉토리\n네이버 클라우드에서 Linux 서버를 세팅하게 되면 기본적으로 root 계정으로 접속이 됩니다.\n그래서 LAMP 서비스의 홈디렉토리도 /root/lamp로 설정됩니다.\n\nLAMP 서비스 홈디렉토리 : /root/lamp\n\n\nLAMP 서비스 전체 재시작\n네이버 클라우드에서는 LAMP 전체 서비스를 빠르게 재시작할 수 있는 기능을 제공하고 있습니다.\n\nLAMP 서비스 전체 재시작 명령 : /root/lamp/lamp_restart.sh\n\n\n위 명령을 실행하면 Apache 와 mysql이 순서대로 재시작됩니다.\n\nLAMP 서비스 설치 상태 확인\n네이버 클라우드에서는 LAMP 서비스들의 설치 정보를 확인할 수 있는 기능도 제공하고 있습니다.\n\nLAMP 설치 상태와 정보 확인 명령 : /root/lamp/lamp_info.sh\n\n\n위 명령을 실행하면 LAMP의 기본 웹사이트 경로, 웹사이트 기본 디렉토리, mysql 초기 비번 안내, Apache 버전, mysql 버전, PHP와 Zend 버전 정보 등을 확인할 수 있습니다.\n\nLAMP 웹사이트 기본 디렉토리\n네이버 클라우드에서 제공하는 LAMP의 웹사이트 기본 디렉토리 위치는 다음과 같습니다.\n\n웹사이트 기본 디렉토리 : /ncp/data/www\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docslamp-lamp-1-1.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lamp-config-centos-html": {
						"id": "compute-ncloud-compute-lamp-config-centos-html",
						"title": "LAMP(CentOS) 기본 명령어와 환경 설정 파일 위치",
						"categories": "",
						"url": " /compute/ncloud_compute_lamp_config_centos.html",
						"content": "Apache 시작, 중지, 재시작\n\nApache 시작, 중지, 재시작 명령어는 CentOS 6에서 사용하던 것이 CentOS 7이 되면서 변경되었습니다.\nCentOS 6.x 이하에서는 service {서비스명} [stop|start|restart] 순서였다면 CentOS 7.X 에서는 systemctl [stop|start|restart] {서비스명} 의 순서로 바뀌었습니다.\n내용을 정리하면 다음과 같습니다.\n\nCentOS 6.x 이하\n- 중지 : service httpd stop\n- 시작 : service httpd start\n- 재시작 : service httpd restart\n\n\nCentOS 7.x\n- 중지 : systemctl stop httpd\n- 시작 : systemctl start httpd\n- 재시작 : systemctl restart httpd\n\n\nmysql 시작, 중지, 재시작\nmysql도 Apache와 마찬가지 방식으로 CentOS 6 이하와 CentOS 7에서 사용하는 명령어가 변경되었습니다.\n\nCentOS 6.x 이하\n- 중지 : service mysqld stop\n- 시작 : service mysqld start\n- 재시작 : service mysqld restart\n\n\nCentOS 7.x\n- 중지 : systemctl stop mysqld\n- 시작 : systemctl start mysqld\n- 재시작 : systemctl restart mysqld\n\n\nApache 환경 설정 파일\n\nApache의 환경 설정 파일은 CentOS의 버전과 관계없이 모두 동일합니다.\nhttpd.conf : /etc/httpd/conf/httpd.conf\n\n\nPHP 환경 설정 파일\nPHP의 환경 설정파일인 php.ini는  PHP버전에 해당 하는 디렉토리에 위치하고 있습니다.\nphp.ini : /etc/php/7.2/apache2/php.ini\n\n\nmysql 환경 설정 파일\n\nmysql 환경  설정파일인 my.cnf는 OS버전과 관계없이 /etc/mysql/my.cnf 에 위치하고 있으며, 실제로는 /etc/alternatives/my.cnf로 링크되어 있습니다.\nmy.cnf : /etc/mysql/my.cnf -&gt; /etc/alternatives/my.cnf\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/lamp-lamp-1-1.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lamp-config-ubuntu-html": {
						"id": "compute-ncloud-compute-lamp-config-ubuntu-html",
						"title": "LAMP(Ubuntu) 기본 명령어와 환경 설정 파일 위치",
						"categories": "",
						"url": " /compute/ncloud_compute_lamp_config_ubuntu.html",
						"content": "Apache 시작, 중지, 재시작\nApache 시작, 중지, 재시작 명령어는 OS별로 조금씩 다른데 Ubuntu의 경우에는 systemctl [stop|start|restart] {서비스명} 의 순서로 되어 있습니다.\n\nUbuntu\n- 중지 : systemctl stop apache2\n- 시작 : systemctl start apache2\n- 재시작 : systemctl restart apache2\n\n\nmysql 시작, 중지, 재시작\nmysql 시작, 중지, 재시작 명령어도 Apache와 마찬가지로 systemctl [stop|start|restart] {서비스명} 의 순서로 되어 있습니다.\n\nUbuntu\n- 중지 : systemctl stop mysql\n- 시작 : systemctl start mysql\n- 재시작 : systemctl restart mysql\n\n\nApache 환경 설정 파일\nApache의 기본 환경설정 파일은 CentOS의 경우 httpd.conf라는 파일로 간단하게 구성되어 있는데 Ubuntu의 경우에는 포트, 가상호스트, 로그 등 각각의 항목별로 파일이 나뉘어져 있습니다.\n\nUbuntu\n- 기본 설정 : /etc/apache2/apache2.conf\n- 포트 설정 : /etc/apache2/ports.conf\n- 가상호스트 설정: /etc/apache2/sites-enabled/000-default.conf -&gt; /etc/apache2/sites-available/000-default.conf\n- 로그 : /var/log/apache2\n- 기타 옵션 설정 :\n  /etc/apache2/mods-enabled/*.load -&gt; /etc/apache2/mods-available/*.load\n  /etc/apache2/mods-enabled/*.conf -&gt; /etc/apache2/mods-available/*.conf\n\n\nPHP 환경 설정 파일\nPHP의 환경 설정파일인 php.ini는  PHP버전에 해당 하는 디렉토리에 위치하고 있습니다.\nphp.ini : /etc/php/7.2/apache2/php.ini\n\n\nmysql 환경 설정 파일\n\nmysql 환경  설정파일인 my.cnf는 OS버전과 관계없이 /etc/mysql/my.cnf 에 위치하고 있으며, 실제로는 /etc/alternatives/my.cnf로 링크되어 있습니다.\nmy.cnf : /etc/mysql/my.cnf -&gt; /etc/alternatives/my.cnf\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/lamp-lamp-1-1.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lemp-nginx-install-setting-centos-guide-html": {
						"id": "compute-ncloud-compute-lemp-nginx-install-setting-centos-guide-html",
						"title": "CentOS에서 NginX 설치, 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_lemp_nginx_install_setting_centos_guide.html",
						"content": "개요\nNcloud (네이버 클라우드) CentOS 서버에 NginX 최신 버전을 Package로 설치하고 기본 설정을 하는 방법에 대한 내용을 정리해보겠습니다.\n\n서버 환경\n\n\n⁃ OS: CentOS 7.8 \n⁃ NginX: NginX 1.21.5 \n\n\nyum 유틸리티 설치\nyum으로 NginX를 설치하기 전에 yum-utils를 먼저 설치합니다. 이미 설치 되어 있을 경우에는 아래와 같이 설치되어 있다는 메시지가 출력됩니다.\n\n~# yum install yum-utils\n\n\n  \n  \n    \n  \n\n\nRepository 설정\nNginX package를 다운 받아 설치하기 위해서는 Repository를 설정해야 합니다. \nRepository 디렉토리에 nginx.repo 파일을 만들고 아래와 같은 내용을 입력합니다.\n\n~# vi /etc/yum.repos.d/nginx.repo\n\n\n[nginx-stable]\nname=nginx stable repo\nbaseurl=http://nginx.org/packages/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=1\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n\n[nginx-mainline]\nname=nginx mainline repo\nbaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n\n\nNginX는 stable, mainline 두가지 버전이 있습니다. \nNginX의 공식 설명에 따르면 버그 수정이나 보안 패치 등은 항상 mainline 버전에 먼저 적용되기 때문에 mainline을 사용하는 것을 추천한다고 합니다. \nstable 버전을 사용하는 주된 경우는 third-party 모듈을 사용하고 있어서 신규 버전에서 호환성 문제가 발생할 가능성이 걱정될 때라고 합니다.\n\n\n  \n  \n    \n  \n\n\n버전 선택\nstable, mainline 두가지 버전 중에서 기본은 stable 버전입니다.\nstable 버전을 설치할 경우에는 다음 명령어는 건너띄어도 되고, mainline 버전을 설치하기 위해서는 아래 명령어로 설정을 변경해주어야 합니다.\n\n~# yum-config-manager --enable nginx-mainline\n\n\n\n  \n  \n    \n  \n\n\nNginX 설치\n설정을 마쳤으면 yum으로 NginX를 설치합니다.\n~# yum -y install nginx\n\n\n\n  \n  \n    \n  \n\n\n디렉토리 설정\n다음으로 홈으로 사용할 디렉토리를 생성하고, 해당 디렉토리의 소유권을 설정하겠습니다.\n그리고, NginX가 정상 작동하는지 확인해보기 위해 설치시에 포함된 index.html을 홈 디렉토리로 복사합니다.\n\n~# mkdir -p /ncp/data/www\n~# chown -R nginx:nginx /ncp/data/www\n~# cp /usr/share/nginx/html/index.html /ncp/data/www/index.html\n~# ls -al /ncp/data/www\n\n\n  \n  \n    \n  \n\n\n환경 설정\n주로 변경할 환경 설정 파일은 /etc/nginx/conf.d/default.conf 입니다.\n\n~# vi /etc/nginx/conf.d/default.conf\n\n\nPort와 Server Name 설정\n80이 아닌 다른 Port를 사용할 경우나 도메인을 설정하게 될 경우 2, 3 라인에 있는 아래 항목들을 수정하면 됩니다.\n\nserver_name  localhost;\nserver_name  nginx-test.com;\n\n\n\n  \n  \n    \n  \n\n\n홈 디렉토리, 기본 문서 설정\n앞에서 만들었던 홈 디렉토리 경로를 설정하고 기본 문서를 지정하는 곳입니다.\n\n# 변경 전\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n\n# 변경 후\n    root   /ncp/data/www;\n    index  index.html index.htm;\n\n    location / {\n        try_files $uri $uri/ = 404;\n    }\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nerror 페이지 설정\n404, 500 등의 error 페이지를 설정할 경우 아래 내용들을 수정하면 됩니다.\n\n# 변경 전\n    #error_page  404              /404.html;\n\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n\n# 변경 후\n    error_page  404              /404.html;\n\n    location = /50x.html {\n        root   /ncp/data/www;\n    }\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n.htaccess 파일 접근 금지 설정\n.htaccess 파일에 대한 접근 금지를 설정할 경우 아래 내용을 주석 해제하면 됩니다.\n\n# 변경 전\n    #location ~ /\\.ht {\n    #    deny  all;\n    #}\n\n# 변경 후\n    location ~ /\\.ht {\n        deny  all;\n    }\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nNginX 실행\n설정을 모두 마쳤으면 NginX를 시작하고 상태를 확인합니다.\n\n~# systemctl start nginx\n~# systemctl status nginx\n\n\n  \n  \n    \n  \n\n\n사이트 접속\nNginX가 정상 작동하면 아래와 같이 서버 접속 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  NginX Linux packages 설치 가이드\n    \n      http://nginx.org/en/linux_packages.html\n    \n  \n  Ubuntu에서 NginX 설치, 설정하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_install_setting_ubuntu_guide.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lemp-nginx-install-setting-ubuntu-guide-html": {
						"id": "compute-ncloud-compute-lemp-nginx-install-setting-ubuntu-guide-html",
						"title": "Ubuntu에서 NginX 설치, 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_lemp_nginx_install_setting_ubuntu_guide.html",
						"content": "개요\nNcloud (네이버 클라우드) Ubuntu 서버에 NginX 최신 버전을 Package로 설치하고 기본 설정을 하는 방법에 대한 내용을 정리해보겠습니다.\n\n서버 환경\n\n\n⁃ OS: Ubuntu 20.04 \n⁃ NginX: NginX 1.21.6 \n\n\nNginX Signing Key 설정\nNginX Package 설치에 필요한 Signing Key를 설정합니다.\n\ngnupg2 등 설치\n\n~# sudo apt install curl gnupg2 ca-certificates lsb-release ubuntu-keyring\n\n\n  \n  \n    \n  \n\n\nNginX Signing Key 가져오기\n\n~# curl https://nginx.org/keys/nginx_signing.key | gpg --dearmor \\\n    | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg &gt;/dev/null\n\n\n  \n  \n    \n  \n\n\nNginX Signing Key 검증\n위에서 가져온 Signing Key를 아래 명령어로 검증합니다.\n검증한 FingerPring 값이 573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 와 일치하는지 확인합니다.\n~# gpg --dry-run --quiet --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpg\n\n\n  \n  \n    \n  \n\n\nRepository 설정\nNginX package를 다운 받아 설치하기 위해서는 Repository를 설정해야 합니다.\n아래 명령어로 리포지토리를 설정합니다. NginX의 stable, mainline 두가지 버전 중에서 여기서는 mainline 버전을 설치합니다.\n\nnginx-mainline\n~# echo \"deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \\\n    http://nginx.org/packages/mainline/ubuntu `lsb_release -cs` nginx\" \\\n    | sudo tee /etc/apt/sources.list.d/nginx.list\n\n\nnginx-stable\n~# echo \"deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \\\n    http://nginx.org/packages/ubuntu `lsb_release -cs` nginx\" \\\n    | sudo tee /etc/apt/sources.list.d/nginx.list\n\n\nNginX는 stable, mainline 두가지 버전이 있습니다. \nNginX의 공식 설명에 따르면 버그 수정이나 보안 패치 등은 항상 mainline 버전에 먼저 적용되기 때문에 mainline을 사용하는 것을 추천한다고 합니다. \nstable 버전을 사용하는 주된 경우는 third-party 모듈을 사용하고 있어서 신규 버전에서 호환성 문제가 발생할 가능성이 걱정될 때라고 합니다.\n\n\n  \n  \n    \n  \n\n\nRepository 우선 순위 설정\n배포판에 기본 설정된 리포지토리 보다 위에서 설정한 리포지토리를 우선하도록 설정합니다.\n\n~# echo -e \"Package: *\\nPin: origin nginx.org\\nPin: \\\n    release o=nginx\\nPin-Priority: 900\\n\" | sudo tee /etc/apt/preferences.d/99nginx\n\n\n  \n  \n    \n  \n\n\nNginX 설치\n설정을 마쳤으면 apt로 NginX를 설치합니다.\n\n~# sudo apt update\n\n\n\n  \n  \n    \n  \n\n\n~# sudo apt install nginx\n\n\n\n  \n  \n    \n  \n\n\n디렉토리 설정\n다음으로 홈으로 사용할 디렉토리를 생성하고, 해당 디렉토리의 소유권을 설정하겠습니다.\n그리고, NginX가 정상 작동하는지 확인해보기 위해 설치시에 포함된 index.html을 홈 디렉토리로 복사합니다.\n\n~# mkdir -p /ncp/data/www\n~# chown -R nginx:nginx /ncp/data/www\n~# cp /usr/share/nginx/html/index.html /ncp/data/www/index.html\n~# ls -al /ncp/data/www\n\n\n  \n  \n    \n  \n\n\n환경 설정\n주로 변경할 환경 설정 파일은 /etc/nginx/conf.d/default.conf 입니다.\n\n~# vi /etc/nginx/conf.d/default.conf\n\n\nPort와 Server Name 설정\n80이 아닌 다른 Port를 사용할 경우나 도메인을 설정하게 될 경우 2, 3 라인에 있는 아래 항목들을 수정하면 됩니다.\n\nserver_name  localhost;\nserver_name  nginx-test.com;\n\n\n\n  \n  \n    \n  \n\n\n홈 디렉토리, 기본 문서 설정\n앞에서 만들었던 홈 디렉토리 경로를 설정하고 기본 문서를 지정하는 곳입니다.\n\n# 변경 전\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n\n# 변경 후\n    root   /ncp/data/www;\n    index  index.html index.htm;\n\n    location / {\n        try_files $uri $uri/ = 404;\n    }\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nerror 페이지 설정\n404, 500 등의 error 페이지를 설정할 경우 아래 내용들을 수정하면 됩니다.\n\n# 변경 전\n    #error_page  404              /404.html;\n\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n\n# 변경 후\n    error_page  404              /404.html;\n\n    location = /50x.html {\n        root   /ncp/data/www;\n    }\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n.htaccess 파일 접근 금지 설정\n.htaccess 파일에 대한 접근 금지를 설정할 경우 아래 내용을 주석 해제하면 됩니다.\n\n# 변경 전\n    #location ~ /\\.ht {\n    #    deny  all;\n    #}\n\n# 변경 후\n    location ~ /\\.ht {\n        deny  all;\n    }\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nNginX 실행\n설정을 모두 마쳤으면 NginX를 시작하고 상태를 확인합니다.\n\n~# systemctl start nginx\n~# systemctl status nginx\n\n\n  \n  \n    \n  \n\n\n사이트 접속\nNginX가 정상 작동하면 아래와 같이 서버 접속 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  NginX Linux packages 설치 가이드\n    \n      http://nginx.org/en/linux_packages.html\n    \n  \n  CentOS에서 NginX 설치, 설정하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_install_setting_centos_guide.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lemp-nginx-ssl-setting-centos-guide-html": {
						"id": "compute-ncloud-compute-lemp-nginx-ssl-setting-centos-guide-html",
						"title": "CentOS에서 NginX SSL 인증서 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_lemp_nginx_ssl_setting_centos_guide.html",
						"content": "개요\nNcloud (네이버 클라우드) CentOS 서버에서 NginX 최신 버전에 SSL 인증서를 설정하고, http로 접속 시에 https로 리다이렉트하는 방법에 대한 내용을 정리해보겠습니다.\n\n서버 환경\n\n\n⁃ OS: CentOS 7.8 \n⁃ NginX: NginX 1.21.6 \n⁃ SSL 인증서: 로컬 테스트용 인증서 \n\n\nNginX 설치\nCentOS에 Nginx 최신 버전을 설치하는 방법은 아래 문서에서 확인하시면 됩니다.\n\n  https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_install_setting_centos_guide.html\n\n\n테스트 사이트 접속\n설치한 서버에 IP 주소로 접속해 봅니다.\n\n\n  \n  \n    \n  \n\n\n테스트용 SSL 인증서 생성\nSSL 인증서를 저장할 디렉토리를 생성하고 30일 기한의 테스트용 인증서 파일 (nginx-ssl.key, nginx-ssl.crt)을 생성합니다. \n여기서는 nginx-ssl-test.com 이라는 임의의 테스트용 도메인을 사용하겠습니다.\n\n~# mkdir /root/ssl/\n~# openssl req -x509 -days 30 -nodes -newkey rsa:2048 \\\n   -keyout /root/ssl/nginx-ssl.key -out /root/ssl/nginx-ssl.crt\n\n\n\n  \n  \n    \n  \n\n\n인증서 파일이 제대로 저장되었는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\nNginX SSL 환경 설정\nNginX 환경 설정 파일 (/etc/nginx/conf.d/default.conf) 을 아래와 같이 수정합니다.\n\n~# vi /etc/nginx/conf.d/default.conf\n\nserver {\n    listen       80;\n    server_name  nginx-ssl-test.com;\n    return 301 https://$host$request_uri;\n}\n\nserver {\n    listen       443 ssl;\n    server_name  nginx-ssl-test.com;\n\n    ssl_certificate /root/ssl/nginx-ssl.crt;\n    ssl_certificate_key /root/ssl/nginx-ssl.key;\n\n    ### 이하 생략 ###\n}\n\n\n~# systemctl restart nginx\n\n\nSSL 인증서 파일 설정\n여기서는 테스트용으로 생성한 인증서 파일의 위치를 아래와 같은 양식으로 지정합니다.\n외부 공식 인증서 사이트에서 발급 받은 인증서도 원하는 곳에 저장하고 아래와 같이 위치를 지정해주면 됩니다.\n\n    ssl_certificate /root/ssl/nginx-ssl.crt;\n    ssl_certificate_key /root/ssl/nginx-ssl.key;\n\n\nhttp 접속 시 https 리다이렉트\nNginX 웹서버에 http 접속 시에 https로 강제 리다이렉트를 하려고 할 경우에는 http로 접속하는 포트 (일반적으로 80) 설정에 아래와 같이 지정해주면 리다이렉트 됩니다.\n\n    return 301 https://$host$request_uri;\n\n\n\n  \n  \n    \n  \n\n\nhosts 파일 수정\n테스트용으로 임의 설정한 도메인으로 접속하게 될 경우에는 hosts 파일을 수정해야 합니다.\n실제 도메인을 사용할 경우에는 아래 과정이 필요 없기에 다음 단계로 바로 이동하시면 됩니다.\n\n윈도우 10에서 hosts 파일은 C:\\Windows\\System32\\drivers\\etc 에 존재하는데 직접 수정할 수가 없으므로 다음과 같은 단계를 거쳐야 합니다.\n\n\n  C:\\Windows\\System32\\drivers\\etc\\hosts 파일을 임의의 작업 폴더 (예: D:\\Work)로 복사합니다.\n  복사한 hosts 파일을 수정해서 123.456.789.123 nginx-ssl-test.com 처럼 접속할 IP 주소와 도메인을 추가합니다.\n  수정한 파일을 C:\\Windows\\System32\\drivers\\etc 위치로 덮어쓰기 합니다.\n  덮어쓰기 할 때 관리자 권한이 필요하다는 안내 메시지가 나타나면 [계속] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nhttps 접속 테스트\n모든 설정을 마친 후에 테스트로 설정한 nginx-ssl-test.com 으로 접속하면 아래와 같이 https로 접속되는 것을 확인할 수 있습니다.\n다만 로컬 테스트용 인증서이기 때문에 [주의 요함]이라는 메시지가 나타납니다.\n\n\n  \n  \n    \n  \n\n\n테스트 인증서 확인\n[주의 요함] 부분을 클릭하면 인증서 부분에 [인증서가 올바르지 않음]이라는 메시지가 보이는데 이곳을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n테스트 인증서 정보\n아래와 같이 처음에 설정한 내용이 인증서 정보에 올바르게 표시되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  NginX Linux packages 설치 가이드\n    \n      http://nginx.org/en/linux_packages.html\n    \n  \n  CentOS에서 NginX 설치, 설정하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_install_setting_centos_guide.html\n    \n  \n  Ubuntu에서 NginX SSL 인증서 설정하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_ssl_setting_ubuntu_guide.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-lemp-nginx-ssl-setting-ubuntu-guide-html": {
						"id": "compute-ncloud-compute-lemp-nginx-ssl-setting-ubuntu-guide-html",
						"title": "Ubuntu에서 NginX SSL 인증서 설정하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_lemp_nginx_ssl_setting_ubuntu_guide.html",
						"content": "개요\nNcloud (네이버 클라우드) Ubuntu 서버에서 NginX 최신 버전에 SSL 인증서를 설정하고, http로 접속 시에 https로 리다이렉트하는 방법에 대한 내용을 정리해보겠습니다.\n\n서버 환경\n\n\n⁃ OS: Ubuntu 20.04 \n⁃ NginX: NginX 1.21.6 \n⁃ SSL 인증서: 로컬 테스트용 인증서 \n\n\nNginX 설치\nUbuntu에 Nginx 최신 버전을 설치하는 방법은 아래 문서에서 확인하시면 됩니다.\n\n  https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_install_setting_ubuntu_guide.html\n\n\n테스트 사이트 접속\n설치한 서버에 IP 주소로 접속해 봅니다.\n\n\n  \n  \n    \n  \n\n\n테스트용 SSL 인증서 생성\nSSL 인증서를 저장할 디렉토리를 생성하고 30일 기한의 테스트용 인증서 파일 (nginx-ssl.key, nginx-ssl.crt)을 생성합니다. \n여기서는 nginx-ssl-test.com 이라는 임의의 테스트용 도메인을 사용하겠습니다.\n\n~# mkdir /root/ssl/\n~# openssl req -x509 -days 30 -nodes -newkey rsa:2048 \\\n   -keyout /root/ssl/nginx-ssl.key -out /root/ssl/nginx-ssl.crt\n\n\n\n  \n  \n    \n  \n\n\n인증서 파일이 제대로 저장되었는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\nNginX SSL 환경 설정\nNginX 환경 설정 파일 (/etc/nginx/conf.d/default.conf) 을 아래와 같이 수정합니다.\n\n~# vi /etc/nginx/conf.d/default.conf\n\n\n 환경설정 파일 위치: \nNginX 버전을 위와 같이 최신 버전을 따로 설치하지 않고 \nUbuntu에 기본 설정된 리포지토리에 있는 버전(1.18.0)을 apt install nginx로 바로 설치한 경우에는 \nNginX 환경 설정 파일 위치가 /etc/nginx/sites-available/default로 설정되어 있습니다.\n\n\nserver {\n    listen       80;\n    server_name  nginx-ssl-test.com;\n    return 301 https://$host$request_uri;\n}\n\nserver {\n    listen       443 ssl;\n    server_name  nginx-ssl-test.com;\n\n    ssl_certificate /root/ssl/nginx-ssl.crt;\n    ssl_certificate_key /root/ssl/nginx-ssl.key;\n\n    ### 이하 생략 ###\n}\n\n\n~# systemctl restart nginx\n\n\nSSL 인증서 파일 설정\n여기서는 테스트용으로 생성한 인증서 파일의 위치를 아래와 같은 양식으로 지정합니다.\n외부 공식 인증서 사이트에서 발급 받은 인증서도 원하는 곳에 저장하고 아래와 같이 위치를 지정해주면 됩니다.\n\n    ssl_certificate /root/ssl/nginx-ssl.crt;\n    ssl_certificate_key /root/ssl/nginx-ssl.key;\n\n\nhttp 접속 시 https 리다이렉트\nNginX 웹서버에 http 접속 시에 https로 강제 리다이렉트를 하려고 할 경우에는 http로 접속하는 포트 (일반적으로 80) 설정에 아래와 같이 지정해주면 리다이렉트 됩니다.\n\n    return 301 https://$host$request_uri;\n\n\n\n  \n  \n    \n  \n\n\nhosts 파일 수정\n테스트용으로 임의 설정한 도메인으로 접속하게 될 경우에는 hosts 파일을 수정해야 합니다.\n실제 도메인을 사용할 경우에는 아래 과정이 필요 없기에 다음 단계로 바로 이동하시면 됩니다.\n\n윈도우 10에서 hosts 파일은 C:\\Windows\\System32\\drivers\\etc 에 존재하는데 직접 수정할 수가 없으므로 다음과 같은 단계를 거쳐야 합니다.\n\n\n  C:\\Windows\\System32\\drivers\\etc\\hosts 파일을 임의의 작업 폴더 (예: D:\\Work)로 복사합니다.\n  복사한 hosts 파일을 수정해서 123.456.789.123 nginx-ssl-test.com 처럼 접속할 IP 주소와 도메인을 추가합니다.\n  수정한 파일을 C:\\Windows\\System32\\drivers\\etc 위치로 덮어쓰기 합니다.\n  덮어쓰기 할 때 관리자 권한이 필요하다는 안내 메시지가 나타나면 [계속] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nhttps 접속 테스트\n모든 설정을 마친 후에 테스트로 설정한 nginx-ssl-test.com 으로 접속하면 아래와 같이 https로 접속되는 것을 확인할 수 있습니다.\n다만 로컬 테스트용 인증서이기 때문에 [주의 요함]이라는 메시지가 나타납니다.\n\n\n  \n  \n    \n  \n\n\n테스트 인증서 확인\n[주의 요함] 부분을 클릭하면 인증서 부분에 [인증서가 올바르지 않음]이라는 메시지가 보이는데 이곳을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n테스트 인증서 정보\n아래와 같이 처음에 설정한 내용이 인증서 정보에 올바르게 표시되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  NginX Linux packages 설치 가이드\n    \n      http://nginx.org/en/linux_packages.html\n    \n  \n  Ubuntu에서 NginX 설치, 설정하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_install_setting_ubuntu_guide.html\n    \n  \n  CentOS에서 NginX SSL 인증서 설정하는 방법\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_lemp_nginx_ssl_setting_centos_guide.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-connect-by-public-ip-html": {
						"id": "compute-ncloud-compute-server-connect-by-public-ip-html",
						"title": "Classic 환경 서버 접속 가이드(Linux) - 공인IP 있을 때",
						"categories": "",
						"url": " /compute/ncloud_compute_server_connect_by_public_ip.html",
						"content": "개요\n네이버 클라우드 Classic 환경에서 리눅스 서버에 접속하는 방법 중에서 공인아이피가 있을 때 접속하는 방법에 대한 내용을 정리하였습니다.\n여기서는 서버에 접속하는 방법을 정리하기 때문에 이미 서버는 생성되어 있다는 전제하게 정리하게 됩니다.\n\n요약\n우선은 전체 과정을 텍스트로 간단하게 요약해서 살펴보고 스크린샷을 포함한 상세 과정은 아래쪽에서 살펴보겠습니다.\n\n\n  포트 포워딩 설정 해제 (설정되어 있을 경우)\n  관리자(root) 비밀번호 확인\n  터미널 프로그램(Putty) 실행\n  공인IP로 접속\n  위 2번 관리자 비밀번호 확인에서 기록한 비번 입력\n\n\n포트 포워딩 설정 해제 (설정되어 있을 경우)\n\n네이버 클라우드에서는 Server, Bare Metal Server에서 공인 IP와 포트 포워딩을 동시에 사용하면 22(Linux), 3389(Windows) 포트가 포트 포워딩에 먼저 할당되므로 공인 IP에서 해당 포트 사용이 불가해집니다.\n\n즉, 포트 포워딩이 설정된 상태에서는 서버에 접속할 때 공인IP로는 22, 3389 포트가 접속 되지 않는다는 뜻입니다.  \n\n그러므로, 공인 IP로 22, 3389 포트에 접속하려는 경우에는 포트 포워딩을 해제하시고,\n포트 포워딩을 설정하지 않았다면 다음 순서인 관리자(root) 비밀번호 확인으로 바로 이동하시면 되겠습니다.\n\n  \n  \n    \n  \n\n\n포트 포워딩을 해제 하시려면 아래 화면처럼 설정된 포트 포워딩에서 삭제 버튼을 클릭하시고 하단의 적용 버튼을 클릭합니다.\n\n  \n  \n    \n  \n\n\n관리자 비밀번호 확인\n\n네이버 클라우드에서 처음 서버를 생성하고 접속하게 되면 root와 비밀번호로 접속하게 됩니다.\n물론 매번 비번을 입력하고 접속하는 것은 번거롭기도 하고 보안 측면에서 좋지 않기 때문에 이후에 SSH Key를 생성해서 접속하는 방식으로 바꾸는 것이 좋습니다.\n\n  \n  \n    \n  \n\n\n관리자 비밀번호 확인 메뉴를 클릭하면 인증키를 확인하는 화면이 나옵니다.\n인증키는 서버 생성시에 설정하고 PC에 다운로드 해 둔 확장지 *.pem 파일입니다.\n\n  \n  \n    \n  \n\n\n인증키 파일을 마우스로 끌어오거나 화면을 클릭해서 선택합니다.\n\n  \n  \n    \n  \n\n\n인증키가 일치하면 아래와 같이 root 계정에 해당하는 비밀번호가 나타납니다.\n이 비밀번호를 복사하여 저장해둡니다.\n혹시 복사-저장하는 것을 잊으셨어도 언제든지 관리자 비밀번호 확인 메뉴에 들어가서 인증키를 인증하면 다시 확인할 수 있으니 걱정하지 않으셔도 됩니다.\n\n  \n  \n    \n  \n\n\n터미널 프로그램(Putty) 실행\n\nPutty를 실행해서 공인IP를 입력합니다.\n\n  \n  \n    \n  \n\n\n접속을 하면 rsa2 key fingerprint 를 Putty 캐시에 저장할 것인지 묻는 화면이 나타납니다. \n보통 예(Y)를 선택하면 됩니다.\n\n  \n  \n    \n  \n\n\nroot 계정과 관리자 비밀번호 입력\n\n계정 root와 관리자 비밀번호 확인에서 저장해 둔 비밀번호를 입력합니다.\n\n  \n  \n    \n  \n\n\n접속이 완료되면 이렇게 화면이 나타납니다.\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-3-1-v2.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-connect-no-public-ip-html": {
						"id": "compute-ncloud-compute-server-connect-no-public-ip-html",
						"title": "Classic 환경 서버 접속 가이드(Linux) - 공인IP 없을 때",
						"categories": "",
						"url": " /compute/ncloud_compute_server_connect_no_public_ip.html",
						"content": "개요\n네이버 클라우드 Classic 환경에서 리눅스 서버에 접속하는 방법 중에서 공인아이피가 없을 때 접속하는 방법에 대한 내용을 정리하였습니다.\n여기서는 서버에 접속하는 방법을 정리하기 때문에 이미 서버는 생성되어 있다는 전제하게 정리하게 됩니다.\n또한, Classic 과 VPC 환경 중에서 VPC는 포트 포워딩이 없고 공인 IP로만 접속하기 때문에 아래에서 설명하는 내용은 Classic 환경 기준입니다.\n\n추가로 SSL VPN으로 접속할 경우는 Classic, VPC 모두 사설 IP로 접속하게 되는데 이 내용은 아래 쪽에 별도로 정리한 문서 링크를 참고하시면 됩니다.\n\n요약\n우선은 전체 과정을 텍스트로 간단하게 요약해서 살펴보고 스크린샷을 포함한 상세 과정은 아래쪽에서 살펴보겠습니다.\n\n\n  포트 포워딩 설정\n  관리자(root) 비밀번호 확인\n  터미널 프로그램(Putty) 실행\n  위 1번 포트 포워딩에서 설정한 포트와 IP로 접속\n  위 2번 관리자 비밀번호 확인에서 기록한 비번 입력\n  추가사항: SSL VPN으로 접속하는 방법\n\n\n포트 포워딩 설정\n\n네이버 클라우드에서 공인IP 없이 서버에 접속하려면 외부 접속을 위한 포트 포워딩을 설정해야 합니다.\n생성된 서버를 선택하면 상단 메뉴에 포트 포워딩 설정이 있습니다.\n\n  \n  \n    \n  \n\n\n포트 포워딩 메뉴에 들어가면 아래와 같이 서버 접속용 공인 IP가 보이고, 외부에서 접속할 포트 (Putty에 입력할 포트)를 입력하는 곳이 있습니다.\n\n  \n  \n    \n  \n\n\n포트 포워딩에서 사용할 수 있는 포트 번호 범위는 1,024 ~ 65,534 이며, 이 범위 내에서 원하는 포트를 입력하시면 됩니다.\n(Tip: 서버 접속용 공인IP를 활용해서 포트 번호를 입력하면 기억하기 쉽습니다. )\n(예: OOO.12.45.178 인 경우 포트를 17822,  106.10.OO.OO 인 경우 10622 )\n\n포트를 입력하고 +추가 버튼을 클릭합니다.\n\n  \n  \n    \n  \n\n\n추가된 포트와 서버 접속용 공인 IP 정보를 확인하고 수정할 부분이 있으면 수정합니다.\n더 이상 수정할 내용이 없으면 하단의 적용 버튼을 반드시 클릭합니다.\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n관리자 비밀번호 확인\n\n네이버 클라우드에서 처음 서버를 생성하고 접속하게 되면 root와 비밀번호로 접속하게 됩니다.\n물론 매번 비번을 입력하고 접속하는 것은 번거롭기도 하고 보안 측면에서 좋지 않기 때문에 이후에 SSH Key를 생성해서 접속하는 방식으로 바꾸는 것이 좋습니다.\n\n  \n  \n    \n  \n\n\n관리자 비밀번호 확인 메뉴를 클릭하면 인증키를 확인하는 화면이 나옵니다.\n인증키는 서버 생성시에 설정하고 PC에 다운로드 해 둔 확장지 *.pem 파일입니다.\n\n  \n  \n    \n  \n\n\n인증키 파일을 마우스로 끌어오거나 화면을 클릭해서 선택합니다.\n\n  \n  \n    \n  \n\n\n인증키가 일치하면 아래와 같이 root 계정에 해당하는 비밀번호가 나타납니다.\n이 비밀번호를 복사하여 저장해둡니다.\n혹시 복사-저장하는 것을 잊으셨어도 언제든지 관리자 비밀번호 확인 메뉴에 들어가서 인증키를 인증하면 다시 확인할 수 있으니 걱정하지 않으셔도 됩니다.\n\n  \n  \n    \n  \n\n\n터미널 프로그램(Putty) 실행\n\nPutty를 실행해서 포트 포워딩에서 설정한 포트와 서버 접속용 공인IP를 입력합니다.\n\n  \n  \n    \n  \n\n\n접속을 하면 rsa2 key fingerprint 를 Putty 캐시에 저장할 것인지 묻는 화면이 나타납니다. \n보통 예(Y)를 선택하면 됩니다.\n\n  \n  \n    \n  \n\n\nroot 계정과 관리자 비밀번호 입력\n\n계정 root와 관리자 비밀번호 확인에서 저장해 둔 비밀번호를 입력합니다.\n\n  \n  \n    \n  \n\n\n접속이 완료되면 이렇게 화면이 나타납니다.\n\n  \n  \n    \n  \n\n\nSSL VPN으로 접속하기\nSSL VPN은 Ncloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스입니다. \n즉, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법이므로 Classic, VPC 환경 모두 공인 IP가 아닌 사설 IP로 연결하게 됩니다. \n자세한 SSL VPN 생성 방법과 서버 접속 방법은 아래 링크된 문서를 참고 하시기 바랍니다.\n\n1. Classic 환경에서 SSL VPN 설정하고 접속하는 방법\n2. VPC 환경에서 SSL VPN 설정하고 접속하는 방법\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-3-1-v2.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-http-to-https-centos-html": {
						"id": "compute-ncloud-compute-server-http-to-https-centos-html",
						"title": "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/CentOS",
						"categories": "",
						"url": " /compute/ncloud_compute_server_http_to_https_centos.html",
						"content": "개요\n웹사이트 SSL 인증서를 설치하고 https 접속을 유도할 때 http로 접속하면 https로 강제로 리다이렉트 시키는 방법을 사용하는 경우가 많습니다. 웹페이지 소스에서 http 접속 여부를 판단해서 redirect 시키는 방법 등 여러가지 있을 수 있는데 여기서는 Apache 설정으로 쉽게 할 수 있는 방법을 소개합니다.\n\nSSL 인증서가 설치되어 있다는 가정하에 우선 Linux CentOS에서 설정하는 방법을 확인해보겠습니다.\n\n테스트 환경\n테스트에 사용한 서버 환경은 다음과 같습니다.\n\n\n⁃ OS: CentOS 7.8 \n⁃ 웹서버: Apache 2.4 \n\n\nApache conf 파일 수정\n/etc/httpd/conf/httpd.conf 또는 별도로 설정한 /etc/httpd/conf.d/사이트도메인.conf 등의 Vritual host에 다음 코드를 추가하고 Apache를 재시작하면 됩니다.\n\n방법1 : Redirect 옵션\n첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\nHTTP 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\n\n&lt;VirtualHost *:80&gt;\n    ServerName 사이트_도메인\n\n    Redirect permanent / https://사이트_도메인/    \n&lt;/VirtualHost&gt; \n\n\n\n  301 리다이렉트: Redirect permanent / https://사이트_도메인/\n  302 리다이렉트: Redirect / https://사이트_도메인/\n  301 리다이렉트: Redirect 301 / https://사이트_도메인/\n  302 리다이렉트: Redirect 302 / https://사이트_도메인/\n  307 리다이렉트: Redirect 307 / https://사이트_도메인/\n  308 리다이렉트: Redirect 308 / https://사이트_도메인/\n\n\n방법2 : RewirteRule 옵션\n두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\n\n&lt;VirtualHost *:80&gt;\n    ServerName 사이트_도메인\n\n    RewriteEngine On\n    RewriteCond %{HTTPS} !on\n    RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n&lt;/VirtualHost&gt; \n\n\n위 설정 중에서 [R=301,L] 이 부분에 원하는 상태코드를 입력하면 됩니다.\n\n  301 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n  302 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=302,L]\n  307 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=307,L]\n  308 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=308,L]\n\n\nApache 재시작\n~# systemctl restart httpd\n\n이렇게 재시작하고 http로 접속을 해보면 https로 전환되는 것을 확인할 수 있습니다.\n\nSSL 모듈 설치\n혹시 Apache에 mod_ssl 가 설치되어 있지 않다면 설치하셔야 합니다.\n\n~# yum -y install mod_ssl\n\n\n========================================================================\n Package   Arch       Version                 Repository   Size\n========================================================================\nInstalling:\n mod_ssl    x86_64   1:2.4.6-97.el7.centos   updates    114 k\n\nTransaction Summary\n========================================================================\nInstall  1 Package\n\nTotal download size: 114 k\nInstalled size: 224 k\n\nDownloading packages:\nmod_ssl-2.4.6-97.el7.centos.x86_64.rpm                    | 114 kB  00:00:00\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : 1:mod_ssl-2.4.6-97.el7.centos.x86_64        1/1\n  Verifying  : 1:mod_ssl-2.4.6-97.el7.centos.x86_64        1/1\n\nInstalled:\n  mod_ssl.x86_64 1:2.4.6-97.el7.centos\n\nComplete!\n\n\n참고 URL\n\n  http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Rocky Linux\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-http-to-https-rocky-linux.html\n    \n  \n  http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Ubuntu\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_server_http_to_https_ubuntu.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-http-to-https-ubuntu-html": {
						"id": "compute-ncloud-compute-server-http-to-https-ubuntu-html",
						"title": "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Ubuntu",
						"categories": "",
						"url": " /compute/ncloud_compute_server_http_to_https_ubuntu.html",
						"content": "개요\n웹사이트 SSL 인증서를 설치하고 https 접속을 유도할 때 http로 접속하면 https로 강제로 리다이렉트 시키는 방법을 사용하는 경우가 많습니다.\n웹페이지 소스에서 http 접속 여부를 판단해서 redirect 시키는 방법 등 여러가지 있을 수 있는데 여기서는 Apache 설정으로 쉽게 할 수 있는 방법을 소개합니다.\n\nSSL 인증서가 설치되어 있다는 가정하에 우선 Linux Ubuntu에서 설정하는 방법을 확인해보겠습니다.\n\n테스트 환경\n테스트에 사용한 서버 환경은 다음과 같습니다.\n\n\n⁃ OS: Ubuntu 20.04 \n⁃ 웹서버: Apache 2.4 \n\n\nSSL 엔진 모듈 활성화\n먼저, SSL 엔진 모듈을 활성화 해야 HTTPS 접속을 할 수 있습니다.\n\n~# a2enmod ssl\n~# systemctl restart apache2\n\n\nApache conf 파일 수정\n/etc/apache2/sites-enabled/000-default.conf 파일의 Vritual host에 다음 코드를 추가하고 Apache를 재시작하면 됩니다.\n\n방법1 : Redirect 옵션\n첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\nHTTP 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\n\n&lt;VirtualHost *:80&gt;\n    ServerName 사이트_도메인\n\n    Redirect permanent / https://사이트_도메인/    \n&lt;/VirtualHost&gt; \n\n\n\n  301 리다이렉트: Redirect permanent / https://사이트_도메인/\n  302 리다이렉트: Redirect / https://사이트_도메인/\n  301 리다이렉트: Redirect 301 / https://사이트_도메인/\n  302 리다이렉트: Redirect 302 / https://사이트_도메인/\n  307 리다이렉트: Redirect 307 / https://사이트_도메인/\n  308 리다이렉트: Redirect 308 / https://사이트_도메인/\n\n\n방법2 : RewirteRule 옵션\n두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\n\nRewrite 모듈 설치\n우선, RewirteRule 옵션을 사용하려면 Rewrite 모듈을 활성화 해야합니다.\n\n~# a2enmod rewrite\n~# systemctl restart apache2\n\n\n&lt;VirtualHost *:80&gt;\n\tServerName 사이트_도메인\n\n\tRewriteEngine On\n\tRewriteCond %{HTTPS} !on\n\tRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n&lt;/VirtualHost&gt;\n\n\n위 설정 중에서 [R=301,L] 이 부분에 원하는 상태코드를 입력하면 됩니다.\n\n  301 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n  302 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=302,L]\n  307 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=307,L]\n  308 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=308,L]\n\n\nApache 재시작\n~# systemctl restart apache2\n\n이렇게 재시작하고 http로 접속을 해보면 https로 전환되는 것을 확인할 수 있습니다.\n\n참고 URL\n\n  http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Rocky Linux\n    \n      https://docs.3rdeyesys.com/compute/ncloud-compute-server-http-to-https-rocky-linux.html\n    \n  \n  http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/CentOS\n    \n      https://docs.3rdeyesys.com/compute/ncloud_compute_server_http_to_https_centos.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-image-share-classic-html": {
						"id": "compute-ncloud-compute-server-image-share-classic-html",
						"title": "Classic 환경에서 서버 이미지를 다른 계정에 공유하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_server_image_share_classic.html",
						"content": "개요\n네이버 클라우드 Classic 환경에서 내 서버 이미지를 다른 계정에 공유하는 방법입니다.\nLinux와 Windows OS별 차이는 없으며, 일단은 서버 이미지가 생성되어 있는 것을 가정해서 내용을 정리해보겠습니다.\n\n공유 권한 설정\n네이버 클라우드 콘솔 [Server] - [Server Image]에서 공유할 서버 이미지를 선택하고 상단 메뉴에 있는 [공유 권한 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 서버 이미지를 공유할 계정 즉, 로그인 ID를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n로그인 ID 입력 후 [권한 추가] 버튼을 클릭하고, [적용] 버튼을 클릭해 설정을 적용합니다.\n\n\n  \n  \n    \n  \n\n\n공유 권한 설정을 적용하면 서버 이미지 정보에 [공유 중]이라고 표시되고, [공유 받은 계정] 정보도 확인할 수 있습니다.\n\nLinux (CentOS, Ubuntu)\n\n  \n  \n    \n  \n\n\nWindows\n\n  \n  \n    \n  \n\n\n공유 상태 확인\n\n이제 공유 받은 계정으로 접속해보면 [Server Image]에 추가된 서버 이미지가 보이고, [공유 받음] 표시를 확인할 수 있습니다.\n\nLinux (CentOS, Ubuntu)\n\n  \n  \n    \n  \n\n\nWindows\n\n  \n  \n    \n  \n\n\n다음으로 공유 받은 서버 이미지를 선택하고, [서버 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서버 생성 정보 입력 화면이 나타나면서 문제 없이 서버를 생성할 수 있다는 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n공유 권한 삭제\n\n이제 공유된 권한을 삭제해보겠습니다.\n처음 서버 이미지를 공유할 때 처럼 서버 이미지를 선택하고, [공유 권한 설정]을 클릭하고, [공유 받은 계정]을 삭제합니다.\n\n\n  \n  \n    \n  \n\n\n공유된 계정을 삭제하고, [적용] 버튼을 클릭해 변경될 설정을 적용합니다.\n\n\n  \n  \n    \n  \n\n\n아까 공유 받았던 계정으로 접속해 [Server Image]에 들어가보면 공유되었던 서버 이미지가 삭제된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-5-1-v2"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-micro-type-limit-html": {
						"id": "compute-ncloud-compute-server-micro-type-limit-html",
						"title": "Classic 환경 Micro 타입 서버에서 사용할 수 없는 서비스",
						"categories": "",
						"url": " /compute/ncloud_compute_server_micro_type_limit.html",
						"content": "개요\nNcloud (네이버 클라우드) Classic 환경에서 제공하는 서버 타입 중에서 Micro 타입의 서버는 신규 가입 후 최초 결제수단 등록월부터 1년간 무료로 제공되는 체험용 서버입니다.\n계정당 1대만 이용 가능하며 1년이 지나면 유료로 전환됩니다.\n\n제한되는 서비스\nClassic 환경 Micro 타입의 서버에서 사용할 수 없는 서비스는 다음과 같습니다.\n\n\n  mssql\n  LAMP, WordPress, LEMP 등\n  Network Interface\n  Private Subnet\n\n\nMSSQL\nmssql 중에서 mssql 2017 Express은 무료로 제공되는 서비스이지만, mssql이 1년 무료제공 서버인 Micro서버에서는 설치가 되지 않기 때문에, compact 이상의 유료 서버를 이용해야 합니다.\n즉, mssql 2017 Express는 무료이나 서버와 그에 따른 하드 디스크 비용은 유료입니다.\n\nLAMP\nLAMP (Linux + Apache, Mysql, PHP)의 경우 Micro 타입의 서버에 설치를 할 수 없고, Standard 이상의 서버에서만 설치할 수 있는데, 대신 네이버 클라우드에서는 LAMP 등 많이 사용되는 오픈 소스 소프트웨어가 설치된 서버를 쉽게 이용할 수 있도록 해주는 서비스인 Application Server Launcher를 제공하고 있습니다.\n\nApplication Server Launcher에서는 원하는 소프트웨어의 이미지를 선택하기만 하면 쉽게 Micro 타입의 서버를 세팅하고 이용할 수 있습니다.\n\n다만, Application Server Launcher에서 생성한 서버도 Micro 타입의 서버이기 때문에 계정당 1개만 제공되는 Micro 타입 서버 기준에 따라 Micro 타입의 서버는 더 이상 추가할 수 없습니다.\n\nApplication Server Launcher에서 OS버전(CentOS, Ubuntu)별로 제공되는 애플리케이션은 다음과 같습니다.\n\n\n  Drupal (CMS)\n  Joomla! (CMS)\n  Magento (E-Commerce)\n  Shadowsocks (VPN)\n  LAMP (Web Stack)\n  WordPress (CMS)\n  Jenkins (Dev Tools)\n\n\nPrivate Subnet\nPrivate Subnet을 구성해서 서버환경을 만들려고 해도 Micro 서버 타입은 Network Interface를 추가할 수 없고, 그에 따라 Private Subnet도 적용할 수 없습니다.\n\n참고 URL\n\n  Ncloud 서버 사용 준비 - 제공되는 서버 스펙\n    \n      https://guide.ncloud-docs.com/docs/server-spec"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-pip-python-install-centos6-html": {
						"id": "compute-ncloud-compute-server-pip-python-install-centos6-html",
						"title": "CentOS 6에서 pip - Python 설치하기",
						"categories": "",
						"url": " /compute/ncloud_compute_server_pip_python_install_centos6.html",
						"content": "개요\n2020년 12월 01일부로 CentOS6의 기술지원이 공식 종료되었습니다.\nyum을 이용한 패키지 설치, 업데이트 등을 할 수 없는 상황이기에 pip, Python등의 설치가 원활하지 않습니다.\n그래서 pip설치에 필요한 CentOS6.x의 yum 명령을 수행하려면 \n먼저 아래의 가이드대로 Repository mirror를 변경하는 Script를 다운받아 설치해야 그 다음 단계를 진행할 수 있습니다.\n\n목적\n지원이 종료된 CentOS6에서 굳이 pip를 설치하려고 하는 이유는 DB 백업 파일을 aws cli를 이용해서 Object Storage에 저장하기 위해서 입니다.\n매 일정 시간에 DB나 소스 파일을 백업하고 백업된 파일을 Object Storage에 백업-동기화 하는 작업을 aws cli를 이용해서 처리하게 됩니다.\n\nRepository 변경\n이 Repository 변경 스트립트는 네이버 클라우드에서 공식 제공하는 스크립트입니다.\n~# wget http://repo.ncloud.com/etc/patch/Add-CentOS-Vault-Repo.sh\n~# bash Add-CentOS-Vault-Repo.sh\n~# yum install zsh\n\n\n필요 패키지들 설치\n~# yum -y groupinstall 'Development Tools'\n~# yum -y install openssl-devel* ncurses-devel* zlib*.x86_64\n~# yum update curl nss\n\n\nPython 설치\nCentOS6에는 Python 2.6이 설치되어 있습니다.\n하지만, 위에서 설명한 대로 CentOS 6에 대한 지원이 종료되면서 일반적인 방법으로는 pip를 설치할 수 없습니다.\n몇가지 상황을 테스트 해본 결과 Python 2.7과 Python 3.5에서는 pip를 설치할 수 있는 방법을 찾았고, 그래서 여기서는 Python 3.5.10을 설치하겠습니다.\n\n# Python 3.5 설치 압축파일 다운로드\n~# wget https://www.python.org/ftp/python/3.5.10/Python-3.5.10.tgz\n\n# Python 설치파일 압축해제 후 설치\n~# tar vxzf Python-3.5.10.tgz\n~# cd Python-3.5.10\n~# ./configure\n~# make\n~# make install\n\n# Python 설치 확인\n~# which python3\n\n# Python 버전 확인\n~# python3 -V\n\n\nPIP 설치\npip설치 파일도 위에서 설치한 Python 버전에 맞는 설치파일을 다운받아서 설치해야 문제없이 설치됩니다.\n현재까지 문제 없는 것으로 확인된 버전은 2.7과 3.5 입니다.\n~# curl -O https://bootstrap.pypa.io/3.5/get-pip.py\n~# python3 get-pip.py\n\n\n이후에 aws cli설치나 Object Storage 백업과 관련된 내용은\nCentOS에서 mysql DB를 Object Storage로 자동 백업하기 문서를 참고하시기 바랍니다.\n\n설치 오류 상황과 해결 방법\npip를 설치하는 과정에 발생하는 몇가지 오류 상황과 그에 따른 해결방법을 정리해보겠습니다.\n\n curl: (35) SSL connect error: pip 설치파일을 다운 받기 위해 curl을 실행할 때 발생하는 오류 메시지로 위쪽에서 필요 패키지들 설치할 때 있었던 다음 명령을 실행하면 해결됩니다.\n\n~# yum update curl nss\n\n\n\n\n SyntaxError: invalid syntax: pip를 설치할 때 Python 버전이 일치하지 않는 등의 이유로 발생하는 문제입니다. 위에서 설명했던 대로 Python 버전과 일치하는 pip 설치 파일을 다운 받으면 됩니다.\n\n# 오류가 발생하는 경로\n~# curl -O https://bootstrap.pypa.io/get-pip.py\n\n# 해결방법 : 경로 중간에 Python 버전을 추가\n~# curl -O https://bootstrap.pypa.io/{Python 버전}/get-pip.py\n\n# 오류 없는 버전 예시\n~# curl -O https://bootstrap.pypa.io/2.7/get-pip.py\n~# curl -O https://bootstrap.pypa.io/3.5/get-pip.py"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-repository-change-on-private-network-html": {
						"id": "compute-ncloud-compute-server-repository-change-on-private-network-html",
						"title": "외부 네트워크에 연결할 수 없는 환경에서 Repository를 변경해 리눅스 패키지 설치하기",
						"categories": "",
						"url": " /compute/ncloud_compute_server_repository_change_on_private_network.html",
						"content": "개요\nNcloud(네이버 클라우드) Secure Zone이나 VPC 환경의 Private Network처럼 외부와 통신이 단절된 환경에서 \n리눅스 패키지를 설치해야 할 때 repository 경로를 네이버 클라우드 내부 repository로 바꾸면 문제없이 패키지 설치를 할 수 있습니다. \n여기서는 OS별로, Classic/VPC 환경별로 변경하는 방법을 정리해보겠습니다.\n\nCentOS\n\nCentOS는 /etc/yum.repos.d/CentOS-Base.repo 를 열어보면 아래 repository주소를 확인할 수 있습니다.\n\n~# vi /etc/yum.repos.d/CentOS-Base.repo\n\n\n\nClassic 환경 - CentOS\n네이버 클라우드 Classic 환경 CentOS에서 repository 주소는 미러 사이트가 기본으로 설정 되어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n하지만 현재 서버는 Secure Zone 등 외부와 통신이 되지 않는 상태이므로 이대로는 패키지 설치를 할 수 없습니다.\n이때 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 접속하도록 mirrorlist를 주석처리하고, baseurl을 주석해제하고, 경로를 수정해주면 됩니다.\n\n## 원본\nmirrorlist=http://mirrorlist.centos.org/?release=$releaserver&amp;arch=$basearch....\n#baseurl=http://mirror.centos.org/centos/$releaserver/extras/$basearch/\n\n## 수정\n#mirrorlist=http://mirrorlist.centos.org/?release=$releaserver&amp;arch=$basearch....\nbaseurl=http://mirror.ncloud.com/centos/$releaserver/extras/$basearch/\n\n\n\n  \n  \n    \n  \n\n\n변경 후 패키지 설치 테스트를 해봅니다.\n\n~# yum -y install httpd\n\n\n웹서버 설치가 문제없이 되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nsed 명령어 사용\nsed 명령어를 사용하면 더욱 편하게 변경할 수 있습니다.\n\n## mirrorlist 주석처리\n~# sed -i 's/mirrorlist=/#mirrorlist=/g' /etc/yum.repos.d/CentOS-Base.repo\n\n## baseurl 주석해제, 경로수정\n~# sed -i 's/#baseurl=http:\\/\\/mirror.centos.org\\/centos/baseurl=http:\\/\\/mirror.ncloud.com\\/centos/g' /etc/yum.repos.d/CentOS-Base.repo\n\n\n\nVPC 환경 - CentOS\n네이버 클라우드 VPC 환경은 이미 repository 경로가 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 설정되어 있으므로 별도로 수정할 필요가 없습니다.\n\n\n  \n  \n    \n  \n\n\nUbuntu\n\nUbuntu는 /etc/apt/sources.list 에서 repository list 를  확인할 수 있습니다.\n다만, 기본 미러사이트 주소가 Classic, VPC 두 환경이 다르게 설정되어 있습니다.\n\n  Classic :  kr.archive.ubuntu.com\n  VPC : archive.ubuntu.com\n\n\n~# vi /etc/apt/sources.list\n\n\nClassic 환경 - Ubuntu\n\n  \n  \n    \n  \n\n\nVPC 환경 - Ubuntu\n\n  \n  \n    \n  \n\n\n현재 서버는 Secure Zone 또는 Private Network  등 외부와 통신이 되지 않는 상태이므로 이대로는 패키지 설치를 할 수 없습니다.\n이때 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 접속하도록 경로를 수정해주면 됩니다.\n\n## Classic 환경 - Ubuntu\nkr.archive.ubuntu.com --&gt; mirror.ncloud.com (변경)\nsecurity.ubuntu.com --&gt; mirror.ncloud.com (변경)\n\n## VPC 환경 - Ubuntu\narchive.ubuntu.conm --&gt; mirror.ncloud.com (변경)\n\n\n  \n  \n    \n  \n\n\n/etc/apt/sources.list 에서 위와 같이 변경-저장한 후에 apt update 를 해주면 변경해준 Ncloud 내부 repository에서 패키지 리스트를 가져와 설치를 합니다.\n\n\n  \n  \n    \n  \n\n\n설치 된 repository를 테스트 하기 위해 apt install 을 사용하여 패키지 다운로드를 해보면 Ncloud 내부 repository에서 패키지 설치가 진행되는 것을 확인 할 수 있습니다.\n\n~# apt -y install apache2\n\n\n\n  \n  \n    \n  \n\n\nUbuntu 또한 sed 명령어로 간단하게 변경할 수 있습니다.\n\n## Classic 환경 - Ubuntu\nsed -i 's/kr.archive.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\nsed -i 's/security.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\n\n## VPC 환경 - Ubuntu\nsed -i 's/archive.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\n\n\n참고 URL\n\n  CentOS mirror 사이트 안내\n    \n      https://www.centos.org/download/mirrors/\n    \n  \n  Ubuntu mirror 사이트 안내\n    \n      https://launchpad.net/ubuntu/+archivemirrors"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-spec-change-html": {
						"id": "compute-ncloud-compute-server-spec-change-html",
						"title": "Ncloud 서버 스펙 변경 제한 사항",
						"categories": "",
						"url": " /compute/ncloud_compute_server_spec_change.html",
						"content": "개요\nNcloud (네이버 클라우드)에서는 기본적으로 서버 타입 간의 스펙 변경을 지원하지 않고, 동일한 타입 내에서의 스펙 변경만 지원합니다.\n\n다른 타입의 스펙으로 변경하려면 [내 서버 이미지] 기능을 이용해서 서버 이미지를 생성한 다음, 다른 타입으로 서버를 새로 만들어야 합니다. 이때 IP 주소는 변경됩니다.\n\n\n  \n  \n    \n  \n\n\n타입 간 스펙 변경이 가능한 경우 : 타입간 스펙 변경은 대부분은 불가능하나 Compact 타입과 Standard 타입 간에는 스펙 변경을 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nVPC 환경의 경우 Standard, High Cpu, High Memory 서버들간에 스펙 변경이 되는 경우도 있습니다. 다만, 모든 서버가 스펙 변경이 가능한 것이 아니라 서버가 생성된 인프라에 따라 해당 기능이 지원되지 않을 수도 있습니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-1-1-v2.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-ssh-security-setting-html": {
						"id": "compute-ncloud-compute-server-ssh-security-setting-html",
						"title": "리눅스서버 SSH 접속 보안 설정하기",
						"categories": "",
						"url": " /compute/ncloud_compute_server_ssh_security_setting.html",
						"content": "개요\n리눅스 서버들은 서버에 접속할 때 SSH를 이용하게 되는데, 이때 root 계정에 대한 무작위 패스워드 입력 등의 해킹시도가 있을 수 있습니다.\n여기서는 이러한 해킹시도를 차단하기 위한 보안설정 중에서 root 계정과 관련한 보안설정 2가지를 정리해보겠습니다.\n\n설정 파일 위치\nroot 계정에 대한 보안 설정은 /etc/ssh/sshd_config 파일에 있습니다.\n\n~# vi /etc/ssh/sshd_config\n\n\nCentOS\n\n  \n  \n    \n  \n\n\nUbuntu\n\n  \n  \n    \n  \n\n\nroot 로그인 차단\n로그인 차단은 위 설정에서 PermitRootLogin 항목을 바꾸시면 됩니다.\nCentOS는 주석처리 되어 있으므로 주석을 해제하고 설정을 변경하시면 되고, Ubuntu는 주석이 해제된 상태이므로 설정값만 변경하시면 됩니다.\n\n Warning: root 로그인을 차단하기 전에 다른 관리자 계정을 생성한 후에 차단 설정을 적용해야 합니다.\n\n# 기존 - CentOS\n#PermitRootLogin yes\n\n# 기존 - Ubuntu\nPermitRootLogin yes\n\n# 변경\nPermitRootLogin no\n\n\n  \n  \n    \n  \n\n\n기타 옵션\n# 패스워드 로그인은 차단하고 Key 파일을 이용한 로그인만 허용\nPermitRootLogin prohibit-password\n\n\n\n로그인 시도 횟수 제한\n이 옵션을 지정하게 되면 지정한 횟수 이상으로 로그인을 실패했을 때 접속이 강제 종료되는데, 기본값은 6회이니 적절하게 수정하시면 됩니다.\n\n# 기존\n#MaxAuthTries 6\n\n# 변경\nMaxAuthTries 3\n\n\n데몬 재시작\n설정을 수정하고 파일을 저장한 후에 sshd 데몬을 재시작합니다.\n\n~# systemctl restart sshd\n\n\n데몬 재시작 후 로그인을 시도해보면 로그인이 실패하는 것을 확인하실 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nSSH 접속 로그 확인\nSSH로 접속을 하면 성공, 실패에 대한 로그가 모두 남게 되는데, 이 로그를 주기적으로 확인하는 것이 좋습니다.\n\n접속 실패 로그\n~# last -f /var/log/btmp\n\n# 또는\n~# lastb\n\n\n  \n  \n    \n  \n\n\n접속 성공 로그\n~# last -f /var/log/wtmp\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  네이버 클라우드 리눅스서버 접속 가이드\n    \n      https://guide.ncloud-docs.com/docs/compute-compute-3-1-v2.html\n    \n  \n  네이버 클라우드 플랫폼을 활용한 보안 강화\n    \n      https://m.blog.naver.com/n_cloudplatform/221117956958"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-stop-price-html": {
						"id": "compute-ncloud-compute-server-stop-price-html",
						"title": "서버 정지 시 요금할인",
						"categories": "",
						"url": " /compute/ncloud_compute_server_stop_price.html",
						"content": "개요\n네이버 클라우드에서는 서버를 정지할 경우 일부 타입을 제외한 대부분의 서버에 대해 운영체제 설치를 위해 제공된 기본 디스크 요금만 청구가 되어 요금 할인이 됩니다.\n\n추가 요금이 청구되는 서비스\n공인 IP, 로드밸런서, 추가 디스크, Security Monitoring, 추가 Network Interface 등 서버에 연결된 다른 유료 서비스의 경우 서버가 정지되어도 정상 청구됩니다.\n\n요금 할인 횟수와 서버 정지 기한\n\n  요금이 할인되는 서버의 경우 1회 최대 90일, 12개월 누적 최대 180일까지만 서버를 정지할 수 있습니다.\n  서버 정기 가능 기한을 넘긴 서버는 고객에게 통보 후 서버를 반납하게 됩니다.\n  서버를 반납하게 될 때 서버에 저장된 데이터는 네이버 클라우드에서 30일간 직접 백업하여 보관 후 삭제하게 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n요금 할인이 적용되지 않는 서버 타입\n일부 서버들은 서버를 정지해도 요금 할인이 되지 않고, 서버가 가동 중일 때와 동일한 요금이 청구됩니다.\n할인이 적용되지 않는 서버 타입은 다음과 같습니다.\n\n\n  Micro 서버\n  High Memory 서버\n  GPU 서버\n  Virtual Dedicated Server\n  Baremetal 서버\n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-1-1-v2.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-storage-add-detail-process-html": {
						"id": "compute-ncloud-compute-server-storage-add-detail-process-html",
						"title": "Linux 스토리지(디스크) 추가 상세 가이드",
						"categories": "",
						"url": " /compute/ncloud_compute_server_storage_add_detail_process.html",
						"content": "개요\nNcloud(네이버 클라우드)에서 리눅스 서버에 디스크를 추가하는 것은 스토리지 즉, Block Storage를 생성해서 서버에 연결하는 작업이 필요합니다.\n\n전체 과정 요약\n스토리지(디스크)를 추가하는 전체 과정은 아래와 같이 하이퍼바이저별로 정리할 수 있으며, 각 단계별 상세 설명은 XEN 하이퍼바이저 기반 서버를 이용해서 진행하겠습니다.\n\n\n  \n      \n          XEN 하이퍼바이저 \n      \n  \n      \n          KVM 하이퍼바이저 \n      \n  \n\n\n  \n      \n~# fdisk -l\n\n~# fdisk /dev/xvdb\n\n~# mkfs.xfs /dev/xvdb1\n\n  - CentOS 5.x: mkfs.ext3 /dev/xvdb1\n  - CentOS 6.x: mkfs.ext4 /dev/xvdb1\n  - CentOS 7.x: mkfs.xfs /dev/xvdb1\n  - Rocky Linux: mkfs.xfs /dev/xvdb1\n  - Ubuntu : mkfs.ext4 /dev/xvdb1\n\n~# mkdir /mnt/data\n\n~# mount /dev/xvdb1 /mnt/data\n\n~# df -hT\n\n~# vim /etc/fstab\n### =============================\nUUID=1fd5s61f5d-*** 중략 ***-f84ew13 /mnt/data xfs defaults 1 2\n\n# 또는\n/dev/xvdb1 /mnt/data ext4 defaults 1 2\n### =============================\n\n\n\n  \n      \n~# fdisk -l\n\n~# fdisk /dev/vdb\n\n~# mkfs.xfs /dev/vdb1\n\n  - CentOS 5.x: mkfs.ext3 /dev/vdb1\n  - CentOS 6.x: mkfs.ext4 /dev/vdb1\n  - CentOS 7.x: mkfs.xfs /dev/vdb1\n  - Rocky Linux: mkfs.xfs /dev/vdb1\n  - Ubuntu : mkfs.ext4 /dev/vdb1\n\n~# mkdir /mnt/data\n\n~# mount /dev/vdb1 /mnt/data\n\n~# df -hT\n\n~# vim /etc/fstab\n### =============================\nUUID=1fd5s61f5d-*** 중략 ***-f84ew13 /mnt/data xfs defaults 1 2\n\n# 또는\n/dev/xvdb1 /mnt/data ext4 defaults 1 2\n### =============================\n\n\n\n  \n\n\n스토리지 생성, 할당\n우선은 네이버 클라우드 콘솔 [Server] - [Server]에서 해당 서버를 선택하고 \n[서버 관리 및 설정 변경] - [스토리지 생성]을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 [스토리지 생성] 화면에서 스토리지 종류, 이름, 적용서버, 크기 (최소 10GB, 최대 2000GB) 등을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n앞에서 설정한 스토리지 정보를 다시 살펴보고 이상이 없으면 [확인] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n추가된 스토리지는 [Server] - [Server] 리스트에서 해당 서버를 클릭해 상세정보에서 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n스토리지 할당 확인\n네이버 클라우드 콘솔에서 할당한 스토리지를 확인하기 위해 putty를 실행해 서버에 접속합니다.\n이후 과정은 모두 서버에 접속한 상태에서 진행하게 됩니다.\n\nfdisk -l 명령어를 실행해보면 아래 화면처럼 /dev/xvdb 디스크가 할당된 것을 확인할 수 있습니다.\n\n~# fdisk -l\n\n\n\n  \n  \n    \n  \n\n\n디스크 파티션\n다음 명령어를 입력해 할당된 디스크에 파티션을 생성합니다.\n파티션 설정에는 기본인 MBR 방식과 2TB 이상의 디스크를 인식하기 위해 사용하는 GPT 방식이 있는데, 네이버 클라우드는 최대 2,000GB까지만 지원하므로 여기서는 기본방식인 MBR을 사용하겠습니다.\n~# fdisk /dev/xvdb\n\n\n파티션 생성\n파티션을 생성할 때는 여러 단계의 옵션이 있습니다. 일반적으로는 아래와 같은 단계로 진행하면 됩니다.\n\n\n  파티션을 새로 생성하기 위해 ‘n’을 입력\n\n\n\n  \n  \n    \n  \n\n\n\n  생성할 파티션 타입에 따라 primary type이면 ‘p’, extended type이면 ‘e’를 입력.\n(primary type으로 생성하는 것이 일반적이며, primary 영역의 파티션이 부족할 경우 추가로 extended type으로 생성)\n\n\n\n  \n  \n    \n  \n\n\n\n  생성할 파티션 번호와 cylinder 영역을 입력 (일반적으로 추가할 disk 전체를 mount하게 되고, 이 경우 default값을 그대로 사용하므로 Enter 입력)\n\n\n\n  \n  \n    \n  \n\n\n\n  ‘w’를 입력해 해당 구성을 적용. 파티션 생성 완료.\n\n\n\n  \n  \n    \n  \n\n\n마지막으로 fdisk -l 명령어로 생성된 파티션을 다시 확인합니다.\n디스크가 /dev/xvdb1 장치로 인식된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n디스크 포맷\n다음으로 파티션이 생성된 디스크를 포맷하면 되는데, OS별로 명령어가 다르므로 확인 후에 실행해야 합니다.\n여기서는 CentOS 7.x 기준으로 mkfs.xfs 명령어를 사용했습니다.\n~# mkfs.xfs /dev/xvdb1\n\n- CentOS 5.x: mkfs.ext3 /dev/xvdb1\n- CentOS 6.x: mkfs.ext4 /dev/xvdb1\n- CentOS 7.x: mkfs.xfs /dev/xvdb1\n- Rocky Linux: mkfs.xfs /dev/xvdb1\n- Ubuntu : mkfs.ext4 /dev/xvdb1\n\n\n\n  \n  \n    \n  \n\n\n디스크 마운트\n다음으로 디스크를 마운트할 포인트 즉, 디렉토리를 원하는 이름으로 생성하고 마운트를 합니다.\n아래에 있는 마운트 경로 (/mnt/data)는 예시입니다. 원하는 경로를 직접 설정하시면 됩니다.\n~# mkdir /mnt/data\n~# mount /dev/xvdb1 /mnt/data\n\n\n  \n  \n    \n  \n\n\n\n  마운트된 내역을 확인합니다.\n\n\n~# df -hT\n\n\n  \n  \n    \n  \n\n\n마운트 정보 등록\n마운트 정보는 설정에 저장하지 않으면 서버가 리부팅될 때 사라지기 때문에 fstab에 저장합니다.\n마운트 정보를 등록할 때 장치명을 사용하는 방법과 장치의 UUID를 사용하는 방법이 있는데, 경우에 따라서는 장치명이 변경될 수도 있어, 이를 대비해 가능하면 UUID로 등록합니다.\n\nUUID 확인\nUUID를 확인하려면 blkid 명령어를 사용합니다.\n여기서 확인한 UUID를 별도로 복사해두었다가 fstab에 입력하게 됩니다.\n~# blkid /dev/xvdb1\n\n\n  \n  \n    \n  \n\n\nvi로 /etc/fstab 파일을 열면 다음과 같습니다.\n서버 생성과 함께 장착된 기본 디스크도 UUID로 입력된 것을 확인할 수 있습니다.\n~# vi /etc/fstab\n\n\n  \n  \n    \n  \n\n\n앞에서 확인하고 복사해둔 추가 디스크의 UUID와 기타 정보를 입력합니다.\n입력을 완료한 후 fstab 파일을 저장하고 빠져 나옵니다.\n(fstab에 입력할때 사용하는 디스크 정보 옵션에 대한 정리는 아래에서 다시 확인할 수 있습니다.)\n\n### /etc/fstab\n\nUUID=29f58417-*** 중략 ***38d0f /mnt/data xfs defaults 1 2\n\n# 또는\n/dev/xvdb1 /mnt/data ext4 defaults 1 2\n\n\n\n  \n  \n    \n  \n\n\nfstab 설정 상세정보\n\n/etc/fstab은 부팅 단계에서 마운트되어야 할 볼륨 정보들이 저장되는 곳입니다.\n(OS 이미지에 따라 파일 시스템이 다르기 때문에 주의해야 합니다.)\n\n파일의 각 항목이 의미하는 바는 아래와 같으며 각 항목은 Tab 또는 Space Bar로 구분합니다.\n\n(장치명) (마운트 포인트) (파일시스템 종류) (옵션) (dump 설정) (fsck 설정)\n\n\n  \n    장치명: 장치명은 장치의 UUID를 사용하거나 /dev/xvdb1와 같은 장치이름을 사용합니다.\n  \n  \n    마운트 포인트: 볼륨을 마운트하고자 하는 위치입니다. 예시에서는 /mnt/data 디렉토리에 마운트했습니다.\n  \n  \n    파일시스템 종류: OS별로 기본 파일시스템이 다르므로 알맞게 입력합니다.\n\n    \n      CentOS 5.x : ext3\n      CentOS 6.x : ext4\n      CentOS 7.x : xfs\n      Rocky Linux : xfs\n      Ubuntu Server / Desktop : ext4\n    \n  \n  \n    옵션: 예시에서는 default 옵션을 사용하였으며, 해당 옵션에는 rw, nouser, auto, exec, suid 속성이 포함됩니다.\n각 속성의 내용은 다음과 같습니다. (필요한 옵션만 사용할 시, 각 옵션을 쉼표(,)로 구분하여 작성해주시면 됩니다.)\n\n    \n      auto : 부팅 시 자동 마운트\n      rw : 읽기, 쓰기 모두 가능하도록 마운트\n      nouser : root 계정만 마운트 가능\n      exec : 파일 실행을 허용\n      suid : SetUID와 SetGID를 허용\n    \n  \n  \n    dump 설정: dump 명령으로 백업을 할 것인지에 대한 설정\n\n    \n      0: dump되지 않는 파일 시스템\n      1: dump 가능한 파일 시스템\n    \n  \n  \n    fsck 설정: 부팅시에 fsck 명령으로 파일시스템에 대한 무결성 검사를 할 것인지에 대한 설정\n\n    \n      0 : 부팅 시 fsck 실행하지 않음\n      1 : 부팅 시 root 파일 시스템을 우선 체크\n      2 : 부팅 시 root 이외의 파일 시스템을 우선 체크\n    \n  \n\n\n참고 URL\n\n  Ncloud Block Storage 생성, 추가 가이드\n    \n      https://guide.ncloud-docs.com/docs/blockstorage-create-vpc\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-06-04\n          문서 최초 생성\n        \n      \n        \n          2023-11-23\n          스크린샷 업데이트, Rocky Linux 추가\n        \n      \n        \n          2023-12-07\n          KVM 하이퍼바이저 서버 관련 내용 추가"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-storage-add-guide-html": {
						"id": "compute-ncloud-compute-server-storage-add-guide-html",
						"title": "Linux 스토리지 추가 생성 기본 가이드",
						"categories": "",
						"url": " /compute/ncloud_compute_server_storage_add_guide.html",
						"content": "개요\n네이버 클라우드에서 서버 생성 후에 스토리지를 추가 생성하는 경우가 있는데 이때 사용되는 스토리지는 Block Storage라고 해서 AWS의 EBS(Elastic Block Store)와 유사합니다.\n\n스토리지 추가 제약 사항\n\n  XEN 하이퍼바이저 기반 서버의 경우 Bare Metal 서버와 의 Micro 타입 서버에는 스토리지를 추가할 수 없습니다.\n\n\n추가 가능한 최대 사이즈와 개수\n\n\n\n  \n    \n      하이퍼바이저      \n      스토리지 타입\n      미디어 타입\n      최소 크기\n      최대 크기\n      추가 가능 개수\n    \n  \n      \n    \n      XEN\n      HDD\n      HDD\n      10GB\n      2TB\n      15개\n      \n         \n      SSD\n      SSD\n      10GB\n      2TB\n      15개\n     \n    \n      KVM\n      FB1\n      HDD\n      100GB\n      16TB\n      20개\n      \n         \n      CB1\n      SSD\n      10GB\n      16TB\n      20개\n            \n  \n  \n\n\n리눅스 OS 서버 이미지별 포맷 명령어\n리눅스는 OS 즉, 네이버 클라우드에서 제공하는 서버 이미지별로 추가된 스토리지를 포맷하는 명령어가 다릅니다.\n\n\n⁃ CentOS 5.x: mkfs.ext3 /dev/xvdb1 \n⁃ CentOS 6.x: mkfs.ext4 /dev/xvdb1 \n⁃ CentOS 7.x: mkfs.xfs /dev/xvdb1 \n⁃ Rocky Linux: mkfs.xfs /dev/xvdb1 \n⁃ Ubuntu Server / Desktop: mkfs.ext4 /dev/xvdb1 \n\n\next4 vs XFS 명령어 비교\n\n\n\n  \n    \n      항목\n      ext4\n      XFS\n    \n  \n      \n    포맷mkfs.ext4mkfs.xfs\n    마운트mountmount\n    리사이즈resize2fsxfs_growfs\n    복구e2fsckxfs_repair\n    라벨 변경e2labelxfs_admin -L\n    디버깅debugfsxfs_db\n    할당량 설정quotaquota\n  \n  \n\n\n Tip: xfs_growfs 명령어는 파일 시스템의 크기를 줄일 수는 없고 늘릴 수만 있습니다.\n\n참고 URL\n\n  Ncloud 블록 스토리지 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/server-storage-vpc\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-12-07\n          KVM 하이퍼바이저 서버 관련 내용 추가"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-storage-lvm-create-html": {
						"id": "compute-ncloud-compute-server-storage-lvm-create-html",
						"title": "리눅스서버 스토리지(디스크) LVM 구성하기",
						"categories": "",
						"url": " /compute/ncloud_compute_server_storage_lvm_create.html",
						"content": "개요\n네이버 클라우드 서버는 하나의 서버당 로컬 디스크 즉, 블록 스토리지(Block Storage)를 OS가 설치되는 기본 스토리지 1개 이외에 15개를 추가할 수 있으며, 각 스토리지 용량은 10GB ~2,000GB 까지 가능합니다.\n그리고, 2,000GB 이상을 사용해야 할 경우는 NAS 장비를 사용하거나 Object Storage를 활용하는 경우가 많지만, 상황에 따라서는 2,000GB를 초과하는 용량의 블록 스토리지를 사용해야 하는 경우도 있습니다.\n\n이럴때 사용하는 방법이 LVM (Logical Volume Manager)를 사용하여 여러 개의 스토리지를 합쳐서 대용량으로 사용하거나 합쳐진 대용량을 다시 필요한 용량으로 나누어서 사용하는 방법입니다.\n\n그래서 이번에는 리눅스 환경에서 LVM으로 대용량 스토리지를 생성하는 방법을 정리해보겠습니다.\n\n스토리지 생성\n2,000GB 이상의 용량을 필요로 할 때에 대한 내용이지만, 테스트를 위해 10GB 스토리지 2개를 생성하겠습니다.\n\n\n  \n  \n    \n  \n\n\nlvm-test-1, lvm-test-2 이름으로 생성된 스토리지 2개를 Ubuntu OS가 설치된 lvm-test-svr 서버에 연결했습니다.\n\n\n  \n  \n    \n  \n\n\n파티션 설정\n생성된 스토리지 2개에 각각 파티션을 설정합니다.\n파티션 설정에는 parted 명령어를 사용합니다.\n\n~# parted /dev/xvdb\n\n# (parted)\nmklabel gpt\nmkpart primary 0 100%\ni\nset 1 lvm on   # 1번 파티션에 lvm 사용 가능하게 설정\np\nquit\n\n\n\n  \n  \n    \n  \n\n\n~# parted /dev/xvdc\n\n# (parted)\nmklabel gpt\nmkpart primary 0 100%\ni\nset 1 lvm on   # 1번 파티션에 lvm 사용 가능하게 설정\np\nquit\n\n\n\n  \n  \n    \n  \n\n\n설정된 파티션들을 확인합니다.\n~# fdisk -l\n\n\n\n  \n  \n    \n  \n\n\nPhysical Volume 생성\n각 스토리지 장치에 Physical Volume을 생성합니다.\n\n~# pvcreate /dev/xvdb1\n\n~# pvcreate /dev/xvdc1\n\n\n\n  \n  \n    \n  \n\n\nPhysical Volume이 제대로 생성되었는지 확인합니다.\n~# pvdisplay\n\n\n\n  \n  \n    \n  \n\n\nVolume Group 생성\n준비된 두개의 Volume으로 하나의 Volume Group을 생성합니다.\n\n~# vgcreate VG01 /dev/xvdb1 /dev/xvdc1\n\n\n\n  \n  \n    \n  \n\n\n생성된 Volume Group을 확인합니다.\n~# vgdisplay\n\n\n\n  \n  \n    \n  \n\n\nLogical Volume 생성\n생성된 Volume Group 전체 크기를 사용하는 Logical Volume을 생성합니다.\n~# lvcreate --extents 100%FREE -n LV01 VG01\n\n\n\n  \n  \n    \n  \n\n\n생성된 Logical Volume을 확인합니다.\n~# lvdisplay\n\n\n\n  \n  \n    \n  \n\n\n포맷\n다음으로 포맷을 해야하는데, OS별로 명령어가 다르므로 확인 후에 실행해야 합니다.\n여기서는 Ubuntu 기준으로 mkfs.ext4 명령어를 사용했습니다.\n\n~# mkfs.ext4 /dev/VG01/LV01\n\n- CentOS 5.x: mkfs.ext3 /dev/VG01/LV01\n- CentOS 6.x: mkfs.ext4 /dev/VG01/LV01\n- CentOS 7.x: mkfs.xfs /dev/VG01/LV01\n- Ubuntu : mkfs.ext4 /dev/VG01/LV01\n\n\n\n  \n  \n    \n  \n\n\n마운트\n마운트를 하기 위해 우선 생성된 디스크 장치명을 확인합니다.\n~# fdisk -l\n\n\n\n  \n  \n    \n  \n\n\n다음으로 디스크를 마운트할 포인트 즉, 디렉토리를 원하는 이름으로 생성하고 마운트를 합니다.\n아래에 있는 마운트 경로 (/mnt/data)는 예시입니다. 원하는 경로를 직접 설정하시면 됩니다.\n\n~# mkdir /mnt/data\n~# mount /dev/mapper/VG01-LV01 /mnt/data\n\n\n\n  \n  \n    \n  \n\n\nfstab 설정\n새로 생성된 디스크를 부팅 후에도 인식할 수 있게 blkid 명령으로 UUID를 확인하고 fstab에 등록합니다.\n\n~# blkid |grep /dev/mapper/VG01-LV01\n\n\n  \n  \n    \n  \n\n\n~# vi /etc/fstab\n\n\n  \n  \n    \n  \n\n\nfstab 설정 상세정보\n\n/etc/fstab은 부팅 단계에서 마운트되어야 할 볼륨 정보들이 저장되는 곳입니다.\n(OS 이미지에 따라 파일 시스템이 다르기 때문에 주의해야 합니다.)\n\n파일의 각 항목이 의미하는 바는 아래와 같으며 각 항목은 Tab 또는 Space Bar로 구분합니다.\n\n(장치명) (마운트 포인트) (파일시스템 종류) (옵션) (dump 설정) (fsck 설정)\n\n\n  \n    장치명: 장치명은 장치의 UUID를 사용하거나 /dev/xvdb1와 같은 장치이름을 사용합니다.\n  \n  \n    마운트 포인트: 볼륨을 마운트하고자 하는 위치입니다. 예시에서는 /mnt/data 디렉토리에 마운트했습니다.\n  \n  \n    파일시스템 종류: OS별로 기본 파일시스템이 다르므로 알맞게 입력합니다.\n\n    \n      CentOS 5.x : ext3\n      CentOS 6.x : ext4\n      CentOS 7.x : xfs\n      Ubuntu Server / Desktop : ext4\n    \n  \n  \n    옵션: 예시에서는 default 옵션을 사용하였으며, 해당 옵션에는 rw, nouser, auto, exec, suid 속성이 포함됩니다.\n각 속성의 내용은 다음과 같습니다. (필요한 옵션만 사용할 시, 각 옵션을 쉼표(,)로 구분하여 작성해주시면 됩니다.)\n\n    \n      auto : 부팅 시 자동 마운트\n      rw : 읽기, 쓰기 모두 가능하도록 마운트\n      nouser : root 계정만 마운트 가능\n      exec : 파일 실행을 허용\n      suid : SetUID와 SetGID를 허용\n    \n  \n  \n    dump 설정: dump 명령으로 백업을 할 것인지에 대한 설정\n\n    \n      0: dump되지 않는 파일 시스템\n      1: dump 가능한 파일 시스템\n    \n  \n  \n    fsck 설정: 부팅시에 fsck 명령으로 파일시스템에 대한 무결성 검사를 할 것인지에 대한 설정\n\n    \n      0 : 부팅 시 fsck 실행하지 않음\n      1 : 부팅 시 root 파일 시스템을 우선 체크\n      2 : 부팅 시 root 이외의 파일 시스템을 우선 체크\n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-4-1-v2.html"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-vpc-create-html": {
						"id": "compute-ncloud-compute-server-vpc-create-html",
						"title": "Ncloud VPC 환경에서 서버 생성하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_server_vpc_create.html",
						"content": "개요\nNcloud (네이버 클라우드) VPC환경에서 서버를 생성하는 순서를 정리해보겠습니다.\n얼마전 업데이트에서 서버 생성 콘솔 화면에 큰 변화가 생겼기에 그 내용까지 함께 포함했습니다.\n\n서버 생성 순서\nVPC 환경에서 서버를 생성하려면 Subnet 설정 등 사전에 미리 설정해야 하는 것과 서버 생성 후에 설정해야 하는 것들이 있는데, 순서대로 정리하고 아래쪽에서 차례대로 살펴보겠습니다.\n\n\n  VPC 설정\n  Subnet 설정\n  서버 생성\n  3-1. 서버 인증키 설정\n  ACG (방화벽) 설정\n\n\nVPC 설정\nVPC (Virtual Private Cloud) 즉, 클라우드 상에서 논리적으로 격리된 고객 전용 네트워크 공간을 먼저 생성하고 해당 공간에 서버를 생성하게 됩니다.\nVPC는 고객의 계정마다 최대 3개를 생성할 수 있으며, 각 VPC는 최대 넷마스크 0.0.255.255/16 (IP 65,536개) 크기의 네트워크 주소 공간을 제공합니다.\n\nVPC 서비스 위치\n[VPC] 서비스는 [Console] - [Services] - [Networking]에 위치해 있습니다.\n\n그리고, 아래 스샷에서 확인할 수 있듯이 [VPC]에는 [VPC Management], [Subnet Management], [Network ACL], [NAT Gateway], [Route Table], [VPC Peering], [Virtual Private Gateway] 등의 하부 서비스 메뉴가 있습니다.\n\n\n  \n  \n    \n  \n\n\nVPC 생성\n[VPC] - [VPC Management] [VPC 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  VPC 생성 화면에서 [VPC 이름]과 [IP 주소 범위]를 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n\nVPC의 IP 주소 범위는, private 대역(10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n- 예시: 10.0.0.0/16, 172.16.0.0/16, 192.168.0.0/16\n\n\nSubnet 생성\n[VPC] - [Subnet Management]에서 [Subnet 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [Subnet 이름]을 적절하게 입력하고, 위에서 생성했던 [VPC]를 선택하고, Subnet에서 사용할 [IP 주소 범위]를 입력합니다.\n  [Internet Gateway 전용여부]는 외부와 인터넷 연결이 필요할 경우에는 [Public], 내부 서버끼리만 통신할 경우에는 [Private]을 선택합니다.\n  [용도]는 일반 서버일 경우에는 [일반]을 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\nSubnet의 IP 주소 범위는, private 대역(10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n- 예시: 10.0.1.0/24, 172.16.10.0/24, 192.168.101.0/24\n\n\n서버 생성\n[VPC]와 [Subnet] 설정을 마쳤으니 이제 서버(Server)를 설정해보겠습니다.\n\nServer 서비스 위치\n[Server] 서비스는 [Console] - [Services] - [Compute]에 위치해 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  [Server] - [Server]에서 [서버 생성] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n서버 생성 콘솔 선택\nNcloud 서버 생성 콘솔화면은 신규 기능이 업데이트 되면서 2가지를 선택할 수 있습니다. 여기서는 [신규 콘솔 화면]으로 진행하겠습니다.\n\n\n  기존 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)를 생성할 수 있습니다.\n  신규 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)뿐만 아니라 KVM 기반 및 다양한 성능을 제공하는 기본 스토리지로 서버(g3)를 생성할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n서버 이미지 선택\n[서버 이미지 선택] 단계에서는 Ncloud에서 제공하는 다양한 서버 이미지를 선택할 수 있고, [최신 서버 이미지]와 [내 서버 이미지]를 따로 볼 수 있는 기능도 제공하고 있습니다. 여기서는 [최신 서버 이미지]에서 제공하는 서버 이미지로 서버를 생성해보겠습니다.\n또한 하이퍼바이저 기준으로 [XEN]과 [KVM] 2가지 타입이 제공되는데 여기서는 [XEN] 타입의 서버로 테스트 해보겠습니다. [XEN]과 [KVM]에 대한 설명은 아래쪽에서 별도로 살펴보겠습니다. (XEN 과 KVM 비교)\n\n\n  \n      \n          최신 서버 이미지 \n      \n  \n      \n          NCP 서버 이미지 \n      \n  \n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n      \n\n  \n  \n    \n  \n\n\n\n  \n\n\n서버 설정 (전체 화면)\n서버 설정 단계에서는 위에서 생성한 [VPC]와 [Subnet]을 선택하고  [서버 스펙]과 [요금제], [Network Interface], [공인 IP 할당 여부] 등을 선택하게 됩니다. 각 항목별 상세한 설명은 아래쪽에서 다시 정리해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n서버 설정 (상세 설명)\n그러면 이제부터 서버 설정 항목별로 상세하게 살펴보겠습니다.\n\n\n  [VPC], [Subnet] 선택\n위에서 생성했던 [VPC]와 [Subnet] 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [서버 스펙]\n[서버 스펙]은 [High-CPU], [CPU-Intensive], [Standard], [High-Memory] 등의 타입 중에서 원하는 타입을 선택하고, 각 타입별로 서비스에 적절한 vCPU와 Memory를 선택하시면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [요금제 선택], [서버 개수], [서버 이름]\n요금제는 [월요금제]와 [시간 요금제] 중에서 선택하시고, 한번에 생성할 서버 개수와 서버 이름을 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [Network Interface] 사설 IP 할당\n사설 IP 할당은 자동 할당과 수동 할당 방법 중에서 선택하시면 됩니다.\n\n\n\n  \n      \n          사설 IP 자동 할당 \n      \n  \n      \n          사설 IP 수동 할당 \n      \n  \n\n\n  \n      \n\n[Network Interface]에 할당되는 사설 IP는 아래와 같이 IP 입력 칸에 아무것도 입력하지 않으면 자동할당 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n      \n\nIP 입력 칸에 선택된 [Subnet] 범위 내의 원하는 IP를 입력해서 수동으로 할당할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n\n\n\n  [공인 IP 할당]\nPublic Subnet을 선택했고 서버에 공인 IP가 필요할 경우에는 [새로운 공인 IP 할당]을 선택하시면 됩니다.\n\n\n\n⁃ 공인 IP는 요금이 과금되므로, 사용하지 않을 때는 반납하기를 권장합니다. (월 이용료: 4,032원 ) \n⁃ 서버 생성시 공인 IP를 함께 생성하려면 Subnet 타입은 Public Subnet, 서버 개수는 1개여야 합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [물리 배치 그룹] 설정\n물리 배치 그룹 설정은 서버들을 하나의 그룹으로 묶어서 해당 그룹에 속한 서버들을 클러스터에 배치할 때 어떻게 할 것인지 결정할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [물리 배치 그룹]을 사용하게 되면 배치 그룹명과 배치 종류를 선택할 수 있습니다.\n\n\n[Anti-Affinity (분산 배치)]의 경우 같은 배치 그룹에 소속된 서버들은 가급적 서로 다른 클러스터에 배치됩니다. 다만 그 결과가 엄격히 보장되지 않는 Best effort 방식입니다.\n\n\n  \n  \n    \n  \n\n\n\n  [반납 보호]\n반납 보호를 설정하면 실수로 서버를 반납하여, 서버가 삭제되는 사고를 방지할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  [Script 선택]\n서버가 켜질 때 자동으로 실행되어야 하는 스크립트가 있다면 [Server] - [Init Script] 메뉴에서 미리 Script를 등록한 후에 적용할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n스토리지 설정\n하이퍼바이저 [XEN] 타입의 서버는 서버 생성이 완료된 이후에 추가 스토리지를 설정할 수 있으므로 이번 단계는 그냥 넘어가겠습니다.\n\n\n  \n  \n    \n  \n\n\n인증키 설정\n인증키 이름을 입력하고, [인증키 생성 및 저장] 버튼을 클릭해서 인증키를 로컬 PC에 다운로드 받아서 안전한 곳에 보관해야 합니다. 기존에 사용하고 있던 인증키가 있을 경우에는 [보유하고 있는 인증키 이용]을 선택하면 됩니다.\n\n 인증키: 인증키는 해당 서버의 관리자 비밀번호를 확인하는데 사용되므로 안전한 곳에 잘 보관해야 합니다.\n\n\n  \n  \n    \n  \n\n\n\n  아래와 같이 로컬 PC에 인증키 (PEM) 파일을 저장합니다.\n\n\n\n  \n  \n    \n  \n\n\n네트워크 접근 설정\n네트워크 접근은 [ACG]로 설정하게 되는데, ACG(Access Control Group)는 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스로, 서버에 별도의 복잡한 방화벽 구축없이 간단하게 서버에 대한 네트워크 접근 제어를 할 수 있습니다.\n[VPC]를 생성하면 자동으로 생성되는 기본 ACG를 선택하거나 별도로 생성한 ACG가 있을 경우 해당 ACG를 선택하면 됩니다. 적용할 ACG는 최대 3개까지 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 생성 완료\n모든 단계를 마치고 나면 아래와 같이 서버가 생성된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 접속\n이제 생성된 서버에 관리자(root) 계정으로 접속해보겠습니다.\n\n방화벽 (ACG) 설정\n우선 서버 접속을 위한 방화벽 (ACG)을 설정하겠습니다.\n\n\n  테스트로 생성했던 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다.\n\n\n  \n  \n    \n  \n\n\n\n  ACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  [Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  ACG 규칙 설정 화면 [Inbound] 탭에서 [myIp] 버튼을 클릭해서 현재 접속한 PC나 회사 IP를 입력하고, 허용 포트에는 SSH 접속을 위한 22포트를 추가합니다.\n\n\n  \n  \n    \n  \n\n\n관리자 비밀번호 확인\n다음으로, 서버 접속에 필요한 관리자 비밀번호를 확인하려면, 서버를 선택하고 [서버 관리 및 설정 변경] 메뉴에서 [관리자 비밀번호 확인] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  메뉴를 선택하면 다음과 같은 [관리자 비밀번호 확인] 팝업이 나타납니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  팝업에서 [마우스로 파일을 끌고 오거나 여기를 클릭하세요] 부분을 클릭하면 파일 선택 창이 나타나는데, 위에서 저장했던 pem 인증키 파일을 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  인증키 파일이 선택된 상태에서 아래쪽에 있는 [비밀번호 확인] 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  그러면 아래와 같이 관리자 계정(root)에 대한 비밀번호를 확인할 수 있습니다. 아래쪽에서 서버에 접속할때 사용하기 위해 비밀번호를 복사합니다.\n\n\n\n  \n  \n    \n  \n\n\n서버 IP 주소 확인\n다음으로 서버 정보 화면에서 서버의 [공인 IP 주소]를 확인하고, 복사합니다. (SSL VPN 등을 사용하는 경우에는 사설 IP 주소를 사용하면 됩니다.)\n\n\n  \n  \n    \n  \n\n\n서버 접속\n대표적인 서버 접속 클라이언트인 Putty를 실행하고, 서버의 IP주소를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n\n  처음 연결하는 서버의 경우 아래와 같이 SSH 프로토콜에서 필요한 FingerPrint를 저장할 것인지 묻는데, [Accept] (또는 예)를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  마지막으로 관리자 계정인 [root]와 위에서 확인했던 [관리자 비밀번호]를 입력하면 서버에 접속됩니다.\n\n\n  \n  \n    \n  \n\n\nXEN vs KVM\nNcloud (네이버 클라우드)에서 제공하는 하이퍼바이저의 종류는 XEN, KVM이 있으며, 각각의 특징은 다음과 같습니다.\n\n\n\n  \n    \n      하이퍼바이저\n      서버 세대\n      서버 타입\n      서버 이미지\n      스토리지 타입\n    \n  \n      \n    \n      XEN\n      g1, g2\n      Micro, Standard, CPU-Intensive, High-CPU, High-Memory\n      \n      HDD, SDD\n     \n    \n      KVM\n      g3\n      Micro, Standard, High-CPU, High-Memory\n      \n      KVM 기반 서버 이미지\n      FB1, CB1\n        \n  \n  \n\n\n스토리지 특징\n\n\n\n  \n    \n      하이퍼바이저      \n      스토리지 타입\n      미디어 타입\n      최소 크기\n      최대 크기\n      추가 가능 개수\n    \n  \n      \n    \n      XEN\n      HDD\n      HDD\n      10GB\n      2TB\n      15개\n      \n         \n      SSD\n      SSD\n      10GB\n      2TB\n      15개\n     \n    \n      KVM\n      FB1\n      HDD\n      100GB\n      16TB\n      20개\n      \n         \n      CB1\n      SSD\n      10GB\n      16TB\n      20개\n            \n  \n  \n\n\n참고 URL\n\n  Ncloud VPC 서버 생성 가이드\n    \n      https://guide.ncloud-docs.com/docs/server-create-new-vpc\n    \n  \n  Ncloud 하이퍼바이저 개요\n    \n      https://guide.ncloud-docs.com/docs/hypervisor-info\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-07-28\n          관리자 비밀번호 확인 후 서버 접속 방법 추가\n        \n      \n        \n          2023-12-04\n          KVM 서버 정식 업데이트 반영, 스크린샷 업데이트"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-windows-server-image-copy-classic-to-vpc-html": {
						"id": "compute-ncloud-compute-server-windows-server-image-copy-classic-to-vpc-html",
						"title": "Classic 환경 Windows 서버 이미지를 VPC 환경으로 복제하는 방법",
						"categories": "",
						"url": " /compute/ncloud_compute_server_windows_server_image_copy_classic_to_vpc.html",
						"content": "개요\n네이버 클라우드 Classic 환경의 Windows 서버 이미지를 VPC 환경으로 복제하려면 몇가지 사전 작업과 조건이 있습니다.  이 사전 작업과 조건을 차례대로 정리해보겠습니다.\n\nOS 조건 확인\nClassic 환경의 서버 이미지를 VPC 환경으로 복제하는 것이므로 VPC에서 지원하는 OS만 복제 가능합니다.\n즉, 현재 네이버 클라우드 VPC 환경에서 지원하는 Windows OS 버전은\nWindows Server 2016 (64-bit) English Edition 하나이기 때문에 2016 R2 등의 OS를 사용 중이라면 \nVPC에서 지원하지 않아 복제가 불가능하니 VPC에서 지원할 때까지 작업을 보류하셔야 합니다.\n\n\n  \n  \n    (2021년 6월 1일 현재 VPC 환경에서 지원하는 Windows OS 버전)\n  \n\n\n사전 작업 확인\n우선 사전 작업이 어떤 것이 있는지 확인해 보기 위해 Windows 서버 이미지를 하나 만들어서 상단에 있는 [VPC로 복제] 버튼을 클릭해 봅니다.\n\n안내 팝업에는 다음과 같은 작업이 필요하다고 적혀 있습니다.\n\n\n  백신 솔루션 확인 및 필요시 백신 삭제\n  백신 상태 확인 스크립트 실행\n  내 서버 이미지 다시 생성 후 VPC 복제 기능 사용\n\n\n\n  \n  \n    \n  \n\n\n백신 삭제\nWindows 서버에 설치된 백신 솔루션을 확인해서, ApexOne 또는 OfficeScan이라면 백신 삭제가 필요하며, 그 외 솔루션은 삭제하지 않아도 됩니다.\n\nApexOne 삭제방법\n\n  제어판 -&gt; 프로그램 추가제거로 이동 후 ‘Trend Micro Apex One Security Agent’를 선택하고, 삭제합니다.\n  C:\\Program Files (x86) 경로의 Trend Micro\\Security Agent 폴더를 삭제합니다.\n(삭제되지 않는 파일은 그대로 두셔도 됩니다)\n\n\nOfficeScan 삭제방법\n\n  제어판 -&gt; 프로그램 추가제거로 이동 후 ‘Trend Micro officescan Security Agent’를 선택하고, 삭제합니다.\n  C:\\Program Files (x86) 경로의 Trend Micro\\Security Agent 폴더를 삭제합니다.\n\n\n그 외 솔루션\n\n  백신 삭제 불필요\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n백신상태 확인\n백신이 모두 정상적으로 제거되었는지 확인하는 툴을 실행합니다.\n\n백신상태 확인 Tool 다운로드\nWindows PowerShell을 열고, 다음의 명령어를 실행하면 바탕화면에 Tool이 다운로드 됩니다.\n\ncd c:\\users\\Administrator\\Desktop \nInvoke-WebRequest http://init.ncloud.com/vpcporting/real/ncp_vac_chk.exe -outfile ncp_vac_chk.exe\n\n\n  \n  \n    \n  \n\n\n백신상태 확인 Tool 실행\n바탕화면에 다운로드 된 ncp_vac_chk.exe 파일을 관리자 권한으로 실행합니다.\n\n\n  \n  \n    \n  \n\n\n백신상태 확인 체크 결과 확인\n백신상태 확인이 정상적으로 수행되면 바탕화면에 notifyFreeAntiVirusRemoved, result 파일 2개가 생성되며, 백신상태 확인이 비정상으로 수행되면 result 파일 1개만 생성이 됩니다.\n\nnotifyFreeAntiVirusRemoved 파일이 생성되지 않거나 해당 파일의 내용이 OK가 아닌 경우 백신상태 확인이 정상적으로 완료되지 못한 경우이므로 백신솔루션에 따라 필요시 백신이 잘 제거되었는지 다시 한번 더 체크 후 해당 Tool을 실행해야 합니다.\n\n백신상태 확인이 정상적으로 완료되지 않고 문제가 지속되면 result 파일을 첨부하여 네이버 클라우드 고객센터에 문의하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\n서버 이미지 복제\n\n서버 이미지 재 생성\n위에서 백신상태 확인 체크가 정상적으로 완료되었다면, 서버 이미지를 다시 생성합니다.\n\n서버 이미지 VPC로 복제\n[콘솔] - [Classic] - [Server] - [Server Image]에서 새로 생성한 이미지를 선택하고 상단의 [VPC 로 복제] 버튼을 클릭합니다.\n위에서도 설명했듯이 현재는 Windows Server 2016 (64-bit) English Edition 버전만 지원합니다.\n\n\n  \n  \n    \n  \n\n\n복제되는 신규 서버 이미지 이름을 입력하고 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n실제 VPC 환경에 복제 진행 중인 이미지가 표시되기까지는 다소 시간이 걸릴 수 있으니 잠시 기다리시면 확인하실 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n복제된 서버 이미지 확인\n복제가 완료된 서버 이미지의 상세 정보를 살펴보면 Classic 복제 여부 항목이 Y로 표시되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 생성\nClassic 환경에서 VPC 환경으로 복제된 서버 이미지로 새로운 서버가 생성되는지 확인해보겠습니다.\n이미지를 선택하고 [서버 생성] 버튼을 클릭해서 서버 생성화면에서 정보를 입력하고 서버를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n정상적으로 생성된 서버를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-5-1-v2"
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-windows-storage-add-detail-process-html": {
						"id": "compute-ncloud-compute-server-windows-storage-add-detail-process-html",
						"title": "Windows 서버 스토리지(디스크) 추가 상세 가이드",
						"categories": "",
						"url": " /compute/ncloud_compute_server_windows_storage_add_detail_process.html",
						"content": "개요\nNcloud (네이버 클라우드)는 스토리지 당 최대 2TB까지 확장할 수 있으며, 최대 16개의 스토리지를 이용할 수 있습니다.\n이번에는 Windows 서버에 스토리지 즉, 디스크를 추가하는 방법에 대해 정리해보겠습니다.\n\n테스트 환경\nWindows Server 2016 (64-bit) English Edition 으로 진행 되었습니다. 추가 스토리지는 총 10G disk 총 4개 입니다.\n\n스토리지 생성\n\n\n  서버 &gt; 서버 관리 및 설정 변경 &gt; 스토리지생성\n\n\n\n  \n  \n    \n  \n\n\n\n  스토리지 생성에 필요한 내용을 입력합니다.\n  크기는 스토리지 하나 당 10GB~2000GB까지 사용할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  사용 될 추가디스크를 생성합니다.\n\n\n\n  \n  \n    \n  \n\n\n윈도우 서버 디스크 관리\n\n\n  디스크관리(윈도우키+r) : diskmgmt.msc\n\n\n\n  \n  \n    \n  \n\n\n디스크 초기화\n\n  initializeDisk를 선택하여 디스크를 초기화 합니다.\n\n\n\n  \n  \n    \n  \n\n\n초기화 방식 선택\n\n  두 가지 방식 중 하나를 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\nMBR과  GPT 차이\n\n\n  \n    \n      MBR\n      GTP\n    \n  \n  \n    \n      주파티션을 4개까지 생성 가능\n      주 파티션을 128개까지 생성 가능\n    \n    \n      디스크 용량 최대 2TB까지 인식\n      디스크 용량 최대 9.4ZB까지 인식\n    \n    \n      BIOS가 설치된 PC에서 사용\n      UEFI 또는 EFI가 설치된 PC에서 사용 가능\n    \n    \n      Windows 32비트와 64비트 사용 가능\n      Windows 32비트 사용 불가\n    \n  \n\n\n볼륨 생성\n\n  새 단순 볼륨 생성하기\n\n\n\n  \n  \n    \n  \n\n\n\n  추가한 총 4개의 디스크 단순 볼륨 생성을 하였습니다.\n\n\n\n  \n  \n    \n  \n\n\n디스크 추가 확인\n\n  아래와 같이 추가 생성한 디스크 추가가 완료되었습니다."
					}
					
				
			
		
			
				
					,
					
					"compute-ncloud-compute-server-x-forwarded-for-client-ip-logging-guide-html": {
						"id": "compute-ncloud-compute-server-x-forwarded-for-client-ip-logging-guide-html",
						"title": "X-Forwarded-For를 이용해 Proxy, Load Balancer 환경에서 Client IP 기록하기",
						"categories": "",
						"url": " /compute/ncloud_compute_server_x_forwarded_for_client_ip_logging_guide.html",
						"content": "개요\nX-Forwarded-For (XFF) 는 HTTP Header 중 하나로 Load Balancer(로드밸런서)나 Proxy Server를 통해 웹서버에 접속하는 Client의 IP 주소를 식별하는 표준 헤더입니다.\n웹서버나 WAS 앞쪽에 Load Balancer 혹은 Proxy Server 등이 위치하게 된다면 서버 접근 로그에는 Client IP가 아닌 Load Balancer 혹은 Proxy Server의 IP 주소가 기록됩니다. \n이때 웹 어플리케이션에서 X-Forwarded-For 헤더를 이용하면 Client IP를 서버 접근 로그에 남길 수 있습니다.\n\n여기서는 Load Balancer와 연동된 CentOS와 Ubuntu, 그리고 Rocky Linux의 Apache 웹서버 환경에서 X-Forwarded-For 를 이용하여 Apache access_log에 Clinet의 IP를 저장하는 과정을 살펴보겠습니다.\n\n테스트 환경\n테스트는 CentOS, Ubuntu,  Rocky Linux OS가 각각 설치된 서버를 Load Balancer와 연동한 후 Cloud Log Analytics에서 Apache access_log를  수집해 IP 주소를 확인하는 방식으로 진행하겠습니다.\n\nNetwork 환경\n\n  VPC 대역 : 10.0.0.0/16\n  Subnet 대역 (Server) : 10.0.0.0/24\n  Subnet 대역 (Load Balancer) : 10.0.4.0/24\n\n\nServer 환경\n\n  xff-test-centos : CentOS 7.8\n  xff-test-ubuntu : Ubuntu 20.04\n  xff-test-rocky : Rocky Linux 8.6\n\n\n테스트 서버\n위 서버 환경에서 정리한 대로 CentOS, Ubuntu, Rocky Linux 이렇게 3대의 서버를 준비했습니다. VPC 환경에서 서버 생성하는 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 서버 생성하는 방법\n\n\n\n  \n  \n    \n  \n\n\n로드밸런서도 마찬가지로 준비하고, 서버와 연동까지 완료했습니다. VPC 환경에서 로드밸런서를 생성하는 방법은 아래 문서를 참고하시면 됩니다.\n\n\n⁃ VPC 환경에서 Application Load Balancer 생성하는 방법\n\n\n\n  로드밸런서 상세 정보에서 [10.0.4.0/24]로 표시되는 서브넷 정보를 기억했다가 아래쪽에서 테스트할 때 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n설정 전 테스트\n우선, X-Forwarded-For (XFF) 설정을 하기 전에 어떻게 기록이 남는지 확인해보겠습니다.\n아래와 같이 Load Balancer 주소로 접속해서 3대의 서버에 각각 접근하도록 합니다.\n위에서 소개한 Application Load Balancer 생성하는 방법을 그대로 따라하면 아래와 같은 메시지를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nApache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하지만, 저희는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해보겠습니다.\n\n  CentOS : /var/log/httpd/access_log\n  Ubuntu : /var/log/apache2/access.log\n  Rocky Linux : /var/log/httpd/access_log\n\n\n\n⁃ Cloud Log Analytics 설정 가이드\n\n\nCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 Load Balancer의 IP 대역 (10.0.4.xx)이 기록된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  Rocky Linux는 아직 Cloud Log Analytics Agent를 지원하지 않아 서버에서 직접 로그를 확인해보았습니다.\n\n\n  \n  \n    \n  \n\n\nCentOS 설정\n이제 실제 Client IP가 기록 되도록 설정을 변경해보겠습니다.\n우선 CentOS에서는 httpd.conf 파일만 수정하면 됩니다.\n\n~# vim /etc/httpd/conf/httpd.conf\n\n\nhttpd.conf 파일 [log_config_module] 설정에 있는 LogFormat 항목에서 %h 를 %{X-Forwarded-For}i 로 수정합니다.\n\nhttpd.conf 수정 전\nLogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined\n\n\n  \n  \n    \n  \n\n\nhttpd.conf 수정 후\nLogFormat \"%{X-Forwarded-For}i %l %u %t \\\"%r\\\" %&gt;s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined\n\n\n  \n  \n    \n  \n\n\nApache 재시작\nhttpd.conf 파일 수정 후에 Apache를 재시작합니다. 로그 테스트는 Ubuntu까지 설정을 마친 후에 진행하겠습니다.\n\n~# systemctl restart httpd\n\n\nRocky Linux 설정\nRocky Linux는 CentOS와 마찬가지로 /etc/httpd/conf/httpd.conf 파일에 있는 로그 관련 설정을 변경해주면 완료됩니다.\n\n\n  \n  \n    \n  \n\n\nUbuntu 설정\nUbuntu에서는 apache2.conf 파일을 수정하기 전에 remoteip 모듈을 사용하도록 설정해줘야 합니다.\n\nremoteip 설정\n아래 명령어를 실행하면 remoteip 모듈이 활성화 됩니다.\n\n~# a2enmod remoteip\n\n\n  \n  \n    \n  \n\n\nremoteip.load 수정\n다음으로 remoteip.load 파일을 수정해서 아래쪽에 [RemoteIPHeader X-FORWARDED-FOR]을 추가 합니다.\n\n~# vim /etc/apache2/mods-enabled/remoteip.load\n\n\n\n  remoteip.load 수정 전\n\n\nLoadModule remoteip_module /usr/lib/apache2/modules/mod_remoteip.so\n\n\n  remoteip.load 수정 후\n\n\nLoadModule remoteip_module /usr/lib/apache2/modules/mod_remoteip.so\nRemoteIPHeader X-FORWARDED-FOR\n\n\n  \n  \n    \n  \n\n\napache2.conf 수정\n다음으로 apache2.conf 파일을 수정합니다.\n\n~# vim /etc/apache2/apache2.conf\n\n\napache2.conf LogFormat 부분에서 %h 를 %a 로 변경합니다.\n\n\n  apache2.conf 수정 전\n\n\nLogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined  \n\n\n  \n  \n    \n  \n\n\n\n  apache2.conf 수정 후\n\n\nLogFormat \"%a %l %u %t \\\"%r\\\" %&gt;s %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined  \n\n\n  \n  \n    \n  \n\n\nApache 재시작\n~# systemctl restart apache2\n\n\n설정 후 테스트\n위와 같이  CentOS, Ubuntu, Rocky Linux 3대 서버에서 설정을 모두 마친 후에 로드 밸런서 URL로 접속합니다.\n이후에 Cloud Log Analytics에서 로그를 확인해보면 아래와 같이 로드밸런서 IP가 아닌 실제 접속한 Client의 IP가 기록된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  Rocky Linux는 아직 Cloud Log Analytics Agent를 지원하지 않아 서버에서 직접 로그를 확인해보았습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  X-Forwarded-For 안내\n    \n      https://developer.mozilla.org/ko/docs/Web/HTTP/Headers/X-Forwarded-For\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-12-29\n          문서 최초 생성\n        \n      \n        \n          2023-08-21\n          Rocky Linux 추가, 최신 OS 반영, 스크린샷 업데이트"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cdb-mysql-restore-error-1227-troubleshooting-html": {
						"id": "database-ncloud-database-cdb-mysql-restore-error-1227-troubleshooting-html",
						"title": "MySQL 복구 시 ERROR 1227 (42000) 문제 원인과 해결방법",
						"categories": "",
						"url": " /database/ncloud_database_cdb_mysql_restore_error_1227_troubleshooting.html",
						"content": "개요\n네이버 클라우드(Ncloud) Cloud DB for MySQL을 사용하면서 백업 데이터를 복구 하려고 할 때 ERROR 1227 (42000) 오류가 발생하는 경우가 있습니다. \n오류 메시지로만 보면 계정 권한에 문제가 있는 것처럼 보이는데 정확하게 문제 원인이 무엇인지, 그리고 해결방법은 어떤 것이 있는지 정리해보겠습니다.\n\n오류 메시지\n전체 오류 메시지는 아래와 같습니다.\n이 오류 메시지의 원인은 크게 2가지로 구분할 수 있는데, 상황에 따라 각각의 원인 1가지에 해당하는 경우도 있고, 2가지 원인이 모두 해당되는 경우도 있습니다.\n\n ERROR 1227 (42000) at line 77: Access denied; you need (at least one of) the SUPER privilege(s) for this operation\n\n원인 1\n첫번째 원인은 GTID(global transaction identifier)와 관련되어 있습니다.\n네이버 클라우드(Ncloud) Cloud DB for MySQL 상품은 GTID(Global Transaction IDentifier)를 사용하는데, \n보통의 mysql db 복구(Restore)는 GTID를 사용하지 않는 방법이기 때문에 백업(Backup) 단계에서 [–set-gtid-purged=OFF] 옵션을 추가해야 하는데 이 옵션을 사용하지 않았기 때문입니다.\n\nGTID 란?\nGTID는 Global Transaction Identifier의 약자로 MySQL 복제에서 서버의 각 트랜잭션을 구분하는 고유한 식별자입니다. \nGTID는 모든 트랜잭션과 1:1 관계이며, GTID를 활용하면 복제본으로 장애 조치, 계층적 복제, 특정 시점으로 백업 복구하는 등의 작업을 더 쉽게 구현할 수 있으며, 오류 발생 빈도도 줄일 수 있습니다.\n\n오류 상황 재현\n아래와 같이 서버에서 mysqldump 명령으로 Cloud DB for MySQL DB를 백업 받는 상황을 가정해보겠습니다. 여기서는 [–set-gtid-purged=OFF] 옵션을 사용하지 않았습니다.\n[–set-gtid-purged=OFF] 옵션을 사용하지 않고, 백업을 받으면 백업은 정상 진행되지만, 아래와 같이 [–set-gtid-purged=OFF] 해야 한다는 Warning 메시지가 표시됩니다.\n\n~# mysqldump -u user -p -h db-......vpc-cdb.ntruss.com -S /var/lib/mysql/mysql.sock --single-transaction --routines --triggers --events --databases test  &gt; dumpfile1.sql\n\n\n\n  \n  \n    \n  \n\n\n위에서 생성한 [–set-gtid-purged=OFF] 옵션을 사용하지 않은 백업 파일(dumpfile1.sql)을 이용해서 복구(Restore)시에 아래와 같이 ERROR 1227 (42000) 오류가 발생하면서 복구가 되지 않습니다.\n\n~# mysql -h db-......vpc-cdb.ntruss.com -u user -p &lt; ./dumpfile1.sql\n\n\n  \n  \n    \n  \n\n\n해결 방법 1\n이번에는 Warning 메시지에 나온 것처럼 [–set-gtid-purged=OFF] 옵션을 사용해서 백업을 받아 보겠습니다.\n\n~# mysqldump --set-gtid-purged=OFF -u user -p -h db-......vpc-cdb.ntruss.com -S /var/lib/mysql/mysql.sock --single-transaction --routines --triggers --events --databases test  &gt; dumpfile2.sql\n\n\n\n  \n  \n    \n  \n\n\n[–set-gtid-purged=OFF] 옵션을 사용해서 생성한 백업 파일(dumpfile2.sql)을 이용해서 복구를 하면 아래와 같이 문제없이 복구가 잘됩니다.\n그런데 이렇게 옵션을 적용해도 동일한 오류가 발생하는 경우가 있는데 이에 대해서는 아래쪽 원인 2에서 확인해보겠습니다.\n\n~# mysql -h db-......vpc-cdb.ntruss.com -u user -p &lt; ./dumpfile2.sql\n\n\n  \n  \n    \n  \n\n\n해결 방법 2\n그런데 서비스를 하다 보면 DB 사이즈가 너무 커서 다시 백업을 진행하기 어렵다던가 하는 경우가 있습니다. 이럴 때는 백업 파일에 있는 GTID 관련 내용을 삭제하고 복구하시면 문제가 해결됩니다.\n백업 파일 상단과 하단에 각각 아래와 같은 코드가 포함되어 있는데 이 내용을 삭제하거나 주석처리한 후에 복구를 시도하면 문제 없이 복구가 완료됩니다.\n# 백업 파일 상단에 위치\nSET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION.SQL_LOG_BIN;\nSET @@SESSION.SQL_LOG_BIN= 0;\n\n# 백업 파일 하단에 위치\nSET @@GLOBAL.GTID_PURGED='207****-4***-7**-9*****c:1-12,\n2****-4**-9**-b**-d*****:1-19';\n\n\n원인 2\n위에서 설명한 [–set-gtid-purged=OFF]을 적용한 백업 파일을 이용해서 복구를 진행해도 동일한 오류가 발생하는 경우가 있는데 \n원인은 Trigger, Stored Routines (Procedures and Functions), View, Event 생성과 관련된 [DEFINER] 권한 때문입니다.\n DEFINER 권한문제: 즉,  Trigger, Stored Routines (Procedures and Functions), View, Event를 생성한 계정과 DB 복구를 시도하는 계정이 다른 경우에 발생하는 문제입니다. \n\n[원인 1]에서는 복구를 시도할 때 [user] 계정을 사용했었는데 이 [user]계정으로 Trigger, Stored Routines (Procedures and Functions), View, Event 등을 생성한 상황에서 다른 계정 [new_user]를 이용해서 복구를 시도하는 상황을 가정보겠습니다. \n[new_user] 계정으로 복구를 시도하면 [–set-gtid-purged=OFF]을 적용한 백업 파일(dumpfile2.sql)을 이용했음에도 동일한 ERROR 1227 (42000) 오류가 발생하는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n아래와 같이 MySQL은 보안 강화를 위해 Trigger, Stored Routines (Procedures and Functions), View, Event를 처음 생성한 계정을 [DEFINER]로 명시해 둠으로써 다른 계정으로 접근하지 못하도록 하는 것이 기본 설정이 되어 있습니다.\n그러므로 DB 복구를 시도할 때는 [DEFINER] 관련 내용을 삭제하거나 동일한 계정 또는 SUPER privilege를 가진 계정으로 복구해야 합니다.\n\n\n  \n  \n    \n  \n\n\n해결 방법 1\n첫번째 해결 방법은 백업 파일에서 [DEFINER] 관련 내용을 모두 찾아서 삭제하는 방법이 있습니다. \n여기서는 대표적으로 FUNCTION, PROCEDURE, VIEW에 해당하는 예시를 살펴보겠습니다.\n\nFUNCTION\nDB에서 FUNCTION을 사용했다면 아래와 같이 FUNCTION 생성 코드에 [CREATE DEFINER=`user`@`%` FUNCTION]처럼 계정이 표시되는데, 여기서 [DEFINER=`user`@`%`] 이 부분을 삭제하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\nPROCEDURE\nDB에서 PROCEDURE를 사용했다면 아래와 같이 PROCEDURE 생성 코드에 [CREATE DEFINER=`user`@`%` PROCEDURE]처럼 계정이 표시되는데, 여기서 [DEFINER=`user`@`%`] 이 부분을 삭제하시면 됩니다.\n\n  \n  \n    \n  \n\n\nVIEW\nDB에서 VIEW를 사용했다면 아래와 같이 VIEW 생성 코드에 [/*!50013 DEFINER=`user`@`%` SQL SECURITY DEFINER */]처럼 계정이 표시되는데, 여기서는 이 라인을 모두 삭제하시면 됩니다.\n\n  \n  \n    \n  \n\n\n해결 방법 2\n두번째 해결 방법은 백업 파일 [DEFINER=]에 표시되어 있는 계정과 동일한 계정으로 복구를 진행하면 됩니다.\n\n참고 URL\n\n  Cloud DB for MySQL 백업, 복구 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-4\n    \n  \n  GTID를 이용한 Mysql 복제 가이드\n    \n      https://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html\n    \n  \n  GTID를 이용한 MariaDB 복제 가이드\n    \n      http://mariadb.com/kb/en/gtid/\n    \n  \n  MySQL Stored Object Access Control : DEFINER 안내\n    \n      https://dev.mysql.com/doc/refman/5.7/en/stored-objects-security.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mysql-guide-html": {
						"id": "database-ncloud-database-cloud-db-for-mysql-guide-html",
						"title": "VPC환경에서 Cloud DB for MySQL 생성하기",
						"categories": "",
						"url": " /database/ncloud_database_cloud_db_for_mysql_guide.html",
						"content": "개요\nNcloud(네이버 클라우드)의 Cloud DB for MySQL 서비스는 MySQL 데이터베이스를 쉽고 간편하게 구축하고 관리할 수 있고 자동 Fail-Over, 자동백업, 네이버 서비스에서 검증된 최적화된 설정 등을 제공해주는 완전 관리형 클라우드 데이터베이스 서비스입니다.\n\n여기서는 VPC환경에서 Cloud DB for MySQL 서비스를 생성하는 과정을 정리해보겠습니다.\n\n특징\n\n  기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6,000GB까지 자동으로 용량이 증가합니다.\n  하나의 마스터 DB마다 최대 10대의 슬레이브 DB를 생성할 수 있습니다.\n  Load Balancer 상품을 통해 슬레이브 DB 서버들을 읽기 전용 복제본으로 사용함으로써 데이터베이스의 읽기 부하를 분산 시킬 수 있습니다.\n  매일 1회 고객이 원하는 시간에 DB를 자동으로 백업하며, 백업한 데이터를 최대 30일까지 보관할 수 있습니다.\n  VPC 환경에서는 멀티 존으로 구성해 높은 안정성을 보장받을 수 있습니다.\n  Cloud DB for MySQL 서비스는 완전 관리형 상품으로 사용자는 DB서버의 운영체제에 접근할 수 없습니다.\n\n\nDB 접속 방법 3가지\n\n  Private 도메인을 이용해 접속하는 방법\n  SSL VPN을 이용해 접속하는 방법\n  Public 도메인을 이용해 접속하는 방법\n\n\n아래에서는 VPC환경에서 Private 도메인을 이용해 접속하는 방법을 설명하도록 하겠습니다.\n만약 네이버 클라우드 외부 환경에서  Cloud DB for MySQL로 접속하려면 Public 도메인을 사용해야 합니다. 하지만, DB 보안을 위해 특수한 상황인 아닌한 Private 도메인에서 생성하는 것을 권장합니다.\n\nVPC-Subnet 생성\n이미 생성된 VPC와 Subnet이 있다면 이 단계는 건너띄고 다음 단계로 이동하시면 됩니다.\n\nVPC 생성\nVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nSubnet 생성\nSubnet은 Cloud DB for MySQL을 위한 Private Subnet과 DB 접속 테스트 Server용 Public Subnet을 각각 생성합니다.\n\n\n  \n  \n    \n  \n\n\nCloud DB for MySQL을 위한 Private Subnet\n\n\n  \n  \n    \n  \n\n\n테스트용 Server를 위한 Public Subnet\n\n  \n  \n    \n  \n\n\n테스트 Server 생성\nDB 서버 접속을 테스트 하기 위한 Server를 생성합니다. 여기서는 Rocky Linux 8.8 서버를 생성했습니다.\n\n\n  \n  \n    \n  \n\n\nDB 서버 생성\n[Database] - [Cloud DB for MySQL]에서 [DB Server 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nDB 서버 엔진 버전\nDB 엔진 버전은 MySQL 최신 버전 중 네이버에서 안정성이 검증된 버전인 8.0.x 버전과 5.7.x 버전을 제공합니다. (기본값 8.0.32)\n\n\n  \n  \n    \n  \n\n\nDB 서버 이름과 DB 서비스 이름\n\n  DB Server 이름은 고객이 DB 서버를 구분하기 위한 명칭으로, 사용자가 입력한 이름 뒤에 001, 002와 같이 숫자를 붙여 서버를 구분하게 됩니다.\n  예를 들어 DB 서버 이름을 mydb라고 입력하면 생성되는 DB 서버 이름은 mydb-001, mydb-002와 같습니다.\n  DB 서비스 이름은 역할별 DB 서버를 구분하기 위한 이름입니다.\n  일반적으로 하나의 액티브 마스터 DB, 스탠바이 마스터 DB, 다수의 슬레이브 DB로 구성되는 DB 서버군을 말하며, 동일한 데이터를 갖고 있는 DB 서버들을 하나의 DB 서비스라 말합니다.\n  예를 들어 “쇼핑 메인 DB”, “게임 유저 DB”와 같은 식으로 DB 서비스의 역할을 구분하기 위해 사용합니다.\n\n\n\n  \n  \n    \n  \n\n\nCloud DB를 위한 ACG는 자동 생성됩니다(예: cloud-mysql-*)\n\nDB 서버 설정\nDB 이름과 계정. 비번, 접속 포트 등을 설정합니다.\nHOST(IP) 설정에는 전체 허용을 뜻하는 [%]를 입력하고, 대신에 접근 제한은 방화벽인 ACG에서 설정하겠습니다.\nACG 외에 추가로 접근 제한을 하고 싶은 경우에는 접근을 허용할 IP대역을 입력합니다.\n\n  테스트용 서버의 Subnet 대역을 모두 허용하려면 [10.0.0.%]를 입력\n  만약 특정 서버 1대만 허용하려고 할 경우에는 앞에서 생성한 테스트 서버 IP처럼 [10.0.0.7]을 입력\n\n\n 접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\nCloud DB for MySQL을 생성할 때 자동 생성된 ACG [cloud-mysql-*]을 선택하고 ACG 설정을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nInbound 설정에 테스트용 Server의 Subnet 대역인 [10.0.0.0/24]를 접근소스에 입력합니다.\n또는 특정 서버 1대만 허용하려고 할 경우에는 앞에서 생성한 테스트 서버 IP처럼 [10.0.0.7]을 입력합니다.\n\n\n  \n  \n    \n  \n\n\nMySQL Client 설치\nDB 접속 테스트를 위해 생성한 Rocky Linux 8.8 서버에서 MySQL 8.0 Client를 설치합니다.\n\n# mysql 8.0\n# {version-number} 확인 : https://dev.mysql.com/downloads/repo/yum/\n# dnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-{version-number}.noarch.rpm\n~# dnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-8.noarch.rpm\n~# dnf module reset mysql\n~# dnf module disable mysql\n~# dnf repolist all | grep mysql\n~# dnf -y install mysql-community-server\n~# mysqld --initialize-insecure --user=mysql\n~# systemctl start mysqld\n~# mysql_secure_installation\n\n\n\n  \n  \n    \n  \n\n\nDB 서버 접속\nCloud DB for MySQL에 접속하기 위한 주소인 [Private 도메인]을 확인 합니다.\n\n\n  \n  \n    \n  \n\n\n테스트용 Server에서 Cloud DB for MySQL로 접속하는 방법은 다음과 같습니다.\n\n~# mysql -u [user_id] -p -h [Private 도메인명]\n\n\nDB에 접속해보면 처음 Cloud DB for MySQL 생성할 때 입력한 테이터베이스 [testdb]를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 서버 상세보기\n[DB 관리] - [DB 서버 상세보기] 메뉴에서는 [Process list], [Variables], [Status], [Database 관리], [DB Config 관리], [DB User 관리], [Backup 설정 관리], [DB Server Logs] 등을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDatabase 관리\n[Database 관리] 메뉴에서는 Cloud DB 서버의 Database를 생성하거나 삭제할 수 있습니다. 추가, 삭제 작업은 한번에 10개까지 가능하고, 최대 1,000개까지 생성 및 조회할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  콘솔이 아닌 터미널 환경에서 직접 Database를 생성하려면 다음과 같은 Stored Procedure를 사용해야 합니다.\n\n\nmysql&gt; CALL sys.ncp_create_db('생성할 DB명[필수]','Character Set[선택]','Collation[선택]');\n\n--예제\n--character set, collation 은 mysql 서버 default 설정으로 지정\nmysql&gt; CALL sys.ncp_create_db('testdb','','');\n\n\nDB User 관리\nDB 서버를 이용하다보면 여러 계정이 필요하게 됩니다. 이때 계정을 추가하기 위해 [DB 서버 상세보기] - [DB User 관리] 메뉴를 클릭합니다.\n\nUSER_ID, HOST, DB 권한, 암호를 입력하고 DB User 추가 버튼을 클릭합니다.\n\n  사용자가 변경한 DB 계정은 DB 서비스 전체에 적용됩니다.\n  USER_ID + HOST(IP) 단위로 계정 추가 및 권한 관리를 합니다.\n  DB 권한에서 DDL 권한은 CRUD 권한을 포함합니다.\n  콘솔에서 허용하지 않는 문자로 DB User를 생성한 경우는 콘솔에서 수정, 삭제가 불가능합니다.\n DB 서버에 직접 접속 후 변경해 주세요.\n  최대 1000개까지 계정을 추가 및 조회 할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nDB 계정 가져오기\nDB Server에 생성된 계정 정보 가져오기를 수행하면 DB Server 에서 사용자가 직접 생성한 DB 계정 정보를 Console 에서 확인 및 삭제 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Cloud DB for MySQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-6\n    \n  \n  Cloud DB 서버 외부 접근 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-10\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-08-02\n          문서 최초 생성\n        \n      \n        \n          2023-09-01\n          Database 생성하는 방법 안내 추가, 전체 스크린샷 업데이트"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-cloud-db-for-mysql-public-domain-guide-html": {
						"id": "database-ncloud-database-cloud-db-for-mysql-public-domain-guide-html",
						"title": "Cloud DB for MySQL 생성후 Public 도메인으로 접속하기",
						"categories": "",
						"url": " /database/ncloud_database_cloud_db_for_mysql_public_domain_guide.html",
						"content": "개요\n네이버 클라우드의 Cloud DB for MySQL 서비스는 MySQL 데이터베이스를 쉽고 간편하게 구축하고 관리할 수 있고 자동 Fail-Over, 자동백업, 네이버 서비스에서 검증된 최적화된 설정 등을 제공해주는 \n완전 관리형 클라우드 데이터베이스 서비스입니다.\n여기서는 VPC환경에서 Cloud DB for MySQL 서비스를 생성하고, Public 도메인으로 접속하는 과정을 정리해보겠습니다.\n\n네이버 클라우드는 Classic환경에서는 DB 서버 이미지를 제공하지만, VPC 환경에서는 제공하지 않습니다. \n그러므로 VPC 환경에서 DB서버를 사용하려면 OS에 사용자가 직접 DB를 설치해서 사용하는 방법과 Cloud DB를 사용하는 방법 중에서 선택해야 합니다.\n\n특징\n\n  기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6,000GB까지 자동으로 용량이 증가합니다.\n  하나의 마스터 DB마다 최대 10대의 슬레이브 DB를 생성할 수 있습니다.\n  Load Balancer 상품을 통해 슬레이브 DB 서버들을 읽기 전용 복제본으로 사용함으로써 데이터베이스의 읽기 부하를 분산 시킬 수 있습니다.\n  매일 1회 고객이 원하는 시간에 DB를 자동으로 백업하며, 백업한 데이터를 최대 30일까지 보관할 수 있습니다.\n  VPC 환경에서는 멀티 존으로 구성해 높은 안정성을 보장받을 수 있습니다.\n  Cloud DB for MySQL 서비스는 완전 관리형 상품으로 사용자는 DB서버의 운영체제에 접근할 수 없습니다.\n\n\nDB 접속 방법 3가지\n\n  Private 도메인을 이용해 접속하는 방법\n  SSL VPN을 이용해 접속하는 방법\n  Public 도메인을 이용해 접속하는 방법\n\n\n아래에서는 VPC환경 기준으로 네이버 클라우드 외부 환경에서  Cloud DB for MySQL로 접속할 때 필요한 Public 도메인을 이용해 접속하는 방법을 정리하도록 하겠습니다.\n\nVPC-Subnet  생성\n\nVPC 생성\nVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nSubnet 생성\nSubnet은 Public Subnet을 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nDB 서버 생성\n[Database] - [Cloud DB for MySQL]에서 [DB Server 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nDB 서버 엔진 버전\nDB 엔진 버전은 MySQL 최신 버전 중 네이버에서 안정성이 검증된 버전인 5.7버전과 8.0버전을 제공합니다. (기본값 5.7.32)\n\n\n  \n  \n    \n  \n\n\nDB 서버 이름과 DB 서비스 이름\n\n  DB Server 이름은 고객이 DB 서버를 구분하기 위한 명칭으로, 사용자가 입력한 이름 뒤에 001, 002와 같이 숫자를 붙여 서버를 구분하게 됩니다.\n  예를 들어 DB 서버 이름을 mydb라고 입력하면 생성되는 DB 서버 이름은 mydb-001, mydb-002와 같습니다.\n  DB 서비스 이름은 역할별 DB 서버를 구분하기 위한 이름입니다.\n  일반적으로 하나의 액티브 마스터 DB, 스탠바이 마스터 DB, 다수의 슬레이브 DB로 구성되는 DB 서버군을 말하며, 동일한 데이터를 갖고 있는 DB 서버들을 하나의 DB 서비스라 말합니다.\n  예를 들어 “쇼핑 메인 DB”, “게임 유저 DB”와 같은 식으로 DB 서비스의 역할을 구분하기 위해 사용합니다.\n\n\n\n  \n  \n    \n  \n\n\nCloud DB를 위한 ACG는 자동 생성됩니다(예: cloud-mysql-*)\n\nDB 서버 설정\nDB 이름과 계정. 비번, 접속 포트 등을 설정합니다.\nHOST(IP) 설정에는 DB에 접근을 허용할 IP대역을 입력합니다. 여기서는 Public 도메인을 이용하게 되므로 우선 모든 대역을 허용하기 위해 [%]를 입력합니다. \n대신 접속 IP 제한의 경우 ACG에서 설정하게 됩니다.\n\n 접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\nCloud DB for MySQL을 생성할 때 자동 생성된 ACG [cloud-mysql-*]을 선택하고 ACG 설정을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nInbound 설정에 접속을 허용할 IP를 입력합니다. 여기서는 테스트를 위해 [myIp] 버튼을 클릭해 현재 로컬PC IP를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nPublic 도메인 할당\nDB 서버를 생성한 직후에는 아래 스샷과 같이 Public 도메인이 미할당 상태입니다.\n\n\n  \n  \n    \n  \n\n\n[DB 관리] - [Public 도메인 관리] 메뉴를 클릭해 Public 도메인을 신청합니다.\n\n\n  \n  \n    \n  \n\n\nPublic 도메인을 신청하면 네이버 클라우드 플랫폼 외부에서 DB 서버로 접근할 수 있습니다. \n이때 외부에서 통신하는 데이터는 네트워크 사용량으로 과금이 됩니다.\n\n\n  \n  \n    \n  \n\n\nPublic 도메인 신청을 하고  나면 할당된 Public 도메인을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB User 관리\n네이버 클라우드 외부에서 DB에 접속하려고 할때는 보안을 위해 별도의 계정을 추가해서 사용하는 것을 추천합니다.\n계정을 추가하기 위해 [DB 관리] - [DB User 관리] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nUSER_ID, HOST, DB 권한, 암호를 입력하고 DB User 추가 버튼을 클릭합니다.\n\n  사용자가 변경한 DB 계정은 DB 서비스 전체에 적용됩니다.\n  USER_ID + HOST(IP) 단위로 계정 추가 및 권한 관리를 합니다.\n  DB 권한에서 DDL 권한은 CRUD 권한을 포함합니다.\n  최대 1,000개까지 계정을 추가 및 조회 할 수 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n외부접속 테스트\n네이버 클라우드 외부 접속을 테스트 하기 위해 로컬PC에 MySQL Workbench를 설치해서 접속해보겠습니다. \nMySQL Workbench는 아래 경로에서 다운 받을 수 있습니다.\n\nhttps://www.mysql.com/products/workbench/\n\n앞에서 확인한 Public 도메인을 입력하고 Port와 Username도 함께 입력한 후에 [Test Connection]을 클릭해 문제없이 연결되는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\nDB 서버 접속 후에 Database를 확인해보면 처음 Cloud DB for MySQL을 생성할 때 설정한 test Database가 존재하는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n기타\n\nDB 서버 상세보기\nDB 서버 상세보기 메뉴에서는 [Process list], [Variables], [Status], [Database 관리], [DB Config 관리], [DB User 관리], [Backup 설정 관리], [DB Server Logs] 등을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Cloud DB for MySQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-6\n    \n  \n  Cloud DB 서버 외부 접근 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-5-10"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-compare-html": {
						"id": "database-ncloud-database-compare-html",
						"title": "설치형 DB서버와 관리형 Cloud DB 비교",
						"categories": "",
						"url": " /database/ncloud_database_compare.html",
						"content": "개요\n서버에 DB가 설치된 상태로 제공되는 설치형 DB서버와 Cloud 형태로 제공되는 관리형 DB서버는 어떤 특징과 차이점이 있는지 확인합니다.\n더불어 비용 비교와 함께 각각의 DB서버를 어떤 경우에 사용하면 좋은지 예시를 통해 DB서버 선택에 도움을 드리고자 합니다.\n\n설치형 DB  특징\n\n  저렴한 비용\n  DB관련 아주 세부적인 부분까지 직접 설정 가능\n\n\n관리형 Cloud DB 특징\n\n  빠르고 손쉬운 설치\n  네이버 클라우드에서 검증된 최적화 설정\n  자동으로 증가하는 데이터 스토리지 (MSSQL : 2TB까지, Mysql : 6000GB까지)\n  장애 발생시 자동 Fail-over를 통한 장애 최소화를 할 수 있는 탁월한 가용성 제공\n  읽기 부하 분산을 위한 읽기 전용 Slave 5개까지 지원\n  자동화된 DB 백업, 최대 30일까지 보관\n  성능 모니터링과 알람\n  원하는 시간을 선택하여 DB 자동 복원 (Mysql)\n  1분 단위의 쿼리 레벨 성능 분석을 지원 (MSSQL)\n\n\n비용 전체 비교\n\n  DB 서버 스펙 : Standard(2 vCPU, 4GB 메모리, 100GB 디스크)\n\n\n\n  \n    \n      DB 구분\n      설치형 DB (서버 비용 포함)\n      관리형 Cloud for DB\n    \n  \n  \n    \n      mysql\n      69,000원/월\n      115,200원/월\n    \n    \n      MSSQL\n      379,000원/월\n      614,880원/월\n    \n  \n\n\n비용 비교 상세 (Mysql)\n\n설치형\n\n  69,000원/월 : 서버 비용 + DB 무료\n\n\n관리형 Cloud\n-115,200원/월 : 160원(시간당) * 24시간(1일) * 30일(한달)\n\n비용 비교 상세 (MSSQL)\n\n설치형\n\n  379,000원/월 : 69,000원(서버) + 20,000원(서버 Windows 라이선스) + 290,000원(MSSQL 라이선스)\n\n\n관리형 Cloud\n\n  614,880원/월 : 854원 (시간당) * 24시간(1일) * 30일(한달)\n\n\n HA 구성 시 요금 적용: 관리형 Cloud for MSSQL에서 HA (Principal-Mirror 구성) 구성을 할 경우, DBMS 라이선스 요금은 마스터/슬레이브 서버에만 적용됩니다.\n\n설치형 DB서버를 사용하면 좋은 경우\n\n  사내에 DB전문가가 있을 경우\n  서비스에 최적화된 DB설정을 하고 싶은 경우\n  장애 시 자동 Fail-over가 굳이 필요하지 않은 경우\n  DB백업을 원하는 방식으로 직접 하고 싶은 경우\n  DB 사이즈가 일정 크기 이상으로 늘어나는 것을 원하지 않는 경우\n  서비스 안정성 보다 비용 절감이 더 중요한 경우\n\n\n관리형 Cloud DB를 사용하면 좋은 경우\n\n  장애 시 자동 Fail-over를 통해 서비스 중지 시간을 최소로 하고 싶을 경우\n  DB의 읽기 요청이 많아서 읽기 전용 DB를 마련했을 때 효과가 큰 경우\n  DB백업과 디스크 용량 증설 등이 특별한 작업 없이 자동으로 진행되길 원하는 경우\n  비용보다 서비스 안정성이 더 중요한 경우\n  DB전문가가 없는 경우\n\n\n참고 URL\nhttps://www.ncloud.com/product/database"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mariadb-access-from-remote-centos-html": {
						"id": "database-ncloud-database-mariadb-access-from-remote-centos-html",
						"title": "CentOS에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL",
						"categories": "",
						"url": " /database/ncloud_database_mariadb_access_from_remote_centos.html",
						"content": "개요\n네이버 클라우드 CentOS에서 mariaDB 외부접속을 허용하고, mariaDB용 클라이언트 HeidiSQL을 이용해서 원격접속하는 방법을 정리해보겠습니다.\n여기서 원격접속이라 함은 SSH의 Tunnels를 이용하지 않고, 외부 클라이언트 등을 이용한 직접 접속을 뜻합니다.\nCentOS는 Ubuntu와 달리 mariaDB 환경설정 파일 my.cnf에서 외부 IP에서 접근이 막혀 있지 않기에 환경설정 파일은 수정하지 않습니다.\n\n계정 비밀번호 생성\n여기서는 네이버 클라우드에서 서버를 생성했을 때 자동으로 설정되는 root 계정을 이용한 방법을 정리하게 됩니다. \n네이버 클라우드에서는 처음 mariaDB를 설치하면 root 계정에 비밀번호가 설정되어 있지 않습니다.\n\n# mariadb 실행\n~# mysql\n\n# 비밀번호 설정\nMariaDB [(None)]&gt; set password=password('비밀번호');\n\n\n계정 권한 부여\n외부에서 해당 계정(여기서는 root)으로 접속할 수 있도록 계정에 권한을 부여하는 쿼리입니다.\nMariaDB [(None)]&gt; GRANT ALL PRIVILEGES ON *.* to 'root'@'%' IDENTIFIED BY '비밀번호';\n\n\nACG 포트 추가\n네이버 클라우드 ACG에 mariaDB가 사용하는 포트 3306을 추가해줍니다.\n\n\n  \n  \n    \n  \n\n\nHeidiSQL 다운로드\nmariaDB용 클라이언트 중에서 대표적인 HeidiSQL을 사용합니다.\n\n다운로드 경로 : https://www.heidisql.com/download.php\n\n\n  \n  \n    \n  \n\n\nHeidiSQL 설정\nHeidiSQL를 실행하면 DB접속을 위한 세션관리자가 먼저 나타납니다.\n왼쪽 하단의 [신규] 버튼을 누르고 서버 IP, 사용자, 암호를 입력하고 열기 버튼을 누르면 DB에 접속할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 접속\nmariaDB 접속에 성공하면 아래와 같은 화면을 볼 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n  https://guide.ncloud-docs.com/docs/database-database-7-1.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mariadb-access-from-remote-ubuntu-html": {
						"id": "database-ncloud-database-mariadb-access-from-remote-ubuntu-html",
						"title": "Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL",
						"categories": "",
						"url": " /database/ncloud_database_mariadb_access_from_remote_ubuntu.html",
						"content": "개요\n네이버 클라우드 Ubuntu에서 mariaDB 외부접속을 허용하고, mariaDB용 클라이언트 HeidiSQL을 이용해서 원격접속하는 방법을 정리해보겠습니다.\n여기서 원격접속이라 함은 SSH의 Tunnels를 이용하지 않고, 외부 클라이언트 등을 이용한 직접 접속을 뜻합니다.\n\n계정 비밀번호 생성\n여기서는 네이버 클라우드에서 서버를 생성했을 때 자동으로 설정되는 root 계정을 이용한 방법을 정리하게 됩니다. \n네이버 클라우드에서는 처음 mariaDB를 설치하면 root 계정에 비밀번호가 설정되어 있지 않습니다.\n\n# mariadb 실행\n~# mysql\n\n# 비밀번호 설정\nMariaDB [(None)]&gt; set password=password('비밀번호');\n\n\n계정 권한 부여\n외부에서 해당 계정(여기서는 root)으로 접속할 수 있도록 계정에 권한을 부여하는 쿼리입니다.\nMariaDB [(None)]&gt; GRANT ALL PRIVILEGES ON *.* to 'root'@'%' IDENTIFIED BY '비밀번호';\n\n\n환경설정 파일 수정\nmariaDB의 환경설정 파일 위치는 /etc/mysql/my.cnf 입니다.\nCentOS와 달리 Ubuntu에서 mariaDB는 기본적으로 외부 IP에 대한 접속이 차단되어 있고, 127.0.0.1 즉, localhost만 접속이 허용되어 있는 상태입니다.\n~# vi /etc/mysql/my.cnf\n\n\n아래는 환경 설정 파일의 일부입니다.\n# MariaDB database server configuration file.\n#\n# 중략 #\n\n[mysqld]\n#\n# * Basic Settings\n#\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\n#\n# Instead of skip-networking the default is now to listen only on\n# localhost which is more compatible and is not less secure.\nbind-address            = 127.0.0.1\n#\n\n\n위 환경설정 파일중에서 bind-address 항목을 주석처리하면 외부에서 접속이 가능합니다.\n# bind-address            = 127.0.0.1\n\n# 다른 방법\nbind-address            = 0.0.0.0\n\n# 특정 IP만 허용\nbind-address            = 허용할 IP 리스트\nbind-address            = 192.168.1.1,10.0.0.1\n\n\nDB 재시작\n~# systemctl restart mysql.service\n\n\nACG 포트 추가\n네이버 클라우드 ACG에 mariaDB가 사용하는 포트 3306을 추가해줍니다.\n\n\n  \n  \n    \n  \n\n\nHeidiSQL 다운로드\nmariaDB용 클라이언트 중에서 대표적인 HeidiSQL을 사용합니다.\n\n다운로드 경로 : https://www.heidisql.com/download.php\n\n\n  \n  \n    \n  \n\n\nHeidiSQL 설정\nHeidiSQL를 실행하면 DB접속을 위한 세션관리자가 먼저 나타납니다.\n왼쪽 하단의 [신규] 버튼을 누르고 서버 IP, 사용자, 암호를 입력하고 열기 버튼을 누르면 DB에 접속할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nDB 접속\nmariaDB 접속에 성공하면 아래와 같은 화면을 볼 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  CentOS에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n  https://guide.ncloud-docs.com/docs/database-database-7-1.html"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-auto-backup-html": {
						"id": "database-ncloud-database-mysql-auto-backup-html",
						"title": "Mysql DB 자동백업 방법",
						"categories": "",
						"url": " /database/ncloud_database_mysql_auto_backup.html",
						"content": "개요\n매일 일정한 시간에 mysql DB를 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n\n백업 폴더 생성\n루트에 /data_backup 폴더를 만들고 그 아래에 db 폴더를 생성합니다.\n~# mkdir /data_backup\n~# mkdir /data_backup/db\n\n\nmysql DB 백업 스크립트 작성\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# DATE=$(date +%Y%m%d%H%M%S)는 백업할 파일명을 \n# 202001224505 와 같은 형식으로 저장할 수 있게 날짜를 변수로 담습니다.  \n# find $BACKUP_DIR -ctime +7 -exec rm -f {} \\;  \n# 여기서 -ctime +7은 7일이 지난 백업 파일을 찾아서 삭제하기 위한 코드입니다.  \n\n# 추가로 분 단위로 설정하려고 할 때는 아래와 같이 \n# -cmin +10 처럼 작성하면 10분이 지난 파일을 찾아서 삭제하게 됩니다.\n# find $BACKUP_DIR -cmin +10 -exec rm -f {} \\;\n\n\n\n# 백업 스크립트에 실행 권한을 부여합니다.\n~# chmod 755 /bin/db_backup.sh\n\n\n스케쥴링을 위한 crontab 설정\n~# crontab -e\n\n# 매일 새벽 6시에 백업이 진행됩니다.\n00 06 * * * /bin/db_backup.sh\n\n\n그 외 시간 설정 방법\n# 30분 마다 실행\n*/30 * * * * /bin/db_backup.sh\n\n# 매주 일요일 새벽 6시에 실행\n0 06 * * 0 /bin/db_backup.sh\n\n# 매월 1일 새벽 6시에 실행\n0 06 1 * * /bin/db_backup.sh\n\n# 매년 12월 31일 새벽 6시에 실행\n0 06 31 12 * /bin/db_backup.sh\n\n\n참고 URL\nhttps://www.ncloud.com/product/database"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-mariadb-config-bind-address-html": {
						"id": "database-ncloud-database-mysql-mariadb-config-bind-address-html",
						"title": "Mysql, MariaDB 외부접속을 위한 환경설정 bind-address 위치",
						"categories": "",
						"url": " /database/ncloud_database_mysql_mariadb_config_bind_address.html",
						"content": "개요\n네이버 클라우드 DB중에서 mysql과 MariaDB를 외부에서 접속하기 위해서는 여러 설정이 필요한데 그 중에서 bind-address 설정 항목이 어느 파일에 위치하고 있는지 정리해보겠습니다.\nOS중에서 CentOS는 기본 설정이 허용이지만, Ubuntu는 기본 설정이 localhost 만 접속 가능하도록 되어 있기 때문에 외부 접속을 허용해주기 위해서는 bind-address 설정을 수정해야 합니다.\n그래서 여기서는 Ubuntu에 대해서 살펴보겠습니다.\n\nmysql 5.6\nmysql 5.6에서는 bind-address 설정이 /etc/mysql/my.cnf 파일에 있습니다.\nOS는 Ubuntu 14.04만 제공됩니다.\n\n\n  \n  \n    \n  \n\n\nmysql 5.7\nmysql 5.7에서는 bind-address 설정이 /etc/mysql/mysql.conf.d/mysqld.cnf 파일에 있습니다.\nOS는 Ubuntu 14.04와 16.04 두 버전이 있는데 모두 동일합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nmariaDB\nmariaDB는 10.2 버전만 있으며 bind-address 설정이 /etc/mysql/my.cnf 파일에 있습니다.\nOS는 Ubuntu 16.04만 제공됩니다.\n\n\n  \n  \n    \n  \n\n\n기타 - mariaDB CentOS\n그 외에 mysql의 경우 CentOS는 개요에서 말씀드렸듯이 기본적으로 외부 접속을 차단하는 bind-address 항목이 존재하지 않는데\nmariaDB의 경우 외부 접속을 차단하지는 않지만, bind-address 항목이 주석처리된 상태로 포함되어 있습니다.\n혹시나 차단하고 싶을 경우 사용하기 쉽게 미리 준비해둔 것으로 보입니다.\n주석처리된 bind-address의 위치는 /etc/my.cnf.d/server.cnf 입니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n  CentOS에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-mariadb-config-my-cnf-html": {
						"id": "database-ncloud-database-mysql-mariadb-config-my-cnf-html",
						"title": "Mysql, MariaDB 환경설정 파일 my.cnf 위치",
						"categories": "",
						"url": " /database/ncloud_database_mysql_mariadb_config_my_cnf.html",
						"content": "개요\nNcloud (네이버 클라우드)에서 Mysql MariaDB 환경설정 파일인 my.cnf 파일이 CentOS, Ubuntu, Rocky Linux OS 별로 어떤 경로에 위치하고 있는지 정리해보겠습니다.\n\nCentOS\n우선 CentOS 부터 살펴보겠습니다.\n\nMySQL\nMySQL은 my.cnf 파일이 /etc/ 바로 밑에 위치합니다.\n\n/etc/my.cnf\n\n\n\n  \n  \n    \n  \n\n\nMariaDB\nMariaDB에서도 my.cnf 파일이 /etc/ 바로 밑에 위치하기는 하지만, 실제로 /etc/my.cnf 파일을 열어보면 다음과 같이 my.cnf.d 디렉토리에 있는 파일을 include만 하게 되어 있습니다.\n즉, my.cnf 파일에 설정을 추가해도 되지만 가능하면 하위의 각각의 설정 파일에 추가하는 것이 좋습니다.\n\n/etc/my.cnf.d/server.cnf\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  /etc/my.cnf.d/server.cnf 파일을 열어 보면 다음과 같이 구성 되어 있습니다.\n\n\n\n  \n  \n    \n  \n\n\nUbuntu\nUbuntu에서는 my.cnf 파일이 /etc/mysql 밑에 위치합니다.\n\n/etc/mysql/my.cnf\n\n\nMySQL\nUbuntu 20.04, MySQL 8.0에서는 아래의 3가지 파일을 주로 확인하면 되겠습니다.\n\n/etc/mysql/my.cnf\n/etc/mysql/mysql.conf.d/mysql.cnf\n/etc/mysql/mysql.conf.d/mysqld.cnf\n\n\n\n  \n  \n    \n  \n\n\n먼저 /etc/mysql/my.cnf 파일을 열어 보면 다음과 같이 conf.d 디렉토리와 mysql.conf.d 디렉토리에 있는 파일을 include 하도록 되어 있습니다.\n\n\n  \n  \n    \n  \n\n\n/etc/mysql/ 디렉토리의 파일과 서브 디렉토리 구조를 살펴보면 다음과 같습니다. 여기서 mysql.conf.d 디렉토리에 있는 mysql.cnf 파일과 mysqld.cnf 파일을 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  /etc/mysql/mysql.conf.d/mysql.cnf\n이 파일을 열어 보면 다음과 같이 [The MySQL database client configuration file]이라고 되어 있습니다.\n즉, MySQL Client 관련 설정은 이곳에 지정하면 되겠습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  /etc/mysql/mysql.conf.d/mysqld.cnf\n이 파일을 열어 보면 다음과 같이 [The MySQL database server configuration file]이라고 되어 있습니다.\n즉, MySQL Server 관련 설정은 이곳에 지정하면 되겠습니다.\n\n\n\n  \n  \n    \n  \n\n\nMariaDB\nUbuntu 20.04, MariaDB 10.3에서는 아래의 4가지 파일을 주로 확인하면 되겠습니다.\n\n/etc/mysql/my.cnf\n/etc/mysql/mariadb.cnf\n/etc/mysql/mariadb.conf.d/50-client.cnf\n/etc/mysql/mariadb.conf.d/50-server.cnf\n\n\n\n  \n  \n    \n  \n\n\n그런데, /etc/mysql/my.cnf 파일의 정보를 확인해보면 결국 /etc/mysql/mariadb.cnf 파일의 심볼릭 링크라는 것을 알 수 있습니다. 그러므로 /etc/mysql/mariadb.cnf 파일을 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n/etc/mysql/mariadb.cnf 파일을 열어 보면 다음과 같이 conf.d 디렉토리와 mariadb.conf.d 디렉토리에 있는 파일을 include 하도록 되어 있습니다.\n\n\n  \n  \n    \n  \n\n\n/etc/mysql/ 디렉토리의 파일과 서브 디렉토리 구조를 살펴보면 다음과 같습니다.\n여기서 mariadb.conf.d 디렉토리에 있는 50-client.cnf 파일과 50-server.cnf 파일을 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  /etc/mysql/mariadb.conf.d/50-client.cnf\n이 파일을 열어 보면 다음과 같이 [This group is read by the client library]이라고 되어 있습니다.\n즉, MariaDB Client 관련 설정은 이곳에 지정하면 되겠습니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  /etc/mysql/mariadb.conf.d/50-server.cnf\n이 파일을 열어 보면 다음과 같이 [These groups are read by MariaDB server]이라고 되어 있습니다.\n즉, MariaDB Server 관련 설정은 이곳에 지정하면 되겠습니다.\n\n\n\n  \n  \n    \n  \n\n\nRocky Linux\n\nMySQL\nRocky Linux도 MySQL은 my.cnf 파일이 /etc/ 바로 밑에 위치합니다.\n\n/etc/my.cnf\n\n\n\n  \n  \n    \n  \n\n\nMariaDB\nRocky Linux에서는 mariadb-server.cnf 파일입니다.\n\n/etc/my.cnf.d/mariadb-server.cnf\n\n\nMariaDB에서도 my.cnf 파일이 /etc/ 바로 밑에 위치하기는 하지만, 실제로 /etc/my.cnf 파일을 열어보면 다음과 같이 my.cnf.d 디렉토리에 있는 파일을 include만 하게 되어 있습니다.\n즉, my.cnf 파일에 설정을 추가해도 되지만 가능하면 하위의 각각의 설정 파일에 추가하는 것이 좋습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  /etc/my.cnf.d/mariadb-server.cnf 파일을 열어 보면 다음과 같이 구성 되어 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud MySQL 서버 이미지 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-1-1\n    \n  \n  Ncloud MariaDB 서버 이미지 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-7-1"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-mariadb-replication-html": {
						"id": "database-ncloud-database-mysql-mariadb-replication-html",
						"title": "MYSQL(MARIADB) Replication 생성하기",
						"categories": "",
						"url": " /database/ncloud_database_mysql_mariadb_replication.html",
						"content": "선행조건\n\n\n  master, slave 장비의 mysql설치가 사전에 완료된 조건\n  mysql 버전 5.7이상 조건에서 작성됨\n  mysql 리플리케이션작업을 진행시 masterdb의 데이터베이스는 쓰기작업이 없는 서비스 미진행 상태이어야함.\n\n\nMASTER 장비 구성\n\nmy.cnf파일 내용 추가\n\n[mysqld]\nlog-bin=mysql-bin\nbinlog_format = mixed\n\n# 해당 ID값은 마스터장비만 1을 설정할수있음\nserver-id = 1 \n\n# 마스터 장비의 bin로그 특정일자(예시는10일) 이후 삭제\n# (해당 내역이없을 경우 지속적으로 기록되어 디스크 사용)\nexpire_logs_days = 10 \n\n\nmysql접속 후 리플리케이션을 진행할 계정 생성\n\nGRANT REPLICATION SLAVE ON *.* TO '리플리케이션계정명'@'%' IDENTIFIED BY '패스워드';\nFLUSH PRIVILEGES;\n\n\nSLAVE 장비 구성\n\nmy.cnf파일 내용 추가\n\n[mysqld]\nserver-id=2 #해당ID값은 1을 제외한 숫자지정\nslave-skip-errors = all  \n\n\n\n데이터베이스 사전 동기화작업\n\n\n  \n    master장비의 데이터베이스가 생성되어 있고 데이터가 있을 경우\n\n    A. master장비 데이터베이스 백업 진행\n    # 데이터베이스가 추가로 있다면 남은 데이터베이스도 백업\nmysqldump -u root -p --databases 데이터베이스명 &gt; 백업파일.sql \n    \n    \n B. slave장비 데이터베이스 복구 진행\n    create database 데이터베이스명; #mysql 접속 후 생성\nmysql -u root -p 데이터베이스명 &lt; 백업파일.sql  \n    \n    \n  \n  \n    master 장비의 데이터베이스가 없을 경우\n\n    A. 별도 작업 없으며, 데이터베이스만 생성되어 데이터가 없을경우도 slave장비에 동일한 데이터베이스 생성으로 마무리\n  \n\n\n리플리케이션 작업\n\n\n  \n    master 장비 mysql 접속 후 현재 로그파일번호와 포지션 넘버 확인\n\n    show master status;\nfile| Position #내역을 확인 후 별도 기입.\n    \n  \n  \n    slave 장비 mysql 접속 후 아래 명령어 실행 하여 리플리케이션 master정보 기입\n\n    CHANGE MASTER TO MASTER_HOST='마스터IP',MASTER_USER='생성한리플리케이션계정명',MASTER_PASSWORD='패스워드',MASTER_LOG_FILE='위에서확인된 file이름',MASTER_LOG_POS=위에서 확인된 포지션번호;\n    \n  \n  \n    slave 리플리케이션 시작및 확인\n\n    start slave;\nshow slave status\\G; #실행 후 에러가 없다면 정상."
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-object-storage-auto-backup-centos-html": {
						"id": "database-ncloud-database-mysql-object-storage-auto-backup-centos-html",
						"title": "CentOS에서 mysql DB를 Object Storage로 자동 백업하기",
						"categories": "",
						"url": " /database/ncloud_database_mysql_object_storage_auto_backup_centos.html",
						"content": "개요\n네이버 클라우드 CentOS에서 설치형 mysql  DB를 매일 일정한 시간에 Object Storage로 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n순서는 로컬에 백업 파일 생성 후에 Object Storage로 저장하는 단계로 진행됩니다.\n\n백업 폴더 생성\n~# mkdir /data_backup\n~# mkdir /data_backup/db\n\n\nmysql DB 로컬 백업 스크립트 작성\n우선은 mysql DB를 로컬에 백업 받는 스크립트를 작성합니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 백업 파일을 202001224505 와 같은 형식으로 저장하고, 생성된지 7일이 지난 백업 파일을 삭제하는 코드입니다.\n\n\n# 백업 스크립트에 실행 권한을 부여합니다.\n~# chmod 755 /bin/db_backup.sh\n\n\npip 설치\naws cli를 설치하려면 pip가 먼저 설치되어 있어야 합니다.\n혹시 이미 pip가 설치되어 있다면 아래에 있는 AWS CLI설치로 바로 이동하시면 되겠습니다.\n~# yum -y install python-pip\n\nCentOS 6.x 버전은 기술지원 종료로 인해 위 방법대로 설치가 되지 않습니다. 아래 문서의 방법대로 설치하면 됩니다.\nCentOS6에서 pip - Python 설치하기\n\nAWS CLI 설치\n네이버 클라우드의 설명에 따르면 aws cli 1.16이후 버전은 일부 기능을 사용할 수 없어서 1.15버전을 사용한다고 합니다.\n~# pip install awscli==1.15.85\n\n\nAPI 인증키 생성\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nAWS CLI 환경 설정\n이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목을 입력하지 않으셔도 됩니다.\n~# aws configure\n\nAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\nAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\nDefault region name [None]: [Enter]\nDefault output format [None]: [Enter]\n\n\nObject Storage Bucket 생성\nObject Storage에 data-back-up Bucket을 생성하고 그 아래에 db 폴더를 생성합니다.\n\n\n  \n  \n    \n  \n\n\nObject Storage 접속 테스트\n이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# s3 ls 명령으로 Object Storage에 존재하는 버킷 리스트를 조회합니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\n\n2021-01-21 15:34:07 data-back-up\n\n\nmysql DB 백업 스크립트 수정\n이제 위 단계에서 만들었던 DB 로컬 백업 스크립트에 DB백업 파일을 Object Storage로 백업-동기화 하는 명령을 추가하겠습니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어입니다.\naws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\n\n\n여기서 db 폴더만 백업-동기화를 하는 것이 아닌 상위 폴더인 /data_backup/ 폴더부터 백업-동기화를 한 이유는 이후에 db 말고도 개발소스 파일 등도 압축해서 백업하기 위해서입니다.\n\n스케쥴링을 위한 crontab 설정\n이제 마지막으로 완성된 스크립트를 일정한 시간, 여기서는 매일 새벽 6시에 실행되도록 설정합니다.\n~# crontab -e\n\n# 매일 새벽 6시에 백업이 진행되는 코드입니다.\n00 06 * * * /bin/db_backup.sh\n\n\n백업 결과 확인\n백업이 진행되고 나면 아래와 같이 db 백업 파일이 Object Storage에 저장된 것을 확인할 수 있습니다.\n스샷에서는 빠른 확인을 위해 새벽 6시가 아닌 5분 단위로 백업한 내역입니다.\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  mysql DB 자동백업 방법\n    \n      mysql DB 자동백업 방법\n    \n  \n  AWS CLI를 이용한 Object Storage 접속 방법\n    \n      AWS CLI를 이용한 Object Storage 접속 방법"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-object-storage-auto-backup-ubuntu-html": {
						"id": "database-ncloud-database-mysql-object-storage-auto-backup-ubuntu-html",
						"title": "Ubuntu에서 mysql DB를 Object Storage로 자동 백업하기",
						"categories": "",
						"url": " /database/ncloud_database_mysql_object_storage_auto_backup_ubuntu.html",
						"content": "개요\n네이버 클라우드 Ubuntu에서 설치형 mysql  DB를 매일 일정한 시간에 Object Storage로 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n순서는 로컬에 백업 파일 생성 후에 Object Storage로 저장하는 단계로 진행됩니다.\n\n백업 폴더 생성\n~# mkdir /data_backup\n~# mkdir /data_backup/db\n\n\nmysql DB 로컬 백업 스크립트 작성\n우선은 mysql DB를 로컬에 백업 받는 스크립트를 작성합니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 백업 파일을 202001224505 와 같은 형식으로 저장하고, 생성된지 7일이 지난 백업 파일을 삭제하는 코드입니다.\n\n\n# 백업 스크립트에 실행 권한을 부여합니다.\n~# chmod 755 /bin/db_backup.sh\n\n\npip 설치\naws cli를 설치하려면 pip가 먼저 설치되어 있어야 합니다.\n혹시 이미 pip가 설치되어 있다면 아래에 있는 AWS CLI설치로 바로 이동하시면 되겠습니다.\n~# apt install python-pip\n\nCentOS 6.x 버전은 기술지원 종료로 인해 위 방법대로 설치가 되지 않습니다. 아래 문서의 방법대로 설치하면 됩니다.\nCentOS6에서 pip - Python 설치하기\n\nAWS CLI 설치\n네이버 클라우드의 설명에 따르면 aws cli 1.16이후 버전은 일부 기능을 사용할 수 없어서 1.15버전을 사용한다고 합니다.\n~# pip install awscli==1.15.85\n\n\nAPI 인증키 생성\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nAWS CLI 환경 설정\n이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목을 입력하지 않으셔도 됩니다.\n~# aws configure\n\nAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\nAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\nDefault region name [None]: [Enter]\nDefault output format [None]: [Enter]\n\n\nObject Storage Bucket 생성\nObject Storage에 data-back-up Bucket을 생성하고 그 아래에 db 폴더를 생성합니다.\n\n\n  \n  \n    \n  \n\n\nObject Storage 접속 테스트\n이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# s3 ls 명령으로 Object Storage에 존재하는 버킷 리스트를 조회합니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\n\n2021-01-21 15:34:07 data-back-up\n\n\nmysql DB 백업 스크립트 수정\n이제 위 단계에서 만들었던 DB 로컬 백업 스크립트에 DB백업 파일을 Object Storage로 백업-동기화 하는 명령을 추가하겠습니다.\n~# vi /bin/db_backup.sh\n\n#!/bin/bash\nDATE=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=/data_backup/db/\n# 전체 DB를 백업할 경우\nmysqldump -u root -p디비패스워드 --all-databases &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\n# 특정 DB를 백업할 경우\n# mysqldump -u root -p디비패스워드 --databases DB명  &gt; $BACKUP_DIR\"backup_\"$DATE.sql\n\nfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\n\n# 여기서부터 추가되는 명령입니다.\n# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어입니다.\n# aws 명령어를 crontab에서 실행하기 위해 aws 파일의 전체 경로를 적어줍니다\n/usr/local/bin/aws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\n\n여기서 db 폴더만 백업-동기화를 하는 것이 아닌 상위 폴더인 /data_backup/ 폴더부터 백업-동기화를 한 이유는 이후에 db 말고도 개발소스 파일 등도 압축해서 백업하기 위해서입니다.\n\n스케쥴링을 위한 crontab 설정\n이제 마지막으로 완성된 스크립트를 일정한 시간, 여기서는 매일 새벽 6시에 실행되도록 설정합니다.\n~# crontab -e\n\n# 매일 새벽 6시에 백업이 진행되는 코드입니다.\n00 06 * * * /bin/db_backup.sh &gt; /dev/null 2&gt;&amp;1\n\ncrontab에 &gt; /dev/null 2&gt;&amp;1를 추가하지 않으면 /var/log/syslog 파일에 (CRON) info (No MTA installed, discarding output) 라는 오류 메시지가 계속 쌓입니다. \npostfix를 설치하면 해결된다는 이야기도 있는데 굳이 필요하지 않은 것을 설치하기 보다는 필요하지 않은 오류 메시지는 없애는 것이 나을 듯합니다.\n\n백업 결과 확인\n백업이 진행되고 나면 아래와 같이 db 백업 파일이 Object Storage에 저장된 것을 확인할 수 있습니다.\n스샷에서는 빠른 확인을 위해 새벽 6시가 아닌 5분 단위로 백업한 내역입니다.\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  mysql DB 자동백업 방법\n    \n      mysql DB 자동백업 방법\n    \n  \n  AWS CLI를 이용한 Object Storage 접속 방법\n    \n      AWS CLI를 이용한 Object Storage 접속 방법"
					}
					
				
			
		
			
				
					,
					
					"database-ncloud-database-mysql-root-password-set-update-guide-html": {
						"id": "database-ncloud-database-mysql-root-password-set-update-guide-html",
						"title": "설치형 MySQL DB에서 root Password 설정, 변경하는 방법",
						"categories": "",
						"url": " /database/ncloud_database_mysql_root_password_set_update_guide.html",
						"content": "개요\n네이버 클라우드에서는 MySQL Password 정책에 따라 처음 MySQL DB를 설치할 때 root의 초기 패스워드가 설정되지 않습니다. \n그러므로 보안 침해 방지를 위해 설치 후에 root Password를 설정한 후에 DB를 사용하는 것이 안전합니다.\n여기서는 Classic환경에서 MySQL 5.6과 5.7 버전의 root Password를 설정, 변경하는 방법에 대해 정리해보겠습니다.\n\nMySQL 버전\n네이버 클라우드 Classic환경에서 지원하는 설치형 MySQL 버전은 5.6과 5.7 입니다.\n\n\n  \n  \n    \n  \n\n\nNcloud는 Classic환경에서는 DB 서버 이미지를 제공하지만, VPC 환경에서는 제공하지 않습니다. \n그러므로 VPC 환경에서 DB서버를 사용하려면 OS에 사용자가 직접 DB를 설치해서 사용하는 방법과 Cloud DB를 사용하는 방법 중에서 선택해야 합니다.\n\nMySQL 5.6 설정\n우선 mysql 5.6 DB서버를 생성한 후 root 계정의 패스워드 상태를 확인해봅니다. 그 이후에 패스워드를 설정합니다.\n\n#mysql 접속\n~# mysql -u root\n\n#계정 정보 조회\nmysql&gt; select host, user, password from mysql.user;\n\n#패스워드 설정-변경\nmysql&gt; set password = password('패스워드');\n\n#변경된 패스워드 조회\nmysql&gt; select host, user, password from mysql.user;\n\n\n초기 패스워드가 설정되어있지 않기 때문에 -p 옵션을 사용하지 않고 바로 접속 해서 user 테이블에 있는 계정 정보를 확인해보면 password 값이 비어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n패스워드를 설정하고 다시 확인을 해보면 localhost의 root 계정에 패스워드가 설정된 것을 확인할 수 있습니다.\n\n 계정 구분: Mysql의 계정은 host-user 두개를 합쳐서 키로 사용하게 되어 있습니다. 같은 user라도 접속하는 host 값이 다르면 별도의 계정처럼 인식합니다.\n\n\n  \n  \n    \n  \n\n\n그런데 위에서 사용한 set password = password(‘패스워드’)는 localhost@root에 대해서만 패스워드를 설정-변경합니다.\n만약 외부에서 접속하기 위해 특정 IP를 추가했다거나 외부 접속을 모두 허용하기 위해 host에 %값을 설정했을 경우에는 패스워드가 설정-변경되지 않습니다. \n이때 사용하는 방법은 아래와 같습니다.\n\nmysql&gt; update mysql.user set password = password('패스워드') where user = 'root';\n\nmysql&gt; select host, user, password from mysql.user;\n\n\n쿼리를 실행한 후에 조회를 해보면 user값이 root인 모든 계정의 password 값이 동일하게 설정된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nMySQL 5.7 설정\n마찬가지로 mysql 5.7 DB서버를 생성한 후 root 계정의 패스워드 상태를 확인해봅니다. 그 이후에 패스워드를 설정합니다.\nMySQL 5.7은 패스워드 칼럼이 password가 아니고 authentication_string로 변경되었습니다.\n\n#mysql 접속\n~# mysql -u root\n\n#계정 정보 조회\nmysql&gt; select host, user, authentication_string from mysql.user;\n\n#패스워드 설정-변경\nmysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '패스워드';\n\n#변경된 패스워드 조회\nmysql&gt; select host, user, authentication_string from mysql.user;\n\n\n초기 패스워드가 설정되어있지 않기 때문에 -p 옵션을 사용하지 않고 바로 접속 해서 user 테이블에 있는 계정 정보를 확인해보면 password 값이 비어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n이때 MySQL 5.6 이하 버전처럼 update 명령어로 authentication_string 칼럼 값을 변경하려고 해도 적용되지 않습니다.\n위에 적은 것처럼 ALTER 명령으로 변경해야 적용되니 주의해야 합니다.\n\n\n  \n  \n    \n  \n\n\nMySQL 패스워드 정책\nMySQL은 아래와 같이 기본 패스워드 정책이 설정되어 있습니다. 그러므로 패스워드 설정 시에는 아래 조건에 맞게 입력하셔야 합니다.\n\n\n  최소 길이 8자 이상\n  특수문자 1개 이상\n  숫자 1개 이상\n  대소문자 조합 1개 이상\n\n\nMySQL DB에 접속해서 아래와 같이 설정된 정책을 조회할 수 있습니다.\n\nmysql&gt; SHOW VARIABLES LIKE 'validate_password%';\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  설치형 MySQL 기본 가이드\n    \n      https://guide.ncloud-docs.com/docs/database-database-1-1\n    \n  \n  MySQL 패스워드 정책 가이드\n    \n      https://dev.mysql.com/doc/refman/5.7/en/validate-password-options-variables.html"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-classic-monitoring-guide-html": {
						"id": "management-ncloud-management-classic-monitoring-guide-html",
						"title": "서버 모니터링 서비스 Monitoring 설정 가이드",
						"categories": "",
						"url": " /management/ncloud_management_classic_monitoring_guide.html",
						"content": "개요\n네이버 클라우드 Classic 환경에서 서버 모니터링을 설정하는 가이드입니다.\nClassic에서는 Monitoring 서비스와 Cloud Insite(Monitoring) 서비스 이렇게 2가지 서비스가 있는데 여기서는 Monitoring 서비스를 설정하는 방법에 대해 정리해보겠습니다.\n\n기본 모니터링 vs 상세 모니터링\n기본 모니터링 : 네이버 클라우드에서 서버를 생성하면 별다른 설정을 하지 않아도 CPU, Memory 사용 등의 기본적인 항목들의 데이터를 확인할 수 있는데 이를 기본 모니터링이라고 하며 5분 단위의 데이터를 확인할 수 있습니다.\n  확인 가능한 데이터는 다음과 같습니다. \n⁃ [CPU Used] \n⁃ [Memory Used (except cache/buffer)] \n⁃ [Disk Used], [Disk Read (bytes)], [Disk Write (bytes)] \n⁃ [Swap Used] \n⁃ [Network In (bps)], [Network Out (bps)] 입니다.\n\n상세 모니터링 : 기본 모니터링보다 훨씬 많고 상세한 데이터를 확인하고, 상태 감시와 통보 알람 설정을 통해 지정한 수치 이상의 상태가 되면 문자나 메일로 통보 받을 수 있는 모니터링 서비스이며, 1분 단위의 데이터를 확인할 수 있습니다. \n⁃ 네이버 클라우드 [Console] - [Monitoring] 서비스가 바로 [상세 모니터링]입니다. \n⁃ 또한 [Monitoring] 서비스에서는 Auto Scaling 그룹에 대한 이벤트 설정도 할 수 있습니다.\n\n기본 모니터링\n아래와 같이 서버 리스트에서 모니터링할 서버를 선택하고 위에 있는 [모니터링] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n기본 모니터링에서는 5분 주기의 데이터를 확인할 수 있고, 날짜와 기간을 선택해서 데이터를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n상세 모니터링\n[Monitoring] 서비스 즉, 상세 모니터링 서비스는 별도로 설정이 필요한데 설정하는 방법은 아래와 같이 기본 모니터링 화면에서 [상세 모니터링 설정] 링크를 클릭하거나, \n서버 리스트에서 [서버 관리 및 설정 변경] 메뉴 - [상세 모니터링 설정 변경] 메뉴를 클릭하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n[상세 모니터링] 신청화면입니다. 특별한 설정이 필요한 것은 아니므로 신청 화면에서 [예] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[상세 모니터링] 신청이 끝나면 바로 [Monitoring] - [Notification Recipient] 즉, 이벤트 통보 대상자 화면으로 넘어갑니다.  여기서는 모니터링 대상인 서버에서 이벤트가 발생했을 때 연락이 가도록 대상자를 등록하게 됩니다.\n기본으로 계정 사용자 정보가 등록되어 있는데, 혹시 등록되지 않았을 경우에는 [대상자 추가] 버튼을 클릭해서 통보 대상자를 등록합니다.\n\n\n  \n  \n    \n  \n\n\n대시보드\n\n통합 대시보드\n[Monitoring] - [Integrated Dashboard] 즉, 통합 대시보드 메뉴로 이동합니다.\n여기서는 일별 이벤트 발생 횟수와 히스토리, 그리고, 각 모니터링 항목별로 상위 5개의 서버 정보를 통합해서 표시합니다.\n\n\n  \n  \n    \n  \n\n\n서버 대시보드\n[Monitoring] - [Dashboard] - [Server Dashboard]에서는 전체 서버들의 상세한 모니터링 데이터를 리스트로 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n좀 더 자세한 정보를 확인하고 싶으면 서버 리스트에서 원하는 서버를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n서버를 선택하면 아래와 같이 모니터링 데이터를 차트로 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n그리고 서버 Process와 File System 사용 정보도 상세하게 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n감시-통보 설정\nMonitoring 시스템에서 수집하는 성능 Item 중 사용자가 지정한 Item이 임계치 값을 벗어난 경우에 Event가 발생합니다. \nEvent를 발생 하게 하는 조건을 감시설정이라 하며 해당 Event를 Mail or SMS로 수신 받는 설정을 통보설정이라고 합니다.\n\n[Monitoring] - [Configuration] - [New Observation] 메뉴에서 우선 감시설정에 등록하고자 하는 서버를 먼저 선택하고 하단의 감시설정 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 감시할 항목을 설정합니다. CPU, Memory 등 원하는 분류와 항목을 선택하고 임계치 등의 수치를 입력 후 추가 버튼을 클릭합니다.\n또한, 미리 Template을 등록해 두면 이후에 여러 서버들에 설정을 쉽게 적용할 수 있습니다.\n\n분류 항목별 주의 사항\n\n  프로세스: 상세 입력칸에 프로세스명을 입력할 때는 정규 표현식으로 입력해야 합니다.\n  파일 시스템:  상세 입력칸에 경로 입력 시 Linux의 경우 ‘/’ 경로로 입력하고, Windows의 경우 ‘C:, D:’ 등의 경로로 반드시 대문자로 입력합니다.\n\n\n\n  \n  \n    \n  \n\n\n 주의사항: 감시 통보설정에서 중요한 것은 지속시간입니다. 위 설정화면을 예로 설명하자면 CPU 사용률이 90% 이상인 상태가 5분 이상 지속되면 통보되도록 설정된 상태입니다. \n즉, 중간에 한번이라도 90% 미만으로 내려가면, 예를 들어 4분 50초 동안 90% 이상을 유지하다 85%로 내려간 경우라면 통보가 되지 않습니다. \n혹시 통보 알람을 테스트 하고 싶을 경우에는 지정한 상태가 5분 이상 지속되는 상황을 연출해서 테스트 해보셔야 합니다.\n\n그 다음은 통보 받을 대상자와 통보 방법을 선택하고 [추가] 버튼을 클릭합니다. 통보 대상자가 리스트에 없을 경우 위쪽에 있는 [통보대상관리] 버튼을 클릭해서 대상자를 등록한 후에 다시 추가합니다.\n\n\n  \n  \n    \n  \n\n\n마지막으로 지금까지 설정한 내용들을 다시 한번 확인 한 후에 [최종 확인] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n통보 알람 중지\n서버 점검 등을 진행할 때는 통보 알람 기능을 중지 시켜두면 불필요한 알람을 받을 필요가 없어서 편리합니다.\n[Monitoring] - [Configuration] - [Notification Stop] 메뉴에서 서버를 선택하고 [알람중지] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n알람 중지 팝업 화면에서 목적과 기간 등을 선택해서 적용합니다.\n\n\n  \n  \n    \n  \n\n\n정보 수집 오류\n간혹 서버 모니터링 성능 정보 수집에 오류가 발생하는 경우가 있습니다.\n그 중에서 Classic 환경의 Windows 서버에서 오류가 발생했을 때의 해결 방법을 아래 문서에 따로 정리해두었습니다.\n\n\n  Windows 서버 모니터링 성능 정보 수집 오류 해결 방법\n\n\n참고 URL\n\n  상세 모니터링 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/management-management-1-1"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-classic-vs-vpc-guide-html": {
						"id": "management-ncloud-management-classic-vs-vpc-guide-html",
						"title": "Ncloud Classic 환경 vs VPC 환경 비교",
						"categories": "",
						"url": " /management/ncloud_management_classic_vs_vpc_guide.html",
						"content": "개요\n네이버 클라우드 (Ncloud)에는 Classic과 VPC 이렇게 2가지의 환경이 있습니다.\n각각의 특징을 장점을 중심으로 비교해보도록 하겠습니다.\n\nClassic 환경 장점 요약\n\n  서로 다른 계정의 서버들 간에 사설 통신 가능\n  리전간 서버들의 사설 통신 가능 (한국, 미국, 싱가포르, 홍콩, 일본, 독일)\n  다양한 설치형 서버 이미지 이용 가능\n\n\nVPC 환경 장점 요약\n\n  논리적으로 분리된 Network\n  사용자가 직접 Network 설계 가능\n  기존 고객의 데이터센터 네트워크와 유사하게 구현 가능\n  좀 더 상세하고, 높은 수준의 보안 설정 가능\n\n\nClassic 환경 장점 상세\n위에서 요약한 장점들을 좀 더 상세하게 살펴보겠습니다.\n\n서로 다른 계정의 서버들 간 사설 통신 가능\n사용자가 2개 이상의 계정을 보유하고 있을 경우 각 계정에 생성된 서버들간에 사설 통신을 할 수 있습니다.\n\n리전간 서버들의 사설 통신 가능\n현재 네이버 클라우드는 한국, 미국, 싱가포르, 홍콩, 일본, 독일 이렇게 6개의 리전으로 서비스가 구분되어 있는데, 각 리전에 생성된 서버들끼리 사설 통신을 할 수 있습니다.\n\n다양한 설치형 서버 이미지 이용 가능\nClassic 환경에서는 LAMP, Wordpress 등 사용자들이 편하게 각 종 애플리케이션과 DB가 미리 설치된 서버를 쉽게 생성할 수 있도록 설치형 서버 이미지를 제공하고 있습니다. \n지원하는 주요 이미지는 다음과 같습니다.\n\n\n  Jenkins, Tensorflow, RabbitMQ, Pinpoint, LAMP, WordPress, Magento, Drupal, Joomla!, Shadowsocks, LEMP, Hugo, Gitlab CE, Node.js, Superset, Tomcat, JEUS, WebtoB, Gradle\n  MySQL, MSSQL, Cubrid, PostgreSQL, MariaDB, Redis, Tibero\n\n\nVPC 환경 장점 상세\n위에서 요약한 장점들을 좀 더 상세하게 살펴보겠습니다.\n\n논리적으로 분리된 Network\n\n  논리적으로 분리된 Network 체계를 제공하기 때문에 다른 이용자와의 간섭 없이 더 안전하고, 투명한 환경을 구현할 수 있습니다.\n\n\n사용자가 직접 Network 설계 가능\n\n  네트워크 서브넷(Subnet) 기능을 통해 용도에 따라 네트워크를 세분화하여 서비스 맞춤형 네트워크를 사용자가 직접 구성하실 수 있습니다\n  Load Balancer가 Application Load Balancer / Network Load Balancer / Network Proxy Load Balancer 등 3가지로 구분되어 있어, 고객이 각자의 서비스 환경에 최적화된 Load Balancer를 선택할 수 있습니다.\n  원하는 사설 IP 대역을 직접 할당할 수 있습니다. \n그러므로 사용해야 하는 사설 IP대역이 정해져 있어 변경할 수 없거나, 서버의 사설 IP를 변경하기 어려운 경우에도 VPC 환경에서는 원하는 대역의 원하는 IP를 직접 부여할 수 있습니다.\n\n\n기존 고객의 데이터센터 네트워크와 유사하게 구현 가능\n\n  기존 고객 데이터센터 네트워크와 유사하게 구현 가능합니다.\n즉, 기존에 AWS를 사용하고 있었던 고객은 AWS는 VPC 환경만 제공하기 때문에 거의 비슷하게 구현 가능합니다.\n또한 온프레미스 환경의 IDC 센터를 이용했던 고객이 클라우드 환경으로 마이그레이션해야 할 때 VPC 환경은 기존의 구조를 거의 그대로 구현해서 마이그레이션할 수 있습니다.\n\n\n좀 더 상세하고, 높은 수준의 보안 설정 가능\n\n  서버 측면에서 접근 제어를 위한 ACG(Access Control Group) 외에도,  네트워크 서브넷 측면에서 접근 제어를 할 수 있도록 NACL(Network Access Control List)을 제공합니다. \n이처럼 여러가지 접근제어 기능을 이용해 클라우드 상에서 발생할 수 있는 다양한 공격에 대한 대비가 가능합니다.\n  ACG, NACL등의 네트워크 접근제어 설정에서 Inbound, Outbound 각각에 대한 제어 설정 등 상세한 보안 설정을 직접 할 수 있습니다.\n\n\nVPC 환경 활용사례\n\n  \n    외부와 인터넷 연결이 필요한 서브넷과 이와 별개로 중요 데이터를 저장하기 위해 외부 접속을 최소화하기 위한 서브넷을 구성하는 경우\n하나의 서브넷에 인터넷 게이트웨이를 연결하여 프런트-엔드(Front-end) 전용 서브넷을 구성하고, 다른 하나의 서브넷에는 NAT 게이트웨이를 연결하여 백-엔드(Back-end)용 서브넷으로 활용\n  \n  \n    Cloud Connect만을 이용하여 접근할 수 있는 서브넷을 구성하는 경우\n Cloud Connect를 이용하여 On-Premise에 있는 고객의 전산망을 클라우드로 확장한 하이브리드 클라우드 구성\n  \n  \n    외부와 인터넷 연결이 필요한 서브넷과 이와 별개로 외부 인터넷 연결을 차단하고 VPN을 통해 On-Premise에서만 접근할 수 있는 서브넷을 구성하는 경우\n하나의 서브넷은 외부와 연결되는 일반 구성으로 하고, 다른 하나의 서브넷에 IPsec VPN을 연결하여 VPN 전용 서브넷(VPN Only Subnet)을 구성하는 방식\n  \n  \n    다른 두개의 서비스를 각각 다른 사설 IP대역에서 서비스하려는 경우\nVPC를 2개 생성해서 각각 다른 사설 IP 대역을 할당해서 구성 가능\n  \n\n\nClassic vs VPC 선택\n\nClassic 선택\n\n  구축하려는 서비스 규모가 작으며 네트워크 설정은 신경 쓰고 싶지 않은 경우는 Classic 환경\n  리전간 서버끼리 사설통신이 필요하다면 (ex. DB 한국리전, 서비스서버 일본리전) Classic 환경\n  다양한 설치형 서버 이미지들이 필요하다면 Classic 환경\n\n\nVPC 선택\n\n  네트워크 세분화및  서비스에 별도 사설 대역이 필요한 경우는 VPC 환경\n  서버, 네트워크 통신의 inbound, outbound를 직접 통제하고 싶은 경우는 VPC 환경\n  좀 더 다양한 기능을 지원하는 상품을 이용하고자 할때는 VPC환경\n\n\n참고 URL\n\n  VPC 제품 설명\n    \n      https://www.ncloud.com/product/networking/vpc\n    \n  \n  VPC 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/networking-vpc-vpcoverview"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-cloud-insight-guide-html": {
						"id": "management-ncloud-management-cloud-insight-guide-html",
						"title": "모니터링 서비스 Cloud Insight 설정 가이드",
						"categories": "",
						"url": " /management/ncloud_management_cloud_insight_guide.html",
						"content": "개요\n네이버 클라우드와 사용자 애플리케이션의 성능/운영 지표를 통합 관리하고, 장애나 이벤트가 발생했을 때 SMS 및 Email로 알람 통보를 해주는 서비스인 Cloud Insight 서비스를 설정하는 방법에 대해 정리해보겠습니다.\n\nMonitoring 서비스 vs Cloud Insight 서비스\nClassic 환경에 있는 Monitoring 서비스와 Cloud Insight 서비스의 차이점을 정리하면 다음과 같습니다.\n\n- Monitoring 서비스는 Classic 환경에서만 사용할 수 있다.\n- Cloud Insight 서비스는 Classic, VPC 양쪽에서 모두 사용할 수 있고, 두가지 환경을 통합해서 보여준다.\n- Monitoring 서비스는 Server 제품 (AutoScaling 포함)만 모니터링 한다.\n- Cloud Insight 서비스는 Server 뿐만 아니라 Object Storage, Load Balancer 등 10여개의 서비스를 모니터링 한다.\n\n적용 서비스 리스트\n위 비교에서도 설명했듯이 Cloud Insight는 Server 뿐만 아니라 네이버 클라우드의 다양한 서비스의 모니터링 정보를 확인할 수 있는데 해당 리스트는 다음과 같습니다.\n\nClassic\n\n  Server\n  Load Balancer\n\n\nVPC\n\n  Server(VPC)\n  Load Balancer(VPC)\n  Cloud DB for MySQL(VPC)\n  Cloud DB for MSSQL(VPC)\n  Cloud DB for Redis(VPC)\n  Cloud DB for MongoDB(VPC)\n  Cloud Hadoop(VPC)\n  Auto Scaling Group(VPC)\n  Kubernetes Service(VPC)\n  Search Engine Service(VPC)\n  Cloud Data Streaming Service(VPC)\n\n\n통합\n\n  Cloud Search\n  Object Storage\n\n\nCloud Insight 서비스\n[Cloud Insight] 서비스는 [콘솔] - [Services] - [Management &amp; Governance] - [Cloud Insight(Monitoring)]에 위치하고 있습니다.\n\n\n  \n  \n    \n  \n\n\n좀 더 쉽게 찾는 방법은 [콘솔] - [Services]에서 [검색] 기능을 이용하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n이용 신청\nCloud Insight 서비스는 이용 신청을 해야 사용할 수 있습니다. Classic, VPC 어떤 환경에서든 [Cloud Insight(Monitoring)] - [Subscription]에서 [상품 이용 신청] 버튼을 클릭해서 이용 신청을 합니다.\n\n\n  \n  \n    \n  \n\n\n대시보드\n이용 신청을 한 후에 [Dashboard] 메뉴에 가면 아래와 같이 현재 사용 중인 서비스 중에서 모니터링 가능한 서비스 리스트를 확인할 수 있습니다.\n또한 기본으로 제공되는 대시보드에서 확인할 수 있는 모니터링 항목을 각 서비스별로 고정되어 있습니다. \n추가적인 항목을 확인하려면 별도로 대시보드를 생성해야 하는데 이에 대해서는 아래쪽에서 확인해보겠습니다.\n\n일부 서비스의 경우 리스트에 나타날 때까지 시간이 걸릴 수도 있습니다. 여유있게 1시간 정도 후에 확인해보시면 됩니다.\n\n\n  \n  \n    \n  \n\n\nLoad Balancer 모니터링\n\n  \n  \n    \n  \n\n\nObject Storage 모니터링\n\n  \n  \n    \n  \n\n\nServer 모니터링\n위에서 설명했듯이 Server 제품도 GPU 관련 항목을 제외하면 5가지 정도의 기본 모니터링 항목을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n커스텀 대시보드\n좀 더 상세한 모니터링 데이터를 확인하려면 커스텀 대시보드가 필요하고 그전에 [상세 모니터링]을 설정해야 합니다. 서버 설정에서 [상세 모니터링 설정 변경] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[상세 모니터링 신청] 팝업에서 [예] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n대시보드 생성\n[Dashboard] 화면에서 [대시보드 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n생성 팝업에서 대시보드 이름과 설명을 입력합니다.\n\n  \n  \n    \n  \n\n\n생성된 대시보드에서 [위젯 추가] 버튼을 클릭해서 위젯을 추가합니다.\n\n  \n  \n    \n  \n\n\n위젯 이름을 입력하고, 종류는 [Time Series], [Pie Chart], [Table], [Index], [Markdown] 중에서 하나를 선택합니다.  여기서는 [CPU Usage]와 [Time Series]를 선택했습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 데이터 설정에서 CPU 사용률에 해당하는 [SERVER/avg_cpu_used_rto] 등 필요한 항목을 선택하고 [선택 항목 추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n항목을 추가하면 아래쪽 화면에 다음과 같이 리스트를 확인할 수 있습니다. 설정이 완료되었으면 [다음] 버튼을 클릭해 마지막 확인을 하고 생성을 완료합니다.\n\n\n  \n  \n    \n  \n\n\n위에서 추가한 [CPU Usage] 위젯과 함께 추가로 [Server - Load Average], [File System], [Memory Usage], [Net Work (Max In/Out bps)] 데이터를 확인할 수 있는 위젯을 추가하면 다음과 같은 대시보드를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n통보 대상자 등록\n이제 이벤트를 등록하고 알람을 통보 받을 대상자를 등록해보겠습니다.\n먼저 통보 대상자 그룹을 생성합니다.  [Cloud Insight(Monitoring)] - [Notification Recipient] 메뉴에서 [전체 대상자] 옆에 있는 [ + ] 버튼을 클릭하고 아래 입력칸에 그룹명을 입력합니다.\n\n\n  \n  \n    \n  \n\n\n네이버 클라우드 계정 생성을 할 때 기본으로 1명의 대상자가 등록됩니다. 해당 대상자를 위에서 생성한 그룹에 할당하기 위해 선택하고 [할당] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n그룹 할당 팝업에서 [할당] 버튼을 클릭합니다.\n\n  \n  \n    \n  \n\n\n대상자 리스트에서 해당 대상자에 그룹이 할당된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n이벤트 규칙 등록\n이제 이벤트를 등록해보겠습니다. [Cloud Insight(Monitoring)] - [Configuration] - [Event Rue]에서 [Event Rule 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n이벤트 규칙을 생성해서 감시가 필요한 상품을 선택합니다. 여기서는 [Sever(VPC)]를 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n[감시 대상 설정]에서 [전체 보기]를 선택하고, 감시 대상에 체크한 후 [다음] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n감시 항목 및 조건 설정에서 [전체 보기]를 선택하고, Server, Memory 등의 항목 중에서 원하는 항목을 선택합니다.\n여기서는 가장 많이 사용하는 [SERVER의 CPU 사용률]에 해당하는 [SERVER/avg_cpu_used_rto]를 선택하고, 90% 이상인 상태가 5분 이상 지속되면 경고 알림을 보내도록 설정했습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 감시 대상에서 설정한 이벤트가 발생했을 때 어떤 액션을 취할 것인가를 설정해보겠습니다.\n설정 가능한 액션은 [알림 메시지 발송], [Integration], [Cloud Functions], [Auto Scaling 정책] 중에서 선택할 수 있는데, 여기서는 [알림 메시지 발송]을 선택하겠습니다.\n통보 대상자 그룹을 선택하고, [Email]과 [SMS]중에서 원하는 것을 선택하고, [리마인드 알림 주기], [종료 알림 여부]를 설정한 후 [다음] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n마지막으로 이벤트 규칙 이름을 입력하고, 앞에서 설정한 내용들을 확인한 후에 [생성] 버튼을 클릭합니다.\n\n  \n  \n    \n  \n\n\n유지보수 계획 설정\n앞에서 설정한 이벤트 규칙이 업데이트나 점검 등의 유지보수가 진행되는 동안에도 작동되면 유지보수 시간 동안 쉼없이 통보 알람이 울리게 됩니다.\n이런 불편함이 없도록 Cloud Insight에서는 유지보수 계획 일정을 등록해두면 등록된 기간 동안에는 이벤트 규칙에 따른 통보알람이 울리지 않습니다.\n\n유지보수 일정은 아래와 같이 달력 행태나 리스트 형태로 확인 가능하며 [유지보수 계획 설정하기] 버튼으로 일정을 등록할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n제목을 입력하고, 작업 기간, 작업 대상, 디멘션을 선택하면 아래와 같이 선택한 대상과 디멘션이 리스트로 나타납니다.  보통 위에서 설정했던 이벤트 규칙에 해당하는 항목들을 선택하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n유지보수 계획을 설정하면 아래와 같이 일정에서 확인할 수 있으며 해당 기간 동안에는 이벤트 통보가 진행되지 않습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Cloud Insight 소개\n    \n      https://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightoverview\n    \n  \n  Cloud Insight 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightconsole\n    \n  \n  Cloud Insight Rule Template 설정 가이드\n    \n      https://docs.3rdeyesys.com/management/ncloud-management-cloud-insight-rule-template-guide.html"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-monitoring-win-perf-data-error-troubleshoot-html": {
						"id": "management-ncloud-management-monitoring-win-perf-data-error-troubleshoot-html",
						"title": "Windows 서버 모니터링 성능 정보 수집 오류 해결 방법",
						"categories": "",
						"url": " /management/ncloud_management_monitoring_win_perf_data_error_troubleshoot.html",
						"content": "개요\nNcloud(네이버 클라우드) Monitoring 서비스를 이용해 서버 시스템 자원들(CPU, Memory 등)의 성능 정보를 수집, 모니터링할 때 간혹 성능 정보가 수집되지 않는 경우가 발생하기도 합니다. \n특히 Windows 서버의 경우 Windows 자체 성능 테이블을 참조하여 데이터를 수집하기 때문에 Windows 자체 성능 테이블에 문제가 발생할 경우 성능 정보를 수집하지 못하게 됩니다.\n여기서는 Ncloud(네이버 클라우드) Classic 환경에서 Windows 서버의 모니터링 성능 정보가 수집되지 않을 때 해결 방법을 정리해보겠습니다.\n\n서버 환경\n\n  Classic 환경\n  Windows Server 2016 64bit R2 en\n\n\n오류 상황\n성능 정보가 수집되지 않을 경우 아래와 같이 Monitoring 정보에서 그래프가 특정 시점 이후로 끊겨서 표시되게 됩니다.\n\n\n  \n  \n    \n  \n\n\n서버 상태 확인\n\n서버 성능 정보 상태 확인\n우선 서버에 접속해서 서버의 작업 관리자 (Task Manager)를 실행, 성능(Performance)탭을 열고 CPU, Memory, Disk, Ethernet 등의 성능 정보가 제대로 표시되는지 확인합니다.\n\n\n  \n  \n    \n  \n\n\n모니터링 Agent 상태 확인\nNcloud(네이버 클라우드) 서버들에는 모니터링 정보를 수집하기 위한 Agent가 설치되는데 이 모니터링 Agent가 작동하고 있는지 확인합니다.\n\n아래와 같이 Windows PowerShell에서 서비스를 검색합니다. \nAgent가 표시되는지 Status가 Running 상태인지 확인합니다.\n\n&gt; Get-Service -name *nsight*\n\n\n\n  \n  \n    \n  \n\n\n문제 해결\n\n서버 성능 정보에 문제가 있는 경우\n혹시 서버 성능 정보가 제대로 표시 되지 않을 경우에는 cmd 창에서 아래 명령어로 성능 정보 테이블을 복구합니다.\n\n&gt; lodctr /R\n\n\n  \n  \n    \n  \n\n\n서버 성능 정보가 정상인 경우\n서버의 성능 정보가 제대로 표시되는데도 Monitoring 데이터가 제대로 수집되지 않는다면 cmd 창에서 모니터링 Agent를 다시 실행합니다.\n\n우선 Agent를 중지 시킵니다.\n&gt; sc stop noms_nsight\n\n\n  \n  \n    \n  \n\n\n그리고 Agent를 다시 실행 시킵니다.\n&gt; sc start noms_nsight\n\n\n\n  \n  \n    \n  \n\n\nMonitoring 정보 수집 복구\n문제가 해결되었다면 아래와 같이 Monitoring 정보가 제대로 수집되면서 그래프가 나타나기 시작합니다.\n\n\n  \n  \n    \n  \n\n\n복구 불가 상황\n위 방법대로 했는데에도 복구가 되지 않을 경우에는 다음 2가지 데이터를 모아서 Ncloud(네이버 클라우드) 고객센터로 문의하셔야 합니다.\n\n\n  모니터링 Agent 상태 정보\n  모니터링 Agent 로그\n\n\n모니터링 Agent 상태 정보 확인\n모니터링 Agent가 설치된 경로에서 아래의 상태 정보 확인 명령어를 실행합니다.\n\nC:\\Program Files (x86)\\NBP\\NSight&gt;noms_nsight.exe -status\n\n\n  \n  \n    \n  \n\n\n모니터링 Agent 로그\n모니터링 Agent가 설치된 경로에 있는 파일과 폴더를 모두 압축합니다.\n\nC:\\Program Files (x86)\\NBP\\NSight\\\n\n\n참고 URL\n\n  성능 수집 오류 해결 FAQ\n    \n      https://www.ncloud.com/support/faq/all/1292"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-sub-account-guide-html": {
						"id": "management-ncloud-management-sub-account-guide-html",
						"title": "Ncloud 서브 계정 (Sub Account) 생성 가이드",
						"categories": "",
						"url": " /management/ncloud_management_sub_account_guide.html",
						"content": "개요\nSub Account(서브 계정)는 네이버 클라우드의 서비스 자원을 여러 사용자가 동시에 이용, 관리해야 할 때 필요한 만큼만 권한을 부여해서 사용할 수 있게 해주는 서비스입니다.\nSub Account를 사용하면 사내 담당부서나 담당자별로 지정된 자원에만 접근하도록 하거나, 협력사에게 일부 접근권한을 부여해야 할 때 효과적입니다.\n\n특징\n네이버 클라우드의 Sub Account는 다음과 같은 특징이 있습니다.\n\n\n  별도의 로그인 페이지를 이용하여 접속\n  대시보드에서 서브 계정 수, 그룹 수, 정책 수, 접속 페이지 설정을 확인할 수 있음\n  그룹, 정책, 역할을 생성해 상세한 권한 설정을 할 수 있음\n  Access Key를 별도로 생성해서 사용할 수 있음\n\n\n주요 권한\n\n\n  \n    네이버 클라우드 메인 계정과 동일한 접근 권한\n  NCP_ADMINISTRATOR 정책을 부여하시면 메인 계정과 동일하게 네이버클라우드플랫폼 내 포털, 콘솔을 접근할 수 있습니다\n  \n  \n    네이버 클라우드 콘솔 내 모든 상품/서비스 접근 권한\n  NCP_INFRA_MANAGER 정책을 부여하시면 메인 계정과 동일하게 콘솔 내 모든 상품/서비스에 접근할 수 있습니다.\n  \n  \n    네이버 클라우드 콘솔 내 각 상품/서비스별 접근 권한\n  NCP_상품/서비스명_MANAGER/VIEWER 정책을 부여하시면 해당 상품/서비스에 접근할 수 있습니다.\n  \n  \n    네이버 클라우드 포털 내 마이페이지 “이용관리” 메뉴 접근 권한\n  NCP_FINANCE_MANAGER 정책을 부여하시면 포털 마이페이지 내 “서비스 이용내역/현황, 프로모션 내역, 청구 내역 추세” 메뉴에 접근할 수 있습니다.\n  \n\n\nSub Account 서비스\n[Sub Account] 서비스는 [콘솔] - [Services] - [Management &amp; Governance] - [Sub Account]에 위치하고 있습니다.\n\n\n  \n  \n    \n  \n\n\n좀 더 쉽게 찾는 방법은 [콘솔] - [Services]에서 [검색] 기능을 이용하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n서브 계정 생성\n[Sub Account] - [Sub Accounts]에서 [서브 계정 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서브 계정 생성 화면에서는 로그인 아이디, 이름, 이메일 주소를 우선 입력합니다.\n\n다음으로 접근 유형으로 [Console 접근]과 [API 접근]을 모두 허용할 것인지, 하나만 허용할 것인지 선택하고, \nConosole 접근의 경우에 지정한 IP대역에서만 접근하게 할 것인지, 모두 허용할 것인지도 선택합니다.\n\n휴대폰 문자인증 또는 이메일 인증 등의 2차 인증을 적용할 것인지도 선택합니다.\n\n\n  \n  \n    \n  \n\n\n비밀번호 설정\n\n마지막으로 로그인 비밀번호는 [자동 생성] 또는 [직접 입력] 중에서 선택할 수 있으며, 해당 서브 계정으로 로그인 시에 비밀번호를 변경하도록 할 것인지 선택할 수 있습니다.\n\n자동 생성\n\n  \n  \n    \n  \n\n\n\n  자동 생성된 비밀번호는 이 화면에서만 확인 가능하므로 반드시 별도 저장해야 합니다.\n\n\n  \n  \n    \n  \n\n\n직접 입력\n직접 입력하는 비밀번호는 영문자, 숫자, 특수 문자를 조합하여 8자~16자 이내로 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n계정 정책 추가\n생성된 서브 계정을 클릭하면 서브 계정 상세 설정 화면으로 이동합니다.\n\n\n  \n  \n    \n  \n\n\n서브 계정 상세 화면에서는 정책, 그룹, Access Key 등을 추가하고 관리할 수 있습니다.  우선 아래쪽에 있는 [정책] 탭에서 [개별 권한 추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 추가 화면에서는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책]과 사용자가 직접 정의하는 [사용자 정의 정책]이 있습니다.\n우선 [관리형 정책]에서 필요한 정책을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책이 워낙 많기 때문에 가능하면 위쪽의 검색 기능을 이용해서 정책을 찾는 것을 추천합니다.\n\n\n  \n  \n    \n  \n\n\n여기서는 네이버 클라우드의 플랫폼 내 모든 상품을 이용할 수 있는 권한인 [NCP_INFRA_MANAGER] 선택했고, 아래와 같이 추가된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n접속 환경 설정\n네이버 클라우드 서브 계정은 별도의 로그인 페이지가 존재하는데, \n[Sub Account] - [Dashboard]에서 서브 계정으로 접속하기 위한 페이지 주소를 입력할 수 있습니다.\n\n우선 서브 계정 로그인 페이지 접속 접속키를 입력합니다. 입력한 접속키를 바탕으로 로그인 페이지 URL이 결정됩니다.\n\n추천되는 접속키의 형태는 다음과 같습니다.\n\n  회사명 + α (ex: mycompany, samplecomsub)\n  서비스명 + α (ex: mygame, testservicesub)\n  회사명 + 서비스명 + α (ex: mycompanygame, mycomsamplegamesub)\n\n\n접속키는 영어 소문자와 숫자를 이용해서 3~20자로 구성해야 합니다.\n\n\n  \n  \n    \n  \n\n\n서브 계정 로그인 페이지 URL은 [주소 복사] 버튼을 클릭하면 복사할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 [미사용 세션 만료 설정]에서 [변경] 버튼을 클릭하면 로그인된 서브 계정이 아무 활동없이 미사용일 경우 지정한 시간 기준으로 자동 로그아웃이 되도록 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[비밀번호 만료 설정]에서 [변경] 버튼을 클릭해서 비밀번호 만료를 활성화할 경우 지정된 만료일을 초과했을 때 비밀번호를 변경해야만 접속 할 수 있습니다. \n활성화 하지 않았을 경우에는 90일이 지난 후에 비밀번호 변경 안내 팝업만 나타납니다.\n\n\n  \n  \n    \n  \n\n\n접속 - 로그인\n위에서 설정한 접속 페이지 [ https://www.ncloud.com/nsa/******] 에 접속하면 아래와 같이 서브 계정 로그인 화면을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nAPI Key 설정\n서브 계정에서 API Access Key를 사용해야 할 경우 먼저 API GateWay 접근 권한을 부여하고, 서브 계정 상세 화면 [Access Key]탭에서 [추가] 버튼을 클릭해 생성할 수 있습니다.\n\nAPI Gateway 접근 권한 설정\n우선, 서브 계정 리스트에서 해당 계정을 클릭해서 [서브 계정 세부 정보] 화면으로 이동합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [서브 계정 세부 정보] 화면에서 [수정] 메뉴 버튼을 클릭합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  [서브 계정 정보] 수정 화면에서 [접근 권한]에 있는 [API Gateway 접근]을 체크합니다. 그리고, 되도록이면 [지정된 Source에서만 접근 가능] 옵션을 선택하고, 지정된 IP 등을 추가하는 것을 권장합니다.\n\n\n\n  \n  \n    \n  \n\n\n\n  위 화면에서 [추가] 버튼을 클릭하면 아래와 같이 [접근 가능 Source 지정] 팝업이 나타나는데, IP를 입력하거나 VPC Server를 선택하면 됩니다.\n\n\n\n  \n  \n    \n  \n\n\nAPI Access Key 추가\n위에서 [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나고 [추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n계정 그룹 설정\n여러 개의 서브 계정을 묶어서 하나의 그룹으로 구성하면 해당 그룹의 서브 계정에 동일한 정책을 동시에 적용할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n사용자 정의 정책 생성\n서브 계정 정책에는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책] 외에도 사용자가 직접 설정하는 [사용자 정의 정책]도 사용할 수 있습니다. \n[Sub Account] - [Plicies]에서 [정책 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nVPC 환경에서 정책 생성\n정책 이름을 입력하고, VPC를 선택 후, 어떤 서비스 상품에 적용할 것인지 선택합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 Actions 항목에서는 읽기 권한인 View 또는 수정 권한인 Change를 선택하면 아래쪽에 리소스별로 상세한 권한 설정을 할 수 있는 화면이 나타납니다. \n모든 설정을 마치고, 아래쪽 [적용대상 추가] 버튼을 클릭하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nClassic 환경에서 정책 생성\nClassic 환경에서는 리소스별 상세 권한은 설정할 수 없고, View 또는 Change를 선택한 후에 [적용대상 추가] 버튼을 클릭하면 모든 권한이 추가됩니다.\n\n\n  \n  \n    \n  \n\n\n아래와 같이 선택한 서비스 상품에 대해 모든 리전, 모든 리소스에 선택한 권한이 지정됩니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Sub Account 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/ko/subaccount-overview\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2023-08-07\n          콘솔 UI, 텍스트 업데이트 내역 반영"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-sub-account-sts-temporary-accesskey-create-guide-html": {
						"id": "management-ncloud-management-sub-account-sts-temporary-accesskey-create-guide-html",
						"title": "STS 기간 제한 임시 API AccessKey 발급하기",
						"categories": "",
						"url": " /management/ncloud-management-sub-account-sts-temporary-accesskey-create-guide.html",
						"content": "개요\n클라우드 환경에서 서비스를 하다 보면 회사 내부의 다른 팀이나 외부 고객사에 서버나 오브젝트 스토리지 등 특정 서비스에 접근할 수 있는 API를 제공해야 하는 하는 경우가 생길 수 있습니다.\n그런데 Ncloud(네이버 클라우드)에서 제공되는 기본 API Access Key는 기간 제한이 없는 Access Key이기 때문에 외부에 제공하게 되면 보안측면에서 위험한 상황이 생길 수 있습니다. 이때 STS를 이용하면 Access Key를 제한된 기간 동안 일회성으로 제공하거나 유효 기간이 매우 짧은 Access Key를 반복적으로 제공하게 되면 훨씬 안전한 서비스를 유지할 수 있습니다.\n\nSTS란\n[STS (Secure Token Service)]는 Sub Account에 연관되어 제공되는 서비스로 Ncloud (네이버 클라우드) 내 리소스에 대한 액세스를 제어할 수 있는 기간 제한이 있는 임시 Access Key를 생성하는 서비스입니다.\n임시 Access Key는 기간 제한이 없는 서브 계정의 Access Key와 달리 제한된 기간 동안만 유효하며 MFA 등 추가 인증 수단을 적용할 수도 있습니다.\n\n다른 클라우드 서비스에서는 [Security Token Service(STS)], [임시 보안 자격 증명], [Security Token], [API One Day Token] 등으로 찾아볼 수 있습니다.\n\nSTS 임시 Access Key 특징\n\n  임시 Access Key는 서브계정만 생성할 수 있습니다. 메인 계정으로 생성하려고 할 때 발생하는 오류 메시지는 메인 계정 Access Key를 사용했을 때 에서 확인 가능합니다.\n  임시 Access Key는 만료 기한이 존재합니다.\n  Access Key는 몇 분에서 몇 시간까지 지속되도록 생성할 수 있습니다.\n  Access Key가 만료된 후 Ncloud는 더는 그 Access Key를 인식하지 못하거나 그 Access Key를 사용한 API 요청으로부터 이루어지는 어떤 종류의 액세스도 허용하지 않습니다.\n  임시 Access Key를 생성할 때, MFA 인증을 포함할 수 있습니다. Ncloud는 MFA 수단으로 OTP 인증을 제공합니다.\n  임시 Access Key가 만료된 후에는 해당 Access Key는 다시 사용할 수 없습니다.\n  임시 Access Key는 STS API를 호출해서 생성합니다.\n\n\nSub Account 생성\n\nSTS로 생성하는 임시 Access Key의 권한은 Sub Account의 권한을 그대로 상속 받기 때문에 해당 Access Key를 발급하기 위한 전용 Sub Account를 생성해야 합니다.\n\n\nSub Account를 생성하는 방법은 아래 가이드 문서를 참고하시면 됩니다.\n\n  Sub Account 생성 가이드: https://docs.3rdeyesys.com/management/ncloud_management_sub_account_guide.html\n\n\n\n  \n  \n    \n  \n\n\n사용자 정의 정책 생성\nSub Account에 적용할 정책을 기본으로 제공되는 관리형 정책이 아니라 STS 생성만 허가 하기 위한 사용자 정의 정책을 생성합니다.\n[Sub Account] - [Policies]에서 [사용자 정의 정책] 탭을 선택하고 [정책 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 정보 설정\n정책 이름과 설명을 입력합니다.\n\n\n  \n  \n    \n  \n\n\n적용 대상 설정\nSTS는 VPC, Classic 관계없이 적용되므로 플랫폼 항목은 그대로 두고 나머지 항목은 다음과 같이 설정합니다.\n\n  Product: Sub Account 선택\n  Actions: View 항목에서 STS 탭 선택하고, [getStsSessionToken]을 선택\n\n\n선택을 마친 후 [적용 대상 추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n적용 대상 목록\n선택한 내용을 마지막으로 확인하고 이상이 없으면 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n생성된 정책 확인\n정책이 생성되면 [사용자 정의 정책] 탭에 아래와 같이 정책이 나타납니다.\n\n\n  \n  \n    \n  \n\n\nSub Account에 정책 적용\n[Sub Account] - [Sub Accounts]에서 해당 Sub Account를 선택하고 [정책] 탭에서 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 추가\n정책 추가 팝업에서 위에서 만들었던 정책을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n적용된 정책 확인\nSub Account 상세 정보에서 정책 탭에 추가된 정책을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n기간 제한 없는 Access Key 발급\n여기서는 우선 기간 제한이 없는 Access Key를 발급하고 이 Access Key를 이용해서 나중에 기간 제한이 있는 임시 Access Key를 발급하겠습니다.\n[Sub Account] - [Sub Accounts] - [Access Key] 탭에서 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nAccess Key 추가\n팝업에서 [추가] 버튼을 클릭해 새로운 Access Key를 추가합니다.\n\n\n  \n  \n    \n  \n\n\nAccess Key 확인\n[Access Key] 탭에서 추가된 Access Key와 Secret Key를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n기간 제한 임시 Access Key 발급\n임시 Access Key를 발급 받기 위해서는 STS API를 호출해야 합니다.\nSTS API를 이용해 기간 제한이 있는 임시 Access Key를 발급 받으면 아래와 같은 정보를 얻을 수 있습니다.\n\n  Access Key\n  Secret key\n  Create Time: Key 생성 날짜\n  Expire Time: Key 만료 날짜\n  Use MFA: MFA (MultiFactorAuthentication) 사용 여부\n\n\n\n  \n  \n    \n  \n\n\nAPI 호출 방법\nNcloud API 호출 방법에 대한 기본 가이드는 아래 문서를 확인하시면 됩니다.\n\n  PHP로 Ncloud API 호출 방법: https://docs.3rdeyesys.com/api/ncloud_api_call_php_sample.html\n  C#으로 Ncloud API 호출 방법: https://docs.3rdeyesys.com/api/ncloud_api_call_csharp_sample.html\n  Python으로 Ncloud API 호출 방법: https://docs.3rdeyesys.com/api/ncloud_api_call_python_sample.html\n\n\n임시 Access Key 발급 PHP 샘플 예제\n&lt;?php\t\n  $unixtimestamp =  round(microtime(true) * 1000);\n  $ncloud_sub_account_accesskey = \"{기간 제한 없는 Sub Account API Access Key}\";\n  $ncloud_sub_account_secretkey = \"{기간 제한 없는 Sub Account API Secret Key}\";\t\n  $apicall_method = \"POST\";\n  $api_server = \"https://sts.apigw.ntruss.com\";\n  $api_url = \"/api/v1/credentials\";\n  $msg_signature = \"\";\n\n  $array_postvars = Array (\t\t\t\n    \"durationSec\" =&gt; 900\n  );\n  $postvars = json_encode($array_postvars);\n\n  $space = \" \";\n  $new_line = \"\\n\";\n  $message = \n    $apicall_method\n    .$space\n    .$api_url\n    .$new_line\n    .$unixtimestamp\n    .$new_line\n    .$ncloud_sub_account_accesskey;\t\n  $msg_signature = base64_encode(hash_hmac('sha256', $message, $ncloud_sub_account_secretkey, true));\n\n  $http_header = array();    \n  $http_header[0] = \"Content-Type:application/json; charset=utf-8\";\n  $http_header[1] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\n  $http_header[2] = \"x-ncp-iam-access-key:\".$ncloud_sub_account_accesskey.\"\";\n  $http_header[3] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\n\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\t\n  curl_setopt($ch, CURLOPT_POST, TRUE);\n  curl_setopt($ch, CURLOPT_POSTFIELDS, $postvars);\n  $json_response = curl_exec($ch);\n  curl_close($ch);\n\n  if ($json_response)\n  {\n    $obj_array = json_decode($json_response, 1);\n\n    $sts_accesskey= $obj_array[\"accessKey\"];\n    $sts_secretkey= $obj_array[\"keySecret\"];\n    $sts_createtime= $obj_array[\"createTime\"];\n    $sts_expiretime= $obj_array[\"expireTime\"];\n    $sts_use_mfa= $obj_array[\"useMfa\"];\t\n  }\n?&gt;\n\n\nPHP 예제 코드 상세 설명\n위 전체 소소코드 중에서 중요한 부분만 다시 살펴보겠습니다.\n\n기간 제한 없는 API Key\n아래 2가지 변수에는 위쪽 기간 제한 없는 Access Key 발급 에서 생성했던 기간 제한 없는 Sub Account API Access Key와 Secret Key를 입력하시면 됩니다.\n\n&lt;?php\t  \n  $ncloud_sub_account_accesskey = \"{기간 제한 없는 Sub Account API Access Key}\";\n  $ncloud_sub_account_secretkey = \"{기간 제한 없는 Sub Account API Secret Key}\";\n?&gt;\n\n\nSTS API 호출 서버와 URL\n\nSTS API 서버와 URL은 아래와 같습니다.\n그리고 API 호출 방식은 POST 방식입니다.\n&lt;?php\n  $apicall_method = \"POST\";\n  $api_server = \"https://sts.apigw.ntruss.com\";\n  $api_url = \"/api/v1/credentials\";\n?&gt;\n\n\nRequest 파라미터\nSTS 생성을 위한 Request 파라미터는 총 3가지입니다.\n여기서는 만료시간을 나타내는 durationSec 값만 설정해보았습니다.\n\n\n  \n    \n      파라미터\n      필수여부\n      타입\n      설명\n    \n  \n  \n    \n      durationSec\n      N\n      Integer\n      accessKey 지속 시간(초) default: 43,200 (12시간) min: 900 (15분) max: 129,600 (36시간)\n    \n    \n      serialNumber\n      N\n      String\n      OTP 디바이스 nrn 또는 시리얼 번호\n    \n    \n      tokenCode\n      N\n      Integer\n      OTP 인증 번호\n    \n  \n\n\n&lt;?php\n  $array_postvars = Array (\t\t\t\n    \"durationSec\" =&gt; 900\n  );\n?&gt;\n\n\nAPI Header 설정\nHeader를 설정할 때 다른 값들은 보통의 API 호출할 때와 동일한데\nSTS로 임시 Access Key를 생성할 때에는 Content-Type과 charset을 포함해야 합니다.\n\n&lt;?php\n  $http_header = array();    \n  $http_header[0] = \"Content-Type:application/json; charset=utf-8\";\n  $http_header[1] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\n  $http_header[2] = \"x-ncp-iam-access-key:\".$ncloud_sub_account_accesskey.\"\";\n  $http_header[3] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\n?&gt;\n\n\nAPI 호출\nSTS API를 호출할 때에는 반드시 POST 방식으로 호출해야 합니다.\n\n&lt;?php \n  curl_setopt($ch, CURLOPT_POST, TRUE);\n  curl_setopt($ch, CURLOPT_POSTFIELDS, $postvars);\n?&gt;\n\n\nAPI 호출 테스트\nSTS로 생성한 기간 제한 임시 Access Key로 Ncloud API를 호출하는 테스트를 진행해보겠습니다.\n\n테스트로 호출할 API 정보는 다음과 같습니다.\n\n  getServerInstanceList: 사용 중인 서버 인스턴스(VM) 리스트를 조회\n\n\n권한 없이 호출\n우선 Sub Account에 아무 권한도 주지 않은 상태에서 호출해보면 다음과 같은 결과 메시지를 확인할 수 있습니다.\n\n returnMessage:: You do not have authority about action: [VPCSever:View/GetServerInstanceList].\n\n\n  \n  \n    \n  \n\n\n권한 정책 추가\n이제는 권한을 추가해서 테스트 해보겠습니다.\n[Sub Account] - [Sub Accounts]에서 Sub Account를 선택하고 [정책] 탭에서 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n정책 추가\n정책 추가 팝업에서 연관 상품에서 [Server (VPC)]를 선택하면 나타나는 정책 리스트에서 [NCP_VPC_SERVER_VIEWER] 정책을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n추가된 정책 확인\n정책 추가 후에 Sub Account 상세 정보 화면에서 추가된 정책을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n권한 추가 후 호출\n권한 정책을 추가 후에 호출해보면 아래와 같이 호출이 성공하고 Success 메시지가 리턴되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nAccess Key 기한 만료\nSTS로 기간 제한 있는 임시 Access Key를 만들때 설정했던 만료기한이 지난 후에 해당 Access Key를 사용해 API를 호출하면 아래와 같이 인증 실패 메시지가 리턴됩니다.\n\n Error:: errorCode: 200, message:Authentication Failed, details: This account is not allowed.\n\n\n  \n  \n    \n  \n\n\n메인 계정 Access Key를 사용했을 때\n처음에 설명한 것처럼 STS 임시 Access Key는 Sub Account로만 생성할 수 있습니다.\n혹시나 메인 계정으로 생성하려고 하면 아래와 같이 오류 메시지가 리턴됩니다.\n\n Error:: errorCode: 401, message:접근 권한 없음\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Sub Account 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/management-management-4-1\n    \n  \n  STS API 사용 가이드\n    \n      https://api.ncloud-docs.com/docs/management-sts"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-webservice-monitoring-system-guide-html": {
						"id": "management-ncloud-management-webservice-monitoring-system-guide-html",
						"title": "Web service Monitoring System 사용 가이드",
						"categories": "",
						"url": " /management/ncloud_management_webservice_monitoring_system_guide.html",
						"content": "개요\nNcloud Web service Monitoring System은 고객의 웹 서비스를 실제 사용자 환경에서 모니터링하는 서비스입니다.\n웹 서비스 URL을 입력하여 실시간으로 테스트를 진행할 수 있고, 스케줄을 등록하여 반복적으로 모니터링을 할 수도 있으며, 오류 발생 시 알람을 받을 수도 있습니다.\n\n이용신청\nNcloud 콘솔 [Management] - [Web service Monitoring System] - [Subscription]에서 이용 신청을 합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 [Web Monitoring]에서 [서비스 등록] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n스텝 작성\n\n테스트 환경 선택\n모니터링 설정 전에 모니터링 유형, 서비스 유형, 지역 선택 등의 테스트를 진행할 환경을 설정합니다.\n\n스텝 작성\n스텝은 여러 가지를 추가할 수 있으나 여기서는 간단하게 URL만 추가해서 진행하겠습니다. \nURL 접속 설정에서는 모니터링 대상이 되는 METHOD (GET, POST, PUT, DELETE, HEAD) 선택 및 URL을 입력합니다.\n\n\n  \n  \n    \n  \n\n\n- 모니터링 유형에서 URL을 선택해도 스텝을 추가하면 자동으로 SCENARIO로 변경됩니다. - 지역 선택은 테스트 환경에서는 1곳만 선택이 가능하고, 다음 단계인 서비스 설정에서 원하는 지역을 모두 선택할 수 있습니다.\n\n테스트\n모니터링 할 URL을 입력하고 [테스트 시작] 버튼을 클릭하면 아래와 같이 테스트 결과 메시지와 URL 접속 화면 즉, 오브젝트 탐색기가 나타납니다.\n\n\n  \n  \n    \n  \n\n\nURL 접속 옵션\nURL 설정에서 추가 설정이 필요할 경우 [옵션] 버튼을 클릭하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n옵션에서는 Header, Body, Cookie 등의 Request 값을 설정해서 테스트에 적용할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n스텝 추가\n이번 설정에서는 URL 접속만 테스트하는 것으로 진행하지만, 추가로 스텝을 추가해서 다양한 모니터링 설정을 하고자 할 경우에는 [스텝 추가] 버튼을 클릭하면 됩니다.\n추가 가능한 스텝에는 [대기 시간], [마우스 클릭], [텍스트 입력], [유효성 검사 (오브젝트 찾기)], [유효성 검사 (텍스트 찾기)], [팝업 창 이동], [사용자 정의 스크립트 실행] 등이 있습니다.  자세한 내용은 아래쪽 스텝 추가 상세 내용에서 다시 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n오류 확인\n혹시 테스트 결과에 Success가 아닌 Error가 나타났을 경우 아래쪽 [오류 로그]에서 어떤 오류인지 자세히 확인 가능합니다.\n특별한 문제가 없다면 [다음] 버튼을 클릭해서 다음 단계로 이동합니다.\n\n\n  \n  \n    \n  \n\n\n오류 항목 필터 추가\n오류 유형이 URL, JavaScript인 경우에는 향후 테스트에서 오류로 분류되지 않기를 바라는 항목은 아래 스샷처럼 [+ 추가] 버튼을 클릭해 필터에 추가하면 오류로 측정되지 않도록 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서비스 설정\n서비스에 필요한 설정을 선택합니다.\n\n  모니터링 실행 주기: 1분이 기본값이며, 5분, 10분을 선택할 수 있습니다.\n  측정 지역: 국내, 홍콩, 일본, 싱가콜, 미국(서부), 독일 중에서 최소 1곳 이상을 선택하면 됩니다.\n  Request Timeout: 요청 대기 시간을 5초, 10초, 30초 중에서 선택합니다.\n  Run Timeout: 모니터링 전체 시나리오 실행 시간을 30초, 40초, 50초, 60초 중에서 선택합니다.\n\n\n\n  \n  \n    \n  \n\n\n서비스 등록\n앞에서 선택한 설정을 최종 확인하고, 서비스 이름을 적당히 입력한 후에 [서비스 등록] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n모니터링 확인\n서비스 등록을 완료하면 모니터링 화면으로 이동하게 되고, 어느 정도 시간이 지나면 아래와 같이 모니터링 결과가 그래프로 나타납니다.\n\n\n  \n  \n    \n  \n\n\n알람 설정\n모니터링 중에 오류가 발생할 경우 SMS나 Email로 알람을 받도록 설정할 수 있습니다. 알람 설정은 모니터링 화면에서 왼쪽 설정 버튼을 클릭하면 나타나는 [알람 설정] 메뉴를 클릭하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n알람 설정 항목\n\n  알람 ON/OFF: 알람을 끄거나 켤 수 있습니다.\n  발생 조건: 기본 값은 3분 이내에 3건 이상 오류가 발생했을 경우 알람 메시지를 보내게 되어 있으며 원하는 값으로 변경하면 됩니다.\n  발송 기준: 일정 시간에 1번씩 알람을 받을 것인지, 조건에 해당할 때 마다 바로 받을 것인지 설정합니다.\n  SMS/Email: 통보 대상 관리에 등록된 대상을 선택하고, Email과 SMS를 선택합니다.\n  Webhook: SMS나 Email외에 Slack등의 Webhook URL을 등록해서 알람을 받을 수도 있습니다.\n\n\n\n  \n  \n    \n  \n\n\n일시 정지\n모니터링 화면 오른쪽 상단에 있는 추가 설정에서 모니터링에 대한 [일시 정지], [스텝 수정], [삭제]를 선택할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n모니터링 상세 결과\n모니터링 화면 상단에 있는 서비스 이름을 클릭하면 상세 모니터링 내용을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n모니터링 상세 결과 화면에서는 선택한 기간의 상세 그래프와 각각의 모니터링 결과 리스트를 모두 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n성공 상세 결과\n모니터링 결과 리스트에서 Success로 나오는 항목의 날짜를 클릭하면 상세 내역을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n성공했을 경우에는 아래와 같이 간단하게 성공 내역이 표시됩니다.\n\n\n  \n  \n    \n  \n\n\n오류 상세 결과\n모니터링 결과 리스트에서 Error로 나오는 항목의 날짜를 클릭하면 오류 상세 내역을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n오류 상세 결과 화면에서는 어떤 스텝에서 어떤 유형의 오류가 발생했는지 로그까지 자세히 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n지역, 필터 설정\n지역 설정을 변경하거나 필터링할 내용을 설정하고자 할 경우에는 설정에서 [지역 설정], [필터 설정]을 변경하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n지역 설정\n초기에 서비스 설정에서 선택했던 모니터링 지역을 지역 설정에서 원하는 지역으로 변경할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n필터 설정\n모니터링에서 발생한 오류나 이벤트 중에서 알람을 받고 싶지 않은 것이 있다면 필터링에 추가해서 알람 대상에서 제외할 수 있습니다.\n\n\n  URL: 입력한 로그와 완벽히 일치하는 로그를 필터링하고 싶을 때\n  URL_PREFIX: 입력한 로그를 포함하고 있는 모든 로그를 필터링하고 싶을 때\n  JS: 입력한 스크립트와 완벽히 일치하는 스크립트를 필터링하고 싶을 때\n  JS_PREFIX: 입력한 스크립트를 포함하고 있는 모든 스크립트를 필터링하고 싶을 때\n\n\n\n  \n  \n    \n  \n\n\n스텝 추가 상세 내용\n[스텝 추가]에서 추가 가능한 스텝은 다음과 같습니다.\n\n\n  URL 접속 : 입력한 URL에 접속 합니다.\n  대기 시간 : 입력한 시간 만큼 대기 후에 진행합니다.\n  마우스 클릭 : 설정된 대상을 찾아 클릭 합니다.\n  텍스트 입력 : 설정된 대상을 찾아 텍스트를 입력 합니다.\n  유효성 검사 (오브젝트 찾기) : 페이지에서 설정된 오브젝트를 찾습니다.\n  유효성 검사 (텍스트 찾기) : 페이지에서 설정된 텍스트를 찾습니다.\n  팝업 창 이동 : 팝업이 생성된 경우 해당 팝업으로 대상을 전환하여 모니터링 할 수 있습니다.\n  사용자 정의 스크립트 실행 : 사용자가 설정한 Javascript를 실행합니다.\n\n\n\n  \n  \n    \n  \n\n\n스텝 추가 상세 가이드\n위 스텝 추가 항목들에 대한 상세 가이드는 아래 문서에서 확인 가능합니다.\n\n\n  Web service Monitoring System 스텝 추가 상세 가이드\n\n\n참고 URL\n\n  Ncloud Web service Monitoring System 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/management-management-3-1"
					}
					
				
			
		
			
				
					,
					
					"management-ncloud-management-webservice-monitoring-system-step-guide-html": {
						"id": "management-ncloud-management-webservice-monitoring-system-step-guide-html",
						"title": "Web service Monitoring System 스텝 추가 상세 가이드",
						"categories": "",
						"url": " /management/ncloud_management_webservice_monitoring_system_step_guide.html",
						"content": "개요\nNcloud Web service Monitoring System의 모니터링 스텝에는 URL 접속 외에 텍스트 입력, 오브젝트 클릭 등이 있는데 구체적으로 어떻게 활용할 수 있는지 확인해보겠습니다.\n\n스텝 종류\n[스텝 추가]에서 추가 가능한 스텝은 다음과 같습니다.\n\n\n  URL 접속 : 입력한 URL에 접속 합니다.\n  대기 시간 : 입력한 시간 만큼 대기 후에 진행합니다.\n  마우스 클릭 : 설정된 대상을 찾아 클릭 합니다.\n  텍스트 입력 : 설정된 대상을 찾아 텍스트를 입력 합니다.\n  유효성 검사 (오브젝트 찾기) : 페이지에서 설정된 오브젝트를 찾습니다.\n  유효성 검사 (텍스트 찾기) : 페이지에서 설정된 텍스트를 찾습니다.\n  팝업 창 이동 : 팝업이 생성된 경우 해당 팝업으로 대상을 전환하여 모니터링 할 수 있습니다.\n  사용자 정의 스크립트 실행 : 사용자가 설정한 Javascript를 실행합니다.\n\n\n\n  \n  \n    \n  \n\n\n스텝 추가 예시\n기본 스텝은 URL 접속 1가지 이지만 위에서 살펴본 여러 스텝들 중에서 몇가지를 아래 스샷처럼 추가해볼 수 있습니다.\n스텝을 추가하고, [테스트 시작]을 클릭하면 아래쪽에 테스트 결과가 각 스텝별로 결과가 Success, Error로 표시됩니다.\n\n\n  \n  \n    \n  \n\n\n스텝 상세 설명\n각 스텝별로 어떤 역할을 하고, 어떤 설정값을 입력해야 하는지 확인해보겠습니다.\n\nURL 접속\n모니터링 대상이 되는 URL을 입력하고 접속 방식 (GET, POST, PUT, DELETE, HEAD)을 선택합니다.\n옵션 버튼을 클릭하면 요청 옵션(Header, Body, Cookie) 값을 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n대기 시간\n입력한 시간 만큼 대기했다가 다음 스텝을 진행합니다.\n\n\n  \n  \n    \n  \n\n\n마우스 클릭\n지정한 대상을 찾아서 클릭하고 입력한 시간 만큼 대기후 클릭 Action을 실행합니다.\n아래 예시에서는 search-input-main이라는 id를 가진 Input Box를 찾아서 mysql이라는 텍스트를 입력하게 됩니다.\n\n  \n  \n    \n  \n\n\n텍스트 입력\n지정한 Input 오브젝트를 찾아서 지정한 텍스트를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n유효성 검사 (오브젝트 찾기)\n접속한 페이지에서 지정한 오브젝트를 찾습니다. 여기서 [존재 유/무] 항목은 true, false에 따라 Success와 Error가 결정됩니다.\n\n예를 들어 id=security인 오브젝트를 찾기 하는 경우 [존재 유/무] 항목 설정에 따른 결과는 다음과 같습니다.\n\n  true 설정: id=security인 오브젝트를 찾았을 경우 Success, 못 찾았을 경우 Error\n  false 설정: id=security인 오브젝트를 찾았을 경우 Error, 못 찾았을 경우 Success\n\n\n\n  \n  \n    \n  \n\n\n유효성 검사 (텍스트 찾기)\n접속한 페이지에서 지정한 텍스트를 찾습니다. 여기서 [존재 유/무] 항목은 true, false에 따라 Success와 Error가 결정됩니다.\n\n예를 들어 Update 텍스트를 찾기 하는 경우 [존재 유/무] 항목 설정에 따른 결과는 다음과 같습니다.\n\n  true 설정: Update 텍스트를 찾았을 경우 Success, 못 찾았을 경우 Error\n  false 설정: Update 텍스트를 찾았을 경우 Error, 못 찾았을 경우 Success\n\n\n\n  \n  \n    \n  \n\n\n팝업창 이동\n해당 페이지에 접속했을 때 팝업창이 생성되는 경우 해당 팝업창으로 이동해서 모니터링을 진행할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\n사용자 정의 스크립트 실행\n직접 작성한 자바스크립트를 실행시켜서 결과를 확인할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\n[작성하기] 버튼을 클릭하면 아래와 같이 사용자 정의 자바스크립트를 작성할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n마우스 클릭으로 스텝 추가하기\n스텝을 추가하는 방법은 위에서 확인한 것처럼 직접 설정값을 입력하는 것 말고도 [테스트 시작] 버튼 클릭 후에 오른쪽 하단에 나타나는 URL 미리 보기 화면 즉, 오브젝트 탐색기에서 직접 마우스 클릭으로 스텝을 추가할 수도 있습니다.\n\n우선 오브젝트 탐색기에 마우스를 가져가면 아래 스샷처럼 선택 가능한 오브젝트들이 붉은 색 선택 영역으로 표시됩니다.\n이때 해당 오브젝트를 클릭하면 아래 스샷처럼 스텝 추가 팝업 창이 나타납니다.\n현재 오브젝트 탐색기에서 마우스 클릭으로 추가 가능한 스텝은 3가지가 있습니다.\n\n\n  마우스 클릭\n  텍스트 입력\n  유효성 검사 (오브젝트 찾기)\n\n\n\n  \n  \n    \n  \n\n\n사용 기본 가이드\n스텝 추가 상세 가이드 외에 Web service Monitoring System 사용 기본 가이드는 아래 문서에서 확인 가능합니다.\n\n\n  Web service Monitoring System 사용 기본 가이드\n\n\n참고 URL\n\n  Ncloud Web service Monitoring System 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/management-management-3-1"
					}
					
				
			
		
			
				
					,
					
					"media-ncloud-media-video-player-sample-html": {
						"id": "media-ncloud-media-video-player-sample-html",
						"title": "Video Player 구현하기 샘플 예제",
						"categories": "",
						"url": " /media/ncloud_media_video_player_sample.html",
						"content": "Video Player 상품 서비스 종료\n\n 서비스 종료: \n그 동안 네이버 클라우드에서 제공해왔던 Video Player 서비스가 2023년 7월 31일부로 서비스를 종료하게 되었습니다. \n이후로는 이 보다 업그레이드 된 [Video Player Enhancement] 상품을 이용해주시면 감사하겠습니다.\n\n\n\n⁃  Video Player Enhancement 사용 가이드\n\n\n개요\n네이버 클라우드 비디오 플레이어는 최신의 네이버 미디어 플레이어를 기반으로 개발된 클라우드 전용 상품으로 \n네이버 동영상 서비스에 적용되어 수 많은 성공사례를 가지고 있는 최신의 네이버 플레이어를 손쉽고 빠르게 고객의 미디어 서비스에 적용할 수 있습니다.\n\n플레이어 생성하기\n우선은 네이버 클라우드 콘솔에서 js 파일로 구성된 플레이어를 생성하는 과정부터 살펴보겠습니다.\n\n[네이버 클라우드 콘솔] - [Video Player]에서 [플레이어 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n플레이어 이름, 유-무료 상품(현재는 무료만 선택 가능), 플레이어 사이즈, 버전, 플레이어가 저장될 Object Storage 위치 등을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n재생 속도 조절 등의 기능을 설정하고, 우클릭 메뉴 바로가기를 추가할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\n자동 재성이나 대역폭 등의 재생 관련 설정을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n마지막으로 현재까지 선택한 설정을 확인하고, 플레이어 미리보기를 한 후에 [플레이어 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n생성된 플레이어 js 파일의 경로를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\njs 파일이 저장된 Object Storage에서도 확인 가능합니다.\n\n\n  \n  \n    \n  \n\n\n플레이어 구현하기\n생성된 플레이어는 자바스크립트 js 파일이므로 html 파일을 만들어서 플레이어를 구현해야 합니다.\n\n플레이어 JavaScript 소스 예시\n\n  var player = new ncplayer('divVideoPlayer', {\n    playlist: \"http://example.com/myVideo.mp4\"\n  });\n\n  player.play();\n\n\n플레이어 html 소스 예시\n아래 예시에서는  컨트롤러 표시, 자동 재생 안함, 음소거, 가로 크기 1024로 옵션을 설정했습니다. 상세한 옵션을 아래쪽에서 다시 살펴보겠습니다.\n\n&lt;!doctype html&gt;\n&lt;html lang=\"kr\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Video Player Sample&lt;/title&gt;\n\n    &lt;script src=\"https://kr.object.ncloudstorage.com/플레이어 파일명.js\"&gt;&lt;/script&gt;\n  &lt;/head&gt;\n\n  &lt;body&gt;\n\n    &lt;div style=\"text-align:center\"&gt;\n      &lt;div id=\"divVideoPlayer\" name=\"divVideoPlayer\"&gt;&lt;/div&gt;\n    &lt;/div&gt;\n\n     &lt;script&gt;\n\n      var player = new ncplayer('divVideoPlayer', {\n        controls: true,\n        autostart: false,\n        mute: true,\n        width: 1024,\n        playlist: [\n        {\n          file: 'https://kr.object.ncloudstorage.com/재생할 동영상 파일명.mp4',\n        },\n        ],\n      });\n\n      player.play();\n\n     &lt;/script&gt;\n\n   &lt;/body&gt;\n&lt;/html&gt;\n\n\n플레이어 구현 예시\n위 html 소스대로 플레이어를 구현해서 웹브라우져에서 확인해보면 다음과 같이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n플레이어 상세 옵션\n플레이어 상세 옵션을 간단하게 정리해보겠습니다. 좀 더 자세한 설명은 아래 링크에 있는 네이버 클라우드 가이드 문서를 참고하시면 됩니다.\n\n\nvar player = new ncplayer('divVideoPlayer', {\n  controls: true,\n  autostart: false,\n  mute: true,\n  width: 1024,\n  playlist: [\n    { file: 'https://CDN도메인/example_video_01.mp4' },\n    { file: 'https://CDN도메인/example_video_02.mp4' },\n    { file: 'https://CDN도메인/example_video_03.mp4/index.m3u8' }\n  ],\n  });\n\n\n\n\n  \n    \n      PROPERTY\n      TYPE\n      DESCRIPTION\n      DEFAULT\n    \n  \n  \n    \n      playlist\n      string/array\n      재생하고자 하는 video 정보 (단일 경로 또는, 여러 경로를 전달)\n      -\n    \n    \n      autostart\n      boolean\n      player 시작 시, video를 자동으로 재생 (브라우저의 자동재생 정책을 따름)\n      false\n    \n    \n      mute\n      boolean\n      player 시작 시, video를 자동으로 음소거 상태로 설정\n      false\n    \n    \n      controls\n      boolean\n      player 제어를 위한 컨트롤의 표시 여부 결정\n      true\n    \n    \n      autoPause\n      boolean\n      창이 전환되거나 최소화되었을 때, 자동으로 player를 정지 상태로 만듦\n      false\n    \n    \n      aspectRatio\n      string\n      player의 가로X세로 비율 지정, “width:height” 형식으로 전달해야 합니다.\n      -\n    \n    \n      width\n      number\n      player의 가로 사이즈 고정\n      -\n    \n    \n      height\n      number\n      player의 세로 사이즈 고정\n      -\n    \n    \n      playbackRate\n      boolean\n      video 의 재생속도 조절, 1.0보다 낮으면 느려지고, 1.0보다 높으면 빠르게 재생\n      1.0\n    \n    \n      repeat\n      boolean\n      video의 반복 재생 여부 결정\n      false\n    \n    \n      about\n      object\n      마우스 우클릭 시 표시되는 바로가기 정보 수정\n      false\n    \n  \n\n\n참고 URL\n\n  Video Player 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/videoplayer-videoplayerguide\n    \n  \n  Video Player Demo 가이드\n    \n      https://guide.ncloud-docs.com/docs/videoplayer-videoplayerdemo"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-global-dns-guide-html": {
						"id": "networking-ncloud-networking-global-dns-guide-html",
						"title": "Global DNS 사용 가이드 - 도메인 추가",
						"categories": "",
						"url": " /networking/ncloud_networking_global_dns_guide.html",
						"content": "개요\nDNS 서버는 개인이 직접 운영하기 어려운데, 네이버 클라우드 Global DNS를 이용하면 도메인 설정 등을 쉽고 편하게 사용할 수 있습니다.\n\n도메인 추가\n네이버 클라우드는 도메인 구매/등록을 지원 하지 않습니다. 그러므로 가비아, 아이네임즈, 닷네임코리아 등 전문 도메인 등록 기관에서 도메인을 구입 하셔야 합니다.\n새로 구입한 도메인 혹은 기존 도메인을 [네이버 클라우드 콘솔] - [Networking] - [Global DNS] 메뉴에서 [도메인 추가] 버튼을 클릭해 도메인주소를 입력합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n다음과 같이 생성된 도메인 정보에서 네임서버의 주소를 확인합니다.\n\n\n  \n  \n    \n  \n\n\n도메인을 구입한 등록기관 사이트에서 해당 도메인의 네임서버를 위에서 확인한 네이버 클라우드 Global DNS에서 제공하는 네임서버 정보로 등록합니다.\n\n\n  \n  \n    \n  \n\n\n레코드 추가\n레코드를 추가하려면 도메인 정보에서 [레코드 추가]를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n추가하려고 하는 레코드 즉, 호스트명과 IP 주소를 입력합니다,\n\n\n  \n  \n    \n  \n\n\n추가된 레코드를 도메인 정보에서 아래와 같이 확인한 후, [설정 적용] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[배포] 버튼을 클릭해 변경된 정보를 배포-적용합니다.\n\n\n  \n  \n    \n  \n\n\n네이버 클라우드 네임서버를 클라이언트의 DNS로 설정하지 않은 경우, 레코드의 추가/변경 내역이 반영되는데 전파시간이 소요될 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-networking-12-1"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-load-balancer-acg-html": {
						"id": "networking-ncloud-networking-load-balancer-acg-html",
						"title": "Classic Load Balancer 운영을 위한 ACG 설정 방법",
						"categories": "",
						"url": " /networking/ncloud_networking_load_balancer_acg.html",
						"content": "개요\nLoad Balancer가 정상적으로 동작하기 위해서는 Load Balancer –&gt; Server의 지정된 포트로 접근할 수 있어야 합니다.\n그러기 위해서는 Server의 ACG에 Load Balancer가 접근할 수 있도록 권한을 설정해주어야 하는데, 여기서는 네이버 클라우드의 Classic Load Balancer를 운영할 때 ACG 설정을 어떻게 하는가에 대한 내용을 정리해보겠습니다.\n\n서버연결 실패 상황\n서버 등록하고 Load Balancer의 다른 설정들을 모두 올바르게 했는데도 아래와 같이 서버연결 상태가 실패로 나타나고 Load Balancer는 동작이 정지되는 경우가 있습니다.\n이런 경우가 바로 ACG에 Load Balancer의 접근 권한을 설정하지 않았을 때 입니다.\n\n\n  \n  \n    \n  \n\n\nACG 권한 설정\nACG에 Load Balancer가 접근할 수 있도록 권한을 설정하려면 접근소스에 아래와 같이 입력합니다.\n접근소스 : ncloud-load-balancer\n\n\n그 외에 프로토콜과 허용포트도 지정된 정보를 입력하고 추가를 하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n서버연결 성공\nACG에 접근권한을 설정하고 나서 잠시 기다리면 Load Balancer가 서버에 접근시도를 하고 정상 접근이 되면서 서버연결 상태가 성공으로 바뀌고 Load Balancer도 정상 작동하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-loadbalancer-classiclbconsole.html"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-load-balancer-application-lb-html": {
						"id": "networking-ncloud-networking-load-balancer-application-lb-html",
						"title": "VPC 환경에서 Application Load Balancer 생성하기",
						"categories": "",
						"url": " /networking/ncloud_networking_load_balancer_application_lb.html",
						"content": "개요\n네이버 클라우드 VPC 환경의 대표적인 Load Balancer인 Application Load Balancer 를 생성하는 가이드입니다.\nVPC와 Subnet을 생성하고, 테스트를 위한 서버 2대를 CentOS와 Ubuntu 각각 1대씩 준비해서 Application Load Balancer와 연결하고 접속해보는 과정까지 정리해보겠습니다.\n\nVPC 생성\nVPC 환경에서는 먼저 VPC를 먼저 생성해야 하며, 이미 만들어진 VPC가 있다면 그대로 이용하셔도 됩니다.\nVPC의 IP 주소 범위는 private 대역 (10.0.0.0/8, 172.160.0./12, 192.168.0.0/16) 내에서 /16 ~ /28 범위여야 합니다.\n여기서는 192.168.0.0/16 범위의 VPC를 생성하겠습니다.\n\n\n  \n  \n    \n  \n\n\nSubnet 생성\nLoad Balancer를 생성할 때 Server와는 다른 Subnet을 사용해야 정상 작동합니다.\n그래서 여기서도 Load Balancer용 Subnet과 테스트 Server용 Subnet을 각각 생성하도록 하겠습니다.\n\nLoad Balancer용 Subnet 생성\nLoad Balancer는 Private Subnet에 위치해야 하므로 192.168.1.0/24 IP 대역에 Internet Gateway 전용 여부 옵션은 N (Private)을 선택합니다.\n\n\n  \n  \n    \n  \n\n\nServer용 Subnet 생성\n일반 서버용 Subnet은 192.168.2.0/24 IP 대역에 Internet Gateway 전용 여부 옵션은 Y (Public)을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n테스트용 Server 생성\n테스트를 위한 서버는 위에서 생성했던 192.168.2.0/24 IP 대역의 Subnet을 선택하고 Network Interface도 동일한 Subnet을 선택합니다.\nLoad Balancer를 테스트 하기 위한 서버이므로 2대를 생성하면서 1대는 CentOS, 나머지 1대는 Ubunt로 생성하겠습니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group 생성\n[VPC] - [Load Balancer] - [Target Group]에서 Load Balancer가 바라보게 될 Target Group를 설정합니다.\n여기서는 HTTP 프로토콜과 80 포트를 선택하겠습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 Health Check 설정에서는 HTTP, 80포트, HEAD Method를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n마지막으로 Target 즉, 대상이 되는 서버 2대 (lb-test-ubuntu, lb-test-centos)를 선택하고, 적용 Target쪽으로 이동시키는 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n대상 서버들이 적용 Target으로 설정된 모습입니다. 이후에는 전체 설정을 다시 확인하고 생성 완료를 하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nLoad Balancer 생성\n네이버 클라우드 VPC 환경에서 제공하는 Load Balancer는 애플리케이션 로드밸런서, 네트워크 로드밸런서, 네트워크 프록시 로드밸런서 이렇게 3가지가 있습니다.\n그 중에서 가장 많이 사용하는 HTTP, HTTPS 트래픽을 사용하는 웹 애플리케이션용 Application Load Balancer를 생성하겠습니다.\n\n\n  \n  \n    \n  \n\n\nNetwork는 Public IP, Subnet은 앞에서 생성했던 192.168.1.0/24 대역의 Subnet을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n리스너 설정에서 프로토콜은 HTTP, 포트는 80을 선택하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nTarget Group은 앞에서 생성했던 test-tg을 선택하면, 아래에 해당 Target Group의 설정이 표시됩니다.\n다음으로 전체 설정을 다시 확인하고 최종 생성하기 버튼을 클릭하면 Load Balancer가 생성됩니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\nLoad Balancer가 정상 작동하기 위해서는 [Server] - [ACG]에서 [Inbound 규칙]에 Load Balancer용 Subnet 대역인 192.168.1.0/24 대역의 80 포트를 허용포트로 설정해 줍니다.\n\n\n  \n  \n    \n  \n\n\nServer 웹서버 설정\nApplication Load Balancer를 테스트 하기 위해서는 테스트 Server에 웹서버가 설정되어 있어야 하는데, 네이버 클라우드 VPC 환경에서는 LAMP, LEMP 등의 웹서버가 설정된 이미지를 제공하지 않습니다.\n그래서 기본 OS만 설치된 서버에 Apache 웹서버와 php를 설치하도록 하겠습니다. 설치 작업은 아래와 같이 Ubuntu와 CentOS 각각 스크립트를 만들어서 한번에 설치하는 방법을 사용했는데, 필요에 따라서는 하나씩 별도로 설치하셔도 됩니다.\n\nUbuntu에 Apache, PHP 설치하기 스크립트\nApache와 PHP를 설치하고 기본문서 index.html에 서버의 호스트명을 출력하는 스크립트를 적용합니다.\n\n사용한 OS는 Ubuntu 16.04 입니다.\n\n#!/bin/bash\n\napt update\napt install apache2 \napt install php\napt install libapache2-mod-php\n\nsystemctl start apache2\n\ncd /var/www/html\necho \"&lt;?php\" &gt; index.html\necho \"echo \\\"Your server name is \\\".(gethostname()).\\\"&lt;br&gt;\\\";\" &gt;&gt; index.html\necho \"?&gt;\" &gt;&gt; index.html\n\necho AddType application/x-httpd-php .php .php3 .php4 .php5 .html .htm .inc &gt;&gt; phpadd\ncat phpadd &gt;&gt; /etc/apache2/apache2.conf\n\nsystemctl restart apache2\nsystemctl enable apache2\nsystemctl status apache2\n\n\n\nCentOS에 Apache, PHP 설치하기 스크립트\n사용한 OS는 CentOS 7.3 입니다.\n\n#!/bin/bash\n\nyum -y install httpd php\n\nsystemctl start httpd\n\ncd /var/www/html\necho \"&lt;?php\" &gt; index.html\necho \"echo \\\"Your server name is \\\".(gethostname()).\\\"&lt;br&gt;\\\";\" &gt;&gt; index.html\necho \"?&gt;\" &gt;&gt; index.html\n\necho AddType application/x-httpd-php .php .php3 .php4 .php5 .html .htm .inc &gt;&gt; phpadd\ncat phpadd &gt;&gt; /etc/httpd/conf/httpd.conf\n\nsystemctl restart httpd\nsystemctl enable httpd\nsystemctl status httpd\n\n\n접속 테스트\n앞에서 생성했던 Load Balancer 정보에서 접속 정보용 주소를 확인하고 복사합니다.\n\n\n  \n  \n    \n  \n\n\n복사한 Load Balancer 주소를 웹브라우저에 입력하고 계속 새로 고침을 해보면 아래와 같이 CentOS 서버와 Ubuntu에 접속될 때 마다 해당 서버의 호스트명이 출력되면서 Load Balancer가 정상 작동하는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud Application Load Balancer 가이드\n    \n      https://guide.ncloud-docs.com/docs/loadbalancer-application-vpc\n    \n  \n  Ncloud Target Group 가이드\n    \n      https://guide.ncloud-docs.com/docs/loadbalancer-targetscreen-vpc"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-load-balancer-http-to-https-html": {
						"id": "networking-ncloud-networking-load-balancer-http-to-https-html",
						"title": "LoadBalancer에 http로 접속 시에 https로 리다이렉트 시키는 방법",
						"categories": "",
						"url": " /networking/ncloud_networking_load_balancer_http_to_https.html",
						"content": "개요\nNcloud에서는 웹서버에 인증서를 설치하지 않고 Application LoadBlancer에 인증서를 추가 할수 있습니다.\nLoadBalancer에 에 인증서를 두고 로드밸런서에서 HTTPS/443 요청을 받아 서버의 80 포트와 통신을 하게 되는 구조입니다.\n이럴 경우 HTTPS 접속만 허용되어 HTTP 요청을 못 받을수 있는데 HTTP로 접속할시 로드밸런서에서 HTTPS로 리다이렉트 시키는 방법을 알아보겠습니다.\n\n테스트환경 사전준비\n\n\n  웹서버: httpd 패키지를 설치 후 간단한 index.html 생성, 80포트를 오픈\n  Target group: 웹서버를 포함하는 HTTP protocol 과 80 port 설정\n  로드밸런서: 리스너를 HTTPS protocol 과 443 port로 설정\n  DNS 및 인증서: 테스트에 사용할 인증서와 DNS(test1.3rdeyesys.com) 등록\n\n\n서버생성과 Application Load Balancer 의 생성 가이드는 아래 문서를 참고하시기 바랍니다. \n- VPC 환경에서 서버 생성 \n- VPC 환경에서 Application Load Balancer 생성하기\n\nHTTPS와 HTTP 접속\n\n로드밸런서 생성시 HTTPS/443 요청은 받을수 있게 설정하고, HTTP/80 요청을 설정하지않아 \ntest1.3rdeyesys.com 요청은 받을수 있지만 HTTP/80 요청은 연결이 불가한 상태임을 확인할 수 있습니다.\n\nHTTPS/433 접속 상태 확인\n\n  \n  \n\n\nHTTP/80 접속 상태 확인\n\n  \n  \n\n\n리스너 추가\n\n로드밸런서 생성시 설정한 HTTPS/443 요청 외에 HTTP/80 요청도 받을 수 있게 로드밸런서에서  HTTP/80 요청을 받을 새로운 리스너를 설정합니다.\n\n로드밸런서를 선택하고 상단의 [리스너 설정 변경] 버튼을 클릭합니다.\n\n  \n  \n\n\n\n[리스너 추가] 버튼을 클릭합니다.\n\n\n  \n  \n\n\n\n\nHTTP 프로토콜 항목란에 80포트, Target Group 항목란에 80  으로 설정하여 확인버튼을 눌러 마무리 합니다.\n\n  \n  \n\n\n\n다음과 같이 80 to 80 으로 리스너가 추가되어 HTTP/80 요청에도 응답하여 페이지를 띄울수 있습니다.\n\n\n  \n  \n\n\nHTTP/80 요청은 로드밸런서를 거쳐 그대로 서버의 80 포트와 통신하기에 보안상에 문제가 생길수 있습니다. 그러므로 Application LoadBalancer의 기능을 이용하여 HTTP/80으로 들어오는 요청을 HTTPS/443으로 Redirection 하겠습니다.\n\n규칙 추가\n\nHTTP로 생성한 리스너를 선택하고 [규칙 조회/변경] 버튼을 클릭합니다.\n\n  \n  \n\n\n\n다음으로 [규칙 추가] 버튼을 클릭합니다.\n\n  \n  \n\n\n\n다음의 항목들을 설정합니다.\n\n\n  우선순위: 규칙을 적용할 순번을 정할수 있습니다.\n  조건: Host Header 와 Path Pattern 를 선택 할수 있습니다. (본 테스트 에서는 Host Header 기반을 사용하였습니다.)\n  액션: Target group과 Redierction 을 선택할 수 있습니다. (Redierction 선택합니다.)\n\n\n\n  \n  \n\n\n-  우선순위는 적당한 순번의 숫자를 넣습니다.\n- 조건에서 호스트 헤더를 선택후 리디렉션할 도메인 명을 입력한뒤 +추가 버튼을 눌러 추가합니다.\n- 액션에서 Redirection 을 선택 Protocol은 HTTPS 로 Port는 443으로 설정하고 확인을 눌러 규칙을 추가합니다. \n- 그 외 사용환경에 맞게 규칙을 설정해 사용합니다.\n\n\n설정된 규칙들을 확인 합니다.\n\n  \n  \n\n\n\n\n최종 테스트\n이제 다시 HTTP로 도메인 주소를 접속 해보면 규칙에 추가된 Host Header 기반으로 HTTPS로 Redirection 되는 모습을 확인 할수가 있습니다.\n\nHTTP/80 으로 접속시도\n\n  \n  \n\n\nHTTPS/443 으로 Redirection 확인\n\n  \n  \n\n\n참고 URL\n\n  Application Load Balancer 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-loadbalancer-applicationlbconsole\n    \n  \n  Target Group 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-loadbalancer-targetgroupconsole"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-natgw-routetb-html": {
						"id": "networking-ncloud-networking-natgw-routetb-html",
						"title": "VPC 환경에서 NAT Gateway 설정하기",
						"categories": "",
						"url": " /networking/ncloud_networking_natgw_routetb.html",
						"content": "개요\nNAT Gateway는 비공인 IP를 가진 다수의 서버들이 대표 공인 IP를 이용해 외부와 통신을 할 수 있도록 도와주는 네트워킹 서비스입니다.\n그리고, 일반적으로 서버에 직접 공인 IP를 부여하는 것과 달리 외부에서 서버로의 직접 접근은 허용하지 않기 때문에 높은 수준의 보안을 유지할 수 있는 것이 특징입니다.\n여기서는 VPC 환경에서 NAT Gateway를 어떻게 구성하고, NAT Gateway를 적용하기 전과 후의 외부와 통신 상태에 대해 확인해보도록 하겠습니다.\n\nNAT Gateway 특징\n[NAT Gateway]는 생성 시 [공인 NAT Gateway]와 [사설 NAT Gateway]를 선택할 수 있습니다. 존당 5개까지 생성이 가능하며, 각 NAT Gateway의 특징은 다음과 같습니다.\n\n공인 NAT Gateway\n\n  사설 IP와 공인 IP를 둘 다 가지고 있습니다.\n  인터넷 outbound 통신을 할 때 Public IP에서 할당된 공인 IP를 사용합니다.\n  VPC 내부에서 NAT Gateway를 통해 통신할 경우 할당된 사설 IP를 사용합니다.\n  할당된 공인 IP는 NAT Gateway를 삭제 시 재사용이 가능합니다.\n\n\n사설 NAT Gateway\n\n  사설 IP만 가지고 있습니다.\n  VPC 내부에서 NAT Gateway를 통해 통신할 경우 할당된 사설 IP를 사용합니다.\n\n\nVPC 서비스 위치\n[VPC] 서비스는 [Console] - [Networking]에 위치해 있습니다.\n\n그리고, 아래 스샷에서 확인할 수 있듯이 [VPC]에는 [VPC], [Subnet], [Network ACL], [NAT Gateway], [Route Table], [VPC Peering], [Virtual Private Gateway] 등의 하부 서비스 메뉴가 있습니다.\n\n\n  \n  \n    \n  \n\n\nVPC 생성\n먼저 VPC를 생성합니다. IP주소 범위는 10.0.0.0/16으로 정하겠습니다.\n\n\n  \n  \n    \n  \n\n\nSubnet 생성\nSubnet은 아래와 같이 총 3가지를 준비하겠습니다.\n\n  NAT Gateway 동작 테스트를 위해 서버용 Public, Private Subnet\n  NAT Gateway를 배치할 NAT Gateway 전용 Subnet\n\n\nPublic Subnet 생성\nPublic Subnet의 IP 범위는 10.0.0.0/24로 설정하겠습니다.\n\n\n  \n  \n    \n  \n\n\nPrivate Subnet 생성\nPrivate Subnet의 IP 범위는 10.0.1.0/24로 설정하겠습니다.\n\n\n  \n  \n    \n  \n\n\nNAT Gateway 전용 Subnet\nNAT Gateway 전용 Subnet은 Subnet 생성 화면에서 아래쪽 용도 설정에서 [NatGateway]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n테스트를 위한 ACG (Access Control Group)를 생성하고 설정합니다.\n\n\n  \n  \n    \n  \n\n\nInbound 설정\nInbound 규칙에는 Public, Private Subnet과 SSH 접속을 위한 로컬PC IP를 허용하고, Ping 테스트를 위한 ICMP도 허용합니다.\n\n\n  \n  \n    \n  \n\n\nOutbound 설정\nOutbound 규칙은 TCP, UDP, ICMP 모두 전체 허용으로 추가합니다.\n\n\n  \n  \n    \n  \n\n\n서버 생성\n테스트를 위해 Public, Private 각각의 Subnet에 1대씩 서버를 설정하고 Public 서버에는 공인 IP도 할당합니다.\n\n\n  \n  \n    \n  \n\n\nPublic -&gt; Private 서버 접속 확인\nPublic Subnet에 있는 서버에서 Private Subnet에 있는 서버로 통신이 가능한 것을 확인할 수 있습니다.\n다음 단계에서 Private 서버로 SSH로 접속하기 위한 사전 확인 단계입니다.\n\n\n  \n  \n    \n  \n\n\nPrivate 서버 외부 접속 여부 확인\nPublic 서버에서 Private 서버로 SSH로 접속한 후에 Private 서버에서 외부로 통신이 되는 것을 확인해보면 불가능한 것을 확인할 수 있습니다.\n이후 단계에서 NAT Gateway를 설정하고 Private 서버에서 외부와 통신이 가능한지 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\nRoute Table 설정 확인\nNAT Gateway를 위한 Route Table 설정을 추가하기 전에 현재 상태의 Route Table 설정을 확인해보겠습니다.\n\nPublic Subnet의 Route Table 설정 확인\n위에서 Public Subnet의 서버와 Private Subnet의 서버가 통신이 가능했던 것은 VPC와 Subnet이 생성될때 Route Table이 생성되면서 VPC 내부 통신을 위한 규칙 (10.0.0.0/16 LOCAL)이 기본으로 설정되기 때문입니다.\n그리고 Public의 경우 외부 통신을 위한 INTERNET GATEWAY가 추가되어 있는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nPrivate Subnet의 Route Table 설정 확인\n반면에 Private의 경우는 VPC 내부 통신을 위한 LOCAL만 설정된 것을 확인 할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nRoute Table 설정 화면에 들어가도 Target Type에 LOCAL만 선택할 수 있는 것을 확인할 수 있습니다.\n\n  \n  \n    \n  \n\n\nNAT Gateway 생성\n[NAT Gateway]는 별도의 메뉴가 있지 않고, [Networking] - [VPC] 서비스 내에 하부 서비스로 존재합니다. 그러면 이제 [NAT Gateway 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n이름을 입력하고 서비스 상황에 따라 유형을 [공인] 또는 [사설]을 선택한 후, VPC와 위에서 생성했던 전용 Subnet을 선택하고, NAT Gateway를 생성합니다. 그리고 마지막으로 Route Table에 NATGW 설정을 추가해야 완료되는데, 관련 설정은 아래에서 확인 가능합니다.\n\n\n  \n  \n    \n  \n\n\nRoute Table 설정\n앞에서 LOCAL 항목만 존재했던 Private Subnet의 Route Table 설정 화면에 가보면 Target Type에 NATGW가 추가된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n목적지(Destination)에 0.0.0.0/0을 입력하고, Target Type을 NATGW를 선택하고 생성 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n외부 접속 테스트\n마지막으로 다시 한번 Private 서버에서 외부 통신이 가능한지 ping 테스트를 해보면, 아래 화면과 같이 정상적으로 통신이 되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n고려사항\n 요금: NAT Gateway는 사용하지 않고 생성만 해두어도 요금이 부과됩니다. (데이터 처리요금 별도)\n\n생성 후 보유 시간에 따라 요금이 부과되는데 1개당 56원/시간 입니다. 그러므로 1달간 보유하고만 있다고 가정할 때 비용을 계산해보면 \n24시간 * 30일 * 56원 = 40,320원 그러므로 사용하지 않는 NAT Gatway는 반드시 삭제하기를 추천드립니다.\n\n참고 URL\n\n  NAT Gateway 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailenatgw\n    \n  \n  NAT Gateway 특징과 비교\n    \n      https://m.blog.naver.com/n_cloudplatform/221173116642"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-service-port-info-html": {
						"id": "networking-ncloud-networking-service-port-info-html",
						"title": "주요 서비스 포트(Port) 정보",
						"categories": "",
						"url": " /networking/ncloud_networking_service_port_info.html",
						"content": "포트(Port) 정보\n네이버 클라우드 주요 서비스들에서 사용하는 포트(Port) 정보를 정리해보았습니다.\n네이버 클라우드에서 사용하는 포트이므로 일부 서비스의 경우 일반적으로 사용되는 포트와 조금 다른 경우도 있을 수 있습니다.\n\n\n  22 : SSH\n  80 : http\n  443 : https\n  1433 : mssql\n  3000 : Node.js Express\n  3306 : mysql\n  3389 : 윈도 원격데스크톱\n  5432 : PostgreSQL\n  5672 : RabbitMQ\n  5985 : Packer\n  6379 : Redis\n  8001 : CUBRID\n  8080 : Ambari\n  8081 : Hue\n  8388 : Shadowsocks 서버\n  9736 : Jeus WebAdmin\n  10090 : Pinpoint 서버\n  11313 : Hugo 서버\n  15672 : RabbitMQ Management UI\n  18080 : Tomcat, Jenkins\n  18088 : Superset\n  18888 : TensorFlow Jupyter Notebook\n  18889 : TensorBoard\n  27017 : MongoDB\n  50070 : HDFS NameNode"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-ssl-vpn-classic-guide-html": {
						"id": "networking-ncloud-networking-ssl-vpn-classic-guide-html",
						"title": "Classic 환경에서 SSL VPN 설정하고 접속하는 방법",
						"categories": "",
						"url": " /networking/ncloud_networking_ssl_vpn_classic_guide.html",
						"content": "개요\nNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 Classic 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\n\nSSL VPN이란?\n\n  VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다.\n  사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다.\n  가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다.\n\n\nSSL VPN 생성\n[SSL VPN 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n우선 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다. Classic 환경에서는 3개, 5개, 10개 상품만 선택 가능합니다. \n다음으로 인증 방식은 ID/PW 만으로 접속하는 일차인증과 OTP까지 사용하는 이차 인증 중에서 원하는 방식을 선택합니다. \n그리고 이차인증을 선택했을 경우에는 SMS와 Email 어떤 것을 이용할 것인지도 선택하게 됩니다.\n\n\n⁃ 인증방식과 OTP 전송 방식은 SSL VPN 생성 시에 한번 선택하면 변경할 수 없으니 주의해야 합니다. \n⁃ 만약 변경 하고 싶을 경우에는 SSL VPN을 새로 생성해야 합니다. \n⁃ Classic 환경에서는 이차인증을 선택하면 별도의 이용요금이 부과됩니다.\n\n\n\n  \n  \n    \n  \n\n\n다음으로 개인정보 수집 및 이용에 동의해야 합니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN이 생성되면 다음과 같이 리스트에 서 확인 가능하며 여기서 [SSL VPN IP POOL]은 뒤쪽에서 네트워크 접근 제한을 설정할 때 필요한 중요한 정보입니다.\n\n\n  \n  \n    \n  \n\n\n사용자 설정\nSSL VPN에 접속할 사용자 정보를 설정합니다.  리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\nSSL VPN을 사용하려면 서버에 적용된 ACG에 [SSL VPN IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 적용된 ACG를 확인합니다.\n\n\n  \n  \n    \n  \n\n\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정 화면에서 위에서 확인했던 [SSL VPN IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. \n기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\n\n\n  \n  \n    \n  \n\n\nAgent 다운로드\nSSL VPN 접속을 위한 Agent를 다운로드 합니다.\n\n\n  윈도우 용 다운로드\n  맥 용 다운로드\n\n\n\n  \n  \n    \n  \n\n\nAgent 접속\nAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다.\nAgent에는 Classic 환경 SSL VPN 서버(Ncloud-kr-01)가 기본으로 설정되어 있는데, 혹시 빠져 있다면 [서버 변경] 버튼을 클릭해서 https://sslvpn-kr-01.ncloud.com을 입력하고 연결 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nOTP 접속도 설정했다면 도착한 인증 번호를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에  [SSL VPN IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 접속\n이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\n\n IP 입력: 이때 혹시나 포트 포워딩이나 공인 IP를 설정하고 그 IP를 입력하는 일이 없도록 주의해야 합니다.\n\n\n  \n  \n    \n  \n\n\nAgent 기타 설정\nSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n\n트래픽 그래프\nAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n스펙 변경\n처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [스펙 변경] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n3개, 5개, 10개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n주의사항\n 접속 오류: SSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다.  이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n삭제\n삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  SSL VPN 사용 가이드(Classic)\n    \n      https://guide.ncloud-docs.com/docs/security-security-5-1\n    \n  \n  SSL VPN 요금\n    \n      https://www.ncloud.com/product/security/sslVpn"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-ssl-vpn-vpc-guide-html": {
						"id": "networking-ncloud-networking-ssl-vpn-vpc-guide-html",
						"title": "VPC 환경에서 SSL VPN 설정하고 접속하는 방법",
						"categories": "",
						"url": " /networking/ncloud_networking_ssl_vpn_vpc_guide.html",
						"content": "개요\nNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 VPC 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\n\nSSL VPN이란?\n\n  VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다.\n  사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다.\n  가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다.\n\n\nSSL VPN 생성 요청\n[SSL VPN 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n우선 접근할 서버가 속해 있는 VPC를 선택하고, 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다.\nVPC 환경에서는 3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 선택 가능합니다.\n\n\n  \n  \n    \n  \n\n\nVPC 환경의 SSL VPN은 콘솔에서 자동으로 생성하는 것이 아니라 생성 요청을 하면 Ncloud 담당자가 직접 생성하고 결과를 안내 받는 구조로 되어 있습니다. \n생성 완료까지 걸리는 기간은 업무일 기준 2~3일 정도이며, 생성이 완료되면 SSL VPN 상태가 [운영중]으로 변경되고, 안내 메일이 도착합니다.\n\n\n  \n  \n    \n  \n\n\n아래와 같이 생성 요청을 하고 나면 상태가 [생성중] 상태로 표시 됩니다. 2~3일 후 생성 완료 안내 메일이 도착할때까지 기다리시면 됩니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN 생성 완료\nSSL VPN 생성이 완료되면 아래와 같은 메일을 받을 수 있습니다. \n메일 내용에는 [SSL VPN IP POOL] 정보와 접속 경로 정보가 포함되어 있으니 잘 확인해야 합니다.\n\n IP POOL: 특히 [SSL VPN IP POOL] 정보는 Ncloud 콘솔에서 확인할 수 없고, 오로지 생성 완료 메일에서만 확인 가능하니 잘 보관해야 합니다.\n\n\n  \n  \n    \n  \n\n\n생성 완료 메일 확인 후에 콘솔에 접속하면 아래와 같이 [운영중] 으로 상태 메시지가 바뀐 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n사용자 설정\nSSL VPN에 접속할 사용자 정보를 설정합니다.  리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\nVPC 환경은 Classic 환경과 달리 이차인증이 필수이므로  SMS와 Email 정보를 함께 입력합니다.\n\n\n  \n  \n    \n  \n\n\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nRoute Table 설정\n네트워크 설정에서는 우선 접속할 서버가 속해 있는 VPC Subnet의 Route Table에 SSL VPN으로 접근할 수 있게 [SSL VPN IP POOL]을 등록해야 합니다.\n아래와 같이 접속할 서버의 상세정보에서 VPC와 Subnet을 확인합니다. 여기서는 Private Subnet에 생성한 서버에 접속할 예정입니다.\n\n\n  \n  \n    \n  \n\n\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭합니다.\nPublic Subnet에 생성한 서버에 접근해야 할 경우에는 public-table을 선택하고 설정하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n[Destination]에 SSL VPN 생성 완료 메일에서 확인한 [SSL VPN IP POOL] 정보를 등록하고, [Target Type]은 SSLVPN을 선택, [Target Name]은 위에서 생성한 SSL VPN 이름을 선택하고 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n다음으로 서버에 적용된 ACG에 [SSL VPN IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다.\n\n\n  \n  \n    \n  \n\n\nACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정 화면에서 위에서 확인했던 [SSL VPN IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. \n기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\n\n\n  \n  \n    \n  \n\n\nAgent 다운로드\nSSL VPN 접속을 위한 Agent를 다운로드 합니다.\n\n\n  윈도우 용 다운로드\n  맥 용 다운로드\n\n\n\n  \n  \n    \n  \n\n\nAgent 접속\nAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다.\nAgent에는 Classic 환경 SSL VPN 서버(Ncloud-kr-01)가 기본으로 설정되어 있는데, VPC 환경 SSL VPN 서버 주소로 바꾸기 위해 [연결끊기] 클릭해서 연결을 끊고, [서버 변경] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n서버 선택 창에 https://sslvpn-kr-vpc-01.ncloud.com 주소를 입력하고, [다음] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n주소 변경 후에 [연결] 버튼을 클릭하면 로그인 화면이 나타나는데 위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n그리고 도착한 OTP 인증 번호를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에  [SSL VPN IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 접속\n이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nAgent 기타 설정\nSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n\n트래픽 그래프\nAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n스펙 변경\n처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [스펙 변경] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n주의사항\n 접속 오류: SSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다.  이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n삭제\n삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n하지만, 바로 삭제가 되지 않고 다음과 같이 “Route Table에서 Target으로 지정된 Route 정보를 모두 삭제해야 삭제가 가능합니다”라는 메시지가 뜹니다.\n\n\n  \n  \n    \n  \n\n\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭해서 등록된 설정을 확인하고 [X] 버튼을 클릭해서 설정을 삭제합니다. \nRoute Table 정보를 삭제한 후에 SSL VPN을 삭제하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  SSL VPN 사용 가이드(VPC)\n    \n      https://guide.ncloud-docs.com/docs/security-security-5-2\n    \n  \n  SSL VPN 요금\n    \n      https://www.ncloud.com/product/security/sslVpn"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-vpc-acg-nacl-html": {
						"id": "networking-ncloud-networking-vpc-acg-nacl-html",
						"title": "ACG와 NACL 비교",
						"categories": "",
						"url": " /networking/ncloud_networking_vpc_acg_nacl.html",
						"content": "개요\n네이버 클라우드에서는 VPC의 보안을 강화하기 위해 ACG와 NACL의 두 가지 보안 정책을 제공하고 있습니다.\n\n\n  ACG : Access Control Group은 서버의 NIC별 Inbound 및 Outbound 트래픽을 제어\n  NACL : Network Access Control List는 Subnet의 Inbound 및 Outbound 트래픽을 제어\n\n\nACG vs NACL\n\n\n  \n    \n      구분\n      ACG\n      NACL\n    \n  \n  \n    \n      적용 대상\n      서버의 접근 제어\n      Subnet의 접근 제어\n    \n    \n      지원 규칙\n      허용 (Allow)\n      허용 및 거부 (Allow / Deny)\n    \n    \n      상태 저장 여부\n      상태 저장(Stateful)(규칙에 관계없이 반환 트래픽이자동으로 허용됨)\n      상태 비저장(Stateless)(반환 트래픽이 규칙에 의해명시적으로 허용되어야 함)\n    \n    \n      적용 방법\n      서버의 NIC에 ACG 정책 적용\n      Subnet 단위로 적용(Subnet 별 1개만 허용)\n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailedsubnet.html"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-vpc-load-balancer-html": {
						"id": "networking-ncloud-networking-vpc-load-balancer-html",
						"title": "VPC 환경 Load Balancer 상품군의 변화",
						"categories": "",
						"url": " /networking/ncloud_networking_vpc_load_balancer.html",
						"content": "개요\nLoad Balancer는 수신 트래픽을 다수의 서버로 분산시키는 서비스로서, 수신 트래픽을 등록된 멤버 서버로 분산시켜 가용성을 높이고 시스템 가동률을 조절하는 역할을 수행합니다.\nVPC 플랫폼에서는 Network Load Balancer / Application Load Balancer / Network Proxy Load Balancer 가 제공되어 서비스에 적합한 로드밸런서를 선택할 수 있습니다.\n\n종류\n\n\n  \n    Application Load Balancer\nHTTP 및 HTTPS 트래픽을 사용하는 웹 애플리케이션을 위한 유연한 기능을 제공\n  \n  \n    Network Load Balancer\nDSR(Direct Server Return) 구조의 고성능, 대규모 네트워크 연결에 적합한 로드밸런서로 고정 IP를 제공\n  \n  \n    Network Proxy Load Balancer\nTCP 세련 유지에 최적화 되어 있으며, Network Load Balancer와 다르게 DSR를 지원하지 않으며, Load Balander가 세션을 관리.\n  \n\n\nKR존/서브넷 별 LB 생성지역 지정 가능 : VPC 환경에서는 내가 원하는 KR존의 특정 서브넷에 LB생성 가능, KR-1/2 존에 각각 생성하여 고가용성을 확보 할 수 있다.\n\nLB 선택 기준 및 기능 비교\n\n\n  \n    \n      기능\n      Network LB\n      Network Proxy LB\n      Application\n    \n  \n  \n    \n      프로토콜\n      TCP\n      TCP, TLS\n      HTTP/HTTPS\n    \n    \n      상태확인\n      O\n      O\n      O\n    \n    \n      로깅\n      X\n      O\n      O\n    \n    \n      DSR\n      O\n      X\n      X\n    \n    \n      동일 인스턴스의여러 포트로로드밸런싱\n      X\n      X\n      O\n    \n    \n      HTTP 2.0\n      N/A\n      N/A\n      O\n    \n    \n      경로기반 라우팅\n      N/A\n      N/A\n      O (출시 예정)\n    \n    \n      SSL Offload\n      X\n      O\n      O\n    \n    \n      고정 세션\n      X\n      O\n      O\n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-loadbalancer-loadbalanceroverview.html"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-vpc-overview-html": {
						"id": "networking-ncloud-networking-vpc-overview-html",
						"title": "VPC 구성요소",
						"categories": "",
						"url": " /networking/ncloud_networking_vpc_overview.html",
						"content": "개요\n이 문서는 VPC를 구성하는 요소들에 대한 설명으로 네이버 클라우드 파트너 테크데이에서 발표된 내용을 정리한 것입니다.\n\nVPC\nVPC(Virtual Private Cloud)는 퍼블릭 클라우드 상에 논리적으로 완전하게 분리된 고객전용 네트워크를 제공하는 서비스.\n최대 /16의 IP 네트워크 공간을 제공 (IP 대역: RFC 1918).\n\n@ RFC 1918 IP대역\n\n10.0.0.0/8 (10.0.0.0 - 10.255.255.255)  \n172.16.0.0/12 (172.16.0.0 - 172.31.255.255)  \n192.168.0.0/16 (192.168.0.0 - 192.168.255.255)\n\n\nSubnet (Internet Gateway)\n할당된 VPC를 용도에 맞게 네트워크 공간을 세분화 하여 사용.\n/16 ~ /28의 네트워크 주소 할당이 가능.\nPublic Subet 생성 시 Internet Gateway가 연결됨.\n\nNAT Gateway\nNetwork Address Translation의 약자로, 폐쇄된 네트워크에서 외부와의 인터넷 동신 시 사용하는 게이트웨이.\n\nRoute Table\n네트워크 경로를 설정할 수 있는 기능을 제공. VPC 내부 통신을 위한 Local은 기본적으로 설정.\n\nACG\n서버에서 인바운드/아웃바운드의 네트워크 접근제어를 지원하며 Stateful 기반으로 동작.\n\nNACL\nNetwork Access Control List의 약자로, Subnet에서 인바운드/아웃바운드의 네트워크 접근제어를 지원하며 Stateless 기반으로 동작.\n\nVirtual Private Gateway\nCloud Connect와 IPSec VPN에 연결되는 네이버 클라우드의 VPC측 연결 접점으로서 Cloud Connect와 IPSec VPN 연결을 지원.\n\nVPC Peering\nVPC간 사설연결을 보장하는 기능으로, 일반적인 VPC &lt;-&gt; VPC 간의 통신은 인터넷을 통하게 되고, 이는 과다한 요금 발생 및 성능 저하를 일으킬 수 있음.\nVPC Peering을 이용하면 보다 안전한 사설 IP기반의 통신이 가능함.\nVPC Peering은 단방향 통신을 제공하기 때문에 양방향 통신을 원하면 Src -&gt; Dest 별로 각각 1개씩, 두개의 정책을 모두 적용해야 함.\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcoverview.html"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-vpc-peering-guide-html": {
						"id": "networking-ncloud-networking-vpc-peering-guide-html",
						"title": "VPC Peering 생성 가이드",
						"categories": "",
						"url": " /networking/ncloud_networking_vpc_peering_guide.html",
						"content": "개요\nVPC(virtual Private Cloud)는 퍼블릭클라우드상에서 제공되는 사설 가상 네트워크 입니다. 계정당 3개의 VPC를 만들수 있으며 다른 VPC 네트워크와 논리적으로 분리되어 있어 독립적인 네트워크 환경을 구현할 수 있습니다.\n그런데, 간혹 VPC 환경에서 분리되어 있는 VPC간의 통신이 필요할때가 있는데 이때 사용할 수 있는 서비스가 [VPC Peering] 입니다.\n\nVPC Peering은 공인 아이피를 거치지 않고 Ncloud 내부 네트워크를 이용하여 VPN없이 VPC간 통신을 할수 있게 해주는 서비스 입니다.\n\nVPC 생성\n우선 테스트에 사용할 VPC로 [test-vpc], [test2-vpc] 이렇게 2개를 준비했습니다.\n\n\n  \n  \n    \n  \n\n\nSubnet 생성\n\n이제 각 VPC에 서브넷을 생성합니다. [test-vpc]에는 [test-subnet(192.168.10.0/24)]으로 생성합니다.\n\n\n  \n  \n    \n  \n\n\n[test2-vpc]에는 [test2-subnet(172.16.10.0/24)]으로 생성합니다.\n\n\n  \n  \n    \n  \n\n\n생성된 Subnet은 다음과 같습니다.\n\n\n  \n  \n    \n  \n\n\nVPC Peering 생성\n네이버 클라우드(Ncloud) 콘솔에서 [Networking] -&gt; [VPC] -&gt; [VPCPeering] 메뉴로 이동해서 [VPC peerig 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  ① 이름을 적고\n  ② 요청 VPC는 [testVPC]를 선택\n  ③ 수락 VPC는 [내계정], [test2VPC]를 선택\n\n\n설정이 끝났으면 생성버튼을 클릭합니다.\n\n다른 계정의 VPC와 연결하는 경우는 아래쪽에서 살펴보겠습니다.\n\n\n  \n  \n    \n  \n\n\n마지막으로 VPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n[test-vpc] -&gt; [test2-vpc]로 설정된 VPC Peering을 아래와 같이 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n역방향 설정 추가\n그런데 VPC peering은 단방향 통신이기에 TCP, ICMP 등의 양방향 통신을 하는 프로토콜을 이용하려면 역방향 즉, [test2-vpc] -&gt; [test-vpc]로 설정된 VPC Peering도 추가해야 합니다.\n\n\n  ① 이름을 적고\n  ② 요청 VPC에는 test2VPC를 선택\n  ③ 수락 VPC에는 testVPC를 선택\n\n\n\n  \n  \n    \n  \n\n\nVPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n아래와 같이 [test-vpc] -&gt; [test2-vpc] , [test2-vpc] -&gt; [test-vpc] 2가지 VPC Peering을 모두 생성했으므로 양방향 통신이 가능하게 되었습니다.\n\n\n  \n  \n    \n  \n\n\nRoute Table 설정\n\n이제 통신할 서브넷 혹은 서버의 아이피를 Route Table 설정에 추가 합니다. 여기서는 서브넷을 추가하도록 하겠습니다.\n\n우선 [VPC] - [Route Table]에서, [test-vpc-default-public-table]의 [Routes 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Destination에는 [test2-subnet]의 아이피 대역을 입력 (서버의 아이피로 입력해도 됨)\n  Target Type은 [VPCPEERING]을 선택\n  Target Name은 [test-vpc-peering]을 선택\n\n\n\n  \n  \n    \n  \n\n\n다음으로 [test2-vpc-default-public-table]의 [Routes 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  Destination에는 [test-subnet]의 아이피 대역을 입력 (서버의 아이피로 입력해도 됨)\n  Target Type은 [VPCPEERING]을 선택\n  Target Name은 [test2-vpc-peering]을 선택\n\n\n\n  \n  \n    \n  \n\n\n서버 준비\n아래와 같이 테스트로 사용할 서버 2대를 준비했습니다.\n테스트는 [test-vpc]에 위치한 [test-vpc-peering-svr]서버 -&gt; [test2-vpc]에 위치한 [test2-vpc-peering-svr]로 접속 시도를 해보겠습니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\nACG를 설정하지 않고 [test-vpc-peering-svr] -&gt; [test2-vpc-peering-svr]로 접속 시도를 하면 접속이 되지 않는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[test2-vpc-peering-svr]로 접속할 것이므로 해당 서버에 설정된 acg인 [test2-vpc-default-acg]를 선택하고 [ACG 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n접근소스에는 [test-vpc-peering-svr] 서버의 subnet 대역인 [192.168.10.0/24]를 입력하고, 포트는 22번 포트를 입력하고 추가해서 적용합니다.\n\n\n  \n  \n    \n  \n\n\n접속 테스트\nACG 설정까지 완료하고 나서 다시 접속 테스트를 해보면 아래와 같이 접속이 잘 되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다른 계정 VPC 연결\n위에서는 동일한 내 계정에 생성된 VPC들 간의 Peering을 살펴보았는데, 아래에서는 다른 계정에 생성된 VPC와 연결할 때의 화면을 살펴보겠습니다.\n\nVPC Peering 생성 화면에서 [다른 계정]을 선택하면 아래와 같이 [로그인 ID (이메일)], [VPC ID], [VPC 이름]을 입력하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n마찬가지로 VPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 수락을 요청받은 다른 계정의 VPC Peering 화면에 가면 요청 내용을 확인할 수 있고, 요청 응답에서 [수락] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n한번 더 VPC Peering 연결 요청을 수락할 것인지 확인하는 창이 나타납니다.\n\n\n  \n  \n    \n  \n\n\n수락하고 나면 역방향의 VPC Peering 연결을 생성해야 한다는 안내와 함께 역방향 VPC Peering 생성 화면이 나타납니다.\n역방향은 위의 설정과 반대로 진행하면 되고, 그 이후에는 내 계정에서 설정했던 것과 마찬가지로 설정하시면 완료됩니다.\n\n\n  \n  \n    \n  \n\n\n제한사항\n\n\n⁃ VPC Peering은 연결하려는 VPC들의 IP주소 대역이 달라야 합니다. \n⁃ 일치되거나 중첩되는 대역이 있으면 설정되지 않습니다.\n\n\n⁃ VPC Peering은 단방향입니다. \n⁃ TCP등 양방향 통신을 해야 하는 경우에는 요청 / 수락 VPC를 맞바꾸어 역방향 Peering도 추가 생성해야 합니다.\n\n\n⁃ VPC Peering은 전이적 연결 관계를 지원하지 않습니다. \n⁃ 즉, Peering된 VPC를 통하여 다른 VPC 혹은 외부로 통신하는 것은 불가능 합니다.\n\n\n⁃ VPC Peering은 동일한 리전 내 VPC 끼리만 연결할 수 있습니다.\n\n참고 URL\n\n  VPC Peering 가이드\n    \n      https://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailedpeering\n    \n  \n  VPC Peering 설정 시나리오\n    \n      https://guide.ncloud-docs.com/docs/networking-vpc-vpcuserscenario4\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-11-25\n          문서 최초 생성\n        \n      \n        \n          2023-11-03\n          스크린샷 업데이트"
					}
					
				
			
		
			
				
					,
					
					"networking-ncloud-networking-vpc-subnet-natgw-html": {
						"id": "networking-ncloud-networking-vpc-subnet-natgw-html",
						"title": "Subnet 과 NAT Gateway",
						"categories": "",
						"url": " /networking/ncloud_networking_vpc_subnet_natgw.html",
						"content": "개요\n네이버 클라우드에서는 VPC의 보안을 강화하기 위해 두 가지 서브넷을 제공하고 있습니다.\n\n\n  Public Subnet : 인터넷과 자유로운 통신이 필요할 때 사용할 수 있는 서브넷으로 Interget GW를 통해 외부와 통신\n  Private Subnet : 보안상 외부에서 서버에 접근하는 것을 막아야 할 때 사용하는 서브넷으로 NAT GW를 통해 외부와 통신\n\n\nPublic vs Private Subnet\n\n\n  \n    \n      구분\n      Public Subnet\n      Private Subnet\n    \n  \n  \n    \n      용도\n      인터넷 연결이 필요할 때\n      외부 접속을 최소화 해야 할 때\n    \n    \n      지원 리소스\n      서버\n      서버, 로드밸런서\n    \n    \n      인터넷 연결 시필요한 리소스\n      Internet Gateway (Default)\n      NAT Gateway\n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/networking-networking-10-1.html"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-acg-guide-html": {
						"id": "security-ncloud-security-acg-guide-html",
						"title": "Ncloud 방화벽 ACG 설정 기본 가이드",
						"categories": "",
						"url": " /security/ncloud_security_acg_guide.html",
						"content": "개요\nACG(Access Control Group)는 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스로 AWS에서는 비슷하게 Security Group이라는 것이 있습니다.\n\n제한 사항\n\nVPC 환경\n\n  VPC당 최대 500개까지 ACG 생성 가능\n  NIC당 3개의 ACG를 허용\n  Inbound / Outbound 각각 50개의 규칙 생성 가능\n\n\nClassic 환경\n\n  계정당 최대 100개까지 ACG를 생성 가능\n  각 ACG에는 최대 100개까지의 규칙을 설정할 수 있음\n  서버는 최대 5개의 ACG에 중복 포함될 수 있음\n  서버가 생성될 시 선택한 ACG는 변경이 불가하며, 반납 전까지 해당 ACG 규칙을 적용 받게 됨\n\n\nClassic 환경에서는 서버 자체에 할당되는 개념이었으나 VPC에는 NIC 즉, 네트워크 카드에 할당되는 개념이어서 VPC 환경에서는 NIC 당 최대 3개까지 ACG를 적용할 수 있습니다.\n\nACG 위치\nNcloud 콘솔에서 ACG의 위치는 [Services] - [Compute] - [Server] - [ACG]에 있습니다.\n\nVPC 환경\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nClassic 환경\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n기본 규칙\n\nDefault ACG\n기본적으로 추가되는 ACG\n\n\n  모든 들어오는 연결(inbound traffic)을 차단함\n  모든 나가는 연결(outbound traffic)을 허용함\n  Default ACG 내 속한 서버들끼리의 네트워크 양방향 통신(TCP, UDP, ICMP)이 허용됨\n  원격 접속 기본 포트 (Linux - 22, Windows - 3389)에 대한 TCP 허용됨\n\n\nVPC 화면\n\nInbound (기본 설정)\n\n  \n  \n    \n  \n\n\n기본으로 생성된 ACG에는 위처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 허용되어 있는데 보안을 위해 이 항목을 삭제하고 아래와 같이 지정된 IP에서만 접속하도록 수정하는 것을 적극 권장합니다.\n\nInbound (권장 설정)\n\n  \n  \n    \n  \n\n\nOutbound\n\n  \n  \n    \n  \n\n\nClassic 화면 (기본 설정)\n\n  \n  \n    \n  \n\n\n기본으로 생성된 ACG에는 위처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 허용되어 있는데 보안을 위해 이 항목을 삭제하고 아래와 같이 지정된 IP에서만 접속하도록 수정하는 것을 적극 권장합니다.\n\nClassic 화면 (권장 설정)\n\n  \n  \n    \n  \n\n\nCustom ACG\nDefault ACG 이외에 사용자가 추가하는 ACG\n\n\n  모든 inbound traffic을 차단함(규칙으로 명시되어 있지 않음)\n  모든 outbound traffic을 허용함(규칙으로 명시되어 있지 않음)\n\n\n접근소스 설정\nACG를 설정할 때 접근 소스 항목은 보통 IP주소를 입력하게 됩니다. \n하지만 특수한 경우로 Load Balancer를 지정하거나 ACG 이름을 지정하는 경우도 있습니다. \n이 중에서 다른 ACG를 접근 소스 항목으로 지정하는 경우는 해당 ACG가 적용된 서버들이 접근할 수 있도록 규칙을 설정하는 것인데, 아래 예시를 이용해 정리해보겠습니다.\n\nACG-1\n\n  적용서버 : SVR-1, SVR-2\n\n\nACG-2\n\n  적용서버 : SVR-3\n\n\nACG-2 적용 규칙\n\n  프로토콜 :  TCP\n  접근소스 :  ACG-1\n  허용포트 : 80\n\n\n Note: 위와 같은 경우 ACG-1이 적용된 SVR-1, SVR-2 서버에서 ACG-2가 적용된 SVR-3 서버로 80포트를 이용한 접근을 허용한다는 의미입니다.\n\nVPC 환경에서 ACG를 접근소스를 설정할 때는 동일한 VPC에 생성된 ACG만 접근소스로 설정할 수 있습니다.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/compute-compute-2-3.html"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-onpremise-compare-html": {
						"id": "security-ncloud-security-onpremise-compare-html",
						"title": "Ncloud vs On-Premise Security 비교",
						"categories": "",
						"url": " /security/ncloud_security_onpremise_compare.html",
						"content": "개요\n기존의 IDC 등의 On-Premise 환경에서 사용하고 있는 보안 서비스를 네이버 클라우드 환경에서 어떻게 구현할 수 있는지에 대한 비교 가이드입니다.\nIDC에 있는 서버들을 네이버 클라우드로 마이그레이션 할 때 참고하시면 되겠습니다.\n\nOn-Premise → Naver Cloud\n\n\n  \n    \n      구분\n      On-Premise\n       \n      Naver Cloud\n      설명\n    \n  \n  \n    \n      Network\n      DDos\n      →\n      Security Monitoring\n      Security Monitoring DDos 서비스를 통해 고객별 특화된 탐지 정책을 적용\n    \n    \n       \n      방화벽\n      →\n      ACG(Access Control Group)\n      ACG Rule 변경 기능으로 서버 접속을 허용할 트래픽 규칙을 안전하고 편리하게 관리\n    \n    \n       \n      IDS/IPS\n      →\n      Security Monitoring\n      Security Monitoring IDS/IPS 서비스를 통해 고객별 특화된 탐지/차단 정책을 적용\n    \n    \n       \n      전송구간 암호화\n      →\n      IPSec/SSL VPN, Cloud Connect\n      고객의 네트워크와 네이버 클라우드에 있는 네트워크에 대한 안전한 연결을 제공\n    \n    \n      DB\n      DB 접근 통제\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n       \n      DB 암호화\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n      Server\n      서버접근통제\n      →\n      SSL VPN, Naver Cloud MarketPlace\n      SSL VPN을 이용해 서버 접근을 관리  MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n       \n      서버보안(SecureOS)\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n       \n      Anti Virus\n      →\n      Security Monitoring\n      Security Monitoring DDos 악성코드 의심 이벤트 발생 시 탐지 보고서 및 분석 정보 전달\n    \n    \n      Application\n      웹 방화벽\n      →\n      Security Monitoring\n      Security Monitoring WAF서비스를 통해 고객별 특화된 탐지/차단 정책을 적용\n    \n    \n       \n      Anti-Webshell\n      →\n      Naver Cloud MarketPlace\n      MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용\n    \n    \n      User Access\n      사용자 접근통제\n      →\n      Sub Account\n      Sub Account 서비스를 이요하여 콘솔 접근에 대한 사용자 접속을 관리\n    \n    \n      Audit\n      -\n      →\n      Cloud Activity Tracer / Resource Manager\n      리소스(서버, 네트워크, DB등) 생성, 변경, 삭제에 대해 추적 기능을 제공\n    \n    \n      Key Management\n      -\n      →\n      Key Management Service\n      Key에 대한 접근 제어 기능을 이용하여 데이터 암호화 키를 안전하게 보호하고 관리\n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/security-security-1-1.html"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-service-summary-html": {
						"id": "security-ncloud-security-service-summary-html",
						"title": "Security 서비스 요약",
						"categories": "",
						"url": " /security/ncloud_security_service_summary.html",
						"content": "개요\n네이버 클라우드에서 제공하는 Security 서비스 상품들을 간단한 설명과 함께 요약 정리한 내용입니다.\n이 내용도 파트너 테크데이에서 공개된 자료입니다.\n\n서비스 요약\n\n\n  \n    \n      구분\n      상품\n      설명\n    \n  \n  \n    \n      침입탐지/대응\n      Basic Security\n      모든 고객에게 기본으로 제공되는 무료 보안 서비스\n    \n    \n       \n      Security Monitoring\n      IDS, Anti-DDos, Anti-Virus, IPS, WAF와 같은 다양한 보안 상품들을 이용하여 높은 수준의 보안 서비스를 제공\n    \n    \n       \n      Site Safer\n      고객이 개발한 웹사이트가 해킹 또는 다른 보안 문제로 인해 악성코드를 배포하는지 검사\n    \n    \n       \n      File Safer\n      고객의 서비스에서 제공하는 파일과 아웃링크 URL의 악성코드 감염 여부를 해시 기반으로 검사\n    \n    \n       \n      App Safer\n      고객의 앱이 모바일에서 실행될 때, 루팅/탈옥, 악성 앱 설치, 앱 변조 등 보안 위협 여부를 실시간으로 탐지\n    \n    \n       \n      Webshell Behavior Detector\n      고객의 웹 서비스를 공격하는 다양한 웹셀을 행위기반으로 실시간 탐지하는 서비스\n    \n    \n      접근제어\n      ACG\n      인스턴스 그룹 단위로 IP, Port 기반의 네트워크 패킷 필터링 기능을 제공\n    \n    \n       \n      Secure Zone\n      개인정보와 같이 중요한 정보를 보다 더 안전하게 보호할 수 있도록 대외 인터넷 망과 분리된 별도의 존을 제공\n    \n    \n      인증/권한 관리\n      Sub Account\n      사용자 업무 역할별로 권한 관리를 할 수 있는 기능 제공\n    \n    \n      암호화\n      KMS\n      고객 데이터의 암/복호화에 이용되는 키를 안전하게 보호할 수 있는 서비스\n    \n    \n       \n      Certificate Manager\n      SSL 인증서의 손쉬운 등록 및 관리 서비스를 제공\n    \n    \n      로깅 및 모니터링\n      Resource Manager\n      네이버 클라우드 서비스 내에 생성한 모든 리소스를 한 눈에 볼 수 있는 통합관리 서비스\n    \n    \n       \n      Cloud Activity Tracer\n      네이버 클라우드 서비스에서 발생한 계정 활동 로그를 자동으로 수집해주는 서비스\n    \n    \n       \n      Cloud Advisor\n      네이버 클라우드 모범 사례에 따른 서비스 이용 권장 지침 안내\n    \n    \n      취약점 관리\n      System Security Checker\n      고객 서버의 운영체제 및 WAS 시스템에 대해서 보안상 취약점이 없는지 점검하고 결과 리포트를 제공해주는 서비스\n    \n    \n       \n      Web Security Checker\n      고객의 웹서비스에 대해 총 20가지의 주요 웹 취약점을 자동으로 진단하고 결과 리포트를 제공해주는 서비스\n    \n    \n       \n      App Security Checker\n      고객의 Andorid 모바일 앱에 대해 취약점을 자동으로 점검하고 결과 리포트를 제공해주는 서비스\n    \n    \n      Compliance\n      Compliance Guide\n      고객이 보안 인증이나 규제에 대응하는데 필요한 사항을 알기 쉽게 정리한 가이드\n    \n  \n\n\n\n  \n  \n    \n  \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/security-security-1-1.html"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-ssl-dcv-method-html": {
						"id": "security-ncloud-security-ssl-dcv-method-html",
						"title": "SSL인증서 DCV (Domain Control Validation) 인증 방법과 유의사항 정리",
						"categories": "",
						"url": " /security/ncloud_security_ssl_dcv_method.html",
						"content": "개요\nHTTPS 접속을 위한 SSL 인증서를 발급 받기 위해서는 DCV (Domain Control Validation)를 인증받아야 하는데, 이때 필요한 인증방법과 유의 사항을 정리해보겠습니다.\n\nDCV 인증 방법\nDCV 인증방법은 3가지가 있습니다.\n\n\n  Email 인증\n  DNS 인증\n  http 인증\n\n\nEmail 인증\nEmail 인증은 도메인 등록정보에서 확인되는 이메일과 추가로 5개의 임의로 지정된 메일주소로 인증메일을 발송합니다.\n\n도메인 등록 정보 이메일\n도메인 등록 기관에서 도메인 소유자 정보를 노출하지 않는 블라인드 서비스를 이용하고 있을 경우 인증메일을 받을 수 없습니다.\nEmail 인증을 하기 전에 블라인드 서비스를 해제하고 인증을 요청하셔야 합니다.\n\n추가 5개의 임의로 지정된 이메일\n임의로 지정된 이메일 주소는 admin, administrator, hostmaster, postmaster, webmaster 등 5가지이며 추가/수정이 불가능합니다.\n\n위의 총 6개 메일 주소 중에서 적어도 1개는 유효한 메일주소여야 이메일 인증을 문제없이 완료할 수 있습니다.\n\n이메일 인증 유의사항\n\n  해외 발신 이메일이 차단되도록 설정되어 있지 않은지 확인이 필요합니다.\n  메일함 용량 부족으로 반송되지 않도록 확인이 필요합니다.\n  자체 메일 서버일 경우 메일서버가 장애가 생기지 않도록 확인이 필요합니다.\n  스팸 차단 서비스나 장비에서 차단이 될 수도 있으므로 확인이 필요합니다.\n\n\n참고 : https://www.sslcert.co.kr/products/domain-control-validation#email\n\nDNS 인증\nDNS 인증은 다음과 같은 순서로 진행하면 됩니다.\n\n\n  인증서 신청 사이트에서 CNAME 처리를 위한 DNS 인증용 Host, Record 용 값을 확인합니다.\n  DNS에 위에서 확인한 값으로 CNAME Record를 등록합니다.\n  인증서 신청 사이트에서 DNS 인증 요청 버튼을 클릭합니다.\n\n\n# 예시\n# {Host값}.test.co.kr CNAME {Record Value}\n_PVG823NLK4DFSVFSANLK.test.co.kr CNAME 089DFCHKJFDSUIFDSLKJ38NF.ssltest.com\n\n\n\nDNS 인증 유의사항\n\n  Host 값 첫번째 문자열이 _(언더바)입니다. CNAME 등록시에 빠뜨리지 않도록 주의해야 합니다.\n  DNS서버에서 TTL 값을 너무 길게 설정하면 그 시간 만큼 인증을 받을 수 없으므로 주의해야 합니다.\n\n\n참고 : https://www.sslcert.co.kr/products/domain-control-validation#dns\n\nhttp 인증\nhttp인증은 http 인증용 코드를 다운로드 받아 해당 도메인 웹사이트에 등록하는 방법입니다.\n\n\n  인증서 신청 사이트에서 http 인증용 코드 파일을 다운로드 받습니다.\n  해당 도메인 사이트에  /.well-known/pki-validation/ 경로를 생성합니다.\n  다운로드 받은 인증 코드 파일을 위 경로에 업로드 합니다.\n  인증서 신청 사이트에서 http 인증 요청 버튼을 클릭합니다.\n\n\n해당 도메인이 test.co.kr 일 경우 인증 코드 파일의 경로는 다음과 같은 형식이어야 합니다.\n   http://test.co.kr/.well-known/pki-validation/[파일명].txt\n\n\n\nhttp 인증 유의사항\n\n  인증 코드 파일은 수정하면 안됩니다.\n  인증 코드 파일 포맷은 ANSI 포맷이어야 합니다.\n  SSL 발급 신청시 도메인에 www. 입력하였더라도, DCV 인증시에는 www를 제외하고 검사가 진행됩니다.\n만약  현재 사이트가 www. 로만 접속가능한 상태라면, DCV 인증을 위해 임시라도 www. 제외된 접속이 가능하게 만들어 놓아야 합니다.\n\n\n참고 : https://www.sslcert.co.kr/products/domain-control-validation#http\n\n로드밸런서(Load Balancer)를 사용하면서 http 인증할 때 사전작업\nhttp 인증을 하려고 할 때 로드밸런서를 사용하게 될 경우 로드밸런서의 도메인을 DNS에서 CNAME 처리를 먼저 진행하고, DNS 전파가 완료된 것을 확인한 후에 http 인증을 요청해야 합니다.\n\n예를 들어 Ncloud (네이버 클라우드)에서는 다음과 같이 처리하면 됩니다.\n\n# DNS CNAME 처리 예제\nwww.test.co.kr  CNAME  slb-{생성된 slb 이름}.ncloudslb.com\n\n\n참고 URL\n\n  인증서 발급 사이트 : SecureSign\n    \n      https://www.sslcert.co.kr/\n    \n  \n  DCV 인증 절차 안내\n    \n      https://www.sslcert.co.kr/products/domain-control-validation"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-ssl-vpn-classic-guide-html": {
						"id": "security-ncloud-security-ssl-vpn-classic-guide-html",
						"title": "Classic 환경에서 SSL VPN 설정하고 접속하는 방법",
						"categories": "",
						"url": " /security/ncloud_security_ssl_vpn_classic_guide.html",
						"content": "개요\nNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 Classic 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\n\nSSL VPN이란?\n\n  VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다.\n  사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다.\n  가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다.\n\n\nSSL VPN 생성\n[SSL VPN 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n우선 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다. Classic 환경에서는 3개, 5개, 10개 상품만 선택 가능합니다. \n다음으로 인증 방식은 ID/PW 만으로 접속하는 일차인증과 OTP까지 사용하는 이차 인증 중에서 원하는 방식을 선택합니다. \n그리고 이차인증을 선택했을 경우에는 SMS와 Email 어떤 것을 이용할 것인지도 선택하게 됩니다.\n\n\n⁃ 인증방식과 OTP 전송 방식은 SSL VPN 생성 시에 한번 선택하면 변경할 수 없으니 주의해야 합니다. \n⁃ 만약 변경 하고 싶을 경우에는 SSL VPN을 새로 생성해야 합니다. \n⁃ Classic 환경에서는 이차인증을 선택하면 별도의 이용요금이 부과됩니다.\n\n\n\n  \n  \n    \n  \n\n\n다음으로 개인정보 수집 및 이용에 동의해야 합니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN이 생성되면 다음과 같이 리스트에 서 확인 가능하며 여기서 [SSL VPN IP POOL]은 뒤쪽에서 네트워크 접근 제한을 설정할 때 필요한 중요한 정보입니다.\n\n\n  \n  \n    \n  \n\n\n사용자 설정\nSSL VPN에 접속할 사용자 정보를 설정합니다.  리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\nSSL VPN을 사용하려면 서버에 적용된 ACG에 [SSL VPN IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 적용된 ACG를 확인합니다.\n\n\n  \n  \n    \n  \n\n\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정 화면에서 위에서 확인했던 [SSL VPN IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. \n기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\n\n\n  \n  \n    \n  \n\n\nAgent 다운로드\nSSL VPN 접속을 위한 Agent를 다운로드 합니다.\n\n\n  윈도우 용 다운로드\n  맥 용 다운로드\n\n\n\n  \n  \n    \n  \n\n\nAgent 접속\nAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다.\nAgent에는 Classic 환경 SSL VPN 서버(Ncloud-kr-01)가 기본으로 설정되어 있는데, 혹시 빠져 있다면 [서버 변경] 버튼을 클릭해서 https://sslvpn-kr-01.ncloud.com을 입력하고 연결 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nOTP 접속도 설정했다면 도착한 인증 번호를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에  [SSL VPN IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 접속\n이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\n\n IP 입력: 이때 혹시나 포트 포워딩이나 공인 IP를 설정하고 그 IP를 입력하는 일이 없도록 주의해야 합니다.\n\n\n  \n  \n    \n  \n\n\nAgent 기타 설정\nSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n\n트래픽 그래프\nAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n스펙 변경\n처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [스펙 변경] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n3개, 5개, 10개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n주의사항\n 접속 오류: SSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다.  이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n삭제\n삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud SSL VPN 개요\n    \n      https://guide.ncloud-docs.com/docs/sslvpn-overview\n    \n  \n  Ncloud SSL VPN 사용 가이드 - Classic\n    \n      https://guide.ncloud-docs.com/docs/sslvpn-start-classic"
					}
					
				
			
		
			
				
					,
					
					"security-ncloud-security-ssl-vpn-vpc-guide-html": {
						"id": "security-ncloud-security-ssl-vpn-vpc-guide-html",
						"title": "VPC 환경에서 SSL VPN 설정하고 접속하는 방법",
						"categories": "",
						"url": " /security/ncloud_security_ssl_vpn_vpc_guide.html",
						"content": "개요\nNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 VPC 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\n\nSSL VPN이란?\n\n  VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다.\n  사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다.\n  가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다.\n\n\nSSL VPN 서비스 위치\nNcloud 콘솔에서 SSL VPN의 위치는 [Services] - [Security] - [SSL VPN]에 있습니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN 생성\n[SSL VPN 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n우선 접근할 서버가 속해 있는 VPC를 선택하고, 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다.\nVPC 환경에서는 3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 선택 가능합니다.\n\n\n  \n  \n    \n  \n\n\nVPC 환경의 SSL VPN은 콘솔에서 자동으로 생성하는 것이 아니라 생성 요청을 하면 Ncloud 담당자가 직접 생성하고 결과를 안내 받는 구조로 되어 있습니다. \n생성 완료까지 걸리는 시간은 약 10~20분 이내 이며, 생성이 완료되면 SSL VPN 상태가 [운영중]으로 변경되고, 안내 메일이 도착합니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN 생성 완료\nSSL VPN 생성이 완료되면 아래와 같이 [IP POOL]과 [접속 URL] 정보를 확인할 수 있는데 SSL VPN Agent 접속 시에 중요한 정보이니 잘 확인해야 합니다.\n\n\n  \n  \n    \n  \n\n\n사용자 설정\nSSL VPN에 접속할 사용자 정보를 설정합니다.  리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\nVPC 환경은 이차인증이 필수이므로  SMS와 Email 정보를 함께 입력합니다.\n\n\n  \n  \n    \n  \n\n\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nRoute Table 설정\n네트워크 설정에서는 우선 접속할 서버가 속해 있는 VPC Subnet의 Route Table에 SSL VPN으로 접근할 수 있게 SSL VPN의 [IP POOL]을 등록해야 합니다.\n\n\n  접속할 서버 정보 확인\n아래와 같이 접속할 서버의 정보에서 VPC와 Subnet을 확인합니다. 여기서는 Private Subnet에 생성한 서버에 접속할 예정입니다.\n\n\n\n  \n  \n    \n  \n\n\nVPC 서비스 위치\n[VPC] 서비스는 [Console] - [Services] - [Networking]에 위치해 있습니다.\n그리고, 아래와 같이 [VPC Management], [Subnet Management], [Route Table] 메뉴를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭합니다.\n(Public Subnet에 생성한 서버에 접근해야 할 경우에는 public-table을 선택하고 설정하시면 됩니다.)\n\n\n  \n  \n    \n  \n\n\n[Destination]에 생성된 SSL VPN 정보에서 확인한 [IP POOL] 정보를 등록하고, [Target Type]은 SSLVPN을 선택, [Target Name]은 위에서 생성한 SSL VPN 이름을 선택하고 [생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 설정\n다음으로 서버에 적용된 ACG에 SSL VPN의 [IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다.\n\n\n  \n  \n    \n  \n\n\nACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nACG 규칙 설정 화면에서 위에서 확인했던 [IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. \n기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\n\n\n  \n  \n    \n  \n\n\nAgent 다운로드\nSSL VPN 접속을 위한 Agent를 다운로드 합니다.\n\n\n  SSL VPN Agent 다운로드\n\n\n\n  \n  \n    \n  \n\n\nAgent 접속\nAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다. \n서버 선택 창에 위에서 생성했던 SSL VPN 정보에서 확인했던 [접속 URL] 주소를 입력하고, [다음] 버튼을 클릭합니다.\n\n Tip: \n접속 URL 확인하는 방법 \n\n\n\n  \n  \n    \n  \n\n\n주소 변경 후에 [연결] 버튼을 클릭하면 로그인 화면이 나타나는데 위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n그리고 도착한 OTP 인증 번호를 입력합니다.\n\n\n  \n  \n    \n  \n\n\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에  [IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n서버 접속\n이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nAgent 기타 설정\nSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n\n트래픽 그래프\nAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n설정 변경\n처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [SSL VPN 설정 변경] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nID 개수 변경\n3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n인증 로그 수집\nNcloud SSN VPN은 이용자가 SSN VPN에 접속 인증한 로그를 수집할 수 있습니다. [설정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n인증 로그 수집을 활성화 하면 [Cloud Log Analytics]에 로그를 전달하여 저장합니다. 해당 상품을 미사용중이면 Cloud Log Analytics 상품 이용 신청을 한 후에 사용하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  Cloud Log Analytics에서 인증 로그 확인\n\n\n  \n  \n    \n  \n\n\n주의사항\n 접속 오류: SSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다.  이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n삭제\n삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n하지만, 바로 삭제가 되지 않고 다음과 같이 “Route Table에서 Target으로 지정된 Route 정보를 모두 삭제해야 삭제가 가능합니다”라는 메시지가 뜹니다.\n\n\n  \n  \n    \n  \n\n\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭해서 등록된 설정을 확인하고 [X] 버튼을 클릭해서 설정을 삭제합니다. \nRoute Table 정보를 삭제한 후에 SSL VPN을 삭제하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  Ncloud SSL VPN 개요\n    \n      https://guide.ncloud-docs.com/docs/sslvpn-overview\n    \n  \n  Ncloud SSL VPN 사용 가이드 - VPC\n    \n      https://guide.ncloud-docs.com/docs/sslvpn-start-vpc"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-archive-storage-api-access-token-create-html": {
						"id": "storage-ncloud-storage-archive-storage-api-access-token-create-html",
						"title": "PHP로 Archive Storage API 인증 토큰 생성하는 방법",
						"categories": "",
						"url": " /storage/ncloud_storage_archive_storage_api_access_token_create.html",
						"content": "개요\n네이버 클라우드(Ncloud) Archive Storage API를 이용하려고 할 때 먼저 인증 토큰을 생성하고 생성된 토큰을 이용해서 API로 Archive Storage에 접근해야 합니다. \n여기서는 PHP로 API 인증 토큰을 생성하는 방법에 대해 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n\nAPI 정보\n\n  OpenStack Swift API : 2.15.1 (Pike)\n  OpenStack Keystone V3 API : v3.8\n\n\n인증 토큰 생성 코드\n&lt;?php\n\n  // 전송해야 할 설정값\n  $ncloud_accesskey = \"네이버 클라우드 AccessKey\";\n  $ncloud_secretkey = \"네이버 클라우드 SecretKey\";\n  $ncloud_domain_id = \"Archive Storage 도메인 ID\";\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n\n  $api_server = \"https://kr.archive.ncloudstorage.com:5000\";\n  $api_url = \"/v3/auth/tokens\";\t\t \n\n  // http 호출 헤더값 설정\n  $http_header = array();\n  $http_header[0] = \"Content-Type: application/json\";\n\n  // 전송할 값들을 배열 형태로 저장한다\n  $postvars = [\n  \t\"auth\"=&gt; [\n  \t\t\"identity\"=&gt; [\n  \t\t\t\"methods\"=&gt; [\n  \t\t\t\t\"password\"\n  \t\t\t],\n  \t\t\t\"password\"=&gt; [\n  \t\t\t\t\"user\"=&gt; [\n  \t\t\t\t\t\"name\"=&gt; $ncloud_accesskey,\n  \t\t\t\t\t\"password\"=&gt; $ncloud_secretkey,\n  \t\t\t\t\t\"domain\"=&gt; [\n  \t\t\t\t\t\t\"id\"=&gt; $ncloud_domain_id\n  \t\t\t\t\t]\n  \t\t\t\t]\n  \t\t\t]\n  \t\t],\n  \t\t\"scope\"=&gt; [\n  \t\t\t\"project\"=&gt; [\n  \t\t\t\t\"id\"=&gt; $ncloud_project_id\n  \t\t\t]\n  \t\t]\n  \t]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환해서 전송\n  $json_portvars = json_encode($postvars);\n\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_POST, TRUE); //POST 방식으로 호출\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\n  curl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\n\n  $response = curl_exec($ch);\n\n  curl_close($ch);\n\n  if ($response)\n  {\n  \t// X-Subject-Token 토큰 값은 request body가 아닌 header로 전달되므로\n  \t// header를 분리해서 배열에 저장한다 \n  \t$headers = array();\n  \t$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n  \tforeach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n  \t{\n  \t\tif ($i === 0)\n  \t\t{\n  \t\t   $headers[\"http_code\"] = $line;\n  \t\t}\n  \t\telse\n  \t\t{\n  \t\t   list ($key, $value) = explode(\": \", $line);\n  \t\t   $headers[$key] = $value;\n  \t\t}\n  \t}\n\t\n\t// 인증 토큰 확인\n  \t$x_auth_token = $headers[\"X-Subject-Token\"]; \n  \techo($x_auth_token);\n\n  \t//var_dump($headers);\n  \t//echo(\"&lt;hr&gt;\");\n  \t//var_dump($response);\n  } \n  else \n  {\n  \techo \"Curl error: \" . curl_error($ch);\n  }\n?&gt;\n\n\n코드 상세 설명\n\nAPI 인증 Key 생성\n[Sub Account] - [Sub Accounts]에서 본인의 계정을 선택하고, [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나는데[추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\n\n : \n메인 계정은 최대 권한을 가지기 때문에 메인 계정으로 생성한 API도 메인 계정과 동일한 최대 권한을 가지게 됩니다. 그러므로 메인 계정으로 API Key를 생성하게 되면 이 Key가 유출되었을 때 심각한 문제가 생기기 때문에 반드시 서브 계정에서 API Key를 생성해야 합니다.\n\n\n\n  \n  \n    \n  \n\n\nArchive Storage API 이용 정보\n  $ncloud_domain_id = \"Archive Storage 도메인 ID\";\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n\nArchive Storage API 이용을 위한 Domain ID와 Project ID는 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[API 이용 정보 확인] 창에서 Domain ID와 Project ID를 확인하고, PHP 소스코드에 입력합니다.\n\n\n  \n  \n    \n  \n\n\nAPI 서버와 URL 설정\n  $api_server = \"https://kr.archive.ncloudstorage.com:5000\";\n  $api_url = \"/v3/auth/tokens\";\n\nArchive Storage API 서버와 토큰 생성을 위한 URL 정보는 위와 같습니다.\n\nHTTP 호출 header 값 설정\n  $http_header = array();\n  $http_header[0] = \"Content-Type: application/json\";\n\nHTTP header에는 json 형태로 호출한다는 것을 설정합니다.\n\n전송할 값 설정\n  // 전송할 값들을 배열 형태로 저장\n  $postvars = [\n  \t\"auth\"=&gt; [\n  \t\t\"identity\"=&gt; [\n  \t\t\t\"methods\"=&gt; [\n  \t\t\t\t\"password\"\n  \t\t\t],\n  \t\t\t\"password\"=&gt; [\n  \t\t\t\t\"user\"=&gt; [\n  \t\t\t\t\t\"name\"=&gt; $ncloud_accesskey,\n  \t\t\t\t\t\"password\"=&gt; $ncloud_secretkey,\n  \t\t\t\t\t\"domain\"=&gt; [\n  \t\t\t\t\t\t\"id\"=&gt; $ncloud_domain_id\n  \t\t\t\t\t]\n  \t\t\t\t]\n  \t\t\t]\n  \t\t],\n  \t\t\"scope\"=&gt; [\n  \t\t\t\"project\"=&gt; [\n  \t\t\t\t\"id\"=&gt; $ncloud_project_id\n  \t\t\t]\n  \t\t]\n  \t]\n  ];\n\n  // 배열 형태로 저장한 값들을 json 형태로 변환해서 전송\n  $json_portvars = json_encode($postvars);\n\n네이버 클라우드 AccessKey, SecretKey, Archive Storage 도메인 ID, 프로젝트 ID를 전송하기 위해 지정된 형태의 배열로 저장한 후에 json 형태로 변환합니다. \n물론 처음부터 json 형태로 저장해도 됩니다.\n\nAPI 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_POST, TRUE); //POST 방식으로 호출\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\n  curl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\n\n  $response = curl_exec($ch);\n  curl_close($ch);\n\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\ncurl_setopt($ch, CURLOPT_HEADER, TRUE); 는 Response에 body 뿐만 아니라 header 값도 수신하기 위해 설정합니다.\n\nAPI 인증 토큰 분리\n  if ($response)\n  {\n  \t$headers = array();\n  \t$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n  \tforeach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n  \t{\n  \t\tif ($i === 0)\n  \t\t{\n  \t\t   $headers[\"http_code\"] = $line;\n  \t\t}\n  \t\telse\n  \t\t{\n  \t\t   list ($key, $value) = explode(\": \", $line);\n  \t\t   $headers[$key] = $value;\n  \t\t}\n  \t}\n\t\n\t// 인증 토큰 확인\n  \t$x_auth_token = $headers[\"X-Subject-Token\"]; \n  \techo($x_auth_token);\n\n  \t//var_dump($headers);\n  \t//echo(\"&lt;hr&gt;\");\n  \t//var_dump($response);\n  } \n\nAPI 인증 토큰값은 X-Subject-Token이라는 이름으로 request body가 아닌 header로 전달되므로 header를 분리해서 배열에 저장합니다.\n실제 전송되는 header 값은 아래와 같은 형태입니다.\nHTTP/1.1 201 Created \nDate: Thu, 11 Nov 2021 07:59:32 GMT \nServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips mod_wsgi/3.4 Python/2.7.5 \nX-Subject-Token: gAAAAABhjM1lbeTW3Vq......중간 생략 ......txWYsWGrC1siPt8CE0rs_KgNMTQ \nVary: X-Auth-Token \nx-openstack-request-id: req-1ce......중간 생략 ......a85eb5b \nContent-Length: 1762 \nContent-Type: application/json\n\n\n인증 토큰 유효 시간\nAPI 인증 토큰의 유효 시간은 24시간이고 삭제 요청을 호출하면 삭제할 수 있습니다.\n\n참고 URL\n\n  Archive Storage API 기본 가이드\n    \n      https://api.ncloud-docs.com/docs/common-archivestorageapi-archivestorageapi\n    \n  \n  OpenStack Keystone V3 API 가이드\n    \n      https://docs.openstack.org/api-ref/identity/v3/\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2021-11-11\n          문서 최초 생성\n        \n      \n        \n          2024-01-31\n          API 인증 Key 생성 방법 안내 변경"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-archive-storage-api-get-container-by-php-html": {
						"id": "storage-ncloud-storage-archive-storage-api-get-container-by-php-html",
						"title": "PHP로 Archive Storage API 호출하기 - 컨테이너(버킷) 오브젝트 목록 조회",
						"categories": "",
						"url": " /storage/ncloud_storage_archive_storage_api_get_container_by_php.html",
						"content": "개요\n네이버 클라우드(Ncloud) Archive Storage API를 이용해서 컨테이너(버킷)에 있는 오브젝트 전체 목록을 PHP로 조회하는 방법에 대해 정리해보겠습니다.\n\nAPI 정보\n\n  OpenStack Swift API : 2.15.1 (Pike)\n  OpenStack Keystone V3 API : v3.8\n\n\n인증 토큰 생성\nArchive Storage API를 호출할 때는 먼저 인증 토큰을 생성해야 하는데, 생성 방법은 내용이 다소 긴 관계로 다른 문서에서 자세히 설명해두었습니다. \n아래 문서를 참고 하시기 바랍니다.\n\nPHP로 Archive Storage API 인증 토큰 생성하는 방법 (docs.3rdeyesys.com)\n\n오브젝트 목록 조회 코드\n&lt;?php\n\n  $x_auth_token = \"Archive Storage API 인증 토큰\";\n\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n  $ncloud_container = \"Archive Storage 컨테이너(버킷) 이름\";\n  \n  $api_server = \"https://kr.archive.ncloudstorage.com\";\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json\";\t\t\n\n  // http 호출 헤더값 설정\n  $http_header = array();\n  $http_header[0] = \"X-Auth-Token: \".$x_auth_token;\n  $http_header[1] = \"charset=UTF-8\";\n\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //request에 header 값도 수신\n  curl_setopt($ch, CURLOPT_POST, FALSE); //GET 방식으로 호출\n\n  $response = curl_exec($ch);\n  $http_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n  curl_close($ch);\n  \t\t\n  if ($response)\n  {\n  \tif ($http_code == 200)\n\t{\n\t\t// response에서 header 값 분리\n\t\t$headers = array();\n\t\t$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n\t\tforeach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n\t\t{\n\t\t\tif ($i === 0)\n\t\t\t{\n\t\t\t   $headers[\"http_code\"] = $line;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t   list ($key, $value) = explode(\": \", $line);\n\t\t\t   $headers[$key] = $value;\n\t\t\t}\n\t\t}\n\n\t\t// response에서 json형태의 body 값 분리\n\t\t$json_response = substr($response, strpos($response, \"\\r\\n\\r\\n\"));\n\t\t$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n\n\t\t$object_count = $headers[\"X-Container-Object-Count\"];\n\t\t$used_bytes = $headers[\"X-Container-Bytes-Used\"];\n\t\t$used_k_bytes = $used_bytes / 1024;\n\t\t$used_m_bytes = $used_k_bytes / 1024;\n\t\t$used_g_bytes = $used_m_bytes / 1024;\n\t}\n\telse if ($http_code == 404)\n\t{\n\t\techo(\"존재하지 않는 컨테이너(버킷)입니다\");\n\n\t\t$rows_response = [];\t\n\n\t\t$object_count = 0;\n\t\t$used_bytes = 0;\n\t\t$used_k_bytes = 0;\n\t\t$used_m_bytes = 0;\n\t\t$used_g_bytes = 0;\n\t}\n\telse\n\t{\n\t\techo($response);\n\t}\n\n  }\n  else\n  {\n  \techo(\"Error\");\n  }\n\n?&gt;\n\n\n&lt;?php\n  // 오브젝트 목록 출력\n  $cnt = 0;\n  foreach ($rows_response as $row)\n  {\t\t\t\t\n  \t$archive_object_name = $row[\"name\"];\n  \t$archive_object_hash = $row[\"hash\"];\n  \t$archive_object_content_type = $row[\"content_type\"];\n  \t$archive_object_last_modified = $row[\"last_modified\"];\n  \t$archive_object_bytes = $row[\"bytes\"];\n\n  \t$cnt++;\n  ?&gt;\n\t&lt;tr&gt; \t  \t\t\t\t\t\t\n\t  &lt;td&gt;&lt;?php echo($cnt);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_name);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_content_type);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_hash);?&gt;&lt;/td&gt;\t\t\t\t\t  \n\t  &lt;td&gt;&lt;?php echo($archive_object_last_modified);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo(number_format($archive_object_bytes));?&gt;&lt;/td&gt;\n\t&lt;/tr&gt;\n\n&lt;?php\t\n  }\n?&gt;\n\n\n코드 상세 설명\n\n\nArchive Storage API 이용 정보\n  $ncloud_project_id = \"Archive Storage 프로젝트 ID\";\n  $ncloud_container = \"Archive Storage 컨테이너(버킷) 이름\";\n\nArchive Storage API 이용을 위한 Project ID는 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n테스트에 사용할 컨테이너(버킷)은 [test]로 설정해두었습니다.\n\n\n  \n  \n    \n  \n\n\n[API 이용 정보 확인] 창에서 Project ID를 확인하고, PHP 소스코드에 입력합니다.\n\n\n  \n  \n    \n  \n\n\nAPI 서버와 URL 설정\n  $api_server = \"https://kr.archive.ncloudstorage.com\";\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json\";\n\nArchive Storage API 서버와 컨테이너(버킷)에 있는 오브젝트 목록을 조회하기 위한 URL 정보는 위와 같습니다. \n[프로젝트 ID]와 [컨테이너(버킷) 이름]을 URL에 포함시키고, 파라미터로는 전달받을 목록의 형태를 설정하게 되는데, 여기서는 json형태로 받겠습니다.\n\nHeader 값 설정\n  // http 호출 헤더값 설정\n  $http_header = array();\n  $http_header[0] = \"X-Auth-Token: \".$x_auth_token;\n  $http_header[1] = \"charset=UTF-8\";\n\nArchive Storage API 인증 토큰은 [X-Auth-Token] 라는 이름으로 header에 담아서 전송합니다.\n\nAPI 호출\n  // api 호출\n  $ch = curl_init();\n  curl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\n  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\n  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\t\n  curl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\n  curl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\n  curl_setopt($ch, CURLOPT_POST, FALSE); //GET 방식으로 호출\n\n이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\ncurl_setopt($ch, CURLOPT_HEADER, TRUE); 는 Response에 body 뿐만 아니라 header 값도 수신하기 위해 설정합니다.\n\nAPI 호출 응답 수신\n  $response = curl_exec($ch);\n  $http_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\n  curl_close($ch);\n\nAPI를 호출하고 응답을 수신합니다. 성공, 실패 등에 대한 HTTP 상태코드도 확인합니다.\n\nHeader, Body 값 분리\n  // response에서 header 값 분리\n  $headers = array();\n  $header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\n\n  foreach (explode(\"\\r\\n\", $header_text) as $i =&gt; $line) \n  {\n\tif ($i === 0)\n\t{\n\t   $headers[\"http_code\"] = $line;\n\t}\n\telse\n\t{\n\t   list ($key, $value) = explode(\": \", $line);\n\t   $headers[$key] = $value;\n\t}\n  }\n\n  // response에서 json형태의 body 값 분리\n  $json_response = substr($response, strpos($response, \"\\r\\n\\r\\n\"));\n  $rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\n\nResoponse에서 Header, Body 값을 따로 분리해서 배열에 저장합니다.\n\n컨테이너(버킷) 기본 정보 확인\n  $object_count = $headers[\"X-Container-Object-Count\"];\n  $used_bytes = $headers[\"X-Container-Bytes-Used\"];\n  $used_k_bytes = $used_bytes / 1024;\n  $used_m_bytes = $used_k_bytes / 1024;\n  $used_g_bytes = $used_m_bytes / 1024;\n\n분리한 Header 값에서 컨테이너(버킷)의 기본 정보를 확인합니다.\n[전체 오브젝트 개수], [사용 중인 용량]을 확인하고 용량은 Bytes 단위이기에 KB, MB, GB 단위로도 변환합니다.\n\nHTTP 상태코드\n  if ($http_code == 200){\n    //성공\n  }\n  else if ($http_code == 404){\n    echo(\"존재하지 않는 컨테이너(버킷)입니다\");\n  }\n\n요청이 성공하게 되면 OK (200), 컨테이너(버킷)이 존재하지 않는 경우는 Not Found (404) 상태 코드를 응답합니다.\n\n오브젝트 목록 html 출력\n&lt;?php\n  // 오브젝트 목록 출력\n  $cnt = 0;\n  foreach ($rows_response as $row)\n  {\t\t\t\t\n  \t$archive_object_name = $row[\"name\"];\n  \t$archive_object_hash = $row[\"hash\"];\n  \t$archive_object_content_type = $row[\"content_type\"];\n  \t$archive_object_last_modified = $row[\"last_modified\"];\n  \t$archive_object_bytes = $row[\"bytes\"];\n\n  \t$cnt++;\n  ?&gt;\n\t&lt;tr&gt; \t  \t\t\t\t\t\t\n\t  &lt;td&gt;&lt;?php echo($cnt);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_name);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_content_type);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo($archive_object_hash);?&gt;&lt;/td&gt;\t\t\t\t\t  \n\t  &lt;td&gt;&lt;?php echo($archive_object_last_modified);?&gt;&lt;/td&gt;\n\t  &lt;td&gt;&lt;?php echo(number_format($archive_object_bytes));?&gt;&lt;/td&gt;\n\t&lt;/tr&gt;\n\n&lt;?php\t\n  }\n?&gt;\n\n오브젝트 목록을 html로 출력합니다.\n출력하는 정보는 [이름], [해시값], [Content Type], [최종 수정일], [용량(Bytes)] 입니다.\n\n목록 출력 예시\n위의 코드를 실행하면 다음과 같이 오브젝트 목록이 출력됩니다.\n\n\n  \n  \n    \n  \n\n\n출력된 오브젝트 정보가 올바른지 확인하기 위해 네이버 클라우드(Ncloud) 콘솔에서 해당 컨테이너(버킷)의 정보를 확인하면 다음과 같이 일치하는 것을 알 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n제한 사항\nArchive Storage API를 이용해서 가져올 수 있는 오브젝트 목록의 최대 개수는 10,000개입니다. \n1만개 이상이 등록된 컨테이너(버킷)에서 오브젝트 목록을 요청해도 아래와 같이 최대 10,000개 까지만 가져올 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n컨테이너(버킷)에 10,000개 이상의 오브젝트가 저장되어 있을 경우에는 아래쪽에서 소개하는 방법처럼 폴더별로 오브젝트 목록을 따로 조회하시면 됩니다.\n\n오브젝트 검색\n위에서는 컨테이너(버킷)에 저장된 모든 오브젝트들을 조회하는 기능을 확인해보았습니다.\n다음으로는 특정 이름으로 시작되는 오브젝트나 특정 폴더에 있는 오브젝트만 조회하는 방법에 대해 위에서 확인한 PHP 예제 소스코드에서 변경이 필요한 부분만 확인해보겠습니다.\n\n테스트에 사용된 오브젝트와 폴더 구조는 다음과 같습니다.\n- Test_Folder_0001.png\n- Test_Folder\n    L Sub_Folder\n        L Sub_Sub_Folder\n\n\n\n특정 이름으로 시작하는 오브젝트 목록\n  $ncloud_object_prefix = \"Test_Folder\";\n\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json&amp;prefix=\".$ncloud_object_prefix;\t\t\n\nAPI URL을 호출할 때 파라미터로 prefix를 전송하면 prefix 값에 해당하는 특정 문자열로 시작하는 오브젝트 목록을 모두 가져 옵니다.\n예를 들어 prefix 값을 [Test_Folder]로 설정하면, 아래와 같이 [Test_Folder]라는 이름으로 시작되는 모든 오브젝트 목록을 가져오게 됩니다.\n\n\n  \n  \n    \n  \n\n\n특정 폴더 아래에 있는 오브젝트 목록\n  $ncloud_object_prefix = \"Test_Folder/\";\n\n  $api_url = \"/v1/AUTH_\".$ncloud_project_id.\"/\".$ncloud_container.\"?format=json&amp;prefix=\".$ncloud_object_prefix;\t\t\n\n특정 폴더 아래에 있는 오브젝트 목록을 가져 올 때는 prefix 값 마지막에 슬래시 [ / ]를 추가하면 됩니다.\n예를 들어 prefix 값을 [Test_Folder/]로 설정하면, 아래와 같이 [Test_Folder]라는 이름의 폴더 아래에 있는 모든 오브젝트 목록을 가져오게 됩니다.\n\n위쪽에서 확인한 [특정 이름으로 시작하는 오브젝트 목록]의 결과 예시와는 다르게 폴더 자체인 [Test_Folder] 그리고 [Test_Folder_0001.png]는 포함되어 있지 않습니다.\n\n\n  \n  \n    \n  \n\n\nAPI 기타 기능\nArchive Storage API에서 지원하는 기능은 컨테이너(버킷)의 오브젝트 목록 외에도 아래와 같이 여러가지가 있습니다. \n위에서 사용한 것은 컨테이너(버킷) 오퍼레이션의 GET 기능입니다.\n\n어카운트 오퍼레이션\n\n  GET : 어카운트에 속한 컨테이너(버킷) 목록을 조회합니다.\n  HEAD : 어카운트의 메타데이터를 조회합니다.\n  POST : 어카운트에 메타데이터를 설정 및 변경합니다.\n\n\n컨테이너(버킷) 오퍼레이션\n\n  PUT : 컨테이너(버킷)을 생성합니다.\n  GET : 컨테이너(버킷)에 속한 오브젝트 목록을 조회합니다.\n  HEAD : 컨테이너(버킷)의 메타데이터를 조회합니다.\n  POST : 컨테이너(버킷)에 메타데이터를 설정 및 변경합니다.\n DELETE : 빈 컨테이너(버킷)을 삭제합니다.\n\n\n오브젝트 오퍼레이션\n\n  PUT : 오브젝트를 업로드합니다. 동일한 이름의 오브젝트가 있을 경우 덮어쓰기를 합니다.\n  COPY : 다른 위치에 있는 오브젝트를 복제합니다.\n  GET : 오브젝트를 다운로드합니다.\n  HEAD : 오브젝트의 메타데이터를 조회합니다.\n  POST : 오브젝트에 메타데이터를 설정 및 변경합니다.\n  DELETE : 오브젝트를 삭제합니다.\n\n\n참고 URL\n\n  Archive Storage API 기본 가이드\n    \n      https://api.ncloud-docs.com/docs/common-archivestorageapi-archivestorageapi\n    \n  \n  Archive Storage API 상세 가이드\n    \n      https://api.ncloud-docs.com/docs/storage-archivestorage\n    \n  \n  OpenStack Keystone V3 API 가이드\n    \n      https://docs.openstack.org/api-ref/identity/v3/"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-archive-storage-cli-windows-guide-html": {
						"id": "storage-ncloud-storage-archive-storage-cli-windows-guide-html",
						"title": "Archive Storage CLI 사용 가이드 - Windows 환경",
						"categories": "",
						"url": " /storage/ncloud_storage_archive_storage_cli_windows_guide.html",
						"content": "개요\n네이버 클라우드(Ncloud) Archive Storage CLI를 Windows 환경에서 사용하는 방법에 대해 정리해보겠습니다.\n\nCLI 정보\nArchive Storage가 OepnStack으로 구성되어 있고, Client는 Python 기반의 Client를 사용하게 됩니다.\n\n\n  python-keystoneclient : 3.17.0\n  python-swiftclient : 3.6.0\n\n\nPython 다운로드\n먼저 Python을 다운로드 합니다. 권장하는 버전은 3.6 이상입니다. 여기서는 3.9를 설치하겠습니다.\n\nhttps://www.python.org/downloads/\n\n\n  \n  \n    \n  \n\n\nPython 설치\n\nPATH 추가\nPython 설치 시작화면에 PATH에 python을 추가하는 옵션이 있습니다.\n“Add Python 3.9 to PATH” 옵션을 선택하고 설치를 시작하면 됩니다.\n\n\n  \n  \n    \n  \n\n\nPATH 문자 길이 제한 해제\nWindows에는 기본설정에 파일경로가 최대 260자로 제한되어 있는데, 이 제한을 풀것인지 확인하는 과정입니다.\n“Disable path length limit” 옵션이 나오는데, 특별한 문제가 없다면 해제하고 가면 됩니다.\n\n\n  \n  \n    \n  \n\n\nCLI Client 설치\n\npython-keystoneclient : 3.17.0 설치\n우선 OepnStack 서비스의 인증을 담당하는  KeyStone Client를 설치합니다.\n\npip install python-keystoneclient==3.17.0\n\n\n  \n  \n    \n  \n\n\npython-swiftclient : 3.6.0 설치\n다음으로 실제 명령을 수행하는 Swift Client를 설치합니다.\n\npip install python-swiftclient==3.6.0\n\n\n\n  \n  \n    \n  \n\n\nClient 설치 오류\nPython Clinet를 설치하는 도중에 아래와 같은 메시지가 나타나면서 오류가 발생하는 경우가 있습니다. \nMicrosoft Visual C++ Build Tools 등이 설치되어 있지 않아서 인데 설치하는 방법 2가지 중에서 하나를 선택해서 설치하시면 됩니다.\n\n error: Microsoft Visual C++ 14.0 is required. Get it with “Microsoft Visual C++ Build Tools” : https://visualstudio.microsoft.com/downloads/\n\n fatal error C1083: 포함 파일을 열 수 없습니다. ‘basetsd.h’ : No such file or directory\nerror: command ‘C:\\Program Files (x86)\\Microsoft Visual Studio\\……. …..\\cl.exe’ failed with exit code 2\n\n\n  \n  \n    \n  \n\n\n방법 1 : Build Tools 직접 설치\n첫번째 방법은 Build Tools를 따로 설치하는 방법입니다. \n아래 링크에서 [Microsoft Build Tools 2015 업데이트3]를 다운로드 받아서 설치하시면 되는데, [Visual Studio]가 설치되어 있는 경우에는 설치가 실패하기도 합니다.\n이때는 아래에 나오는 두번째 방법으로 설치하시면 됩니다.\n\nhttps://visualstudio.microsoft.com/ko/vs/older-downloads/\n\n\n  \n  \n    \n  \n\n\n방법 2 : Visual Studio Installer 설치\nVisual Studio가 설치되어 있는 경우에는 위 1번 방법으로 설치가 되지 않는 경우가 있으므로 Visual Studio Installer에서 설치하도록 하겠습니다.\n[Visual Studio Installer]를 실행하셔서 설치된 Visual Studio 메뉴의 [수정] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n나타난 화면에서 [C++를 사용한 데스크톱 개발]을 선택하시고 오른쪽 [설치 세부정보]에서  다음 2가지를 선택해서 설치하시면 됩니다.\n\n  MSVC vXXX - VS 20XX C++ x64/x86 빌드 도구\n  Windows 10 SDK\n\n\n\n  \n  \n    \n  \n\n\n인증 토큰 생성\nCLI Client가 모두 설치되었으면 이제 접속을 위한 인증 토큰을 생성해야 합니다. \n인증 토큰을 생성하는 명령어는 다음과 같은데 여기에 필요한 값이 4가지 있습니다.\n\nswift --os-auth-url https://kr.archive.ncloudstorage.com:5000/v3 --auth-version 3 --os-username {access_key_id} --os-password {secret_key} --os-user-domain-id {domain_id} --os-project-id {project_id} auth\n\n\n네이버 클라우드 API 인증키 : access_key_id, secret_key\n두가지 Key는 네이버 클라우드 API 인증키로 [네이버 클라우드 포탈] -&gt; [마이페이지] -&gt; [계정관리] -&gt; [인증키 관리] - [API 인증키 관리] 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nArchive Storage API 정보:  domain_id, project_id\n두가지 id 값은 Archive Storage API 이용을 위한 Domain ID와 Project ID로 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[API 이용 정보 확인] 창에서 Domain ID와 Project ID를 확인하고, 인증토큰 생성 코드에 입력합니다.\n\n\n  \n  \n    \n  \n\n\n위에서 확인한 설정 값 4가지를 추가해서 인증토큰 생성 명령을 실행하면 아래와 같이 생성된 인증토큰이 출력됩니다.\nexport OS_STORAGE_URL=https://kr.archive.ncloudstorage.com/v1/AUTH_{project_id}\nexport OS_AUTH_TOKEN={인증 토큰}\n\n\n\n  \n  \n    \n  \n\n\n인증 토큰 유효 시간\nAPI 인증 토큰의 유효 시간은 24시간이고 삭제 요청을 호출하면 삭제할 수 있습니다.\n\n환경 변수 설정\n위에서 생성된 인증토큰과 URL을 환경 변수에 설정합니다. Windows에서는 export 명령을 set로 변경해서 실행합니다.\nset OS_STORAGE_URL=https://kr.archive.ncloudstorage.com/v1/AUTH_{project_id}\nset OS_AUTH_TOKEN={인증 토큰}\n\n\n\n  \n  \n    \n  \n\n\n컨테이너(버킷) 조회\n현재 Archive Storage에 생성되어 있는 컨테이너(버킷)을 확인할 수 있는 명령어는 다음과 같습니다.\nswift list\n\n\n  \n  \n    \n  \n\n\n컨테이너(버킷)의 모든 오브젝트 조회\n특정 컨테이너(버킷)의 모든 오브젝트 목록을 확인하는 명령어는 마지막에 컨테이너(버킷) 이름을 적어주면 됩니다.\nswift list {컨테이너(버킷) 이름}\n\n\n  \n  \n    \n  \n\n\n파일 업로드\n파일 업로드 명령은 특정 파일을 업로드 하는 명령과 폴더를 통째로 업로드 하는 명령을 각각 확인해보겠습니다.\n\n폴더 업로드\n폴더를 통째로 업로드 하는 명령은 다음과 같습니다.\nswift upload {컨테이너(버킷) 이름} --object-name {저장할 Archive Storage 폴더명} {로컬PC 폴더명}\n\n\n폴더 파일을 업로드 후에 list 명령어로 컨테이너(버킷)의 오브젝트 목록을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n개별 파일 업로드\n특정 파일을 업로드 하려면 다음처럼 명령을 실행하면 됩니다.\nswift upload {컨테이너(버킷) 이름} --object-name {저장할 Archive Storage 폴더명/저장할 파일명} {로컬PC 파일 경로}\n\n\n마찬가지로 파일을 업로드 후에 list 명령어로 확인해보시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n파일 삭제\n파일 삭제도 개별 파일 삭제와 폴더 삭제 2가지로 나누어서 확인해보겠습니다.\n\n개별 파일 삭제\n특정 파일을 삭제하는 명령은 다음과 같습니다.\nswift delete {컨테이너(버킷) 이름} {Archive Storage 파일 전체 경로}\n\n\n  \n  \n    \n  \n\n\n폴더 삭제\n폴더 전체를 삭제하는 명령은 prefix 옵션이 들어갑니다.\nswift delete {컨테이너(버킷) 이름} --prefix {Archive Storage 폴더 경로}\n\n\n  \n  \n    \n  \n\n\n파일 다운로드\n파일 다운로드는 개별 파일 다운로드와 폴더 다운로드 그리고, 컨테이너(버킷) 파일 전체 다운로드를 실행해 보고, 로컬PC에서 다운로드 된 것을 확인해보겠습니다.\n\n개별 파일 다운로드\n개별 파일 다운로드에는 output 옵션이 필요합니다.\nswift download {컨테이너(버킷) 이름} --output {저장할 로컬PC 파일 전체 경로} {Archive Storage 파일 전체 경로}\n\n\n  \n  \n    \n  \n\n\n로컬PC에서 확인을 해보면 아래와 같이 다운로드된 파일을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n폴더 다운로드\n폴더 다운로드에는 output-dir 옵션이 필요합니다.\nswift download {컨테이너(버킷) 이름} --output-dir {저장할 로컬PC 폴더 경로} {Archive Storage 폴더 경로}\n\n\n\n  \n  \n    \n  \n\n\n로컬PC에서 확인을 해보면 아래와 같이 폴더가 다운로드 된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n컨테이너(버킷) 전체 다운로드\n컨테이너(버킷)에 있는 모든 파일을 다운로드 할 때는 아래와 같이 폴더 다운로드 명령에서 마지막에 있는 파일명이나 폴더명 파라미터를 지우시면 됩니다.\nswift download {컨테이너(버킷) 이름} --output-dir {저장할 로컬PC 폴더 경로}\n\n\n  \n  \n    \n  \n\n\n로컬PC에서 확인을 해보면 폴더와 파일이 모두 다운로드 된 것을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n주의 사항\n\nArchive Storage CLI를 사용해야 하는 이유\n마지막으로 Archive Storage를 관리할 때는 AWS S3용 Client Tool (ex, CloudBerry Explorer, S3 Browser) 대신에 Archive Storage CLI를 사용해야 하는 이유에 대해 정리해보겠습니다.\n\n네이버 클라우드(Ncloud) Archive Storage는 Object Storage의 데이터를 장기 백업하기 위한 용도 등으로 주로 사용되다 보니 Object Storage와 비슷한 시스템이라고 오해하는 경우가 많습니다. \n하지만, Object Storage가 AWS S3와 호환되는 시스템 구조로 되어 있는 것에 반해, Archive Storage는 OpenStack 기반의 시스템 구조로 되어 있어 전혀 다르다고 보시면 됩니다.\n\n그러다 보니, Object Storage를 관리하는데 자주 사용되는 AWS S3용 Client Tool (ex, CloudBerry Explorer, S3 Browser) 등을 Archive Storage를 관리할 때도 사용하는 경우가 있는데, 가급적 사용하지 않는 것이 좋습니다. \n\n왜냐하면 AWS S3용 Client Tool로 Archive Storage에서 업로드, 다운로드, 삭제, 이름변경 등의 작업을 진행하면 해당 파일에 문제가 생기거나 때로는 컨테이너(버킷) 데이터 전체에 문제가 생길 수도 있기 때문입니다.\n\n혹시나 AWS S3용 Client Tool을 사용하더라도 파일(오브젝트)을 조회하는 용도 정도로만 한정해서 사용하는 것을 추천합니다. 물론 파일 조회도 가능하면 Archive Storage용의 CLI나 API를 이용하는 것이 좋습니다.\n\n참고 URL\n\n  Archive Storage CLI 가이드\n    \n      https://cli.ncloud-docs.com/docs/guide-archivestorage\n    \n  \n  OpenStack CLI 가이드\n    \n      https://docs.openstack.org/ocata/cli-reference/swift.html"
					}
					
				
			
		
			
				
			
		
			
				
					,
					
					"storage-ncloud-storage-compare-html": {
						"id": "storage-ncloud-storage-compare-html",
						"title": "Ncloud에서 제공하는 스토리지들의 요금과 특징 비교",
						"categories": "",
						"url": " /storage/ncloud_storage_compare.html",
						"content": "개요\nNcloud에서 제공하는 스토리지들의 주요 기능과 용도를 QnA 형식으로 비교 정리해보겠습니다.\n\n비교 대상 스토리지\n\n  Block Storage\n  Object Storage\n  NAS\n  Archive Storage\n\n\n가격 비교\n\n\n  \n    \n      스토리지\n      구분\n      과금 단위\n      시간 당 요금\n      500G 기준 요금\n      기타 사항\n    \n  \n  \n    \n      Block Storage\n      HDD\n      10G\n      0.8원\n      40원\n       \n    \n    \n       \n      SDD\n      10G\n      1.6원\n      80원\n       \n    \n    \n      NAS\n       \n      500G\n      50원\n      50원\n       \n    \n    \n      Object Storage\n      1PB 이하\n      1G\n      0.039원\n      19.5원\n      트래픽, API요청수 요금 별도\n    \n    \n       \n      1PB 초과\n      1G\n      0.036원\n      18원\n      트래픽, API요청수 요금 별도\n    \n    \n      Archive Storage\n       \n      1G\n      0.0076원\n      3.8원\n      트래픽, API요청수 요금 별도\n    \n  \n\n\nQnA\n\n\n    \n        \n            \n                서버에 디스크를 추가하고 싶을 때는 어떤 스토리지를 사용하면 되나요?\n            \n        \n        \n            \n                Block Storage를 사용하면 됩니다. \n                Console - Server - 서버 상세 정보 - 스토리지 생성 메뉴에서 스토리지를 추가하고 서버에 마운트해서 사용하시면 됩니다. \n            \n        \n    \n    \n        \n            \n                서버당 디스크는 최대 얼마까지 추가할 수 있나요?\n            \n        \n        \n            \n                네이버 클라우드에서 서버에 직접 추가되는 디스크는 Block Storage로 최대 2,000GB를 지원하며, 서버 1대당 최대 16개의 스토리지를 추가할 수 있습니다. \n            \n        \n    \n    \n        \n            \n                디스크를 추가할 수 없는 서버도 있나요?\n            \n        \n        \n            \n                네이버 클라우드에서 서버에 직접 추가되는 디스크는 Block Storage로 Micro 타입의 서버, Bare Metal 서버, Application Server Launcher는 Block Storage를 추가할 수 없습니다.\n            \n        \n    \n    \n        \n            \n                여러 서버에서 공용으로 사용할 스토리지가 필요합니다.\n            \n        \n        \n            \n                NAS 서비스를 이용하시면 됩니다. \n                서버 간 데이터 공유, 대용량 스토리지, 유연한 용량 확대/축소, 스냅샷 백업 등 NAS 서비스의 주요 기능을 활용해 안전하고 편리하게 데이터를 관리할 수 있습니다.  \n                특히, 프로토콜에 따른 인증 설정으로 높은 보안성을 제공하고, 이중화된 Controller 및 Disk Array Raid 구성으로 강력한 서비스 안정성을 확보하고 있습니다.\n            \n        \n    \n    \n        \n            \n                유저가 업로드 하는 이미지를 저장하고 싶습니다.\n            \n        \n        \n            \n                Block Storage, Object Storage, NAS 모두 가능합니다만 용도에 따라 선택하시면 되겠습니다. \n                매우 빠른 응답 속도가 필요하면 Block Storage. \n                저렴한 비용과 여러 서버에서 동시에 이미지를 저장해야 한다면 Object Storage.  \n            \n        \n    \n    \n        \n            \n                백업 자료를 오랜기간 보관해 두고 싶습니다.\n            \n        \n        \n            \n                Archive Storage를 이용하시면 됩니다. \n                Archive Storage는 높은 내구성과 저렴한 비용이 특징인 데이터 아카이빙 및 장기 백업에 최적화된 스토리지 서비스입니다.  \n            \n        \n    \n    \n        \n            \n                AWS S3와 비슷한 스토리지는 어떤 건가요?\n            \n        \n        \n            \n                Object Storage입니다. \n                네이버 클라우드의 Object Storage는 AWS의 S3에서 사용하는 API와 호환이 되므로 쉽게 사용하실 수 있습니다.\n            \n        \n    \n    \n        \n            \n                CDN를 서비스를 이용하려면 어떤 스토리지를 사용해야 하나요?\n            \n        \n        \n            \n                Object Storage를 사용하시면 됩니다. \n                물론 CDN의 원본 서버로 설정할 수 있는 것은 자체 웹 서버 및 네이버 클라우드 Object Storage, Server 등이 있는데, 그 중에서도 Object Storage를 사용하시는 것이 가장 쉽고 안정적입니다. \n                Object Storage에 파일을 저장하고 나서, CDN+ 또는 GCDN 상품과 연동하시면 됩니다.\n            \n        \n    \n\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/storage-storage-5-1.html"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-nas-vpc-guide-html": {
						"id": "storage-ncloud-storage-nas-vpc-guide-html",
						"title": "NAS 볼륨을 생성하고 Linux 서버에 마운트하기 가이드",
						"categories": "",
						"url": " /storage/ncloud_storage_nas_vpc_guide.html",
						"content": "개요\nNAS (Network Attached Storage)는 다수의 서버, 사용자가 함께 사용하는 네트워크 저장공간으로, \n서버 간 데이터 공유, 대용량 스토리지, 유연한 용량 확대/축소, 스냅샷 백업 등이 필요한 경우에 주로 사용하며, \n네이버 클라우드 NAS 서비스의 주요 기능을 활용해 안전하고 편리하게 데이터를 관리할 수 있습니다.\n이번 가이드에서는 NAS 볼륨을 생성하고, Linux 즉, CentOS와 Ubuntu 서버에 마운트하는 방법을 정리해보겠습니다.\n\n특징\n\n  용량: 500GB ~ 10,000GB까지 가능하며, 확장은 100GB단위로 가능\n  접근제어 설정 가능\n  스냅샷 설정: 자동생성의 경우  최대 7개까지 보관 가능\n  볼륨 암호화: 볼륨 단위로 AES-256 알고리즘 기반의 암호화 키를 사용하여 FIPS-140-2 레벨 1 수준의 암호화를 제공\n  모니터링 및 이벤트 설정 가능\n\n\nVPC-Subnet  생성\n\nVPC 생성\nVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nSubnet 생성\nSubnet 설정은 [Public]과 [일반]을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n서버 생성\nNAS 볼륨을 마운트할 서버 2개를 CentOS 7.8과 Ubuntu 18.04로 생성합니다.\n\n\n  \n  \n    \n  \n\n\nNAS 생성\n[NAS] - [Volume]에서 [NAS 볼륨 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nNAS 볼륨 이름과 용량을 입력하고, 리눅스용 프로토콜인 NFS를 선택합니다.  CIFS는 윈도우용 프로토콜입니다.\n용량은 500GB ~ 10,000GB까지 가능하며, 100GB단위로 추가할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nNFS 접근 제어 설정\nNFS 접근 제어 설정에서는 NAS 볼륨을 마운트할 장비를 선택해서 ACL(네트워그 접근제어) 설정을 하게 됩니다.\n\n\n  \n  \n    \n  \n\n\nNAS 볼륨을 마운트할 장비를 선택하고, [ &gt; ] 버튼을 클릭해 오른쪽으로 이동시킵니다.\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n마지막으로 설정 내용을 확인하고 [볼륨 생성] 버튼을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\nCentOS 설정\n\nNFS 관련 패키지 설치\nNAS 볼륨을 서버에 마운트하기 위해 우선 서버에 NFS 프로토콜 관련 패키지를 설치합니다.\n\n~# yum install nfs-utils\n\n\n\n  \n  \n    \n  \n\n\nNAS 볼륨 마운트하기\nNAS 볼륨을 마운트할 디렉토리를 생성하고 {NAS 볼륨 마운트 정보}를 이용해 마운트한 후에 상태를 확인합니다.\n네이버 클라우드에서는 안정성이 높은 NFS v3(-o vers=3)로 마운트하여 사용할 것을 권고하고 있습니다.\n\n~# mkdir /nas\n~# mount -t nfs -o vers=3 {NAS 볼륨 마운트 정보} /nas\n~# df -Th\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\nfstab 설정\n부팅 후에도 마운트가 될 수 있도록 /etc/fstab 파일에 추가합니다.\n\n\n  \n  \n    \n  \n\n\nUbuntu 설정\n\nNFS 관련 패키지 설치\n우분투에서도 우선 NFS 관련 패키지를 설치합니다.\n\n~# apt install nfs-common -y\n\n\n  \n  \n    \n  \n\n\nNAS 마운트하기\nNAS 볼륨을 마운트할 디렉토리를 생성하고 {NAS 볼륨 마운트 정보}를 이용해 마운트한 후에 상태를 확인합니다.\n네이버 클라우드에서는 안정성이 높은 NFS v3(-o vers=3)로 마운트하여 사용할 것을 권고하고 있습니다.\n\n~# mkdir /nas\n~# mount -t nfs -o vers=3 {NAS 볼륨 마운트 정보} /nas\n~# df -Th\n\n\n  \n  \n    \n  \n\n\nfstab 설정\n부팅 후에도 마운트가 될 수 있도록 /etc/fstab 파일에 추가합니다.\n\n\n  \n  \n    \n  \n\n\n이벤트 설정\n이벤트 설정에서는 NAS 볼륨 사용량 임계치를 설정하고 이벤트 발생 시 SMS나 Email로 통보를 받습니다.\n볼륨 설정에서 이벤트 설정을 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n이벤트 통보 방법과 휴대폰 또는 이메일 등을 입력하고 설정을 완료합니다.\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n  NAS 사용 가이드\n    \n      https://guide.ncloud-docs.com/docs/nas-start-vpc"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-aws-cli-connect-html": {
						"id": "storage-ncloud-storage-object-storage-aws-cli-connect-html",
						"title": "AWS CLI 버전 2를 이용한 Object Storage 접속 방법",
						"categories": "",
						"url": " /storage/ncloud_storage_object_storage_aws_cli_connect.html",
						"content": "개요\nNcloud (네이버 클라우드) Object Storage는 AWS의 스토리지 서비스 S3와 호환이 되도록 설계되어 있습니다.\n그래서 Object Storage에 접속, 관리할 때 AWS의 CLI(Command Line Interface)를 사용할 수 있는데 그 중에서 AWS CLI 버전 2의 설치와 사용방법에 대해 정리해보겠습니다.\n\nAWS CLI 버전 2 설치\n\n Note: AWS CLI 버전 1에서는 설치와 실행에 Python과 PIP를 이용하는 방법이 주로 사용되었지만, AWS CLI 버전 2에서는 Python 임베디드 버전이 포함되어 있어 별도로 설치할 필요가 없기에 설치 파일도 ZIP 압축 파일 형태로 제공됩니다.\n\n설치 파일 다운로드\nAWS CLI 버전 2 설치 파일을 awscliv2.zip 이름으로 다운로드 합니다.\n\n~# curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n\n\n  \n  \n    \n  \n\n\n압축 풀기\nunzip으로 압축을 풀겠습니다.\n\n~# unzip awscliv2.zip\n\n\n  \n  \n    \n  \n\n\n설치\n아래 명령으로 쉽게 설치할 수 있습니다.\n\n~# ./aws/install\n\n\n  \n  \n    \n  \n\n\n버전 확인\n설치가 완료된 후 버전을 확인해보면 아래와 같이 AWS CLI 버전과 임베디드된 Python 버전도 확인할 수 있습니다.\n\n~# aws --version\n\n\n  \n  \n    \n  \n\n\nAPI 인증키 생성\n다음으로 접속에 필요한 인증키를 Ncloud (네이버 클라우드) 포탈 - 마이페이지 - 계정관리 - 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n\n  \n  \n    \n  \n\n\nAWS CLI 환경 설정\n이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목은 입력하지 않으셔도 됩니다.\n~# aws configure\n\nAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\nAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\nDefault region name [None]: [Enter]\nDefault output format [None]: [Enter]\n\n\n\n  \n  \n    \n  \n\n\nObject Storage 접속\n이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# Object Storage에 존재하는 전체 버킷 리스트를 조회하는 명령어입니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\n\n# s3 ls 명령으로 Object Storage에 존재하는 aws-cli-test 버킷에 있는 오브젝트 리스트를 조회하는 예시입니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls s3://aws-cli-test\n\n# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어 예시입니다.\n~# aws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\n\n\n  \n  \n    \n  \n\n\nAWS CLI 업데이트\n설치된 AWS CLI를 최신 버전으로 업데이트 하려면 아래 명령어를 사용하면 됩니다. 최신 버전이 설치된 상태에서는 아래 스샷처럼 이미 최신 버전과 동일한 버전이 설치되어 있다는 메시지가 나타납니다.\n\n~# ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli --update\n\n\n\n  \n  \n    \n  \n\n\nAWS CLI 삭제\n설치된 AWS CLI를 삭제하려면 아래의 단계대로 진행하시면 됩니다.\n\nsymlink 삭제\n~# rm /usr/local/bin/aws\n~# rm /usr/local/bin/aws_completer\n\n\n설치 디렉토리 삭제\n~# rm -rf /usr/local/aws-cli\n\n\n설정 정보 삭제 (선택 사항)\nAWS CLI 환경 설정 정보는 서버 내의 모든 AWS SDK 및 AWS CLI에서 공유되므로 더 이상 사용하지 않는다면 삭제하시면 됩니다.\n\n~# rm -rf ~/.aws/\n\n\n\n  \n  \n    \n  \n\n\n참고 URL\n\n\n  AWS CLI 버전 2 가이드\n    \n      https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/cli-chap-welcome.html\n    \n  \n  Ncloud Object Storage CLI 가이드\n    \n      https://cli.ncloud-docs.com/docs/guide-objectstorage"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-lifecycle-management-html": {
						"id": "storage-ncloud-storage-object-storage-lifecycle-management-html",
						"title": "Object Storage Lifecycle Management 관리대상 설정 방법",
						"categories": "",
						"url": " /storage/ncloud_storage_object_storage_lifecycle_management.html",
						"content": "개요\n네이버 클라우드 Object Storage에 저장된 Object 즉, 파일들의 Lifecycle(수명주기)를 설정할 때 관리대상이 되는 Object를 결정하는 규칙에 대해 정리해보겠습니다.\n\nLifecycle Management(수명주기) 정책설정\n수명주기 정책 설정은 크게 정책, 관리대상, 이동위치 3가지 항목으로 구성됩니다.\n\n정책\n정책 유형은 다음의 3가지가 있습니다.\n\n  만료 삭제 : 설정된 기간이 지난 파일을 삭제\n  이관 : 설정된 기간이 지난 파일을 Archive Storage로 이동\n  이관 후 삭제 : 설정된 기간이 지난 파일을 Archive Storage로 이동한 후 Object Storage에서 삭제\n\n\n그리고 이동 시점은 파일이 Object Storage에 저장-생성된 후 경과한 일자를 기준으로 하며 1일 ~ 3,650일 사이의 값을 입력합니다.\n\n\n  \n  \n    \n  \n\n\n관리대상 (Source)\n관리대상의 버킷(Bucket)을 선택하고 Object 이름의 규칙을 접두어 방식으로 입력합니다.\n\n\n  \n  \n    \n  \n\n\n이동위치 (Target)\n이동할 위치는 Archive Storage로 고정이며, Archive Storage의 컨테이너(버킷)을 선택하고 세부경로 즉, 폴더를 입력합니다.\n세부경로에 아무것도 입력하지 않으면 Source 즉, Object Storage의 위치, 폴더 구조 그대로 이동됩니다.\n\n\n  \n  \n    \n  \n\n\n관리대상(Source) Object 이름 규칙\n\n네이버 클라우드에서 채택하고 있는 규칙은 접두어 방식입니다. \n예를 들어 규칙을 ncp라고 설정하면 이름이 ncp로 시작되는 모든 파일과 폴더가 대상이 됩니다. \n하지만, 접두어 규칙이기 때문에 img_ncp_01.png 처럼 파일명 중간이나 끝에 ncp가  들어간 파일과 폴더는 대상이 아닙니다.\n\n\nObject 이름 규칙의 특수 문자 사용\n\n⁃ &lt; &gt; : \" \\ | ? * % 는 사용할수 없습니다. \n⁃ /는 첫 글자에 사용할 수 없습니다. \n⁃ //처럼 /는 연속해서 사용할 수 없습니다.\n\n\n적용 예시\n아래 스샷처럼 폴더와 파일이 저장되어 있다고 가정하고 예를 들어보겠습니다.\n다른 항목들은 동일하고, 관리대상(Source) Object 이름 규칙에 따라 어떤 결과가 나오지는 확인해보겠습니다.\n물론 아래의 예시들에서 공통적으로 위에서 지정한 수명주기 날짜에 해당하는 파일들만 이동하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n- 3rdeyesys\n\t- img_01.png\n\t- screenshot_01.png\n- 3rdeyesys_img\n\t- img_02.png\n- ncp\n\t- \n- 3rdeyesys_biz.png\n- ncp_server_acg_classic.png\n- ncp_server_acg_vpc_inbound.png\n- vpc_acg_nacl_ncp.png\n\n\n이렇게 3rdeyesys, 3rdeyesys_img 2개의 폴더에는 각각 파일이 존재하고, ncp 폴더에는 아무것도 없습니다.  그리고 4개 파일이 루트에 저장되어 있습니다.\n\nObject 이름 규칙(접두어) : 3rdeyesys\n이 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n즉, 3rdeyesys로 시작하는 파일과 폴더 아래에 있는 파일까지 모두 이동하게 됩니다.\n- 3rdeyesys\n\t- img_01.png\n\t- screenshot_01.png\n- 3rdeyesys_img\n\t- img_02.png\n- 3rdeyesys_biz.png\n\n\nObject 이름 규칙(접두어) : ncp\n이 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n위의 경우와 다르게 ncp 폴더는 이동하지 않는데 그 이유는 ncp 폴더 아래에 아무 파일도 없기 때문에 이동할 파일이 없어 폴더도 이동하지 않습니다.\n\n- ncp_server_acg_classic.png\n- ncp_server_acg_vpc_inbound.png\n\n마찬가지로 ncp 폴더 아래에 파일이 존재하더라도 위에서 지정한 수명주기 날짜에 해당하는 파일이 없는 경우에도 ncp 폴더는 이동하지 않습니다.\n또한 접두어 방식이기 때문에 파일명 중간에 ncp가 들어간 vpc_acg_nacl_ncp.png 파일은 해당되지 않아서 이동하지 않습니다.\n\nObject 이름 규칙(접두어) : 3rdeyesys/\n이렇게 뒤에 “/”를 입력하여 폴더라고 명시한 경우에 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n\n- 3rdeyesys\n\t- img_01.png\n\t- screenshot_01.png\n\n즉, 끝에 “/”를 입력했기 때문에 3rdeyesys로 시작하는 폴더만 대상이 되어 다른 파일은 이동하지 않습니다.\n\nObject 이름 규칙(접두어) : 3rdeyesys/img\n이렇게 폴더와 파일명 접두어까지 함께 입력한 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n\n- 3rdeyesys\n\t- img_01.png\n\n즉, 3rdeyesys 폴더 아래에 있는 파일들 중에서 img로 시작하는 이름을 가진 파일만 이동하게 됩니다.\n\nObject 이름 규칙(접두어) : 아무것도 입력하지 않았을 때\n아무것도 입력하지 않았을 때는 모든 파일과 폴더 아래에 있는 파일들이 이동하게 됩니다.\n물론 마찬가지로 수명주기 날짜에 해당하는 파일만 이동하게되고, 폴더 아래에 해당하는 파일이 없을 경우 해동 폴더는 이동하지 않습니다.\n\n정책 실행 시간\nLifecycle Management(수명주기) 정책 실행시간은 아래와 같습니다.\n\n\n  01:00~02:00,  07:00~08:00, 13:00~14:00, 19:00~20:00\n (※ 파일용량이 클 경우 일부 변동될 수 있음)\n\n\n예시) 정책 유형(이관), 이동 시점(생성 후 1일)로 정책을 생성하고, 대상 파일이 15시에 업로드 되었다면 다음 날 19~20시 사이에 이관 완료.\n\n참고 URL\nhttps://guide.ncloud-docs.com/docs/storage-storage-6-1.html"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-required-service-html": {
						"id": "storage-ncloud-storage-object-storage-required-service-html",
						"title": "Object Storage와 연동이 필수인 서비스",
						"categories": "",
						"url": " /storage/ncloud_storage_object_storage_required_service.html",
						"content": "개요\n네이버 클라우드의 수 많은 서비스들 중에는 Object Storage가 설정, 준비되어 있어야 하는 서비스들, 즉, Object Storage와 연동이 필수인 서비스들이 여럿 있습니다.\n어떤 서비스들이 이에 해당하는지 정리해보겠습니다.\n\n연동 필수 서비스\nObject Storage와 연동이 필수인 서비스들에는 AI-Application Service와 Media 관련 서비스들이 많습니다.\n\n\n  CLOVA Speech\n  CLOVA Dubbing\n  VOD Transcoder\n  VOD Station\n  Video Player\n  Image Optimizer\n  SourceBuild\n  Cloud Hadoop\n  Data Analytics Service\n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n연동 선택 서비스\nObject Storage와 반드시 연동해야 하는 것은 아니지만, Object Storage를 이용하면 훨씬 편하고, 빠르고 안정적으로 서비스 가능한 경우도 있습니다.\n\n\n  CDN+\n  Global CDN"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-s3-client-cloudberry-explorer-html": {
						"id": "storage-ncloud-storage-object-storage-s3-client-cloudberry-explorer-html",
						"title": "Object Storage 접속용 Windows Client Tool - CloudBerry Explorer",
						"categories": "",
						"url": " /storage/ncloud_storage_object_storage_s3_client_cloudberry_explorer.html",
						"content": "개요\n네이버 클라우드의 Object Storage에 접속, 관리하는 방법은 aws cli 등 여러가지 있지만 Windows PC에서 간편하게 접속해서 관리할 수 있는 클라이언트 툴이 몇개 있습니다.\n그 중에서 가장 많이 사용되는 것이 바로 CloudBerry Explorer 인데, 사용법에 대해 간단히 정리해보겠습니다.\n\nCloudBerry Explorer\nCloudBerry Explorer의 정식 명칭은 CloudBerry Explorer Freeware for Amazon S3입니다.\n이 버전은 무료버전이며 더 많은 기능이 포함된 유료 버전도 있습니다. \n그리고 Amazon S3 뿐만 아니라 Microsoft Azur, Google Cloud 등을 위한 버전도 따로 있습니다.\n\n상세한 정보와 다운로드는 아래 링크에서 확인하시면 됩니다.\n\nhttps://www.msp360.com/explorer/windows.aspx\n\n사용법\n\n프로그램을 다운 받아서 설치하고, 실행을 하면 여러 종류의 스토리지 중에서 원하는 것을 선택하게 됩니다.\n이 클라이언트는 AWS S3를 위한 것이지만, 많은 스토리지들이 S3와 호환되는 구조로 만들어졌기 때문에 공통으로 사용 가능합니다. \n이용 가능한 스토리지 리스트는 마지막에서 정리해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n여기에 아직 네이버 클라우드는 리스트에 없기 때문에 저희는 S3 Compatible을 선택하면 됩니다.\n\n  Display name: 여기는 알아보기 쉬운 이름을 적으면 됩니다. 예를 들어 Naver Cloud\n  Service point: 여기는 네이버 클라우드의 endpoint-url을 적습니다. kr.object.ncloudstorage.com\n  Access key: 여기는 Access Key ID\n  Secret key: 여기는 Secret Key\n\n\n\n  \n  \n    \n  \n\n\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n계정 정보를 입력하고 접속을 하면 왼쪽에 로컬PC 폴더가, 오른쪽에 버킷 리스트가 나타나고 원하는 버킷을 선택해서 들어가면 다음처럼 파일들을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nObject Storage에 있는 파일을 로컬PC로 가져오려면 원하는 파일을 선택하고 마우스 오른쪽 버튼을 눌러서 Copy 명령을 선택하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n그 외 여러 가지 기능들이 있는데 그리 어려운 기능은 아니므로 직접 사용해보시면 금방 알 수 있습니다.\n\n마지막으로 CloudBerry Explorer Freeware for Amazon S3로 접속 가능한 클라우드 스토리지 리스트를 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  Amazon S3\n  Amazon S3 (China)\n  Amazon Glacier\n  Amazon Glacier (China)\n  Amazon Cloud Drive\n  Alibaba\n  S3 Compatible\n  Akaza\n  Aruba Cloud\n  Backblaze B3\n  Caringo\n  CenturyLink\n  Cisco\n  Cloudian\n  Connectria\n  Constant\n  DDN\n  dinCloud\n  DreamObjects\n  Dunkel\n  Easy Storage\n  Exoscale\n  GreenQloud\n  HGST\n  Hitachi\n  HostEurope\n  IDC Frontier\n  LeoNovus (S3)\n  Mandic\n  NetApp\n  NiftyCloud\n  Numergy\n  QNAP\n  Revera\n  Scality\n  Seeweb\n  SwiftStack (S3)\n  ThinkOn\n  Tiscali\n  Verizon\n  vCloud Air (EMC)\n  Walrus\n  Zettagrid\n  Wasabi\n\n\nS3 Browser\n또 다른 클라이언트인 S3 Browser입니다. 자세한  내용은 아래 링크에서 확인 가능합니다.\n\nObject Storage 접속용 Windows Client Tool - S3 Browser"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-s3-client-cyberduck-html": {
						"id": "storage-ncloud-storage-object-storage-s3-client-cyberduck-html",
						"title": "Object Storage 접속용 Windows, MacOS Client Tool - Cyberduck",
						"categories": "",
						"url": " /storage/ncloud_storage_object_storage_s3_client_cyberduck.html",
						"content": "개요\n네이버 클라우드 Object Storage에 접속해서 파일을 업로드, 다운로드 등의 관리를 할 수 있는 클라이언트 툴중에서 이번에는 Cyberduck이라는 무료 제품을 소개하려고 합니다.\nObject Storage는 AWS S3와 호환되기 때문에 S3를 지원하는 Cyberduck도 사용할 수 있는데 Cyberduck은 S3뿐만 아니라 \nFTP, SFTP, WebDAV, Amazon S3, OpenStack Swift, Backblaze B2, Microsoft Azure &amp; OneDrive, Google Drive, Dropbox 등에도 접속 가능합니다.\n\n설치파일 다운로드\nCyberduck은 윈도우용과 macOS용 프로그램을 제공하고 있어, 원하는 제품을 다운 받으면 됩니다.\n\nhttps://cyberduck.io/download/\n\n\n  \n  \n    \n  \n\n\n설치\n설치할 디렉토리를 선택하고, Cyberduck을 설치합니다.\n\n\n  \n  \n    \n  \n\n\n접속정보 확인\nCyberduck을 실행하고 새 연결을 메뉴를 선택하면 스토리지에 접속 정보를 입력하는 창이 나타납니다.\n여기서 필요한 정보는 서버 접속용 Endpoint URL, API 인증키 (접근 키 ID, Secret Access Key)가 필요한데, 관련된 정보는 아래쪽에서 다시 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\nAPI 인증키 생성\nCyberduck으로 Object Storage에 접속하기 위해서는 API 인증키가 필요합니다. \nAPI 인증키는 네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져와야 하며, 아직 만들어진 Key가 없다면 새로 만들어야 합니다.\n\nhttps://www.ncloud.com/mypage/manage/authkey\n\n\n  \n  \n    \n  \n\n\n스토리지 접속\nObject Storage에 접속하기 위해 위에서 확인한 API 인증키를 이용하여 다음의 정보를 입력해야 합니다.\n\n# 서버: kr.object.ncloudstorage.com\n# 접근 키 ID: 네이버 클라우드 Access Key ID\n# Secret Access Key: 네이버 클라우드 Secret Key\n\n# 다른 해외 리전의 Object Storage 서버 주소는 다음과 같습니다.\n# 미국: us.object.ncloudstorage.com\n# 싱가포르: sg.object.ncloudstorage.com\n# 일본: jp.object.ncloudstorage.com\n# 독일: de.object.ncloudstorage.com\n\n\n\n  \n  \n    \n  \n\n\nObject Storage에 접속하면 이미 생성된 Bucket이 있을 경우 아래와 같이 Bucket 리스트가 나타납니다.\n\n\n  \n  \n    \n  \n\n\n업로드\nObject Storage에 파일을 업로드 하기 위해서는 먼저 Bucket이 생성되어 있어야 합니다.\n\nBucket (버킷) 생성\n이미 Bucket을 만들었다면 그대로 사용하시면 되고, 새로 만드실 경우에는 [파일]-[새 폴더] 메뉴를 이용하시면 됩니다.\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n\n  \n  \n    \n  \n\n\n파일 업로드\n업로드할 대상 Bucket을 선택하고 마우스 오른쪽 버튼을 클릭하면 업로드 메뉴를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n파일 선택창에서 원하는 파일을 선택하면 되고, 파일이 여러개일 경우 다중 선택도 가능합니다.\n\n\n  \n  \n    \n  \n\n\n전송결과 화면\n\n  \n  \n    \n  \n\n\n업로드 완료 화면\n\n  \n  \n    \n  \n\n\n권한설정\nObject Storage에 업로드한 파일을 외부에서 접근해야 하는 경우에는 파일에 대한 권한을 변경해야 합니다.\n\n권한을 변경할 파일을 선택하고 마우스 오른쪽 버튼을 클릭하면 [정보] 메뉴를 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n파일정보 팝업창에서 [권한] 메뉴를 선택하시면 왼쪽 아래에서 권한 설정 기능에서 [모두]를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n[모두]에 대한 권한을 READ로 선택합니다.\n\n\n  \n  \n    \n  \n\n\n여러 파일의 권한을 동시에 변경할 경우 해당 파일들을 전부 선택하고 권한을 변경할 수도 있습니다.\n\n\n  \n  \n    \n  \n\n\n다운로드\nObject Storage에 저장된 파일을 로컬로 다운로드 받을 경우에는 대상 파일을 선택하고 마우스 오른쪽 버튼을 클릭하여 [지정된 위치로 내려받기] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n다운로드 받을 폴더를 선택합니다.\n\n  \n  \n    \n  \n\n\n다운로드가 완료되었습니다.\n\n  \n  \n    \n  \n\n\n동기화\n이번에는 업로드, 다운로드가 아닌, 로컬 폴더와 Object Storage에 있는 Bucket을 서로 동기화 하는 기능에 대해 확인해보겠습니다.\n\n동기화할 Bucket을 선택하고 마우스 오른쪽 버튼을 클릭해 동기화 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n다음으로 동기화할 로컬 폴더를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n이제 동기화를 시작할 준비가 되었습니다. 동기화 창에서 [계속] 버튼을 클릭해 동기화를 시작합니다.\n\n\n  \n  \n    \n  \n\n\n동기화가 완료되었지만 화면에서는 즉시 반영이 되지 않습니다. Bucket을 선택하고 마우스 오른쪽 버튼을 선택해 [다시보기] 메뉴를 선택하면 새로 고침이 되면서 동기화된 파일을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n삭제\nBucket이나 파일을 삭제할 경우에는 대상 파일 등을 선택하고 마우스 오른쪽 버튼을 클릭해 [삭제] 메뉴를 선택합니다.\n\n\n  \n  \n    \n  \n\n\n삭제 기능은 한번 더 정말 삭제할 것인지 확인하는 단계가 있습니다.\n\n\n  \n  \n    \n  \n\n\n환경설정\nCyberduck의 환경설정에서 중요한 것들을 살펴 보겠습니다.\n\n위쪽 메뉴에서 [편집]-[환경설정]을 선택합니다.\n\n\n  \n  \n    \n  \n\n\n환경설정 중에서 우선 [전송]-[일반]에 들어가시면 다운로드와 업로드에 대한 설정을 할 수 있습니다.\n여기서는 기본 다운로드 폴더를 설정할 수 있고, 업로드할 때 파일명이 겹칠 경우 덮어쓸 것인지, 물어보기 할 것인지 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[전송]-[권한] 설정에서는 업로드 되는 파일의 기본 권한을 원하는 설정으로 변경할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n[전송]-[필터] 설정에서는 다운로드와 업로드 할 때 특정 형식이나 확장자의 파일을 건너띄기 할 수 있는 정규식 기반의 설정을 제공합니다.\n\n\n  \n  \n    \n  \n\n\n[대역폭] 설정에서는 업로드와 다운로드할 때의 네트워크의 대역폭을 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n평가\n마지막으로 Cyberduck 클라이언트 툴의 장점과 단점을 정리해보겠습니다.\n\n장점\n\n  무료제품으로 상업적인 용도로도 사용 가능하다.\n  S3와 그 호환 스토리지 뿐만 아니라 FTP, Dropbox, Google Drive 등 다양한 방식의 접속을 지원한다.\n  메뉴가 한글화 되어 있다.\n\n\n단점\n\n  인터페이스가 탐색기 형식이 아니라서 업로드, 다운로드할 때 불편하다.\n  제공되는 접속용 프로필이 다양하지 않아서 서버 정보를 일일이 입력해야 한다.\n  스토리지 &lt;–&gt; 스토리지 방식의 파일 전송을 지원하지 않는다."
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-s3-client-s3browser-html": {
						"id": "storage-ncloud-storage-object-storage-s3-client-s3browser-html",
						"title": "Object Storage 접속용 Windows Client Tool - S3 Browser",
						"categories": "",
						"url": " /storage/ncloud_storage_object_storage_s3_client_s3browser.html",
						"content": "개요\n네이버 클라우드의 Object Storage에 접속, 관리하는 방법은 aws cli 등 여러가지 있지만 Windows PC에서 간편하게 접속해서 관리할 수 있는 클라이언트 툴이 몇개 있습니다.\n그 중에서 이번에는 S3 Browser의 사용법에 대해 간단히 정리해보겠습니다.\n\nS3 Browser\nS3 Browser는 Amazon S3 and Amazon CloudFront를 위한 클라이언트입니다\n이 버전은 무료버전이기는 하지만, 정확히는 personal use only, non-commecial use only라고 명시되어 있습니다.\n그래서 라이선스와 관계없이 사용 가능하고, 더 많은 기능이 포함된 유료 버전도 있습니다.\n\n상세한 정보와 다운로드는 아래 링크에서 확인하시면 됩니다.\n\nhttps://s3browser.com/\n\n사용법\n\n프로그램을 다운 받아서 설치하고, 실행을 하면 여러 종류의 스토리지 중에서 원하는 것을 선택하게 됩니다.\n이 클라이언트는 AWS S3를 위한 것으로 CloudBerry Explorer와는 다르게 AWS의 다양한 S3 서비스들만 접속이 가능한데, 이용 가능한 스토리지 리스트는 마지막에서 정리해보겠습니다.\n\n\n  \n  \n    \n  \n\n\nAccount Type은  S3 Compatible Storage를 선택하면 됩니다.\n\n  Account name: 여기는 알아보기 쉬운 이름을 적으면 됩니다. 예를 들어 Naver Cloud\n  REST Endpoint: 여기는 네이버 클라우드의 endpoint-url을 적습니다. kr.object.ncloudstorage.com\n  Access Key ID: 여기는 Access Key ID\n  Secret Access Key: 여기는 Secret Key\n\n\n\n  \n  \n    \n  \n\n\n네이버 클라우드 포탈 -&gt; 마이페이지 -&gt; 계정관리 -&gt; 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n\n계정 정보를 입력하고 접속을 하면 버킷 리스트가 나타나고 원하는 버킷을 선택해서 들어가면 다음처럼 파일들을 확인할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\nObject Storage에 있는 파일을 로컬PC로 가져오려면 원하는 파일을 선택하고 마우스 오른쪽 버튼을 눌러서 Download 명령을 선택하면 됩니다.\n\n\n  \n  \n    \n  \n\n\n그 외 여러 가지 기능들이 있는데 그리 어려운 기능은 아니므로 직접 사용해보시면 금방 알 수 있습니다.\n\n마지막으로 S3 Browser로 접속 가능한 S3 리스트를 확인해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n\n  Amazon S3 Storage\n  S3 Compatible Storage\n  Amazon S3 in China\n  Amazon S3 GovCloud Storage\n  Amazon S3 GovCloud Storage (FIPS 140-2)\n  Amazon S3 via EC2 IAM Role\n  Amazon S3 via AssumeRole\n  Amazon S3 (Credentials from Environment Variables)\n  Amazon S3 (Credentials from AWS Config or Credential file)\n\n\n업로드하는 파일 권한 자동 적용\nS3 Browser를 이용해 파일을 업로드할 때 업로드하는 파일의 권한을 자동으로 적용하는 방법에 대해 살펴보겠습니다.\n\n우선 S3 Browser에서 [Tools] - [Option] 메뉴를 클릭합니다.\n\n\n  \n  \n    \n  \n\n\n\n  [Option] 메뉴에 보면 여러 옵션들이 있는데 아래 스샷에서 표시한 2가지 옵션이 중요합니다. 각각에 대한 설명은 아래쪽에서 다시 정리해보겠습니다.\n\n\n  \n  \n    \n  \n\n\n버킷(Bucket) 권한 상속\n[Inherit permissions from parent bucket] 옵션은 버킷(Bucket)에 업로드 되는 파일들은 버킷(Bucket)의 권한을 상속 받게 하는 옵션입니다.\n예를 들어 버킷(Bucket)의 권한이 [All User]에게 [Read] 권한이라면 이 옵션을 선택해두면 이 버킷(Bucket)에 업로드 되는 모든 파일은 [All User]에게 [Read] 권한을 가지게 됩니다.\n\n권한 유지\n[Preserve permissions when overwriting existing files] 옵션은 이미 버킷(Bucket)에 존재하는 파일을 다시 업로드 해서 덮어 쓰기를 할 경우 기존의 권한을 유지하도록 하는 옵션입니다.\n\n참고 URL\n\n  S3 Browser 홈페이지\n    \n      https://s3browser.com/\n    \n  \n  S3 Browser S3-Compatible Storages 설정 가이드\n    \n      https://s3browser.com/s3-compatible-storage.aspx\n    \n  \n\n\n문서 업데이트 내역\n\n  \n    \n      \n        날짜\n        내용\n      \n    \n    \n      \n      \n      \n      \n        \n          2022-08-16\n          문서 최초 생성\n        \n      \n        \n          2023-11-06\n          파일 업로드할 때 권한 적용 안내 추가"
					}
					
				
			
		
			
				
					,
					
					"storage-ncloud-storage-object-storage-transfer-to-archive-storage-html": {
						"id": "storage-ncloud-storage-object-storage-transfer-to-archive-storage-html",
						"title": "Object Storage 데이터를 Archive Storage로 자동으로 이동시키는 방법",
						"categories": "",
						"url": " /storage/ncloud_storage_object_storage_transfer_to_archive_storage.html",
						"content": "개요\n네이버 클라우드 Object Storage는 일반 디스크인 Block Storage나 NAS에 비해 가격도 1/2 ~ 1/4정도이면서도 안정적이기 때문에 데이터 저장 특히 백업 용도로 많이 사용합니다.\n\n그럼에도 불구하고 많이 양의 데이터가 저장되면 비용에 대한 부담이 생길 수 밖에 없는데, 이럴 때 Archive Storage를 이용하면 Object Storage의 1/5정도로 비용이 줄어들기에 매우 효과적입니다.\n\n그래서 이번에는 Object Storage에 있는 데이터를 Archive Storage로 이동시키는 즉, 이관하는 방법에 대해 정리해보겠습니다.\n\n스토리지 가격 비교\n위 개요에서도 간단하게 설명했지만, Archive Storage는 Object Storage에 비해 비용이 1/5 정도입니다.\n이 두가지 뿐만 아니라 여러 스토리지들의 가격과 용도에 대한 비교는 아래 문서에서 확인할 수 있습니다.\n\nhttps://docs.3rdeyesys.com/storage/ncloud_storage_compare.html\n\n스토리지 용도 구분\nObject Storage와 Archive Storage 2가지 스토리지 모두 데이터를 백업하는 용도로 많이 사용됩니다.\n비슷하기는 하지만 전혀 다르기도 한 2가지 스토리지에 대한 용도를 간단하게 구분해보겠습니다.\n\nObject Storage\n\n⁃ 데이터 저장, 삭제가 수시로 이루어지는 경우 \n⁃ 저장된 데이터에 대한 조회가 빈번한 경우 \n⁃ 앱을 사용하는 일반 유저들이 앱을 통해 데이터에 접근하는 경우 \n⁃ 네이버 클라우드의 다른 서비스에서 데이터를 저장, 조회해야 하는 경우\n\n\nArchive Storage\n\n⁃ 저장된 데이터에 대한 조회가 거의 없는 경우 \n⁃ 당장 사용할 일은 없으나 오랜 기간 데이터를 저장해야 하는 경우 \n⁃ 매우 저렴한 비용으로 데이터를 보관하고 싶은 경우 \n\n\n데이터 이관\nObject Storage에 있는 데이터를 자동으로 Archive Storage로 이관하는 방법은 수명주기 관리(LifeCycle Mangement)를 이용하면 됩니다.\n[ 네이버 클라우드 콘솔 - Object Storage - Lifecycle Management - 수명주기 정책 추가 ] 기능을 이용하시면 설정할 수 있습니다.\n\n\n  \n  \n    \n  \n\n\n수명주기 정책 추가\n수명주기 정책 추가 화면에서 정책 유형은 [이관] 또는 [이관 후 삭제], 관리대상은 Object Storage에 있는 대상 버킷, 이동 위치는 Archive Storage에 있는 버킷을 선택하시면 됩니다.\n이렇게 설정하시면 대상 버킷에 있는 데이터 중에서 이름 규칙에 해당하는 데이터가 Archive Storage로 이동하게 됩니다.\n\n\n  \n  \n    \n  \n\n\n정책\n정책 유형은 다음의 3가지가 있습니다.\n\n  만료 삭제 : 설정된 기간이 지난 파일을 삭제\n  이관 : 설정된 기간이 지난 파일을 Archive Storage로 이동\n  이관 후 삭제 : 설정된 기간이 지난 파일을 Archive Storage로 이동한 후 Object Storage에서 삭제\n\n\n그리고 이동 시점은 파일이 Object Storage에 저장-생성된 후 경과한 일자를 기준으로 하며 1일 ~ 3,650일 사이의 값을 입력합니다.\n\n\n  \n  \n    \n  \n\n\n관리대상 (Source)\n관리대상의 버킷(Bucket)을 선택하고 Object 이름의 규칙을 접두어 방식으로 입력합니다.\n\n\n  \n  \n    \n  \n\n\n이동위치 (Target)\n이동할 위치는 Archive Storage로 고정이며, Archive Storage의 컨테이너(버킷)을 선택하고 세부경로 즉, 폴더를 입력합니다.\n세부경로에 아무것도 입력하지 않으면 Source 즉, Object Storage의 위치, 폴더 구조 그대로 이동됩니다.\n\n\n  \n  \n    \n  \n\n\n정책 실행 시간\nLifecycle Management의 수명주기 정책 실행시간은 아래와 같습니다.\n\n  01:00~02:00,  07:00~08:00, 13:00~14:00, 19:00~20:00\n (※ 파일용량이 클 경우 일부 변동될 수 있음)\n\n\n예시) 정책 유형(만료 삭제)﻿, 이동 시점(생성 후 1일)로 정책을 생성하고 대상 파일이 15시에 업로드 되었다면 정책실행은 익일 19~20시 사이에 이관 완료\n\n관리대상 이름 규칙\n관리대상인 Object를 이관하는 이름 규칙은 접두어 방식인데 자세한 규칙 설명은 다음 문서를 참고 하시면 됩니다.\n\nhttps://docs.3rdeyesys.com/storage/ncloud_storage_object_storage_lifecycle_management.html\n\n참고 URL\n\n  Object Storage 가이드\n    \n      https://guide.ncloud-docs.com/docs/storage-storage-6-1\n    \n  \n  CentOS에서 mysql DB를 Object Storage로 자동 백업하기\n    \n      /database/ncloud_database_mysql_object_storage_auto_backup_centos.html"
					}
					
				
			
		
			
				
					,
					
					"news-news-html": {
						"id": "news-news-html",
						"title": "News &amp; Notice",
						"categories": "",
						"url": " /news/news.html",
						"content": "[2023-10-19] (VPC) Cloud DB for Redis 4.0 판매종료 안내 \n            \n        \n        \n            \n                2023년 11월 23일(목) 18시 기준으로 Cloud DB for Redis(VPC)의 redis(4.0.14) 버전이 판매 종료됩니다. 자세한 내용은 아래 공지 링크를 확인해주세요.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1626\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-10-18] (VPC) Security Monitoring WAF 상품 및 요금 조정 안내 \n            \n        \n        \n            \n                2023년 12월 01일부터 기존 WAF 100Mbps 상품은 더 이상 제공 되지 않을 예정이며, 제공되는 WAF상품 재편 (4종→3종), 300Mbps 상품 요금은 인하됩니다. 자세한 내용은 아래 공지 링크를 확인해주세요.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1624\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-09-11] Network Traffic Monitoring 서비스 종료 안내(Classic환경) \n            \n        \n        \n            \n                2023년 11월 23일(목) 18시 기준으로 Ncloud(네이버 클라우드) Classic 환경에서 제공 중인 Network Traffic Monitoring 서비스가 종료됩니다. 자세한 판매 종료 대상은 아래 공지 링크를 확인해주세요.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1603\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-07-26] Object Detection, Ncloud Pose Estimation 서비스 종료 안내 \n            \n        \n        \n            \n                2023년 11월 23일(목) 18시 기준으로 Ncloud(네이버 클라우드) Object Detection, Ncloud Pose Estimation 서비스가 종료됩니다. 자세한 판매 종료 대상은 아래 공지 링크를 확인해주세요.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1579\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-07-20] Windows 2012 서버이미지(OS) 판매종료 대상 및 일정 안내 \n            \n        \n        \n            \n                2023년 11월 09일(목) 18시 기준으로 Ncloud(네이버 클라우드) Windows 2012 서버이미지(OS) 판매가 종료됩니다. 자세한 판매 종료 대상은 아래 공지 링크를 확인해주세요.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1577\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-05-09] Ncloud(네이버 클라우드) 채팅상담 오픈 안내 \n            \n        \n        \n            \n                2023년 5월 8일(월)부터 네이버 클라우드 플랫폼 포털에 로그인하여 기술지원, 서비스 이용 및 도입, 요금 일반 문의에 대해 채팅상담이 가능합니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1540\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-05-03] Ncloud(네이버 클라우드) Classic 서버 이미지(CentOS 7.2 등) 판매 종료 대상 및 일정 안내 \n            \n        \n        \n            \n                2023년 6월 15일(목) 18시 기준으로 Ncloud(네이버 클라우드) Classic 서버 이미지(CentOS 7.2 등) 판매가 종료됩니다. 자세한 판매 종료 대상은 아래 공지 링크를 확인해주세요.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1537\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-04-25] Ncloud(네이버 클라우드) 리전 간 사설 통신 요금 인상 안내 \n            \n        \n        \n            \n                2023년 6월 1일부터 적용될 리전 간 사설 통신 요금 인상에 대해 안내 드립니다\n                - 참고문서: https://www.ncloud.com/support/notice/all/1530\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-04-21] Ncloud(네이버 클라우드) Classic 서버 이미지(Ubuntu16.04 등) 판매 종료 대상 및 일정 안내 \n            \n        \n        \n            \n                2023년 5월 25일(목) 18시 기준으로 Ncloud(네이버 클라우드) Classic 서버 이미지(Ubuntu16.04 등) 판매가 종료됩니다. 자세한 판매 종료 대상은 아래 공지 링크를 확인해주세요.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1528\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-03-24] Ncloud(네이버 클라우드) Video Player 서비스 종료 일정 안내 \n            \n        \n        \n            \n                2023년 07월 31일 기준으로 Video Player 서비스 제공이 종료됩니다. 이후에는 Video Player Enhancement를 이용하시면 보다 개선되고, 다양한 기능의 Player를 이용할 수 있습니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1509\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-03-20] Ncloud(네이버 클라우드) Global Route Manager 서비스 제공 종료 안내 \n            \n        \n        \n            \n                2023년 5월 25일(목) 18시 기준으로 Global Route Manager 서비스 제공이 종료됩니다. 이후에는 Global Traffic Manager를 이용하시면 보다 개선된 기능을 더 저렴한 비용으로 이용할 수 있습니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1505\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2023-03-02] Ncloud(네이버 클라우드) Cloud Security Watcher 요금 유료화 안내 \n            \n        \n        \n            \n                2023년 2월 23일 보안 프레임워크 준수 현황 점검, 리소스 현황 식별, 자산 변경 감시를 지원하는 클라우드 보안 형상 관리 서비스인 Cloud Security Watcher 가 정식 출시되어 3월 31일까지 한시적으로 무료로 제공될 예정이며, 4월 1일 부터는 정상 과금될 예정입니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1501\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2022-07-18] Ncloud(네이버 클라우드) 지원 브라우저 정책 변경 안내 \n            \n        \n        \n            \n                2022년 7월 21일부터 네이버 클라우드 플랫폼의 안정성 강화를 위해 Internet Explorer 서비스 종료와 관련한 브라우저 정책이 변경됩니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1388\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2022-07-18] Ncloud(네이버 클라우드) 일본 리전(Classic) NAS, Object Storage 서비스 요금변경 안내('22/09/01 부터 시행) \n            \n        \n        \n            \n                2022년 9월부터 Ncloud (네이버 클라우드) 일본 리전(Classic) NAS, Object Storage 서비스 요금이 변경됩니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1387\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2022-06-21] 네이버 클라우드 Cloud Log Analytics 일일 인입 로그 용량 제한 적용 안내 \n            \n        \n        \n            \n                현재 Cloud Log Analytics 상품에서 검색 가능한 문서 수에는 별도 제한이 없으나, 안정적인 서비스 제공을 위해 2022년 7월 21일 부터는 각 계정 별로 일일 인입 가능한 최대 로그 용량 제한이 적용될 예정입니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1369\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2022-06-21] 네이버 클라우드 Simple &amp; Easy Notification Service - Global SMS 발송 한도 관리 기능 적용 안내 \n            \n        \n        \n            \n                알람 및 메시지 전송 기능을 쉽게 구현할 수 있는 SENS(Simple &amp; Easy Notification Service)에서  아시아, 유럽, 아메리카 등 약 70여개국 이상의 국가에 SMS 메시지를 전송할 수 있는 Global SMS에 발송한도 관리 기능을 적용할 예정입니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1367\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2022-06-08] 네이버 클라우드 VPC CPU Intensive-G2 서버 요금 일부 조정(인하) 예정 안내 \n            \n        \n        \n            \n                VPC CPU Intensive-G2 서버의 요금이 일부 조정(인하)될 예정이며, 조정된 요금의 적용은 2022년 7월 1일(금) 이용분 부터 해당하고, 변경된 요금은 요금이 조정되는 시점인 7월 1일부터 확인 가능합니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1360\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2021-11-16] 네이버 클라우드 Cloud Log Analytics 검색 문서 수 제한 적용 안내 \n            \n        \n        \n            \n                현재 네이버 클라우드 Cloud Log Analytics 상품에서 검색 가능한 문서 수에는 별도 제한이 없으나, 안정적인 서비스 제공을 위해 2021년 12월 16일 부터는 각 계정 별로 검색 가능한 문서 수의 제한이 적용될 예정입니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1231\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2021-11-16] 네이버 클라우드 WORKPLACE AI OCR 베타 서비스 종료 및 유료화 안내 \n            \n        \n        \n            \n                네이버 클라우드 WORKPLACE에서 NAVER CLOVA OCR 기술이 적용된 영수증 자동인식 기능으로 간편하게 비용정산 처리를 하실 수 있도록 베타서비스로 제공해 드리고 있던 서비스가 2021년 12월 17일(금)부터 정식 서비스로 제공함과 동시에 유료화가 됩니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1230\n            \n        \n                        \n    \n    \n     \n      \n      \n      \n          \n    \n    \n        \n            \n                [2021-10-18] 네이버 클라우드 Cloud Outbound Mailer 서비스 발송 요청 한도 제한 적용​ 안내 \n            \n        \n        \n            \n                네이버 클라우드 Cloud Outbound Mailer 서비스는 현재 별도의 발송 요청 한도가 지정되어 있지 않으나, 2021년 11월 18일 부터는 계정 당 발송 요청 한도를 월 1,000,000건으로 제한 적용할 예정입니다. 자세한 내용은 아래 링크를 참고하시기 바랍니다.\n                - 참고문서: https://www.ncloud.com/support/notice/all/1196"
					}
					
				
			
		
			
		
			
				
			
		
			
		
			
				
			
		
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
			
		
			
				
					,
					
					"update-update-html": {
						"id": "update-update-html",
						"title": "Updates",
						"categories": "",
						"url": " /update/update.html",
						"content": "DateTitleDescription\n    \n    {% assign allpages = site.pages | sort: \"last_updated\" | reverse %}\n    {% for page in allpages limit: 15 %}\n    {% if page.last_updated %}\n    {% unless page.canonical_url %}\n        \n          {{ page.last_updated }}\n          {{page.title}}          \n          {% if page.description %} {{ page.description | strip_html | strip_newlines | truncate: 160 }} {% else %} {{ page.content | truncatewords: 30 | strip_html }} {% endif %}\n        \n    {% endunless %}\n    {% endif %}\n   {% endfor %}"
					}
					
				
			
		
			
		
	};
</script>
<script src="/v2/js/lunr.min.js" charset="utf-8"></script>
<script src="/v2/js/search.js" charset="utf-8"></script>
  
    <div class="tags">
      
        <b>Tags:
        </b>
        
        
      
    </div>
  

</div>

<hr class="shaded"/>


  <!-- docs-body-bottom -->
<ins
  class="adsbygoogle"
  style="display:block"
  data-ad-client="ca-pub-6933218466698885"
  data-ad-slot="6166392790"
  data-ad-format="auto"
  data-full-width-responsive="true"></ins>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<footer>
    <div class="row">
      <div class="col-lg-12 footer"> 
        <div>               
                        
          <a target="_blank" href="https://www.facebook.com/3rdeyesys" class="Facebook-icon no_icon">
          
            
		<svg class="facebook" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M19,4V7H17A1,1 0 0,0 16,8V10H19V13H16V20H13V13H11V10H13V7.5C13,5.56 14.57,4 16.5,4M20,2H4A2,2 0 0,0 2,4V20A2,2 0 0,0 4,22H20A2,2 0 0,0 22,20V4C22,2.89 21.1,2 20,2Z" /></svg>
	

          
          </a>
                        
          <a target="_blank" href="mailto:biz@3rdeyesys.com" class="Email-icon no_icon">
          
            
			<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/><path d="M0 0h24v24H0z" fill="none"/></svg>
		

          
          </a>
        		
        </div>
        &copy;2024 Copyright 3RDEYESYSTEM Corp. All rights reserved. <br />
        Built with <a href="https://jekyllrb-ko.github.io/" target="_blank" class="no_icon">Jekyll</a> & <a href="https://idratherbewriting.com/documentation-theme-jekyll/" target="_blank" class="no_icon">Documentation Theme</a> <br />
         Site last generated: 2024-04-17 <br />        
        <p><img src="/images/3rdeyesys_logo_white.png" alt="Company logo" style="filter: brightness(0.1);"/></p>
        <p><img src="/images/ncloud/ncloud-premium-partner-logo-gray-160px.png" alt="ncloud premium partner logo" /></p>
      </div>
    </div>
</footer>





            </div>
            <!-- /.row -->
          </div>
          <!-- /.container -->
        </div>
        
          
            <div class="side-banner-left">
  <!-- docs-sidebar-left -->
  <ins
    class="adsbygoogle"
    style="display:block"
    data-ad-client="ca-pub-6933218466698885"
    data-ad-slot="3163156637"
    data-ad-format="auto"
    data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>
          
          
          
        
        <!-- /#main -->
      </div>
      <script>
        $(function() {
          $('svg').click(function() {
            $(this).parent('form').submit();
          });
        });
      </script>

      
        
          <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4Q6RVEFJ3S"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4Q6RVEFJ3S');
</script>

        

        
      
    </body>
  </body>
</html>

