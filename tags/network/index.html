<!DOCTYPE html>





    

    

    

    

<html lang="ko-kr"><head>
       
    
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5XRCSF3');</script>
    
    <meta charset="utf-8" />
    <title>Network | 3RDEYESYS Tech Docs</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="keywords" content="Cloud, Server, System, Tech Docs, Documentation"> 
    <meta name="author" content="3RDEYESYSTEM" />
    <meta name="generator" content="Hugo v0.124.0" />
    
    <link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" type="image/svg+xml" href="/favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" crossorigin="use-credentials" href="/site.webmanifest">
<meta property="og:title" content="Network" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://example.org/tags/network/" /><meta property="og:image" content="http://example.org/opengraph/card-base-2_hu06b1a92291a380a0d2e0ec03dab66b2f_17642_filter_6482813604125220799.png"/><meta property="og:locale" content="ko-kr" /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://example.org/opengraph/card-base-2_hu06b1a92291a380a0d2e0ec03dab66b2f_17642_filter_6482813604125220799.png"/><meta name="twitter:title" content="Network"/>
<meta name="twitter:description" content=""/>
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Network","url":"http:\/\/example.org\/tags\/network\/"}
</script>
    
    <script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script>
    
    
            
                
                <script type="text/javascript" src="http://example.org/docs/js/flexsearch.bundle.min.d3bc6e35474ae14c230e078397a02e1773352cc62ec8abcb7dbe2043093f2a413fe25f3ec858b8920ea92d0ff2dc67a5.js" integrity="sha384-07xuNUdK4UwjDgeDl6AuF3M1LMYuyKvLfb4gQwk/KkE/4l8&#43;yFi4kg6pLQ/y3Gel" crossorigin="anonymous" charset="utf-8"></script>
                
        
    
    
    
    
        
        
        
        
    
        
        
        
        
    
    
    <link rel="preconnect" href="https://fonts.gstatic.com/" />
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin />
    <link href="https://fonts.googleapis.com/css?family=Inter:300,400,600,700|Fira+Code:500,700&display=block" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />

    <link rel="stylesheet" href="/docs/scss/style.min.594d663a51a70dd1d897ea96b6c4a8849564ece90a24f22fb32c4e015f64b40469743b6e3377d8b62757deebfff1abaf.css" integrity="sha384-WU1mOlGnDdHYl&#43;qWtsSohJVk7OkKJPIvsyxOAV9ktARpdDtuM3fYtidX3uv/8auv"crossorigin="anonymous">
    
    <link href="/css/customstyles.min.465a90c53687f984e6ea6e1c85d0785052f6745d59f4f78c3fd8ed7aab9a156a.css" rel="stylesheet" integrity="sha256-RlqQxTaH&#43;YTm6m4chdB4UFL2dF1Z9PeMP9jtequaFWo=" />
    
    
    
       
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-4Q6RVEFJ3S"></script>
    <script>
    var doNotTrack = false;
    if ( false ) {
        var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
        var doNotTrack = (dnt == "1" || dnt == "yes");
    }
    if (!doNotTrack) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-4Q6RVEFJ3S');
    }
    </script>
   
    <script
    async
    src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6933218466698885"
    crossorigin="anonymous"></script>
    </head><body>
           
    
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5XRCSF3"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    
    <div class="content">
            <div class="page-wrapper toggled">
<nav id="sidebar" class="sidebar-wrapper">
    <div class="sidebar-brand">
        <a href='/' aria-label="HomePage" alt="HomePage">
            <img src="/images/logo/3rdeyesys_logo_white.png" alt="Company logo" style="filter: brightness(0.1);">
        </a>
    </div>
    <div class="sidebar-content" style="height: calc(100% - 131px);">
        <ul class="sidebar-menu">            
            <div class="sidebar-submenu}">                      
            
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/.net"><i class="material-symbols-outlined me-2">sell</i>.net</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/access"><i class="material-symbols-outlined me-2">sell</i>access</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/account"><i class="material-symbols-outlined me-2">sell</i>account</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/acg"><i class="material-symbols-outlined me-2">sell</i>acg</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/admin"><i class="material-symbols-outlined me-2">sell</i>admin</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ai"><i class="material-symbols-outlined me-2">sell</i>ai</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/analytic"><i class="material-symbols-outlined me-2">sell</i>analytic</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/apache"><i class="material-symbols-outlined me-2">sell</i>apache</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/apahce"><i class="material-symbols-outlined me-2">sell</i>apahce</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/api"><i class="material-symbols-outlined me-2">sell</i>api</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/archive-storage"><i class="material-symbols-outlined me-2">sell</i>archive storage</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/atuh"><i class="material-symbols-outlined me-2">sell</i>atuh</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/auth"><i class="material-symbols-outlined me-2">sell</i>auth</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/autoscaling"><i class="material-symbols-outlined me-2">sell</i>autoscaling</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/aws"><i class="material-symbols-outlined me-2">sell</i>aws</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/backup"><i class="material-symbols-outlined me-2">sell</i>backup</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/c"><i class="material-symbols-outlined me-2">sell</i>c#</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/cdb"><i class="material-symbols-outlined me-2">sell</i>cdb</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/cdn"><i class="material-symbols-outlined me-2">sell</i>cdn</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/centos"><i class="material-symbols-outlined me-2">sell</i>centos</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/certificate"><i class="material-symbols-outlined me-2">sell</i>certificate</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/cla"><i class="material-symbols-outlined me-2">sell</i>cla</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/classic"><i class="material-symbols-outlined me-2">sell</i>classic</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/cli"><i class="material-symbols-outlined me-2">sell</i>cli</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/client"><i class="material-symbols-outlined me-2">sell</i>client</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/cloud-functions"><i class="material-symbols-outlined me-2">sell</i>cloud functions</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/clova"><i class="material-symbols-outlined me-2">sell</i>clova</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/cmd"><i class="material-symbols-outlined me-2">sell</i>cmd</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/config"><i class="material-symbols-outlined me-2">sell</i>config</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/database"><i class="material-symbols-outlined me-2">sell</i>database</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/dkim"><i class="material-symbols-outlined me-2">sell</i>dkim</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/dmarc"><i class="material-symbols-outlined me-2">sell</i>dmarc</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/domain"><i class="material-symbols-outlined me-2">sell</i>domain</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/engine"><i class="material-symbols-outlined me-2">sell</i>engine</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/error"><i class="material-symbols-outlined me-2">sell</i>error</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/event"><i class="material-symbols-outlined me-2">sell</i>event</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/excel"><i class="material-symbols-outlined me-2">sell</i>excel</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/firewall"><i class="material-symbols-outlined me-2">sell</i>firewall</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/fortigate"><i class="material-symbols-outlined me-2">sell</i>fortigate</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/free"><i class="material-symbols-outlined me-2">sell</i>free</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/gateway"><i class="material-symbols-outlined me-2">sell</i>gateway</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/github"><i class="material-symbols-outlined me-2">sell</i>github</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/gmail"><i class="material-symbols-outlined me-2">sell</i>gmail</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/google"><i class="material-symbols-outlined me-2">sell</i>google</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/https"><i class="material-symbols-outlined me-2">sell</i>https</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/iis"><i class="material-symbols-outlined me-2">sell</i>iis</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/install"><i class="material-symbols-outlined me-2">sell</i>install</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ip"><i class="material-symbols-outlined me-2">sell</i>ip</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ipsecvpn"><i class="material-symbols-outlined me-2">sell</i>ipsecvpn</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/jenkins"><i class="material-symbols-outlined me-2">sell</i>jenkins</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/kubernetes"><i class="material-symbols-outlined me-2">sell</i>kubernetes</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/lamp"><i class="material-symbols-outlined me-2">sell</i>lamp</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/limit"><i class="material-symbols-outlined me-2">sell</i>limit</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/linux"><i class="material-symbols-outlined me-2">sell</i>linux</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/load-balancer"><i class="material-symbols-outlined me-2">sell</i>load balancer</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/loadbalancer"><i class="material-symbols-outlined me-2">sell</i>loadbalancer</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/log"><i class="material-symbols-outlined me-2">sell</i>log</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/logging"><i class="material-symbols-outlined me-2">sell</i>logging</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/mail"><i class="material-symbols-outlined me-2">sell</i>mail</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/management"><i class="material-symbols-outlined me-2">sell</i>management</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/mariadb"><i class="material-symbols-outlined me-2">sell</i>mariadb</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/markdown"><i class="material-symbols-outlined me-2">sell</i>markdown</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/migration"><i class="material-symbols-outlined me-2">sell</i>migration</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/mongodb"><i class="material-symbols-outlined me-2">sell</i>mongodb</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/monitoring"><i class="material-symbols-outlined me-2">sell</i>monitoring</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/mssql"><i class="material-symbols-outlined me-2">sell</i>mssql</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/mysql"><i class="material-symbols-outlined me-2">sell</i>mysql</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/nacl"><i class="material-symbols-outlined me-2">sell</i>nacl</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/nas"><i class="material-symbols-outlined me-2">sell</i>nas</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/natgateway"><i class="material-symbols-outlined me-2">sell</i>natgateway</a>       
                </li>
                
            
              
                <li class="current">
                    <a class="sidebar-root-link" href="/tags/network"><i class="material-symbols-outlined me-2">sell</i>network</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/networking"><i class="material-symbols-outlined me-2">sell</i>networking</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/nginx"><i class="material-symbols-outlined me-2">sell</i>nginx</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/object-storage"><i class="material-symbols-outlined me-2">sell</i>object storage</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ocr"><i class="material-symbols-outlined me-2">sell</i>ocr</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/papago"><i class="material-symbols-outlined me-2">sell</i>papago</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/password"><i class="material-symbols-outlined me-2">sell</i>password</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/pdf"><i class="material-symbols-outlined me-2">sell</i>pdf</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/permission"><i class="material-symbols-outlined me-2">sell</i>permission</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/php"><i class="material-symbols-outlined me-2">sell</i>php</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/player"><i class="material-symbols-outlined me-2">sell</i>player</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/port"><i class="material-symbols-outlined me-2">sell</i>port</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/postgresql"><i class="material-symbols-outlined me-2">sell</i>postgresql</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/powershell"><i class="material-symbols-outlined me-2">sell</i>powershell</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/price"><i class="material-symbols-outlined me-2">sell</i>price</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/private"><i class="material-symbols-outlined me-2">sell</i>private</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/proxy"><i class="material-symbols-outlined me-2">sell</i>proxy</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/public"><i class="material-symbols-outlined me-2">sell</i>public</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/python"><i class="material-symbols-outlined me-2">sell</i>python</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/replication"><i class="material-symbols-outlined me-2">sell</i>replication</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/repository"><i class="material-symbols-outlined me-2">sell</i>repository</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/reset"><i class="material-symbols-outlined me-2">sell</i>reset</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/restore"><i class="material-symbols-outlined me-2">sell</i>restore</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/rocky-linux"><i class="material-symbols-outlined me-2">sell</i>rocky linux</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/route-table"><i class="material-symbols-outlined me-2">sell</i>route-table</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/routetable"><i class="material-symbols-outlined me-2">sell</i>routetable</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ruby"><i class="material-symbols-outlined me-2">sell</i>ruby</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/rule"><i class="material-symbols-outlined me-2">sell</i>rule</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/s3"><i class="material-symbols-outlined me-2">sell</i>s3</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/sdk"><i class="material-symbols-outlined me-2">sell</i>sdk</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/security"><i class="material-symbols-outlined me-2">sell</i>security</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/securty"><i class="material-symbols-outlined me-2">sell</i>securty</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/server"><i class="material-symbols-outlined me-2">sell</i>server</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/smtp"><i class="material-symbols-outlined me-2">sell</i>smtp</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/spec"><i class="material-symbols-outlined me-2">sell</i>spec</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/spf"><i class="material-symbols-outlined me-2">sell</i>spf</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ssg"><i class="material-symbols-outlined me-2">sell</i>ssg</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ssh"><i class="material-symbols-outlined me-2">sell</i>ssh</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ssl"><i class="material-symbols-outlined me-2">sell</i>ssl</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/storage"><i class="material-symbols-outlined me-2">sell</i>storage</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/streaming"><i class="material-symbols-outlined me-2">sell</i>streaming</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/subnet"><i class="material-symbols-outlined me-2">sell</i>subnet</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/telegram"><i class="material-symbols-outlined me-2">sell</i>telegram</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/template"><i class="material-symbols-outlined me-2">sell</i>template</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/theme"><i class="material-symbols-outlined me-2">sell</i>theme</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/token"><i class="material-symbols-outlined me-2">sell</i>token</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/tool"><i class="material-symbols-outlined me-2">sell</i>tool</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/ubuntu"><i class="material-symbols-outlined me-2">sell</i>ubuntu</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/upgrade"><i class="material-symbols-outlined me-2">sell</i>upgrade</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/url"><i class="material-symbols-outlined me-2">sell</i>url</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/visual-studio"><i class="material-symbols-outlined me-2">sell</i>visual studio</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/vod"><i class="material-symbols-outlined me-2">sell</i>vod</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/vpc"><i class="material-symbols-outlined me-2">sell</i>vpc</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/vpc-peering"><i class="material-symbols-outlined me-2">sell</i>vpc-peering</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/vpn"><i class="material-symbols-outlined me-2">sell</i>vpn</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/web"><i class="material-symbols-outlined me-2">sell</i>web</a>       
                </li>
                
            
              
                <li class="">
                    <a class="sidebar-root-link" href="/tags/windows"><i class="material-symbols-outlined me-2">sell</i>windows</a>       
                </li>
                
            </div>
            
        </ul>
        
    </div>
    
        <ul class="sidebar-footer list-unstyled mb-0">
            
        </ul>
    
</nav>
<main class="page-content bg-transparent">
                        
<div id="top-header" class="top-header d-print-none">
    <div class="header-bar d-flex justify-content-between">
        <div class="d-flex align-items-center">
            
            <button id="close-sidebar" class="btn btn-icon btn-soft">
                <span class="material-icons size-20 menu-icon align-middle">menu</span>
            </button>
            
            
                    
                    
                
            </div>
        <div class="d-flex align-items-start">
            <div class="nav-lg-menu">
            <ul class="nav">
            
                <li class="nav-item">
                  <a class="nav-link yes_icon" aria-current="page" href="/docs/" target="_self">Docs</a>
                </li>               
            
                <li class="nav-item">
                  <a class="nav-link yes_icon" aria-current="page" href="/docs/help/update/" target="_self">Update</a>
                </li>               
            
                <li class="nav-item">
                  <a class="nav-link yes_icon" aria-current="page" href="/docs/help/faq/" target="_self">FAQ</a>
                </li>               
            
                <li class="nav-item">
                  <a class="nav-link yes_icon" aria-current="page" href="/docs/help/news/" target="_self">News</a>
                </li>               
            
                <li class="nav-item">
                  <a class="nav-link yes_icon" aria-current="page" href="/tags/" target="_self">Tags</a>
                </li>               
            
                <li class="nav-item">
                  <a class="nav-link yes_icon" aria-current="page" href="https://3rdeyesys.com/" target="_blank">Company<svg width="14" height="14" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"/></svg></a>
                </li>               
            
                <li class="nav-item">
                  <a class="nav-link yes_icon" aria-current="page" href="https://www.3rdeyesys.com/question/" target="_blank">1:1 문의하기<svg width="14" height="14" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"/></svg></a>
                </li>               
            
            </ul>
            </div>
            <div class="nav-sm-menu">
            <ul class="nav">               
                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-expanded="false">3rdEYESYS Tech Docs</a>
                  <ul class="dropdown-menu">
                
                    <li><a class="dropdown-item" href="/docs/" target="_self">Docs</a></li>        
                
                    <li><a class="dropdown-item" href="/docs/help/update/" target="_self">Update</a></li>        
                
                    <li><a class="dropdown-item" href="/docs/help/faq/" target="_self">FAQ</a></li>        
                
                    <li><a class="dropdown-item" href="/docs/help/news/" target="_self">News</a></li>        
                
                    <li><a class="dropdown-item" href="/tags/" target="_self">Tags</a></li>        
                
                    <li><a class="dropdown-item" href="https://3rdeyesys.com/" target="_blank">Company<svg width="14" height="14" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"/></svg></a></li>        
                
                    <li><a class="dropdown-item" href="https://www.3rdeyesys.com/question/" target="_blank">1:1 문의하기<svg width="14" height="14" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"/></svg></a></li>        
                            
                  </ul>
                </li>                
            </ul>
            </div>
        </div>
        <div class="d-flex align-items-center">
            <ul class="list-unstyled mb-0">
                
            </ul>
            <button id="mode" class="btn btn-icon btn-default ms-2" type="button" aria-label="Toggle user interface mode">
                <span class="toggle-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" height="30" width="30" viewBox="0 0 48 48" fill="currentColor">
                        <title>Enable dark mode</title>
                        <path d="M24 42q-7.5 0-12.75-5.25T6 24q0-7.5 5.25-12.75T24 6q.4 0 .85.025.45.025 1.15.075-1.8 1.6-2.8 3.95-1 2.35-1 4.95 0 4.5 3.15 7.65Q28.5 25.8 33 25.8q2.6 0 4.95-.925T41.9 22.3q.05.6.075.975Q42 23.65 42 24q0 7.5-5.25 12.75T24 42Zm0-3q5.45 0 9.5-3.375t5.05-7.925q-1.25.55-2.675.825Q34.45 28.8 33 28.8q-5.75 0-9.775-4.025T19.2 15q0-1.2.25-2.575.25-1.375.9-3.125-4.9 1.35-8.125 5.475Q9 18.9 9 24q0 6.25 4.375 10.625T24 39Zm-.2-14.85Z"/>
                    </svg>
                </span>
                <span class="toggle-light">
                    <svg xmlns="http://www.w3.org/2000/svg" height="30" width="30" viewBox="0 0 48 48" fill="currentColor">
                        <title>Enable light mode</title>
                        <path d="M24 31q2.9 0 4.95-2.05Q31 26.9 31 24q0-2.9-2.05-4.95Q26.9 17 24 17q-2.9 0-4.95 2.05Q17 21.1 17 24q0 2.9 2.05 4.95Q21.1 31 24 31Zm0 3q-4.15 0-7.075-2.925T14 24q0-4.15 2.925-7.075T24 14q4.15 0 7.075 2.925T34 24q0 4.15-2.925 7.075T24 34ZM3.5 25.5q-.65 0-1.075-.425Q2 24.65 2 24q0-.65.425-1.075Q2.85 22.5 3.5 22.5h5q.65 0 1.075.425Q10 23.35 10 24q0 .65-.425 1.075-.425.425-1.075.425Zm36 0q-.65 0-1.075-.425Q38 24.65 38 24q0-.65.425-1.075.425-.425 1.075-.425h5q.65 0 1.075.425Q46 23.35 46 24q0 .65-.425 1.075-.425.425-1.075.425ZM24 10q-.65 0-1.075-.425Q22.5 9.15 22.5 8.5v-5q0-.65.425-1.075Q23.35 2 24 2q.65 0 1.075.425.425.425.425 1.075v5q0 .65-.425 1.075Q24.65 10 24 10Zm0 36q-.65 0-1.075-.425-.425-.425-.425-1.075v-5q0-.65.425-1.075Q23.35 38 24 38q.65 0 1.075.425.425.425.425 1.075v5q0 .65-.425 1.075Q24.65 46 24 46ZM12 14.1l-2.85-2.8q-.45-.45-.425-1.075.025-.625.425-1.075.45-.45 1.075-.45t1.075.45L14.1 12q.4.45.4 1.05 0 .6-.4 1-.4.45-1.025.45-.625 0-1.075-.4Zm24.7 24.75L33.9 36q-.4-.45-.4-1.075t.45-1.025q.4-.45 1-.45t1.05.45l2.85 2.8q.45.45.425 1.075-.025.625-.425 1.075-.45.45-1.075.45t-1.075-.45ZM33.9 14.1q-.45-.45-.45-1.05 0-.6.45-1.05l2.8-2.85q.45-.45 1.075-.425.625.025 1.075.425.45.45.45 1.075t-.45 1.075L36 14.1q-.4.4-1.025.4-.625 0-1.075-.4ZM9.15 38.85q-.45-.45-.45-1.075t.45-1.075L12 33.9q.45-.45 1.05-.45.6 0 1.05.45.45.45.45 1.05 0 .6-.45 1.05l-2.8 2.85q-.45.45-1.075.425-.625-.025-1.075-.425ZM24 24Z"/>
                    </svg>
                </span>
            </button>
            
        </div>
    </div>
    
    
            <div class="collapse" id="FlexSearchCollapse">
                <div class="flexsearch-container">
                    <div class="flexsearch-keymap">
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8M10.5 8.5l-3 3-3-3"></path></g></svg></kbd>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8M10.5 6.5l-3-3-3 3"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to navigate</span>
                        </li>
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4M7 11.53088l-3-3 3-3"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to select</span>
                        </li>
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993 0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016.8634 0 1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5c.032.5663-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864 0 1.6425 1.031 1.5443 2.2492h-2.956"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to close</span>
                        </li>
                    </div>
                    <form class="flexsearch position-relative flex-grow-1 ms-2 me-2">
                        <div class="d-flex flex-row">
                            <input id="flexsearch" class="form-control" type="search" placeholder="Search" aria-label="Search" autocomplete="off">
                            <button id="hideFlexsearch" type="button" class="ms-2 btn btn-soft">
                                cancel
                            </button>
                        </div>
                        <div id="suggestions" class="shadow rounded-1 d-none"></div>
                    </form>
                </div>
            </div>
        
    
    
</div>

                            <div class="container-fluid">
                                <div class="layout-spacing">
                                    
                                        <div class="d-md-flex justify-content-between align-items-center"><nav aria-label="breadcrumb" class="d-inline-block pb-2 mt-1 mt-sm-0">
    <ul id="breadcrumbs" class="breadcrumb bg-transparent mb-0" itemscope itemtype="https://schema.org/BreadcrumbList">
        
            
                <li class="breadcrumb-item text-capitalize active" aria-current="page" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/tags/">
                        <i class="material-icons size-20 align-text-bottom" itemprop="name">Home</i>
                    </a>
                    <meta itemprop="position" content='1' />
                </li>
            
        
            <li class="breadcrumb-item text-capitalize active" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                <span itemprop="name">Network</span>
                <meta itemprop="position" content='2' />
            </li>
        
    </ul>
</nav></div>
                                    
                                    <div class="row flex-xl-nowrap">
                                        
                                        <div class="docs-toc col-xl-3 visually-hidden visually-hidden  d-xl-block"><toc>
    <div class="fw-bold text-uppercase mb-2">On this page</div>
    <nav id="toc"></nav>
    </toc></div>
                                        
                                        
                                        <div class="docs-toc-mobile visually-hidden visually-hidden  d-print-none d-xl-none">
                                            <button id="toc-dropdown-btn" class="btn-secondary dropdown-toggle" type="button" data-bs-toggle="dropdown" data-bs-offset="0,0" aria-expanded="false">
                                                Table of Contents
                                            </button>
<nav id="toc-mobile"></nav></div>
                                        <div class="docs-content col-12  mt-0">
                                            <hr />
                                            <div class="mb-0 d-flex">
                                                
                                                <i class="material-symbols-outlined title-icon me-2 ">sell</i>
                                                
                                                <h1 class="content-title mb-0">
                                                    Network
                                                    
                                                </h1>
                                            </div>                                            
                                            
                                            <hr />
                                            <div id="content" class="main-content" data-bs-spy="scroll" data-bs-root-margin="0px 0px -65%" data-bs-target="#toc-mobile">
                                                <ul>
                                                
                                                    <li><a href="/docs/networking/vpc/vpc-peering-guide/">VPC Peering 생성 가이드</a></li>
                                                
                                                </ul>
                                            </div>
                                            <div><hr class="doc-hr">
<div id="doc-nav" class="d-print-none">
</div></div>
                                        </div>
                                    </div>
                                </div>
                            </div>
<footer class="shadow py-3 d-print-none">
    <div class="container-fluid">
        <div class="row align-items-center">
            <div class="col">
                <div class="text-sm-start text-center mx-md-2">
                    <p class="mb-0">
                        
                        © 2024 Copyright 3RDEYESYSTEM Corp. All rights reserved.
                    </p>
                    <p class="mb-0">
                        Built with <a href="https://gohugo.io/" target="_blank" class="no_icon">HUGO</a> & <a href="https://lotusdocs.dev/docs/" target="_blank" class="no_icon">Lotus Docs</a>
                    </p>                    
                                    
                    <p class="mb-0">
                        Page last modified:2024-02-14 <br />
                    </p>
                    
                    <p class="mb-0">
                        Site last modified: 2024-02-19
                    </p>
                    <p class="mb-3">
                    <img src="/images/logo/3rdeyesys_logo_white.png" alt="Company logo" class="main-logo" style="margin-right:15px;">
                    <img src="/images/ncloud/ncloud-premium-partner-logo-gray-200px.png" class="ncloud-partner-logo-gray" alt="Ncloud Partner logo">
                    <img src="/images/ncloud/ncloud-premium-partner-logo-black-200px.png" class="ncloud-partner-logo-black" alt="Ncloud Partner logo">
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>
</main>
            </div>
        </div>

        
        
        <button onclick="topFunction()" id="back-to-top" aria-label="Back to Top Button" class="back-to-top fs-5"><svg width="24" height="24"><path d="M12,10.224l-6.3,6.3L4.32,15.152,12,7.472l7.68,7.68L18.3,16.528Z" style="fill:#fff"/></svg></button>
        
        

        
        
            <script>(()=>{var e=document.getElementById("mode");e!==null&&(window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{e.matches?(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")):(localStorage.setItem("theme","light"),document.documentElement.removeAttribute("data-dark-mode"))}),e.addEventListener("click",()=>{document.documentElement.toggleAttribute("data-dark-mode"),localStorage.setItem("theme",document.documentElement.hasAttribute("data-dark-mode")?"dark":"light")}),localStorage.getItem("theme")==="dark"?document.documentElement.setAttribute("data-dark-mode",""):document.documentElement.removeAttribute("data-dark-mode"))})()</script>
        




    
        
        
    
    






    

    <script src="/docs/js/bootstrap.eac7ee3f6fa791c684e7a51fc2fd50b6f724271b9e39562e4fe8c3942412df3acbfc4045f043d03399dac70091207507.js" integrity="sha384-6sfuP2&#43;nkcaE56Ufwv1QtvckJxueOVYuT&#43;jDlCQS3zrL/EBF8EPQM5naxwCRIHUH"defer></script>


    <script type="text/javascript" src="http://example.org/docs/js/bundle.min.c4afb43dddd895b6285611c0d410a47b27a856b15c067bb3dbced921c4acd06bf390dd77e1cca927c71796dba4006b80.js" integrity="sha384-xK&#43;0Pd3YlbYoVhHA1BCkeyeoVrFcBnuz287ZIcSs0GvzkN134cypJ8cXltukAGuA" crossorigin="anonymous" defer></script>
        

        
        <script type="module"  charset="utf-8">
    var suggestions = document.getElementById('suggestions');
    var search = document.getElementById('flexsearch');

    const flexsearchContainer = document.getElementById('FlexSearchCollapse');

    const hideFlexsearchBtn = document.getElementById('hideFlexsearch');

    const configObject = { toggle: false }
    const flexsearchContainerCollapse = new Collapse(flexsearchContainer, configObject) 

    if (search !== null) {
        document.addEventListener('keydown', inputFocus);
        flexsearchContainer.addEventListener('shown.bs.collapse', function () {
            search.focus();
        });
        
        var topHeader = document.getElementById("top-header");
        document.addEventListener('click', function(elem) {
            if (!flexsearchContainer.contains(elem.target) && !topHeader.contains(elem.target))
                flexsearchContainerCollapse.hide();
        });
    }

    hideFlexsearchBtn.addEventListener('click', () =>{
        flexsearchContainerCollapse.hide()
    })

    function inputFocus(e) {
        if (e.ctrlKey && e.key === '/') {
            e.preventDefault();
            flexsearchContainerCollapse.toggle();
        }
        if (e.key === 'Escape' ) {
            search.blur();
            
            flexsearchContainerCollapse.hide();
        }
    };

    document.addEventListener('click', function(event) {

    var isClickInsideElement = suggestions.contains(event.target);

    if (!isClickInsideElement) {
        suggestions.classList.add('d-none');
    }

    });

    


    document.addEventListener('keydown',suggestionFocus);

    function suggestionFocus(e) {
    const suggestionsHidden = suggestions.classList.contains('d-none');
    if (suggestionsHidden) return;

    const focusableSuggestions= [...suggestions.querySelectorAll('a')];
    if (focusableSuggestions.length === 0) return;

    const index = focusableSuggestions.indexOf(document.activeElement);

    if (e.key === "ArrowUp") {
        e.preventDefault();
        const nextIndex = index > 0 ? index - 1 : 0;
        focusableSuggestions[nextIndex].focus();
    }
    else if (e.key === "ArrowDown") {
        e.preventDefault();
        const nextIndex= index + 1 < focusableSuggestions.length ? index + 1 : index;
        focusableSuggestions[nextIndex].focus();
    }

    }

    


    (function(){

    var index = new FlexSearch.Document({
        charset: "cjk:default",
        tokenize: "full",
        minlength:  0 ,
        cache:  100 ,
        optimize:  true ,
        document: {
        id: 'id',
        store: [
            "href", "title", "description"
        ],
        index: ["title", "description"]
        }
    });


    


    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    


    

    

    index.add(
            {
                id:  0 ,
                href: "\/docs\/compute\/",
                title: "Compute",
                description: "Compute Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  1 ,
                href: "\/docs\/storage\/",
                title: "Storage",
                description: "Storage Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  2 ,
                href: "\/docs\/networking\/",
                title: "Networking",
                description: "Networking Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  3 ,
                href: "\/docs\/database\/",
                title: "Database",
                description: "Database Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  4 ,
                href: "\/docs\/security\/",
                title: "Security",
                description: "Security Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  5 ,
                href: "\/docs\/management\/",
                title: "Management",
                description: "Management Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  6 ,
                href: "\/docs\/containers\/",
                title: "Containers",
                description: "Containers Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  7 ,
                href: "\/docs\/ai-services\/",
                title: "AI Services",
                description: "AI Services Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  8 ,
                href: "\/docs\/application-services\/",
                title: "Application Services",
                description: "Application Services Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  9 ,
                href: "\/docs\/developer-tools\/",
                title: "Developer Tools",
                description: "Developer Tools Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  10 ,
                href: "\/docs\/media\/",
                title: "Media",
                description: "Media Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  11 ,
                href: "\/docs\/api\/",
                title: "API",
                description: "API Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  12 ,
                href: "\/docs\/aws\/",
                title: "AWS",
                description: "AWS Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  13 ,
                href: "\/docs\/etc\/",
                title: "ETC",
                description: "ETC Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  14 ,
                href: "\/docs\/help\/",
                title: "Help",
                description: "Help Docs",
                content: "Create New Content link"
            }
        );
    index.add(
            {
                id:  15 ,
                href: "\/docs\/compute\/vpc\/",
                title: "VPC",
                description: "Compute - VPC Environment Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  16 ,
                href: "\/docs\/compute\/classic\/",
                title: "Classic",
                description: "Compute - Classic Environment Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  17 ,
                href: "\/docs\/compute\/rocky-linux\/",
                title: "Rocky Linux",
                description: "Rocky Linux Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  18 ,
                href: "\/docs\/compute\/redirect-http-to-https\/",
                title: "HTTP 접속 시에 HTTPS로 강제 리다이렉트",
                description: "HTTP 접속 시에 HTTPS로 강제 리다이렉트 시키는 방법",
                content: ""
            }
        );
    index.add(
            {
                id:  19 ,
                href: "\/docs\/compute\/auth-security\/",
                title: "서버 접속을 위한 인증과 보안 설정",
                description: "서버 접속을 위한 인증과 보안 설정",
                content: ""
            }
        );
    index.add(
            {
                id:  20 ,
                href: "\/docs\/compute\/server-storage\/",
                title: "서버 스토리지(디스크) 설정",
                description: "서버 스토리지(디스크) 설정",
                content: ""
            }
        );
    index.add(
            {
                id:  21 ,
                href: "\/docs\/compute\/autoscaling\/",
                title: "Auto Scaling",
                description: "Auto Scaling 설정",
                content: ""
            }
        );
    index.add(
            {
                id:  22 ,
                href: "\/docs\/compute\/lamp\/",
                title: "LAMP (Linux, Apache, MySQL|MariaDB, PHP)",
                description: "LAMP (Linux, Apache, MySQL|MariaDB, PHP) 설정",
                content: ""
            }
        );
    index.add(
            {
                id:  23 ,
                href: "\/docs\/compute\/nginx\/",
                title: "NginX 설치, 설정",
                description: "NginX 설치, 설정",
                content: ""
            }
        );
    index.add(
            {
                id:  24 ,
                href: "\/docs\/compute\/x-forwarded-for\/",
                title: "X-Forwarded-For를 이용해 Client IP 기록",
                description: "X-Forwarded-For를 이용해 Proxy, Load Balancer 환경에서 Client IP 기록하기",
                content: ""
            }
        );
    index.add(
            {
                id:  25 ,
                href: "\/docs\/compute\/cloud-functions\/",
                title: "Cloud Functions 사용 예제",
                description: "Ncloud (네이버 클라우드) Cloud Functions 사용 예제",
                content: ""
            }
        );
    index.add(
            {
                id:  26 ,
                href: "\/docs\/storage\/object-storage\/",
                title: "Object Storage",
                description: "Ncloud(네이버 클라우드) Object Storage 관련 문서입니다.",
                content: ""
            }
        );
    index.add(
            {
                id:  27 ,
                href: "\/docs\/storage\/archive-storage\/",
                title: "Archive Storage",
                description: "Ncloud(네이버 클라우드) Archive Storage 관련 문서입니다.",
                content: ""
            }
        );
    index.add(
            {
                id:  28 ,
                href: "\/docs\/storage\/backup\/",
                title: "Backup 서비스",
                description: "Ncloud(네이버 클라우드) Backup 서비스 관련 문서입니다.",
                content: ""
            }
        );
    index.add(
            {
                id:  29 ,
                href: "\/docs\/storage\/nas\/",
                title: "NAS 스토리지",
                description: "Ncloud(네이버 클라우드) NAS 스토리지 관련 문서입니다.",
                content: ""
            }
        );
    index.add(
            {
                id:  30 ,
                href: "\/docs\/networking\/loadbalancer\/",
                title: "Load Balancer",
                description: "Ncloud(네이버 클라우드) Load Balancer Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  31 ,
                href: "\/docs\/networking\/dns\/",
                title: "Global DNS",
                description: "Ncloud(네이버 클라우드) Global DNS Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  32 ,
                href: "\/docs\/networking\/natgateway\/",
                title: "NAT Gateway",
                description: "Ncloud(네이버 클라우드) NAT Gateway Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  33 ,
                href: "\/docs\/networking\/vpc\/",
                title: "VPC (Virtual Private Cloud)",
                description: "Ncloud(네이버 클라우드) VPC (Virtual Private Cloud) Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  34 ,
                href: "\/docs\/networking\/ipsecvpn\/",
                title: "IPsec VPN",
                description: "Ncloud(네이버 클라우드) IPsec VPN Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  35 ,
                href: "\/docs\/database\/mysql-mariadb\/",
                title: "MySQL/MariaDB",
                description: "MySQL과 MariaDB Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  36 ,
                href: "\/docs\/database\/cloud-db-mysql\/",
                title: "Cloud DB for MySQL",
                description: "Ncloud(네이버 클라우드) Cloud DB for MySQL Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  37 ,
                href: "\/docs\/database\/cloud-db-mssql\/",
                title: "Cloud DB for MSSQL",
                description: "Ncloud(네이버 클라우드) Cloud DB for MSSQL Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  38 ,
                href: "\/docs\/database\/postgresql\/",
                title: "설치형 PostgreSQL DB",
                description: "설치형 PostgreSQL DB Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  39 ,
                href: "\/docs\/database\/cloud-db-postgresql\/",
                title: "Cloud DB for PostgreSQL",
                description: "Cloud DB for PostgreSQL Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  40 ,
                href: "\/docs\/security\/acg\/",
                title: "ACG",
                description: "Ncloud 방화벽 ACG Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  41 ,
                href: "\/docs\/security\/security-monitoring\/",
                title: "Security Monitoring",
                description: "Ncloud Security Monitoring Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  42 ,
                href: "\/docs\/security\/ssl-vpn\/",
                title: "SSL VPN",
                description: "Ncloud SSL VPN Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  43 ,
                href: "\/docs\/security\/certificate\/",
                title: "인증서",
                description: "Ncloud 인증서 관련 Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  44 ,
                href: "\/docs\/management\/sub-account\/",
                title: "Sub Account",
                description: "Ncloud Sub Account Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  45 ,
                href: "\/docs\/management\/cloud-insight\/",
                title: "Ncloud Cloud Insight",
                description: "Ncloud Cloud Insight Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  46 ,
                href: "\/docs\/management\/cloud-log-analytics\/",
                title: "Ncloud Cloud Log Analytics",
                description: "Ncloud Cloud Log Analytics Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  47 ,
                href: "\/docs\/management\/webservice-monitoring-system\/",
                title: "Ncloud Web service Monitoring System",
                description: "Ncloud Web service Monitoring System Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  48 ,
                href: "\/docs\/ai-services\/clova-ocr\/",
                title: "Clova OCR",
                description: "Clova OCR Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  49 ,
                href: "\/docs\/ai-services\/korean-name-romanizer\/",
                title: "Ncloud Korean Name Romanizer",
                description: "Ncloud Korean Name Romanizer Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  50 ,
                href: "\/docs\/application-services\/nshorturl\/",
                title: "nShortURL",
                description: "nShortURL Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  51 ,
                href: "\/docs\/application-services\/cloud-outbound-mailer\/",
                title: "Ncloud Cloud Outbound Mailer",
                description: "Ncloud Cloud Outbound Mailer Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  52 ,
                href: "\/docs\/developer-tools\/sourcecommit\/",
                title: "SourceCommit",
                description: "SourceCommit Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  53 ,
                href: "\/docs\/developer-tools\/jenkins\/",
                title: "Ncloud Jenkins",
                description: "Ncloud Jenkins Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  54 ,
                href: "\/docs\/media\/vod-station\/",
                title: "VOD Station",
                description: "VOD Station Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  55 ,
                href: "\/docs\/media\/video-player-enhancement\/",
                title: "Ncloud Video Player Enhancement",
                description: "Ncloud Video Player Enhancement Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  56 ,
                href: "\/docs\/etc\/markdown\/",
                title: "MarkDown",
                description: "MarkDown Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  57 ,
                href: "\/docs\/compute\/classic\/server-access-linux\/",
                title: "Classic 환경 서버 접속 가이드(Linux)",
                description: "Ncloud  (네이버 클라우드) Classic 환경 서버 접속 가이드(Linux)",
                content: ""
            }
        );
    index.add(
            {
                id:  58 ,
                href: "\/docs\/storage\/object-storage\/cors\/",
                title: "Object Storage CORS 설정",
                description: "Ncloud(네이버 클라우드) Object Storage CORS 설정 관련 문서입니다.",
                content: ""
            }
        );
    index.add(
            {
                id:  59 ,
                href: "\/docs\/storage\/object-storage\/content-type\/",
                title: "Content-Type 설정",
                description: "Ncloud(네이버 클라우드) Object Storage Content-Type 설정 관련 문서입니다.",
                content: ""
            }
        );
    index.add(
            {
                id:  60 ,
                href: "\/docs\/storage\/object-storage\/client-tool\/",
                title: "Object Storage 접속용 Client Tools",
                description: "Ncloud(네이버 클라우드) Object Storage 접속용 Client Tool 관련 문서입니다.",
                content: ""
            }
        );
    index.add(
            {
                id:  61 ,
                href: "\/docs\/networking\/loadbalancer\/proxy-portocol\/",
                title: "Load Balancer Proxy Protocol 설정",
                description: "Ncloud(네이버 클라우드) Load Balancer Proxy Protocol 설정 관련 Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  62 ,
                href: "\/docs\/database\/mysql-mariadb\/install\/",
                title: "DB 설치(Install)",
                description: "MySQL과 MariaDB 설치(Install) 관련 문서",
                content: ""
            }
        );
    index.add(
            {
                id:  63 ,
                href: "\/docs\/database\/mysql-mariadb\/configure\/",
                title: "DB 환경 설정",
                description: "MySQL과 MariaDB 환경 설정 관련 문서",
                content: ""
            }
        );
    index.add(
            {
                id:  64 ,
                href: "\/docs\/database\/mysql-mariadb\/backup\/",
                title: "DB Backup",
                description: "MySQL과 MariaDB 백업 관련 문서",
                content: ""
            }
        );
    index.add(
            {
                id:  65 ,
                href: "\/docs\/database\/mysql-mariadb\/replication\/",
                title: "DB Replication",
                description: "MySQL과 MariaDB 복제 관련 문서",
                content: ""
            }
        );
    index.add(
            {
                id:  66 ,
                href: "\/docs\/database\/cloud-db-mysql\/load-balance\/",
                title: "Cloud DB 읽기 부하 분산",
                description: "Ncloud(네이버 클라우드) Cloud DB 읽기 부하 분산 Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  67 ,
                href: "\/docs\/database\/cloud-db-mysql\/db-migration\/",
                title: "Ncloud 데이터베이스 마이그레이션",
                description: "Ncloud(네이버 클라우드) Database Migration 관련 문서",
                content: ""
            }
        );
    index.add(
            {
                id:  68 ,
                href: "\/docs\/etc\/markdown\/jekyll\/",
                title: "Jekyll",
                description: "Jekyll Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  69 ,
                href: "\/docs\/etc\/markdown\/mkdocs\/",
                title: "MkDocs",
                description: "MkDocs Docs",
                content: ""
            }
        );
    index.add(
            {
                id:  70 ,
                href: "\/docs\/compute\/vpc\/server-create\/",
                title: "Ncloud VPC 환경에서 서버 생성하는 방법",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 서버를 생성하는 방법을 간단하게 정리했습니다",
                content: "개요 linkNcloud (네이버 클라우드) VPC환경에서 서버를 생성하는 순서를 정리해보겠습니다.\n얼마전 업데이트에서 서버 생성 콘솔 화면에 큰 변화가 생겼기에 그 내용까지 함께 포함했습니다.\n서버 생성 순서 linkVPC 환경에서 서버를 생성하려면 Subnet 설정 등 사전에 미리 설정해야 하는 것과 서버 생성 후에 설정해야 하는 것들이 있는데, 순서대로 정리하고 아래쪽에서 차례대로 살펴보겠습니다.\nVPC 설정 Subnet 설정 서버 생성\n3-1. 서버 인증키 설정 ACG (방화벽) 설정 VPC 설정 linkVPC (Virtual Private Cloud) 즉, 클라우드 상에서 논리적으로 격리된 고객 전용 네트워크 공간을 먼저 생성하고 해당 공간에 서버를 생성하게 됩니다.\nVPC는 고객의 계정마다 최대 3개를 생성할 수 있으며, 각 VPC는 최대 넷마스크 0.0.255.255/16 (IP 65,536개) 크기의 네트워크 주소 공간을 제공합니다.\nVPC 서비스 위치 link[VPC] 서비스는 [Console] - [Services] - [Networking]에 위치해 있습니다.\n그리고, 아래 스샷에서 확인할 수 있듯이 [VPC]에는 [VPC Management], [Subnet Management], [Network ACL], [NAT Gateway], [Route Table], [VPC Peering], [Virtual Private Gateway] 등의 하부 서비스 메뉴가 있습니다.\nVPC 생성 link[VPC] - [VPC Management] [VPC 생성] 버튼을 클릭합니다.\nVPC 생성 화면에서 [VPC 이름]과 [IP 주소 범위]를 입력합니다. VPC의 IP 주소 범위는, private 대역(10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n예시: 10.0.0.0/16, 172.16.0.0/16, 192.168.0.0/16 Subnet 생성 link[VPC] - [Subnet Management]에서 [Subnet 생성] 버튼을 클릭합니다.\n[Subnet 이름]을 적절하게 입력하고, 위에서 생성했던 [VPC]를 선택하고, Subnet에서 사용할 [IP 주소 범위]를 입력합니다. [Internet Gateway 전용여부]는 외부와 인터넷 연결이 필요할 경우에는 [Public], 내부 서버끼리만 통신할 경우에는 [Private]을 선택합니다. [용도]는 일반 서버일 경우에는 [일반]을 선택하면 됩니다. Subnet의 IP 주소 범위는, private 대역(10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n예시: 10.0.1.0/24, 172.16.10.0/24, 192.168.101.0/24 서버 생성 link[VPC]와 [Subnet] 설정을 마쳤으니 이제 서버(Server)를 설정해보겠습니다.\nServer 서비스 위치 link[Server] 서비스는 [Console] - [Services] - [Compute]에 위치해 있습니다.\n[Server] - [Server]에서 [서버 생성] 버튼을 클릭합니다. 서버 생성 콘솔 선택 linkNcloud 서버 생성 콘솔화면은 신규 기능이 업데이트 되면서 2가지를 선택할 수 있습니다. 여기서는 [신규 콘솔 화면]으로 진행하겠습니다.\n기존 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)를 생성할 수 있습니다. 신규 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)뿐만 아니라 KVM 기반 및 다양한 성능을 제공하는 기본 스토리지로 서버(g3)를 생성할 수 있습니다. 서버 이미지 선택 link[서버 이미지 선택] 단계에서는 Ncloud에서 제공하는 다양한 서버 이미지를 선택할 수 있고, [최신 서버 이미지]와 [내 서버 이미지]를 따로 볼 수 있는 기능도 제공하고 있습니다. 여기서는 [최신 서버 이미지]에서 제공하는 서버 이미지로 서버를 생성해보겠습니다.\n또한 하이퍼바이저 기준으로 [XEN]과 [KVM] 2가지 타입이 제공되는데 여기서는 [XEN] 타입의 서버로 테스트 해보겠습니다. [XEN]과 [KVM]에 대한 설명은 아래쪽에서 별도로 살펴보겠습니다. (XEN 과 KVM 비교)\n최신 서버 이미지\rNCP 서버 이미지\r서버 설정 (전체 화면) link서버 설정 단계에서는 위에서 생성한 [VPC]와 [Subnet]을 선택하고 [서버 스펙]과 [요금제], [Network Interface], [공인 IP 할당 여부] 등을 선택하게 됩니다. 각 항목별 상세한 설명은 아래쪽에서 다시 정리해보겠습니다.\n서버 설정 (상세 설명) link그러면 이제부터 서버 설정 항목별로 상세하게 살펴보겠습니다.\n[VPC], [Subnet] 선택\n위에서 생성했던 [VPC]와 [Subnet] 선택합니다. [서버 스펙]\n[서버 스펙]은 [High-CPU], [CPU-Intensive], [Standard], [High-Memory] 등의 타입 중에서 원하는 타입을 선택하고, 각 타입별로 서비스에 적절한 vCPU와 Memory를 선택하시면 됩니다. [요금제 선택], [서버 개수], [서버 이름]\n요금제는 [월요금제]와 [시간 요금제] 중에서 선택하시고, 한번에 생성할 서버 개수와 서버 이름을 입력합니다. [Network Interface] 사설 IP 할당\n사설 IP 할당은 자동 할당과 수동 할당 방법 중에서 선택하시면 됩니다. 사설 IP 자동 할당\r사설 IP 수동 할당\r[**Network Interface**]에 할당되는 사설 IP는 아래와 같이 IP 입력 칸에 아무것도 입력하지 않으면 자동할당 됩니다.\rIP 입력 칸에 선택된 [**Subnet**] 범위 내의 원하는 IP를 입력해서 수동으로 할당할 수도 있습니다.\r[공인 IP 할당]\nPublic Subnet을 선택했고 서버에 공인 IP가 필요할 경우에는 [새로운 공인 IP 할당]을 선택하시면 됩니다. ⁃ 공인 IP는 요금이 과금되므로, 사용하지 않을 때는 반납하기를 권장합니다. (월 이용료: 4,032원 ) ⁃ 서버 생성시 공인 IP를 함께 생성하려면 Subnet 타입은 Public Subnet, 서버 개수는 1개여야 합니다.\r[물리 배치 그룹] 설정 물리 배치 그룹 설정은 서버들을 하나의 그룹으로 묶어서 해당 그룹에 속한 서버들을 클러스터에 배치할 때 어떻게 할 것인지 결정할 수 있습니다. [물리 배치 그룹]을 사용하게 되면 배치 그룹명과 배치 종류를 선택할 수 있습니다. {% include callout-v2.html type=“info” level=“1” content=\"[Anti-Affinity (분산 배치)]의 경우 같은 배치 그룹에 소속된 서버들은 가급적 서로 다른 클러스터에 배치됩니다. 다만 그 결과가 엄격히 보장되지 않는 Best effort 방식입니다.\" %}\n[반납 보호]\n반납 보호를 설정하면 실수로 서버를 반납하여, 서버가 삭제되는 사고를 방지할 수 있습니다. [Script 선택]\n서버가 켜질 때 자동으로 실행되어야 하는 스크립트가 있다면 [Server] - [Init Script] 메뉴에서 미리 Script를 등록한 후에 적용할 수 있습니다. 스토리지 설정 link하이퍼바이저 [XEN] 타입의 서버는 서버 생성이 완료된 이후에 추가 스토리지를 설정할 수 있으므로 이번 단계는 그냥 넘어가겠습니다.\n인증키 설정 link인증키 이름을 입력하고, [인증키 생성 및 저장] 버튼을 클릭해서 인증키를 로컬 PC에 다운로드 받아서 안전한 곳에 보관해야 합니다. 기존에 사용하고 있던 인증키가 있을 경우에는 [보유하고 있는 인증키 이용]을 선택하면 됩니다.\n{% include warning.html title=“인증키” content=“인증키는 해당 서버의 관리자 비밀번호를 확인하는데 사용되므로 안전한 곳에 잘 보관해야 합니다.” %}\n아래와 같이 로컬 PC에 인증키 (PEM) 파일을 저장합니다. 네트워크 접근 설정 link네트워크 접근은 [ACG]로 설정하게 되는데, ACG(Access Control Group)는 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스로, 서버에 별도의 복잡한 방화벽 구축없이 간단하게 서버에 대한 네트워크 접근 제어를 할 수 있습니다.\n[VPC]를 생성하면 자동으로 생성되는 기본 ACG를 선택하거나 별도로 생성한 ACG가 있을 경우 해당 ACG를 선택하면 됩니다. 적용할 ACG는 최대 3개까지 선택할 수 있습니다.\n서버 생성 완료 link모든 단계를 마치고 나면 아래와 같이 서버가 생성된 것을 확인할 수 있습니다.\n서버 접속 link이제 생성된 서버에 관리자(root) 계정으로 접속해보겠습니다.\n방화벽 (ACG) 설정 link우선 서버 접속을 위한 방화벽 (ACG)을 설정하겠습니다.\n테스트로 생성했던 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다. ACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다. [Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다. ACG 규칙 설정 화면 [Inbound] 탭에서 [myIp] 버튼을 클릭해서 현재 접속한 PC나 회사 IP를 입력하고, 허용 포트에는 SSH 접속을 위한 22포트를 추가합니다. 관리자 비밀번호 확인 link다음으로, 서버 접속에 필요한 관리자 비밀번호를 확인하려면, 서버를 선택하고 [서버 관리 및 설정 변경] 메뉴에서 [관리자 비밀번호 확인] 메뉴를 선택합니다.\n메뉴를 선택하면 다음과 같은 [관리자 비밀번호 확인] 팝업이 나타납니다. 팝업에서 [마우스로 파일을 끌고 오거나 여기를 클릭하세요] 부분을 클릭하면 파일 선택 창이 나타나는데, 위에서 저장했던 pem 인증키 파일을 선택합니다. 인증키 파일이 선택된 상태에서 아래쪽에 있는 [비밀번호 확인] 버튼을 클릭합니다. 그러면 아래와 같이 관리자 계정(root)에 대한 비밀번호를 확인할 수 있습니다. 아래쪽에서 서버에 접속할때 사용하기 위해 비밀번호를 복사합니다. 서버 IP 주소 확인 link다음으로 서버 정보 화면에서 서버의 [공인 IP 주소]를 확인하고, 복사합니다. (SSL VPN 등을 사용하는 경우에는 사설 IP 주소를 사용하면 됩니다.)\n서버 접속 link대표적인 서버 접속 클라이언트인 Putty를 실행하고, 서버의 IP주소를 입력합니다.\n처음 연결하는 서버의 경우 아래와 같이 SSH 프로토콜에서 필요한 FingerPrint를 저장할 것인지 묻는데, [Accept] (또는 예)를 클릭합니다. 마지막으로 관리자 계정인 [root]와 위에서 확인했던 [관리자 비밀번호]를 입력하면 서버에 접속됩니다. XEN vs KVM linkNcloud (네이버 클라우드)에서 제공하는 하이퍼바이저의 종류는 XEN, KVM이 있으며, 각각의 특징은 다음과 같습니다.\n하이퍼바이저\r서버 세대\r서버 타입\r서버 이미지\r스토리지 타입\rXEN\rg1, g2\rMicro, Standard, CPU-Intensive, High-CPU, High-Memory\rHDD, SDD\rKVM\rg3\rMicro, Standard, High-CPU, High-Memory\rKVM 기반 서버 이미지\rFB1, CB1\r스토리지 특징 link\r하이퍼바이저 스토리지 타입\r미디어 타입\r최소 크기\r최대 크기\r추가 가능 개수\rXEN\rHDD\rHDD\r10GB\r2TB\r15개\rSSD\rSSD\r10GB\r2TB\r15개\rKVM\rFB1\rHDD\r100GB\r16TB\r20개\rCB1\rSSD\r10GB\r16TB\r20개\r참고 URL link Ncloud VPC 서버 생성 가이드\nhttps://guide.ncloud-docs.com/docs/server-create-new-vpc\nNcloud 하이퍼바이저 개요\nhttps://guide.ncloud-docs.com/docs/hypervisor-info\n문서 업데이트 내역 link\r날짜 내용 2023-07-28 관리자 비밀번호 확인 후 서버 접속 방법 추가 2023-12-04 KVM 서버 정식 업데이트 반영, 스크린샷 업데이트 "
            }
        );
    index.add(
            {
                id:  71 ,
                href: "\/docs\/compute\/vpc\/micro-type-server-create\/",
                title: "Ncloud VPC 환경에서 무료 서버(Micro Type) 이용하는 방법",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 서버를 생성하는 방법을 간단하게 정리했습니다",
                content: "개요 linkNcloud (네이버 클라우드)는 체험 및 테스트 용도로 최초 결제 수단 등록 월부터 1년간 무료로 사용할 수 있는 Micro 타입 서버를 제공하고 있습니다. 전에는 Classic 환경에서만 이용할 수 있었는데, 최근 업데이트 이후 VPC 환경에서도 이용할 수 있게 되었기에, VPC 환경에서 무료 서버인 Micro 타입 서버를 생성하는 과정을 정리해보겠습니다.\nMicro 타입 서버 특징 link 스펙: vCPU 1개, 메모리 1GB 계정당 1대만 이용 가능 체험용으로 가용성 및 성능 보장 불가 거주지 국가가 한국인 경우만 제공 신규 가입 후 최초 결제 수단 등록 월부터 1년간 무료 제공, 1년이 지나면 월요금제로 과금 최초 결제 수단 등록 월은 포털 마이페이지 \u003e 결제수단 관리에서 확인 Network Interface는 1개만 이용 가능 3세대(g3) 서버로 KVM 하이퍼바이저 기반의 서버만 제공 기본 스토리지는 10 GB까지만 무료이며, 용량을 늘리거나 추가하는 스토리지의 경우 유료 과금 서버 생성 link[VPC] 환경에서 서버(Server)를 생성하려면 사전에 [VPC]와 [Subnet]이 생성되어 있어야 하는데, 혹시 처음 [VPC] 환경에 접속하셔서 [VPC]와 [Subnet]이 존재하지 않는 경우는 아래 문서를 보고 미리 생성하고 오셔야 합니다.\n⁃ VPC 환경에서 서버 생성하는 방법 (VPC, Subnet 생성 포함)\rServer 서비스 위치 link[Server] 서비스는 [Console] - [Services] - [Compute]에 위치해 있습니다.\n[Server] - [Server]에서 [서버 생성] 버튼을 클릭합니다. 서버 생성 콘솔 선택 linkNcloud 서버 생성 콘솔화면은 신규 기능이 업데이트 되면서 2가지를 선택할 수 있습니다. Micro 타입 서버는 KVM 하이퍼바이저 기반의 서버이므로 [신규 콘솔 화면]으로 진행하겠습니다.\n기존 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)를 생성할 수 있습니다. 신규 콘솔 화면: XEN, RHV 하이퍼바이저 기반의 서버(g1,g2)뿐만 아니라 KVM 기반 및 다양한 성능을 제공하는 기본 스토리지로 서버(g3)를 생성할 수 있습니다. 서버 이미지 선택 linkMicro 타입 서버를 생성하려면 하이퍼바이저 기준으로 [KVM] 서버 이미지를 선택하면 됩니다. 현재 Ncloud에서 제공되는 [KVM] 서버 이미지는 아래와 같이 [Rocky Linux 8.8], [Ubuntu 20.04], [CentOS 7.8] 이렇게 3가지 입니다. 여기서는 Ubuntu 20.04로 생성해보겠습니다.\n서버 설정 link서버 설정 단계에서는 [VPC]와 [Subnet]을 선택하고 [서버 스펙]과 [요금제], [Network Interface], [공인 IP 할당 여부] 등을 선택하게 됩니다.\n서버는 1년간 무료이지만, 공인 IP를 할당하게 되면 공인 IP 비용이 청구됩니다.\n스토리지 설정 linkKVM 하이퍼바이저 기반인 Micro 타입서버는 기본 스토리지 10GB까지만 무료로 제공되며, 용량을 늘릴 경우 비용이 발생합니다.\n인증키 설정 link인증키 이름을 입력하고, [인증키 생성 및 저장] 버튼을 클릭해서 인증키를 로컬 PC에 다운로드 받아서 안전한 곳에 보관해야 합니다. 기존에 사용하고 있던 인증키가 있을 경우에는 [보유하고 있는 인증키 이용]을 선택하면 됩니다.\nreport\r인증키: 인증키는 해당 서버의 관리자 비밀번호를 확인하는데 사용되므로 안전한 곳에 잘 보관해야 합니다.\n네트워크 접근 설정 link네트워크 접근은 [ACG]로 설정하게 되는데, ACG(Access Control Group)는 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스로, 서버에 별도의 복잡한 방화벽 구축없이 간단하게 서버에 대한 네트워크 접근 제어를 할 수 있습니다.\n[VPC]를 생성하면 자동으로 생성되는 기본 ACG를 선택하거나 별도로 생성한 ACG가 있을 경우 해당 ACG를 선택하면 됩니다. 적용할 ACG는 최대 3개까지 선택할 수 있습니다.\n서버 생성 완료 link모든 단계를 마치고 나면 아래와 같이 서버가 생성된 것을 확인할 수 있습니다.\n서버 접속 link생성된 서버에 접속해서 vCPU와 Memory 상태를 확인해보면 다음과 같습니다.\n~# grep -c processor /proc/cpuinfo\r~# free\r참고 URL link Ncloud 서버 접속 가이드\nhttps://guide.ncloud-docs.com/docs/server-access-vpc\nNcloud 서버 인증키 변경하는 방법\nhttps://docs.3rdeyesys.com/compute/ncloud-compute-server-change-authentication-key.html\n문서 업데이트 내역 link\r날짜 내용 2023-06-21 문서 최초 생성 2023-09-11 지원하는 서버 이미지 추가 내용 업데이트 "
            }
        );
    index.add(
            {
                id:  72 ,
                href: "\/docs\/compute\/classic\/server-access-linux\/no-public-ip\/",
                title: "Classic 환경 서버 접속 가이드(Linux) - 공인IP 없을 때",
                description: "Ncloud (네이버 클라우드) Classic 환경에서 공인IP 없이 Ncloud 서버(Linux)에 접속하는 방법입니다",
                content: "개요 link네이버 클라우드 Classic 환경에서 리눅스 서버에 접속하는 방법 중에서 공인아이피가 없을 때 접속하는 방법에 대한 내용을 정리하였습니다. 여기서는 서버에 접속하는 방법을 정리하기 때문에 이미 서버는 생성되어 있다는 전제하게 정리하게 됩니다.\n또한, Classic 과 VPC 환경 중에서 VPC는 포트 포워딩이 없고 공인 IP로만 접속하기 때문에 아래에서 설명하는 내용은 Classic 환경 기준입니다.\n추가로 SSL VPN으로 접속할 경우는 Classic, VPC 모두 사설 IP로 접속하게 되는데 이 내용은 아래 쪽에 별도로 정리한 문서 링크를 참고하시면 됩니다.\r요약 link우선은 전체 과정을 텍스트로 간단하게 요약해서 살펴보고 스크린샷을 포함한 상세 과정은 아래쪽에서 살펴보겠습니다.\n포트 포워딩 설정 관리자(root) 비밀번호 확인 터미널 프로그램(Putty) 실행 위 1번 포트 포워딩에서 설정한 포트와 IP로 접속 위 2번 관리자 비밀번호 확인에서 기록한 비번 입력 추가사항: SSL VPN으로 접속하는 방법 포트 포워딩 설정 link네이버 클라우드에서 공인IP 없이 서버에 접속하려면 외부 접속을 위한 포트 포워딩을 설정해야 합니다.\n생성된 서버를 선택하면 상단 메뉴에 포트 포워딩 설정이 있습니다.\n포트 포워딩 메뉴에 들어가면 아래와 같이 서버 접속용 공인 IP가 보이고, 외부에서 접속할 포트 (Putty에 입력할 포트)를 입력하는 곳이 있습니다.\n포트 포워딩에서 사용할 수 있는 포트 번호 범위는 1,024 ~ 65,534 이며, 이 범위 내에서 원하는 포트를 입력하시면 됩니다.\n(Tip: 서버 접속용 공인IP를 활용해서 포트 번호를 입력하면 기억하기 쉽습니다. )\n(예: OOO.12.45.178 인 경우 포트를 17822, 106.10.OO.OO 인 경우 10622 )\n포트를 입력하고 +추가 버튼을 클릭합니다.\n추가된 포트와 서버 접속용 공인 IP 정보를 확인하고 수정할 부분이 있으면 수정합니다. 더 이상 수정할 내용이 없으면 하단의 적용 버튼을 반드시 클릭합니다.\n관리자 비밀번호 확인 link네이버 클라우드에서 처음 서버를 생성하고 접속하게 되면 root와 비밀번호로 접속하게 됩니다. 물론 매번 비번을 입력하고 접속하는 것은 번거롭기도 하고 보안 측면에서 좋지 않기 때문에 이후에 SSH Key를 생성해서 접속하는 방식으로 바꾸는 것이 좋습니다.\n관리자 비밀번호 확인 메뉴를 클릭하면 인증키를 확인하는 화면이 나옵니다. 인증키는 서버 생성시에 설정하고 PC에 다운로드 해 둔 확장지 *.pem 파일입니다.\n인증키 파일을 마우스로 끌어오거나 화면을 클릭해서 선택합니다.\n인증키가 일치하면 아래와 같이 root 계정에 해당하는 비밀번호가 나타납니다. 이 비밀번호를 복사하여 저장해둡니다. 혹시 복사-저장하는 것을 잊으셨어도 언제든지 관리자 비밀번호 확인 메뉴에 들어가서 인증키를 인증하면 다시 확인할 수 있으니 걱정하지 않으셔도 됩니다.\n터미널 프로그램(Putty) 실행 linkPutty를 실행해서 포트 포워딩에서 설정한 포트와 서버 접속용 공인IP를 입력합니다.\n접속을 하면 rsa2 key fingerprint 를 Putty 캐시에 저장할 것인지 묻는 화면이 나타납니다. 보통 예(Y)를 선택하면 됩니다.\nroot 계정과 관리자 비밀번호 입력 link계정 root와 관리자 비밀번호 확인에서 저장해 둔 비밀번호를 입력합니다.\n접속이 완료되면 이렇게 화면이 나타납니다.\nSSL VPN으로 접속하기 linkSSL VPN은 Ncloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스입니다. 즉, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법이므로 Classic, VPC 환경 모두 공인 IP가 아닌 사설 IP로 연결하게 됩니다. 자세한 SSL VPN 생성 방법과 서버 접속 방법은 아래 링크된 문서를 참고 하시기 바랍니다.\n⁃ Classic 환경에서 SSL VPN 설정하고 접속하는 방법\n⁃ VPC 환경에서 SSL VPN 설정하고 접속하는 방법\r참고 URL link Ncloud Classic 환경 서버 관리 - 포트 포워딩\nhttps://guide.ncloud-docs.com/docs/server-manage-classic#포트포워딩설정 문서 업데이트 내역 link\r날짜 내용 2020-12-21 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  73 ,
                href: "\/docs\/compute\/classic\/server-access-linux\/by-public-ip\/",
                title: "Classic 환경 서버 접속 가이드(Linux) - 공인IP 있을 때",
                description: "Ncloud (네이버 클라우드) Classic 환경에서 공인IP를 사용해 Ncloud 서버(Linux)에 접속하는 방법입니다",
                content: "개요 link네이버 클라우드 Classic 환경에서 리눅스 서버에 접속하는 방법 중에서 공인아이피가 있을 때 접속하는 방법에 대한 내용을 정리하였습니다. 여기서는 서버에 접속하는 방법을 정리하기 때문에 이미 서버는 생성되어 있다는 전제하게 정리하게 됩니다.\n요약 link우선은 전체 과정을 텍스트로 간단하게 요약해서 살펴보고 스크린샷을 포함한 상세 과정은 아래쪽에서 살펴보겠습니다.\n포트 포워딩 설정 해제 (설정되어 있을 경우) 관리자(root) 비밀번호 확인 터미널 프로그램(Putty) 실행 공인IP로 접속 위 2번 관리자 비밀번호 확인에서 기록한 비번 입력 포트 포워딩 설정 해제 (설정되어 있을 경우) link네이버 클라우드에서는 Server, Bare Metal Server에서 공인 IP와 포트 포워딩을 동시에 사용하면 22(Linux), 3389(Windows) 포트가 포트 포워딩에 먼저 할당되므로 공인 IP에서 해당 포트 사용이 불가해집니다.\n즉, 포트 포워딩이 설정된 상태에서는 서버에 접속할 때 공인IP로는 22, 3389 포트가 접속 되지 않는다는 뜻입니다.\r그러므로, 공인 IP로 22, 3389 포트에 접속하려는 경우에는 포트 포워딩을 해제하시고,\n포트 포워딩을 설정하지 않았다면 다음 순서인 관리자(root) 비밀번호 확인으로 바로 이동하시면 되겠습니다.\n포트 포워딩을 해제 하시려면 아래 화면처럼 설정된 포트 포워딩에서 삭제 버튼을 클릭하시고 하단의 적용 버튼을 클릭합니다.\n관리자 비밀번호 확인 link네이버 클라우드에서 처음 서버를 생성하고 접속하게 되면 root와 비밀번호로 접속하게 됩니다. 물론 매번 비번을 입력하고 접속하는 것은 번거롭기도 하고 보안 측면에서 좋지 않기 때문에 이후에 SSH Key를 생성해서 접속하는 방식으로 바꾸는 것이 좋습니다.\n관리자 비밀번호 확인 메뉴를 클릭하면 인증키를 확인하는 화면이 나옵니다. 인증키는 서버 생성시에 설정하고 PC에 다운로드 해 둔 확장지 *.pem 파일입니다.\n인증키 파일을 마우스로 끌어오거나 화면을 클릭해서 선택합니다.\n인증키가 일치하면 아래와 같이 root 계정에 해당하는 비밀번호가 나타납니다. 이 비밀번호를 복사하여 저장해둡니다. 혹시 복사-저장하는 것을 잊으셨어도 언제든지 관리자 비밀번호 확인 메뉴에 들어가서 인증키를 인증하면 다시 확인할 수 있으니 걱정하지 않으셔도 됩니다.\n터미널 프로그램(Putty) 실행 linkPutty를 실행해서 공인IP를 입력합니다.\n접속을 하면 rsa2 key fingerprint 를 Putty 캐시에 저장할 것인지 묻는 화면이 나타납니다. 보통 예(Y)를 선택하면 됩니다.\nroot 계정과 관리자 비밀번호 입력 link계정 root와 관리자 비밀번호 확인에서 저장해 둔 비밀번호를 입력합니다.\n접속이 완료되면 이렇게 화면이 나타납니다.\n참고 URL link Ncloud Classic 환경 서버 Public IP\nhttps://guide.ncloud-docs.com/docs/server-publicip-classic 문서 업데이트 내역 link\r날짜 내용 2020-12-22 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  74 ,
                href: "\/docs\/compute\/classic\/server-image-share\/",
                title: "Classic 환경에서 서버 이미지를 다른 계정에 공유하는 방법",
                description: "Ncloud (네이버 클라우드) Classic 환경에서 서버 이미지를 다른 계정에 공유하는 방법입니다",
                content: "개요 link네이버 클라우드 Classic 환경에서 내 서버 이미지를 다른 계정에 공유하는 방법입니다.\nLinux와 Windows OS별 차이는 없으며, 일단은 서버 이미지가 생성되어 있는 것을 가정해서 내용을 정리해보겠습니다.\n공유 권한 설정 link네이버 클라우드 콘솔 [Server] - [Server Image]에서 공유할 서버 이미지를 선택하고 상단 메뉴에 있는 [공유 권한 설정]을 클릭합니다.\n다음으로 서버 이미지를 공유할 계정 즉, 로그인 ID를 입력합니다.\n로그인 ID 입력 후 [권한 추가] 버튼을 클릭하고, [적용] 버튼을 클릭해 설정을 적용합니다.\n공유 권한 설정을 적용하면 서버 이미지 정보에 [공유 중]이라고 표시되고, [공유 받은 계정] 정보도 확인할 수 있습니다.\nLinux (CentOS, Ubuntu) link\rWindows link\r공유 상태 확인 link이제 공유 받은 계정으로 접속해보면 [Server Image]에 추가된 서버 이미지가 보이고, [공유 받음] 표시를 확인할 수 있습니다.\nLinux (CentOS, Ubuntu) link\rWindows link\r다음으로 공유 받은 서버 이미지를 선택하고, [서버 생성] 버튼을 클릭합니다.\n서버 생성 정보 입력 화면이 나타나면서 문제 없이 서버를 생성할 수 있다는 것을 알 수 있습니다.\n공유 권한 삭제 link이제 공유된 권한을 삭제해보겠습니다.\n처음 서버 이미지를 공유할 때 처럼 서버 이미지를 선택하고, [공유 권한 설정]을 클릭하고, [공유 받은 계정]을 삭제합니다.\n공유된 계정을 삭제하고, [적용] 버튼을 클릭해 변경될 설정을 적용합니다.\n아까 공유 받았던 계정으로 접속해 [Server Image]에 들어가보면 공유되었던 서버 이미지가 삭제된 것을 확인할 수 있습니다.\n참고 URL link Ncloud Classic 환경 내 서버 이미지 공유\nhttps://guide.ncloud-docs.com/docs/server-serverimage-classic#내-서버-이미지-공유 문서 업데이트 내역 link\r날짜 내용 2021-05-31 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  75 ,
                href: "\/docs\/compute\/classic\/micro-type-server-limit\/",
                title: "Classic 환경 Micro 타입 서버에서 사용할 수 없는 서비스",
                description: "Ncloud (네이버 클라우드) Classic 환경 Micro 타입 서버에서 사용할 수 없는 서비스에 대한 정보입니다",
                content: "개요 linkNcloud (네이버 클라우드) Classic 환경에서 제공하는 서버 타입 중에서 Micro 타입의 서버는 신규 가입 후 최초 결제수단 등록월부터 1년간 무료로 제공되는 체험용 서버입니다. 계정당 1대만 이용 가능하며 1년이 지나면 유료로 전환됩니다.\n제한되는 서비스 linkClassic 환경 Micro 타입의 서버에서 사용할 수 없는 서비스는 다음과 같습니다.\nmssql LAMP, WordPress, LEMP 등 Network Interface Private Subnet MSSQL linkmssql 중에서 mssql 2017 Express은 무료로 제공되는 서비스이지만, mssql이 1년 무료제공 서버인 Micro서버에서는 설치가 되지 않기 때문에, compact 이상의 유료 서버를 이용해야 합니다. 즉, mssql 2017 Express는 무료이나 서버와 그에 따른 하드 디스크 비용은 유료입니다.\nLAMP linkLAMP (Linux + Apache, Mysql, PHP)의 경우 Micro 타입의 서버에 설치를 할 수 없고, Standard 이상의 서버에서만 설치할 수 있는데, 대신 네이버 클라우드에서는 LAMP 등 많이 사용되는 오픈 소스 소프트웨어가 설치된 서버를 쉽게 이용할 수 있도록 해주는 서비스인 Application Server Launcher를 제공하고 있습니다.\nApplication Server Launcher에서는 원하는 소프트웨어의 이미지를 선택하기만 하면 쉽게 Micro 타입의 서버를 세팅하고 이용할 수 있습니다.\n다만, Application Server Launcher에서 생성한 서버도 Micro 타입의 서버이기 때문에 계정당 1개만 제공되는 Micro 타입 서버 기준에 따라 Micro 타입의 서버는 더 이상 추가할 수 없습니다.\rApplication Server Launcher에서 OS버전(CentOS, Ubuntu)별로 제공되는 애플리케이션은 다음과 같습니다.\nDrupal (CMS) Joomla! (CMS) Magento (E-Commerce) Shadowsocks (VPN) LAMP (Web Stack) WordPress (CMS) Jenkins (Dev Tools) Private Subnet linkPrivate Subnet을 구성해서 서버환경을 만들려고 해도 Micro 서버 타입은 Network Interface를 추가할 수 없고, 그에 따라 Private Subnet도 적용할 수 없습니다.\n참고 URL link Ncloud Classic 환경 내 서버 이미지 공유\nhttps://guide.ncloud-docs.com/docs/server-spec "
            }
        );
    index.add(
            {
                id:  76 ,
                href: "\/docs\/compute\/rocky-linux\/basic-guide\/",
                title: "Ncloud에서 제공하는 록키 리눅스(Rocky Linux) 서버 소개",
                description: "Ncloud(네이버 클라우드)에서 제공하기 시작한 록키 리눅스 (Rocky Linux) 서버를 간단하게 소개합니다",
                content: "개요 linkRocky Linux (록키 리눅스)는 CentOS의 서비스 지원 종료로 대안으로 떠오른 CentOS 기반의 리눅스 OS입니다.\nNcloud (네이버 클라우드)는 이 록키 리눅스의 핵심 파트너로 선정되어 국내에서 록키 리눅스 인프라와 기술지원을 위해 협력해왔고, 드디어 Ncloud 콘솔에서 록키 리눅스를 제공하기 시작했기에 간단하게 소개해보려고 합니다.\n제공 버전 linkNcloud에서는 현재 Rocky Linux 8.6 버전을 VPC 환경에서 제공하고 있습니다.\n설치할 소프트웨어 link록키 리눅스 서버를 실행하고 보통 자주 사용하게 되는 아래의 소프트웨어들을 설치하고 확인해보겠습니다.\nApache PHP NGINX MariaDB (MySQL) 접속 화면 link서버를 생성하고 접속하면 아래와 같이 Ncloud 로고가 크게 표시된 화면을 볼 수 있습니다.\n패키지 업데이트 link우선 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 해보겠습니다.\n~# dnf -y upgrade-minimal\rinfo\rDandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 Fedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\nApache, PHP 설치 link설치할 소프트웨어 중에서 Apache와 PHP를 동시에 설치해보겠습니다.\n~# dnf -y install httpd php\r설치된 버전은 다음과 같습니다.\nApache: 2.4.37 PHP: 7.2.24 접속화면 link설치 완료 후에 웹브라우저로 접속해보면 다음과 같이 Apache 로고가 포함된 화면을 확인할 수 있습니다.\nPHP 버전 리스트 linkNcloud Rocky Linux 8.6에서 지원하는 PHP 버전은 다음과 같이 확인해볼 수 있습니다.\n리스트를 확인해보면 7.2버전이 기본이고, 현재 활성화된 버전도 7.2버전인 것을 알 수 있습니다.\n~# dnf module list php\rPHP 7.2 (default) PHP 7.3 PHP 7.4 PHP 8.0 PHP 버전 변경 link기본으로 설치된 7.2 버전에서 다른 버전으로 변경하는 방법에 대해 알아보겠습니다. 여기서는 8.0으로 변경해보겠습니다.\n버전 활성화 정보 초기화 link우선 위에서 확인했던 php 버전 활성화 정보를 초기화 합니다.\n~# dnf module reset php\rPHP 8.0 활성화 link다음으로 8.0 버전을 활성화 합니다.\n~# dnf module enable php:8.0\rPHP 8.0 설치 link마지막으로 8.0 버전을 설치하고 버전을 확인해봅니다.\n~# dnf -y install php\r~# php -v\rNginX 설치 link다음으로 NginX 최신버전(mainline)으로 설치해보겠습니다.\nNginX 최신버전(mainline)을 설치하기 위해서는 epel-release 리포지토리 패키지가 필요하고, epel-release 리포지토리 패키지를 설치하기 위해서는 Extras 저장소 설정 파일이 필요합니다.\n리포지토리 설정 파일 추가 link우선, Extras 저장소 설정 파일 준비합니다. 이미 생성되어 있는 경우에는 다음 단계로 넘어가도 되고, 그렇지 않을 경우 아래와 같은 내용으로 파일을 생성합니다.\n~# vi /etc/yum.repos.d/Rocky-Extras.repo\r# Rocky-Extras.repo\r[extras]\rname=Rocky Linux $releasever - Extras\r#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch\u0026repo=extras-$releasever\rbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\rgpgcheck=1\renabled=1\rcountme=1\rgpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\rEPEL 리포지토리 패키지 설치 link다음으로, NginX 최신 버전을 설치하기 위해 epel-release 리포지토리 패키지를 설치하겠습니다.\n~# dnf -y install epel-release\rNginX 버전 리스트 link위 준비사항이 모두 완료되었으면, Ncloud Rocky Linux 8.6에서 지원하는 NginX 버전을 확인합니다.\n리스트를 살펴보면 1.14가 기본 버전이고, 현재 활성화된 버전도 1.14인 것을 알 수 있습니다.\n~# dnf module list nginx\rnginx 1.14 (default) nginx 1.16 nginx 1.18 nginx 1.20 nginx mainline 버전 활성화 정보 초기화 link우선 위에서 확인했던 nginx 버전 활성화 정보를 초기화 합니다.\n혹시 활성화된 버전이 없을 경우에는 별다른 변화 없이 과정이 완료됩니다.\n~# dnf module reset nginx\rmainline 버전 활성화 link최신 버전인 mainline 버전을 활성화합니다.\n~# dnf module enable nginx:mainline\r설치 linkNginX 설치합니다. 설치된 버전은 다음과 같습니다.\n~# dnf -y install nginx\r~# nginx -v\rNGINX: 1.23.1 접속화면 link설치 완료 후에 nginx를 실행 시키고, 웹브라우저로 접속해보면 다음과 같이 NGINX 로고가 포함된 화면을 확인할 수 있습니다.\n~# systemctl enable nginx\r~# systemctl start nginx\rMariaDB (MySQL) 설치 linkMariaDB 버전 리스트 link우선, Ncloud Rocky Linux 8.6에서 지원하는 MariaDB 버전을 확인합니다.\n리스트를 살펴보면 10.3이 기본 버전인 것을 알 수 있습니다.\n~# dnf module list mariadb\rmariadb 10.3 (default) mariadb 10.5 설치 linkRocky Linux에서는 기본 DB가 MariaDB이고, 설치할 때도 [mariadb-server]로 설치하게 됩니다.\n여기서는 기본 버전으로 설치하겠습니다.\n~# dnf -y install mariadb-server\rMariaDB 데몬을 시작합니다.\n그런데 자세히 보시면 생성된 symlink가 [mysql.service]인 것을 확인할 수 있습니다. 즉, MariaDB를 실행할 때는 [mysql] 명령을 입력하면 된다는 뜻입니다.\n~# systemctl enable mariadb\r~# systemctl start mariadb\rDB 접속 link[mysql] 명령을 입력하면 아래와 같이 MariaDB 서버에 접속됩니다.\n설치된 DB 서버 버전은 다음과 같습니다.\nMariaDB: 10.3.32 ~# mysql\r웹 콘솔 linkRocky Linux는 웹브라우저에서 서버에 접속해서 서버를 관리할 수 있는 웹 콘솔을 제공하는데, 처음 서버에 접속했던 콘솔화면을 보면 아래와 같이 웹 콘솔을 활성화하는 방법이 안내되어 있습니다.\n아래 명령어를 입력하면 [9090] 포트로 접속할 수 있는 웹 콘솔이 활성화됩니다.\n~# systemctl enable --now cockpit.socket\r웹 콘솔 접속 link먼저, ACG에서 [9090] 포트를 오픈하고, [https://{서버 IP}:9090]으로 접속하면 아래와 같은 화면을 볼 수 있습니다.\n웹 콘솔 화면 link웹 콘솔에 접속하면 서버 상태와 시스템 정보, CPU-메모리 사용량 등을 확인할 수 있고, 그 외에도 여러 가지 기능을 확인할 수 있습니다.\n버전 활성화 오류 해결 방법 link[dnf module enable ] 명령으로 다른 버전을 활성화하려고 할 때 아래와 같은 오류가 발생하는 경우가 있습니다.\n오류 메시지 하단에 보면 [dnf module reset ] 명령을 입력하면 해결된다 합니다.\nreport\rError: It is not possible to switch enabled streams of a module unless explicitly enabled via configuration option module_stream_switch. It is recommended to rather remove all installed content from the module, and reset the module using ‘dnf module reset ’ command. After you reset the module, you can install the other stream.\n명령을 입력하고 처리가 완료되면 [dnf module enable :] 명령을 다시 입력하면 됩니다.\n#예시\r~# dnf module reset php\r~# dnf module reset nginx\r참고 URL link Rocky Linux 공식 가이드\nhttps://docs.rockylinux.org/guides/\nRocky Linux Apache 설정\nhttps://docs.rockylinux.org/guides/web/apache-sites-enabled/\nRocky Linux NGINX 설정\nhttps://docs.rockylinux.org/guides/web/nginx-multisite/\nRocky Linux MariaDB 설치\nhttps://docs.rockylinux.org/guides/database/database_mariadb-server/\n"
            }
        );
    index.add(
            {
                id:  77 ,
                href: "\/docs\/compute\/rocky-linux\/kvm-hypervisor-repository-mirror-site-error-troubleshooting\/",
                title: "Ncloud KVM Hypervisor 타입의 Rocky Linux 서버 Repository 미러 사이트 오류 문제 해결 방법",
                description: "Ncloud (네이버 클라우드) KVM Hypervisor 타입의 Rocky Linux 서버 리포지토리 미러 사이트 오류 문제 해결 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드)에서 KVM Hypervisor 타입의 록키 리눅스(Rocky Linux) 8.8 서버를 제공하고 있는데, 서버를 생성하고 나서 Apache, PHP 등의 패키지를 설치할 때 패키지 다운로드 사이트 또는 미러 사이트에서 8.8 버전에 대한 패키지 정보를 찾을 수 없다는 메시지가 나타나면서 패키지를 설치할 수 없는 경우가 있습니다.\nXEN Hypervisor 타입의 서버에서는 문제가 없는데 왜 KVM Hypervisor 타입 서버에서만 이런 문제가 생기는지와 어떻게 하면 해결할 수 있는지를 정리해보겠습니다.\n오류 상황 link콘솔에서 서버를 생성한 후에 아무 것도 하지 않고 테스트로 Apache를 설치해보려고 했는데, 오류 메시지가 나타나면서 설치를 할 수 없었습니다. 또한 Extras 리포지토리 미러 사이트도 Ncloud 내부 서버가 아닌 록키 리눅스 공식 미러 사이트로 연결하려고 시도한 것을 확인할 수 있습니다.\n이때, 혹시 외부와 통신이 안되어서 그런 것이 아닐까 오해할 수 있는데, **아래 오류 메시지를 보면 미러 사이트에 접속할 수 없다는 것이 아니고, 파일을 찾을 수 없다는 404 에러 메시지인 것**을 알 수 있습니다. 즉, 외부 통신은 아무 문제 없다는 것입니다.\n~# dnf -y install httpd\rRocky Linux 8.8 - Extras 501 B/s | 3.3 kB 00:06\rErrors during downloading metadata for repository 'extras':\r- Status code: 404 for https://rocky-linux-asia-east2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 35.241.40.125)\r- Status code: 404 for https://rocky-linux-asia-south2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.149.203.6)\r- Status code: 404 for https://rocky-linux-asia-northeast3.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 35.186.196.188)\r- Status code: 404 for https://rocky-linux-asia-northeast1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.160.117.186)\r- Status code: 404 for https://rocky-linux-me-west1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.149.26.62)\r- Status code: 404 for https://rocky-linux-asia-east1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 35.186.202.231)\r- Status code: 404 for https://rocky-linux-asia-southeast1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.160.39.155)\r- Status code: 404 for https://rocky-linux-asia-southeast2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.111.41.84)\r- Status code: 404 for https://rocky-linux-asia-northeast2.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.107.160.108)\r- Status code: 404 for https://rocky-linux-asia-south1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/extras/x86_64/os/repodata/repomd.xml (IP: 34.120.3.13)\rError: Failed to download metadata for repo 'extras': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\r외부 통신이 되지 않는 경우 link외부 통신이 되지 않는 경우는 아래와 같이 더 이상 진행이 되지 않고 계속 멈춰있는 상태가 되므로 여기서 다뤄보는 문제와는 관계가 없습니다.\n해결 방법-1 link첫번째 방법은 패키지를 설치할 때 미러 사이트 주소에서 404 에러가 발생하는 [Extras] 저장소를 비활성화하는 옵션을 적용하는 방법입니다.\n~# dnf -y install httpd --disablerepo=extras\r해결 방법-2 link두번째 방법은 [Rocky-Extras.repo] 리포지토리 설정파일의 주소를 Ncloud 내부 서버로 변경하는 방법입니다.\n# vim /etc/yum.repos.d/Rocky-Extras.repo\r# Rocky-Extras.repo\r#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch\u0026repo=extras-$releasever\r#baseurl=http://dl.rockylinux.org/$contentdir/$releasever/extras/$basearch/os/\rbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\r주소 변경 후에 아파치를 설치해보면 문제 없이 잘 설치 되는 것을 확인할 수 있습니다. KVM vs XEN link그런데 XEN 하이퍼바이저 타입의 서버에서는 아무 문제 없이 설치가 잘되는데 왜 KVM 하이퍼바이저 타입의 서버에서만 문제가 생기는 것인지 궁금해서 두 타입의 서버의 리포지토리 파일들을 비교해봤습니다.\nKVM 타입 link우선, 문제가 발생한 KVM 하이퍼바이저 타입의 서버에서 리포지토리 파일의 리스트를 확인해봤습니다.\n리스트에는 [AppStream], [BaseOS], [Extras] 리포지토리 파일 뿐만 아니라 다수의 파일이 존재하는 것을 알 수 있습니다.\n~# ls -al /etc/yum.repos.d/\rRocky-AppStream.repo\rRocky-BaseOS.repo\rRocky-Debuginfo.repo\rRocky-Devel.repo\rRocky-Extras.repo\rRocky-HighAvailability.repo\rRocky-Media.repo\rRocky-NFV.repo\rRocky-Plus.repo\rRocky-PowerTools.repo\rRocky-ResilientStorage.repo\rRocky-RT.repo\rRocky-Sources.repo\rXEN 타입 link다음으로, 문제가 없는 XEN 하이퍼바이저 타입의 서버에서 리포지토리 파일의 리스트를 확인해봤습니다.\n그런데, 여기는 [AppStream], [BaseOS] 단 두가지의 리포지토리 파일만 존재하는 것을 알 수 있었습니다.\n~# ls -al /etc/yum.repos.d/\rRocky-AppStream.repo\rRocky-BaseOS.repo\r해결 방법-3 link세번째 해결 방법은 위에서 확인했 듯이 [/etc/yum.repos.d/] 경로에 있는 리포지토리 파일 리스트에서 [AppStream], [BaseOS] 두가지만 남겨두고 나머지 파일들은 다른 곳에 백업하고 나서 지우면 이상 없이 패키지 설치가 가능합니다.\n원인 분석 link원인을 찾기 위해 처음에 문제가 생겼을 때 나타났던 오류 메시지에서 리포지토리 미러사이트 주소를 하나 선택해서 접속해봤습니다.\n접속해봤더니 패키지 관련 디렉토리나 파일들은 존재하지 않고 [README.txt] 안내 파일만 존재하는 것을 알 수 있었습니다.\nhttps://rocky-linux-asia-east1.production.gcp.mirrors.ctrliq.cloud/pub/rocky//8.8/\rREADME.txt link해당 파일을 클릭해서 열어보니 아래와 같이 파일들이 다른 곳으로 옮겨졌으니 그쪽에서 확인해보라는 메시지를 확인할 수 있었습니다.\n즉, Rocky Linux 8.8 버전은 출시된지 오래된 버전이어서 미러링 사이트들에서는 삭제되고, 공식 다운로드 사이트의 별도의 디렉토리로 옮겨진 것으로 판단이됩니다.\nThis content has been moved to the Rocky Linux Vault\rhttps://dl.rockylinux.org/vault/rocky/8.8/\r공식 사이트 link위 파일에서 확인한 공식 사이트로 접속해보니 아래와 같이 패키지 관련 디렉토리가 존재하는 것을 알 수 있었습니다.\nhttps://dl.rockylinux.org/vault/rocky/8.8/\r해결 방법-4 link원인 분석에서 확인했 듯이 공식 사이트의 별도 디렉토리에 패키지 파일들이 존재하므로 [Rocky-Extras.repo] 리포지토리 파일을 아래와 같이 수정하는 방법도 가능합니다.\n# vim /etc/yum.repos.d/Rocky-Extras.repo\r# Rocky-Extras.repo\r#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch\u0026repo=extras-$releasever\r#baseurl=http://dl.rockylinux.org/$contentdir/$releasever/extras/$basearch/os/\r#baseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\rbaseurl=https://dl.rockylinux.org/vault/rocky/$releasever/extras/$basearch/os/\r참고 URL link Rocky Linux 서버 소개\n"
            }
        );
    index.add(
            {
                id:  78 ,
                href: "\/docs\/compute\/rocky-linux\/xen-hypervisor-repository-mirror-site-error-troubleshooting\/",
                title: "Ncloud XEN Hypervisor 타입의 Rocky Linux 8.6 서버 Repository 미러 사이트 오류 문제 해결 방법",
                description: "Ncloud (네이버 클라우드) XEN Hypervisor 타입의 Rocky Linux 서버 리포지토리 미러 사이트 오류 문제 해결 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드)에서 XEN Hypervisor 타입의 록키 리눅스(Rocky Linux) 8.6 서버를 제공하고 있는데, 패키지를 설치할 때 간혹 패키지 다운로드 사이트 또는 미러 사이트에서 8.6 버전에 대한 패키지 정보를 찾을 수 없다는 메시지가 나타나면서 패키지를 설치할 수 없는 경우가 있습니다.\n그렇다면 왜 이런 문제가 생기는지와 어떻게 하면 해결할 수 있는지를 정리해보겠습니다.\n오류 상황 link테스트로 아파치를 설치해보려고 했는데, 오류 메시지가 나타나면서 설치를 할 수 없었습니다. 또한 리포지토리 미러 사이트도 Ncloud 내부 서버가 아닌 록키 리눅스 공식 미러 사이트로 연결하려고 시도한 것을 확인할 수 있습니다.\n~# dnf -y install httpd\rRocky Linux 8.6 - Extras 5.4 kB/s | 20 kB 00:03\rErrors during downloading metadata for repository 'extras':\r- Status code: 404 for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64\u0026repo=extras-8.6 (IP: 151.101.26.132)\r- Status code: 404 for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64\u0026repo=extras-8.6 (IP: 146.75.94.132)\rError: Failed to download metadata for repo 'extras': Cannot prepare internal mirrorlist: Status code: 404 for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64\u0026repo=extras-8.6 (IP: 151.101.26.132)\r미러 사이트 확인 link오류 메시지에 나온 공식 미리 사이트에 접속해보니 [AppStream], [extras] 등 모든 8.6 버전에 대한 정보가 사라진 것을 확인할 수 있었습니다.\n오류 상황 요약 정리 link현재 확인되는 오류 상황을 정리해보면 다음과 같습니다.\n패키지를 검색하는 저장소가 [AppStream] 이나 [BaseOS]가 아닌 [Extras]로 변경되어 있다. 리포지토리 미러 사이트를 Ncloud 내부 서버가 아닌 외부에 있는 록키 리눅스 공식 미러 사이트로 접속시도 하고 있다. 외부에 있는 록키 리눅스 공식 미러 사이트에서는 공식 지원이 종료되는 8.6 버전에 대한 데이터가 이미 삭제되어 있다. 원인 분석 link원인 분석을 하기 위해 서버의 리포지토리 설정을 확인해보겠습니다.\n리포지토리 설정 - 오류 서버 link[/etc/yum.repos.d/] 디렉토리에 있는 리포지토리 설정 파일을 확인해보면 아래와 같이 다수의 파일이 존재하는 것을 확인할 수 있습니다.\n~# ls -al /etc/yum.repos.d/\r위에서 확인한 설정 파일들 중에서 [Rocky-Extras.repo] 파일을 열어서 미러 사이트 주소를 확인해보면, Ncloud 내부 서버가 아닌 아래와 같이 록키 리눅스 공식 사이트로 설정되어 있는 것을 알 수 있습니다. ~# vi /etc/yum.repos.d/Rocky-Extras.repo\r리포지토리 설정 - 정상 서버 link그렇다면 아무 문제 없는 정상적인 서버의 경우는 어떤지 비교해서 살펴보겠습니다.\n마찬가지로 [/etc/yum.repos.d/] 디렉토리에 있는 리포지토리 설정 파일을 확인해보면 오류가 발생한 서버와 달리 아래와 같이 [Rocky-AppStream.repo], [Rocky-BaseOS.repo] 이렇게 2가지 파일만 존재하는 것을 확인할 수 있습니다.\n~# ls -al /etc/yum.repos.d/\r또한 2가지 설정 파일들 중에서 [Rocky-AppStream.repo] 파일을 열어서 미러 사이트 주소를 확인해보면, 록키 리눅스 공식 사이트는 주석 처리가 되어 있고, [baseurl]이 [repo.ncloud.com] 이라는 Ncloud 내부 서버로 설정되어 있는 것을 알 수 있습니다. 원인 추적 link오류가 발생한 서버와 정상적인 서버의 차이점을 비교 추적해보니 오류가 발생한 서버에서는 서버 생성 후에 패키지 업데이트가 진행된 것을 알 수 있었습니다. 서버 생성 후에 설치된 패키지들의 업데이트를 적용하기 위해 [dnf upgrade]를 실행했고, 그에 따라 리포지토리 정보가 변경되었다는 것을 알 수 있었습니다.\n~# dnf -y upgrade\r[dnf upgrade]와 [dnf update]의 차이점에 대해 [man dnf] 명령어로 매뉴얼을 살펴보면 Rocky Linux에서 패키지 업데이트를 위한 기본 명령어는 [dnf upgrade]이며, [dnf update]는 더 이상 사용되지 않는 별칭이라고 합니다.\r~# man dnf\r#--- 중략 ---#\rUpgrade Command\rCommand: upgrade\rAliases: up\rDeprecated aliases: update, upgrade-to, update-to, localupdate\r해결 방법 link이 문제를 해결하는 방법은 몇가지가 있는데 차례대로 정리해보겠습니다.\n방법-1 link첫번째 방법은 [Rocky-Extras.repo] 리포지토리 설정파일의 주소를 Ncloud 내부 서버로 변경하는 방법입니다.\n# Rocky-Extras.repo\r#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch\u0026repo=AppStream-$releasever\rbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\r주소 변경 후에 아파치를 설치해보면 문제 없이 잘 설치 되는 것을 확인할 수 있습니다. 방법-2 link두번째 방법은 패키지를 설치할 때 미러 사이트 주소가 변경된 [Extras] 저장소를 비활성화하는 옵션을 적용하는 방법입니다.\n~# dnf -y install httpd --disablerepo=extras\r사전 예방책 link위 방법들은 패키지 업데이트 후에 문제를 해결하는 방법이므로, 사전에 이런 문제가 생기지 않도록 하는 것도 선택지 중의 하나입니다. 가능한 방법은 다음 2가지 입니다.\n패키지 업데이트를 진행하지 않는 방법 보안-버그 수정 사항만 최소한으로 업데이트 하는 방법 패키지 최소 업데이트 link보안-버그 수정 사항만 최소한으로 업데이트 하는 [upgrade-minimal] 옵션으로 업데이트를 했을 경우에는 아래와 같이 리포지토리 파일에 변화가 없어서 이후 패키지 설치에 오류가 생기지 않습니다.\n~# dnf -y upgrade-minimal\r참고 URL link Rocky Linux 서버 소개\n"
            }
        );
    index.add(
            {
                id:  79 ,
                href: "\/docs\/compute\/rocky-linux\/apache-https-ssl-setting\/",
                title: "Rocky Linux에서 Apache SSL 인증서 설정하는 방법",
                description: "Ncloud (네이버 클라우드) Rocky Linux 서버 Apache에 HTTPS 접속을 위한 SSL 인증서 설정하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) Rocky Linux (록키 리눅스) 서버에 Apache 웹서버를 설치하고, HTTPS 접속을 위한 SSL 인증서 설정하고, HTTP로 접속 시에 HTTPS로 리다이렉트하는 방법까지 정리해보겠습니다.\n테스트 환경 link테스트에 사용할 서버 환경은 다음과 같습니다.\n⁃ OS: Rocky Linux 8.6 ⁃ 웹서버: Apache 2.4 ⁃ 테스트 사이트: rocky-https-test.com\r패키지 업데이트 link우선 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 해보겠습니다.\n~# dnf -y upgrade-minimal\r[dnf upgrade-minimal]과 [dnf update-minimal]의 차이점에 대해 [man dnf] 명령어로 매뉴얼을 살펴보면 Rocky Linux에서 패키지 업데이트를 위한 기본 명령어는 [dnf upgrade-minimal]이며, [dnf update-minimal]는 더 이상 사용되지 않는 별칭이라고 합니다.\r~# man dnf\r#--- 중략 ---#\rUpgrade-Minimal Command\rCommand: upgrade-minimal\rAliases: up-min\rDeprecated aliases: update-minimal\rApache 웹서버 설치 link Apache 버전 확인\n[Rocky Linux 8.6]에서 기본으로 지원하는 Apache 버전을 확인해보면 [Apache 2.4]인 것을 확인할 수 있습니다. ~# dnf module list httpd\rApache 2.4 설치 ~# dnf -y install httpd\rApache 실행, 상태 확인\n설치를 마쳤으면 Apache를 실행하고 상태를 확인합니다. ~# systemctl start httpd\r~# systemctl status httpd\r테스트용 웹사이트 생성 link테스트에 필요한 웹사이트 홈 디렉토리와 웹페이지를 생성합니다.\n~# mkdir -p /ncloud/data/www/rocky-https-test.com/\r~# vim /ncloud/data/www/rocky-https-test.com/index.html\r\u003c!doctype html\u003e\rRocky Linux HTTPS Test Site\rRocky Linux HTTPS Test Site\rApache 환경 설정 파일 생성 linkrocky-https-test.com 웹사이트에 대한 Apache 환경 설정 파일을 생성하고, HTTP 접속에 필요한 80 포트용 설정을 추가합니다.\n~# vim /etc/httpd/conf.d/rocky-https-test.com.conf\rServerName rocky-https-test.com\rDocumentRoot /ncloud/data/www/rocky-https-test.com\rDirectoryIndex index.htm index.html\rCustomLog \"/var/log/httpd/rocky-https-test.com-access_log\" combined\rErrorLog \"/var/log/httpd/rocky-https-test.com-error_log\"\rOptions None\rAllowOverride None\rRequire all granted\r설정 파일을 저장한 후에 Apache 데몬을 재시작합니다. ~# systemctl restart httpd\rhosts 파일 수정 link지금과 같이 테스트용으로 임의 설정한 도메인(rocky-https-test.com)으로 접속하게 될 경우에는 hosts 파일을 수정해야 합니다.\n실제 도메인을 사용할 경우에는 아래 과정이 필요 없기에 다음 단계로 바로 이동하시면 됩니다.\n윈도우 10에서 hosts 파일은 C:\\Windows\\System32\\drivers\\etc 에 존재하는데 직접 수정할 수가 없으므로 다음과 같은 단계를 거쳐야 합니다.\nC:\\Windows\\System32\\drivers\\etc\\hosts 파일을 임의의 작업 폴더 (예: D:\\Work)로 복사합니다. 복사한 hosts 파일을 수정해서 123.456.789.123 rocky-https-test.com 처럼 접속할 IP 주소와 도메인을 추가합니다. 수정한 파일을 C:\\Windows\\System32\\drivers\\etc 위치로 덮어쓰기 합니다. 덮어쓰기 할 때 관리자 권한이 필요하다는 안내 메시지가 나타나면 [계속] 버튼을 클릭합니다. ACG (방화벽) 설정 link테스트로 생성했던 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다.\nACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다. [Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다. 내부 테스트용 ACG 설정 link내부 테스트용 설정은 ACG 규칙 설정 화면에서 [Inbound] 탭에서 [myIp] 버튼을 클릭해서 현재 접속한 PC나 회사 IP를 입력하고, HTTP용 80포트와 HTTPS용 443포트를 추가합니다.\n라이브 서비스용 ACG 설정 link라이브 서비스용 설정은 접근 소스에는 [0.0.0.0/0]을 입력하고, 마찬가지로 HTTP용 80포트와 HTTPS용 443포트를 추가합니다.\nHTTP 접속 테스트 linkACG 설정을 마쳤으면 웹브라우저에 테스트용 사이트의 주소 [http://rocky-https-test.com]으로 접속을 해보면 문제 없이 잘 접속되는 것을 확인할 수 있습니다.\nSSL 인증서 설정 linkmod_ssl 설치 link\r~# dnf -y install mod_ssl\r우선 인증서 저장용 디렉토리를 생성합니다. ~# mkdir -p /root/ssl/\rSSL 테스트 인증서 생성 link여기서는 테스트용 인증서를 생성해서 사용하게 되는데, 정식 서비스의 경우 SSL 인증서 발급 기관에서 정식 인증서를 발급 받아 사용하게 됩니다.\n정식 인증서를 사용하는 경우에는 테스트 인증서 생성 단계는 건너띄고 다음 단계로 이동하시면 되겠습니다.\n~# openssl req -newkey rsa:2048 \\\r-nodes -keyout /root/ssl/rocky-https-test.com.key \\\r-x509 -days 365 -out /root/ssl/rocky-https-test.com.crt\r인증서 파일이 제대로 생성되었는지 확인합니다. ~# ls -al /root/ssl/\rHTTPS용 환경 설정 추가 link앞에서 생성했던 환경 설정 파일 [rocky-https-test.com.conf]에 HTTPS용 설정을 추가합니다.\n~# vim /etc/httpd/conf.d/rocky-https-test.com.conf\rServerName rocky-https-test.com\rDocumentRoot /ncloud/data/www/rocky-https-test.com\rDirectoryIndex index.htm index.html\rCustomLog \"/var/log/httpd/rocky-https-test.com-ssl-access_log\" combined\rErrorLog \"/var/log/httpd/rocky-https-test.com-ssl-error_log\"\rSSLEngine on\rSSLProtocol -all +TLSv1.2 +TLSv1.3 SSLHonorCipherOrder on\rSSLCipherSuite PROFILE=SYSTEM\rSSLCertificateFile /root/ssl/rocky-https-test.com.crt\rSSLCertificateKeyFile /root/ssl/rocky-https-test.com.key\rOptions None\rAllowOverride None\rRequire all granted\r⁃ SSLProtocol: SSL Protocol에 대한 설정은 [TLS v1.2], [TLS v1.3] 만 허용하고, 나머지 Protocol은 모두 거부하도록 설정했습니다. ⁃ 정식 인증서에서는 [SSLCertificateFile], [SSLCertificateKeyFile] 외에도 [SSLCertificateChainFile], [SSLCACertificateFile] 등의 키 설정이 필요하게 되는데, 자세한 내용은 인증서 발급 대행사에서 인증서를 발급 받을 때 포함되어 있는 가이드 문서를 참고하시면 됩니다.\r설정 파일을 저장한 후에 Apache 데몬을 재시작합니다. ~# systemctl restart httpd\rHTTPS 접속 테스트 link설정을 마쳤으면 웹브라우저에서 HTTPS로 [https://rocky-https-test.com]에 접속을 해보면 문제 없이 잘 접속되는 것을 확인할 수 있습니다.\n인증서 확인 linkHTTPS로 테스트 사이트에 접속 후에 인증서를 확인해보면 위에서 테스트로 생성했던 정보가 제대로 설정되어 있는 것을 확인할 수 있습니다.\nHTTP 접속 시 HTTPS로 리다이렉트 link이제 HTTPS 설정까지 마쳤으니 HTTP로 접속하는 경우에 HTTPS로 리다이렉트 시키는 설정을 적용해보겠습니다.\n방법 - 1 link첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\n앞에서 설정한 HTTP용 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\n~# vim /etc/httpd/conf.d/rocky-https-test.com.conf\rServerName rocky-https-test.com\rRedirect permanent / https://rocky-https-test.com/\r# 또는\r# Redirect 301 / https://rocky-https-test.com/\r리다이렉트 여부 확인 link웹브라우저에서 [F12] 키로 개발자 모드로 변경한 후에 [http://rocky-https-test.com/]로 접속을 해보면 아래 스샷처럼 HTTP 301 상태코드를 반환하면서 [https://rocky-https-test.com/]로 리다이렉트된 것을 확인할 수 있습니다.\n방법 - 2 link두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\nServerName rocky-https-test.com\rRewriteEngine On\rRewriteCond %{HTTPS} !on\rRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\r참고 URL link Rocky Linux Apache Multiple Site 설정 가이드\nhttps://docs.rockylinux.org/guides/web/apache-sites-enabled/\nRocky Linux Apache with ‘mod_ssl’ 가이드\nhttps://docs.rockylinux.org/guides/web/mod_SSL_apache/\n문서 업데이트 내역 link\r날짜 내용 2023-07-13 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  80 ,
                href: "\/docs\/compute\/redirect-http-to-https\/apache-rocky-linux\/",
                title: "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Rocky Linux",
                description: "Ncloud (네이버 클라우드) Rocky Linux 서버 Apache에서 http 접속 시에 https로 강제 리다이렉트 시키는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) Rocky Linux (록키 리눅스) 서버 Apache 웹서버에서 http 접속 시에 https로 강제 리다이렉트 시키는 방법은 크게 2가지가 있는데 각각에 대해 정리해보겠습니다.\n테스트 환경 link테스트에 사용한 서버 환경은 다음과 같습니다.\n⁃ OS: Rocky Linux 8.6 ⁃ 웹서버: Apache 2.4 ⁃ 테스트 사이트: rocky-https-test.com\r방법1 : Redirect 옵션 link첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\nHTTP 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\nServerName 사이트_도메인\rRedirect permanent / https://사이트_도메인/ 301 리다이렉트: Redirect permanent / https://사이트_도메인/ 302 리다이렉트: Redirect / https://사이트_도메인/ 301 리다이렉트: Redirect 301 / https://사이트_도메인/ 302 리다이렉트: Redirect 302 / https://사이트_도메인/ 307 리다이렉트: Redirect 307 / https://사이트_도메인/ 308 리다이렉트: Redirect 308 / https://사이트_도메인/ 방법2 : RewirteRule 옵션 link두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\nServerName 사이트_도메인\rRewriteEngine On\rRewriteCond %{HTTPS} !on\rRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\r위 설정 중에서 [R=301,L] 이 부분에 원하는 상태코드를 입력하면 됩니다.\n301 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n302 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=302,L]\n307 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=307,L]\n308 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=308,L]\n설정 파일을 저장한 후에 Apache 데몬을 재시작합니다.\n~# systemctl restart httpd\r리다이렉트 여부 확인 link웹브라우저에서 [F12] 키로 개발자 모드로 변경한 후에 [http]로 접속을 해보면 아래 스샷처럼 HTTP 301 상태코드를 반환하면서 [https]로 리다이렉트된 것을 확인할 수 있습니다.\nSSL 모듈 설치 link리다이렉트 설정과 관계없이 SSL 인증서를 설정하고 HTTPS 접속을 하려면 [mod_ssl]가 설치되어 있어야 하는데, 혹시나 설치되어 있지 않다면 설치하셔야 합니다.\n~# dnf -y install mod_ssl\r참고 URL link Rocky Linux에서 Apache SSL 인증서 설정하는 방법\nhttps://docs.3rdeyesys.com/compute/ncloud-compute-lamp-apache-ssl-setting-rocky-linux-guide.html\nRocky Linux Apache with ‘mod_ssl’ 가이드\nhttps://docs.rockylinux.org/guides/web/mod_SSL_apache/\n문서 업데이트 내역 link\r날짜 내용 2023-07-11 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  81 ,
                href: "\/docs\/compute\/redirect-http-to-https\/apache-ubuntu\/",
                title: "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Ubuntu",
                description: "Ncloud (네이버 클라우드) Ubuntu 서버 Apache에서 http 접속 시에 https로 강제 리다이렉트 시키는 방법입니다",
                content: "개요 link웹사이트 SSL 인증서를 설치하고 https 접속을 유도할 때 http로 접속하면 https로 강제로 리다이렉트 시키는 방법을 사용하는 경우가 많습니다.\n웹페이지 소스에서 http 접속 여부를 판단해서 redirect 시키는 방법 등 여러가지 있을 수 있는데 여기서는 Apache 설정으로 쉽게 할 수 있는 방법을 소개합니다.\nSSL 인증서가 설치되어 있다는 가정하에 우선 Linux Ubuntu에서 설정하는 방법을 확인해보겠습니다.\n테스트 환경 link테스트에 사용한 서버 환경은 다음과 같습니다.\n⁃ OS: Ubuntu 20.04 ⁃ 웹서버: Apache 2.4\rSSL 엔진 모듈 활성화 link먼저, SSL 엔진 모듈을 활성화 해야 HTTPS 접속을 할 수 있습니다.\n~# a2enmod ssl\r~# systemctl restart apache2\rApache conf 파일 수정 link/etc/apache2/sites-enabled/000-default.conf 파일의 Vritual host에 다음 코드를 추가하고 Apache를 재시작하면 됩니다.\n방법1 : Redirect 옵션 link첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\nHTTP 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\nServerName 사이트_도메인\rRedirect permanent / https://사이트_도메인/ 301 리다이렉트: Redirect permanent / https://사이트_도메인/ 302 리다이렉트: Redirect / https://사이트_도메인/ 301 리다이렉트: Redirect 301 / https://사이트_도메인/ 302 리다이렉트: Redirect 302 / https://사이트_도메인/ 307 리다이렉트: Redirect 307 / https://사이트_도메인/ 308 리다이렉트: Redirect 308 / https://사이트_도메인/ 방법2 : RewirteRule 옵션 link두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\nRewrite 모듈 설치 link우선, RewirteRule 옵션을 사용하려면 Rewrite 모듈을 활성화 해야합니다.\n~# a2enmod rewrite\r~# systemctl restart apache2\rServerName 사이트_도메인\rRewriteEngine On\rRewriteCond %{HTTPS} !on\rRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\r위 설정 중에서 [R=301,L] 이 부분에 원하는 상태코드를 입력하면 됩니다.\n301 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L] 302 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=302,L] 307 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=307,L] 308 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=308,L] Apache 재시작 link\r~# systemctl restart apache2\r이렇게 재시작하고 http로 접속을 해보면 https로 전환되는 것을 확인할 수 있습니다.\n참고 URL link http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Rocky Linux\n"
            }
        );
    index.add(
            {
                id:  82 ,
                href: "\/docs\/compute\/redirect-http-to-https\/apache-centos\/",
                title: "http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/CentOS",
                description: "Ncloud (네이버 클라우드) CentOS 서버 Apache에서 http 접속 시에 https로 강제 리다이렉트 시키는 방법입니다",
                content: "개요 link웹사이트 SSL 인증서를 설치하고 https 접속을 유도할 때 http로 접속하면 https로 강제로 리다이렉트 시키는 방법을 사용하는 경우가 많습니다. 웹페이지 소스에서 http 접속 여부를 판단해서 redirect 시키는 방법 등 여러가지 있을 수 있는데 여기서는 Apache 설정으로 쉽게 할 수 있는 방법을 소개합니다.\nSSL 인증서가 설치되어 있다는 가정하에 우선 Linux CentOS에서 설정하는 방법을 확인해보겠습니다.\n테스트 환경 link테스트에 사용한 서버 환경은 다음과 같습니다.\n⁃ OS: CentOS 7.8 ⁃ 웹서버: Apache 2.4\rApache conf 파일 수정 link/etc/httpd/conf/httpd.conf 또는 별도로 설정한 /etc/httpd/conf.d/사이트도메인.conf 등의 Vritual host에 다음 코드를 추가하고 Apache를 재시작하면 됩니다.\n방법1 : Redirect 옵션 link첫번째 방법은 [Redirect] 옵션을 이용하는 방법입니다.\nHTTP 환경 설정에서 [ServerName]을 제외한 다른 항목들은 모두 삭제하거나 주석처리한 후에 리다이렉트 설정을 추가합니다.\nServerName 사이트_도메인\rRedirect permanent / https://사이트_도메인/ 301 리다이렉트: Redirect permanent / https://사이트_도메인/ 302 리다이렉트: Redirect / https://사이트_도메인/ 301 리다이렉트: Redirect 301 / https://사이트_도메인/ 302 리다이렉트: Redirect 302 / https://사이트_도메인/ 307 리다이렉트: Redirect 307 / https://사이트_도메인/ 308 리다이렉트: Redirect 308 / https://사이트_도메인/ 방법2 : RewirteRule 옵션 link두번째 방법은 [RewirteRule] 옵션을 이용하는 방법입니다.\n첫번째 방법이 더 간편하기는 하지만, 리다이렉트 시킬 때 HTTP 상태코드 뿐만 아니라 HTTP Header 값 등 다양한 설정이 필요한 경우에는 [RewirteRule]을 이용하는 두번째 방법을 사용해야 합니다.\nServerName 사이트_도메인\rRewriteEngine On\rRewriteCond %{HTTPS} !on\rRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\r위 설정 중에서 [R=301,L] 이 부분에 원하는 상태코드를 입력하면 됩니다.\n301 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L] 302 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=302,L] 307 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=307,L] 308 리다이렉트: RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=308,L] Apache 재시작 link\r~# systemctl restart httpd\r이렇게 재시작하고 http로 접속을 해보면 https로 전환되는 것을 확인할 수 있습니다.\nSSL 모듈 설치 link혹시 Apache에 mod_ssl 가 설치되어 있지 않다면 설치하셔야 합니다.\n~# yum -y install mod_ssl\r========================================================================\rPackage Arch Version Repository Size\r========================================================================\rInstalling:\rmod_ssl x86_64 1:2.4.6-97.el7.centos updates 114 k\rTransaction Summary\r========================================================================\rInstall 1 Package\rTotal download size: 114 k\rInstalled size: 224 k\rDownloading packages:\rmod_ssl-2.4.6-97.el7.centos.x86_64.rpm | 114 kB 00:00:00\rRunning transaction check\rRunning transaction test\rTransaction test succeeded\rRunning transaction\rInstalling : 1:mod_ssl-2.4.6-97.el7.centos.x86_64 1/1\rVerifying : 1:mod_ssl-2.4.6-97.el7.centos.x86_64 1/1\rInstalled:\rmod_ssl.x86_64 1:2.4.6-97.el7.centos\rComplete!\r참고 URL link http 접속 시에 https로 강제 리다이렉트 시키는 방법 - Apache/Rocky Linux\n"
            }
        );
    index.add(
            {
                id:  83 ,
                href: "\/docs\/compute\/auth-security\/server-admin-password-reset\/",
                title: "Ncloud 서버 어드민 패스워드(관리자 비밀번호) 초기화하는 방법",
                description: "Ncloud (네이버 클라우드) 서버 어드민 패스워드(관리자 비밀번호) 초기화하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) 서버의 [관리자 비밀번호] 즉, [어드민 패스워드]를 초기화하는 방법을 정리해보겠습니다.\n어드민 패스워드를 초기화하게 되는 경우는 다음과 같은 경우가 있습니다.\n보안을 위해 주기적으로 비밀번호를 변경하는 경우 해킹이나 패스워드 유출 등이 의심되어 비밀번호를 변경해야 하는 경우 담당자 퇴사 등으로 비밀번호 변경이 필요한 경우 비밀번호 확인 link비밀번호를 초기화 하기 전에 먼저 비밀번호를 확인하는 방법부터 알아보겠습니다.\n(Linux, Windows 서버 모두 동일합니다.)\n어드민 패스워드(관리자 비밀번호) 확인은 서버를 선택하고, [서버 관리 및 설정 변경] - [관리자 비밀번호 확인] 메뉴를 선택하면 됩니다.\n[관리자 비밀번호]를 확인하려면 서버를 생성할 때 사용한 *.pem 형태의 인증키를 사용해야 합니다.\npem 인증키를 사용하면 아래와 같이 비밀번호를 확인할 수 있습니다.\nLinux link\rWindows link\r비밀번호 초기화 link위에서 확인해본 어드민 패스워드(관리자 비밀번호)를 초기화 하려면, 먼저 서버를 정지시키고 [서버 관리 및 설정 변경] - [관리자 비밀번호 초기화] 메뉴를 선택하면 됩니다.\n[관리자 비밀번호 초기화] 기능은 마스터 계정에서만 가능합니다. 서브 어카운트에서는 메뉴가 활성화 되지 않습니다.\r[관리자 비밀번호 초기화] 기능은 서버를 [정지] 시킨 상태에서만 가능합니다.\r사용자 확인 link[관리자 비밀번호 초기화]를 하려면 먼저 아래와 같이 접속 계정의 비밀번호를 입력해서 사용자 확인을 먼저 해야 합니다.\n인증키 확인 link비밀번호를 초기화 할 때에도 확인할 때와 마찬가지로 pem 인증키를 사용해야 합니다.\n초기화 link인증키를 확인하고 나면 아래와 같이 비밀번호가 초기화 되고, 정지 상태인 서버를 [지금 시작]할 것인지, [나중에 시작]할 것인지 묻는 창이 나타납니다. 여기서는 [지금 시작] 버튼을 선택하겠습니다.\n서버 시작 link[지금 시작] 버튼을 클릭하면 아래와 같이 정지되어 있던 서버가 다시 시작됩니다.\n초기화된 비밀번호 확인 link서버가 시작된 후에 다시 [관리자 비밀번호 확인]을 해보면 아래와 같이 비밀번호가 초기화 되고 새로운 비밀번호가 할당된 것을 확인할 수 있습니다.\nLinux link\rWindows link\r참고 URL link Ncloud 서버 정보 확인 및 서버 관리 가이드\nhttps://guide.ncloud-docs.com/docs/compute-server-manage-vpc\nNcloud 서버 인증키 변경하는 방법\n"
            }
        );
    index.add(
            {
                id:  84 ,
                href: "\/docs\/compute\/auth-security\/server-authentication-key-change\/",
                title: "Ncloud 서버 인증키 변경하는 방법",
                description: "Ncloud (네이버 클라우드) 서버의 인증키를 변경하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) 서버의 인증키는 서버의 [관리자 비밀번호 확인], [비밀번호 초기화] 등에 꼭 필요한 *.pem 형태의 파일입니다. 그런데 만약 인증키를 분실했을 경우에는 다른 인증키로 변경해야 하는데, 어떻게 변경하는지 정리해보겠습니다.\n인증키 변경 link인증키를 변경하려면 먼저 서버를 정지시키고, 서버를 선택한 후에 [서버 관리 및 설정 변경] - [서버 인증키 변경] 메뉴를 선택하면 됩니다.\n[서버 인증키 변경] 기능은 마스터 계정에서만 가능합니다. 서브 어카운트에서는 메뉴가 활성화 되지 않습니다.\r[서버 인증키 변경] 기능은 서버를 [정지] 시킨 상태에서만 가능합니다.\r사용자 확인 link인증키를 변경하려면 먼저 사용자 확인을 해야 하므로, [인증 메일 발송] 버튼을 클릭하면 등록된 메일주소로 인증 메일이 발송됩니다.\n인증 메일 확인 link메일을 열어보면 아래와 같이 인증 메시지를 확인할 수 있습니다.\n인증 메시지 입력 link메일에서 확인한 인증 메시지를 입력하면 인증이 완료됩니다.\n인증키 선택 link변경할 인증키는 기존에 있는 다른 인증키를 선택할 수도 있고, 새로운 인증키를 생성할 수도 있습니다.\n여기서는 [새로운 인증키]를 생성해보겠습니다.\n인증키 생성 및 저장 link새로운 인증키 이름을 입력하고 [인증키 생성 및 저장] 버튼을 클릭하면 인증키가 다운로드 됩니다.\n인증키 다운로드 완료 후에 [변경] 버튼을 클릭하면 인증키가 변경됩니다.\n인증키 변경 완료 link서버 인증키가 변경되고 나면 정지 상태인 서버를 [지금 시작]할 것인지, [나중에 시작]할 것인지 묻는 창이 나타납니다.\n여기서는 [지금 시작] 버튼을 선택하겠습니다.\nLinux link\rWindows link\r비밀번호 확인 link변경된 인증키로 서버 관리자 비밀번호를 확인해보겠습니다.\nLinux link\rWindows link\r참고 URL link Ncloud 서버 정보 확인 및 서버 관리 가이드\nhttps://guide.ncloud-docs.com/docs/compute-server-manage-vpc\nNcloud 서버 관리자 비밀번호 초기화하는 방법\n"
            }
        );
    index.add(
            {
                id:  85 ,
                href: "\/docs\/compute\/auth-security\/server-access-by-ssh-key\/",
                title: "Ncloud 서버에 SSH Key를 이용해 접속하는 방법",
                description: "Ncloud (네이버 클라우드) Linux 서버에 SSH Key를 이용해 접속하는 방법입니다",
                content: "개요 link리눅스 서버에 접속하는 방법은 [아이디-패스워드]로 접속하는 방법과 [SSH Key]를 이용해 접속하는 방법이 있습니다.\nNcloud (네이버 클라우드)에서는 기본으로 [아이디-패스워드]로 접속하는 방법을 제공하고 있으므로 여기서는 다른 방법인 [SSH Key]를 이용해 서버에 접속하는 방법을 정리해보게겠습니다.\n테스트 서버 준비 link테스트로 사용할 서버는 [Rocky Linux 8.6] 서버로 생성했습니다.\nSSH Key 생성 link우선 Ncloud 제공하는 [아이디-패스워드] 방식으로 서버에 접속한 후, 아래의 명령으로 SSH key를 생성합니다.\n~# ssh-keygen -t rsa -m pem\r상세 설명 link위의 SSH Key 생성 화면에서 몇가지를 좀 더 자세히 살펴보겠습니다.\nKey 저장 위치 설정\n아래 스샷처럼 생성된 [SSH Key]를 어느 위치에 저장할 것인지 확인하는 단계입니다. 아무것도 입력하지 않고 Enter 키를 입력하면 기본 저장 위치인 [/root/.ssh/id_rsa]에 저장됩니다. Key 파일 암호 설정\n보안을 좀 더 강화하려면 [SSH Key]를 사용할 때 암호(passphrase)를 입력하도록 설정할 수 있습니다. 아무것도 입력하지 않으면 암호 없이 사용하게 됩니다. 생성된 Key 확인 linkKey가 생성된 디렉토리로 이동해서 살펴보면 [id_rsa], [id_rsa.pub] 이렇게 2개의 파일이 생성된 것을 확인할 수 있습니다.\nid_rsa: Private Key id_rsa.pub: Public Key Key 파일명 변경 linkmv 명령어를 사용해 [SSH Key] 인증에서 사용할 파일명으로 변경 합니다.\n~# mv id_rsa id_rsa.pem\r~# mv id_rsa.pub authorized_keys\rPrivate Key 복사 link위에서 생성된 [Private Key]인 [id_rsa.pem] 파일을 로컬 PC로 가져오는 방법은 크게 2가지가 있는데 편하신 방법을 사용하면 되겠습니다.\n암호화 텍스트로 구성된 파일의 내용을 복사해서 로컬 PC 텍스트 편집기에 붙여넣고 새로운 파일로 저장하는 방법 [WinSCP], [FileZilla] 등의 SFTP 프로그램을 이용해서 파일을 로컬 PC로 전송하는 방법 방법 1: 텍스트 복사 link[id_rsa.pem] 파일은 암호화된 텍스트로 구성된 파일이므로 파일 내용을 확인해서 복사합니다.\n복사한 내용을 로컬 PC의 텍스트 편집기에 붙여 넣고 저장합니다. 방법 2: WinSCP 접속 link[WinSCP]로 서버에 접속하면 처음에는 파일이나 디렉토리가 전혀 보이지 않습니다. 즉, 인증키 파일이 저장된 [.ssh] 디렉토리가 숨겨진 디렉토리이기 때문입니다.\n숨겨진 디렉토리를 확인하기 위해 [옵션] - [설정] 메뉴에 들어갑니다. [설정] 창에서 [패널]을 선택하면 위쪽에 [숨김 파일 표시] 옵션이 있는데 이 옵션을 체크하고 [확인] 버튼을 클릭합니다. Key 전송 link[숨김 파일 표시] 옵션을 체크하면 아래와 같이 [.ssh] 디렉토리를 확인할 수 있습니다.\n[.ssh] 디렉토리에 들어가서 [id_rsa.pem] 파일을 로컬 PC로 전송합니다. PPK 파일 변환 link[SSH Key] 인증으로 서버에 접속할 때 주로 사용하는 프로그램이 [PuTTY]인데, [Putty]에서는 [PEM] 파일이 아니라 [PPK]파일을 사용하기 때문에 [PEM] 파일을 [PPK]파일로 변환해야 합니다. 이럴 때 사용하는 것이 [PuTTY Key Generator] 즉, [PuTTYgen]인데, [PuTTY] 통합 설치 파일에 포함되어 있습니다.\nPuTTY 설치 link[PuTTYgen] 사이트에 접속해서 [PuTTY]를 다운로드 받고 설치합니다.\nhttps://www.puttygen.com/ 설치가 완료되었으면 로컬 PC에서 [PuTTYgen]을 찾아서 실행합니다. Key 변환 link우선 위에서 로컬 PC로 전송받았던 [id_rsa.pem]을 파일을 불러오기 위해 [PuTTYgen] 화면에서 가운데에 있는 [Load] 버튼을 클릭합니다.\n파일 선택창에서 파일 확장자를 [All Files]로 선택 하고 [id_rsa.pem] 파일을 선택하고 [열기] 버튼을 클릭합니다. [Notice] 팝업에서 [확인] 버튼을 클릭합니다. [Save private key] 버튼을 눌러 PPK 파일로 변환합니다. Key 파일에 암호 즉, [passphrase]가 없을 경우 경고 팝업이 뜨는데 [예] 버튼을 클릭해서 다음 단계로 넘어 갑니다. 파일명을 입력 후 [저장] 버튼을 클릭합니다. 서버 접속 link이제 위에서 변환 저장한 Key 파일로 서버에 접속해보겠습니다.\nPuTTY 설정 link우선, [PuTTY] 프로그램을 실행합니다.\n[Host Name (or IP address)]에 접속할 서버의 IP를 입력합니다. 또는 [계정@서버IP] 형식으로 미리 로그인 계정을 입력해두는 방법도 있습니다. (예: 123.456.789.012 또는 root@123.456.789.012) IP만 입력\r계정@IP 입력\r좌측의 Category에서 [Conncetion] - [SSH] - [Auth] - [Credentials] 설정 메뉴에서 [Private key file for authentication] 항목에 위에서 변환 저장했던 파일을 선택하기 위해 [Browser] 버튼을 클릭합니다. 위에서 저장했던 test-key.PPK 파일을 선택 합니다. 다음으로 아래쪽에 있는 [Open] 버튼을 클릭해서 서버에 접속합니다. 서버 접속 완료 link그러면 아래와 같이 비밀번호 입력 없이 [Authenticating with public key “imported-openssh-key”]라는 메시지가 나타나면서 서버에 접속됩니다.\n(PuTTY 접속 설정 [Host Name]에 IP만 입력했을 경우에는 [login as]에 로그인 계정을 입력해야 합니다.)\nIP만 입력\r계정@IP 입력\r참고 URL link Ncloud 서버 접속 가이드\nhttps://guide.ncloud-docs.com/docs/server-access-vpc\nNcloud 서버 관리자 비밀번호 초기화하는 방법\n"
            }
        );
    index.add(
            {
                id:  86 ,
                href: "\/docs\/compute\/auth-security\/ssh-access-security-setting\/",
                title: "리눅스서버 SSH 접속 보안 설정하기",
                description: "Ncloud (네이버 클라우드) 리눅스서버 SSH 접속 보안 설정하기입니다",
                content: "개요 link리눅스 서버들은 서버에 접속할 때 SSH를 이용하게 되는데, 이때 root 계정에 대한 무작위 패스워드 입력 등의 해킹시도가 있을 수 있습니다.\n여기서는 이러한 해킹시도를 차단하기 위한 보안설정 중에서 root 계정과 관련한 보안설정 2가지를 정리해보겠습니다.\n설정 파일 위치 linkroot 계정에 대한 보안 설정은 /etc/ssh/sshd_config 파일에 있습니다.\n~# vi /etc/ssh/sshd_config\rCentOS link\rUbuntu link\rroot 로그인 차단 link로그인 차단은 위 설정에서 PermitRootLogin 항목을 바꾸시면 됩니다.\nCentOS는 주석처리 되어 있으므로 주석을 해제하고 설정을 변경하시면 되고, Ubuntu는 주석이 해제된 상태이므로 설정값만 변경하시면 됩니다.\nreport\rWarning: root 로그인을 차단하기 전에 다른 관리자 계정을 생성한 후에 차단 설정을 적용해야 합니다.\n# 기존 - CentOS\r#PermitRootLogin yes\r# 기존 - Ubuntu\rPermitRootLogin yes\r# 변경\rPermitRootLogin no\r기타 옵션 link\r# 패스워드 로그인은 차단하고 Key 파일을 이용한 로그인만 허용\rPermitRootLogin prohibit-password\r## 로그인 시도 횟수 제한\r이 옵션을 지정하게 되면 지정한 횟수 이상으로 로그인을 실패했을 때 접속이 강제 종료되는데, 기본값은 6회이니 적절하게 수정하시면 됩니다.\r# 기존\r#MaxAuthTries 6\r# 변경\rMaxAuthTries 3\r### 데몬 재시작\r설정을 수정하고 파일을 저장한 후에 sshd 데몬을 재시작합니다.\r~# systemctl restart sshd\r데몬 재시작 후 로그인을 시도해보면 로그인이 실패하는 것을 확인하실 수 있습니다.\rSSH 접속 로그 확인 linkSSH로 접속을 하면 성공, 실패에 대한 로그가 모두 남게 되는데, 이 로그를 주기적으로 확인하는 것이 좋습니다.\n접속 실패 로그 link\r~# last -f /var/log/btmp\r# 또는\r~# lastb\r접속 성공 로그 link\r~# last -f /var/log/wtmp\rNcloud 서버 접속 가이드\nhttps://guide.ncloud-docs.com/docs/server-access-vpc\n네이버 클라우드 플랫폼을 활용한 보안 강화\nhttps://m.blog.naver.com/n_cloudplatform/221117956958\n문서 업데이트 내역 link\r날짜 내용 2022-08-18 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  87 ,
                href: "\/docs\/compute\/server-storage\/storage-add-basic-guide\/",
                title: "Linux 서버 스토리지 추가 생성 기본 가이드",
                description: "Ncloud (네이버 클라우드) Linux 서버 스토리지 추가 생성 기본 가이드입니다",
                content: "개요 link네이버 클라우드에서 서버 생성 후에 스토리지를 추가 생성하는 경우가 있는데 이때 사용되는 스토리지는 블록스토리지(Block Storage)라고 해서 AWS의 EBS(Elastic Block Store)와 유사합니다.\n스토리지 추가 제약 사항 link XEN 하이퍼바이저 기반 서버의 경우 Bare Metal 서버와 의 Micro 타입 서버에는 스토리지를 추가할 수 없습니다. 추가 가능한 최대 사이즈와 개수 link\r하이퍼바이저 스토리지 타입\r미디어 타입\r최소 크기\r최대 크기\r추가 가능 개수\rXEN\rHDD\rHDD\r10GB\r2TB\r15개\rSSD\rSSD\r10GB\r2TB\r15개\rKVM\rFB1\rHDD\r100GB\r16TB\r20개\rCB1\rSSD\r10GB\r16TB\r20개\r리눅스 OS 서버 이미지별 포맷 명령어 link리눅스는 OS 즉, 네이버 클라우드에서 제공하는 서버 이미지별로 추가된 스토리지를 포맷하는 명령어가 다릅니다.\n⁃ CentOS 5.x: mkfs.ext3 /dev/xvdb1 ⁃ CentOS 6.x: mkfs.ext4 /dev/xvdb1 ⁃ CentOS 7.x: mkfs.xfs /dev/xvdb1 ⁃ Rocky Linux: mkfs.xfs /dev/xvdb1 ⁃ Ubuntu Server / Desktop: mkfs.ext4 /dev/xvdb1 ext4 vs XFS 명령어 비교 link\r항목\rext4\rXFS\r포맷mkfs.ext4mkfs.xfs\r마운트mountmount\r리사이즈resize2fsxfs_growfs\r복구e2fsckxfs_repair\r라벨 변경e2labelxfs_admin -L\r디버깅debugfsxfs_db\r할당량 설정quotaquota\rinfo\rxfs_growfs 명령어는 파일 시스템의 크기를 줄일 수는 없고 늘릴 수만 있습니다.\n참고 URL link Ncloud 블록 스토리지 사용 가이드\nhttps://guide.ncloud-docs.com/docs/server-storage-vpc 문서 업데이트 내역 link\r날짜 내용 2023-12-07 KVM 하이퍼바이저 서버 관련 내용 추가 "
            }
        );
    index.add(
            {
                id:  88 ,
                href: "\/docs\/compute\/server-storage\/storage-add-detail-process-guide\/",
                title: "Linux 서버 스토리지(디스크) 추가 상세 가이드",
                description: "Ncloud (네이버 클라우드) Linux 서버 스토리지(디스크) 추가 상세 가이드입니다",
                content: "개요 linkNcloud(네이버 클라우드)에서 리눅스 서버에 디스크를 추가하는 것은 스토리지 즉, Block Storage를 생성해서 서버에 연결하는 작업이 필요합니다.\n전체 과정 요약 link스토리지(디스크)를 추가하는 전체 과정은 아래와 같이 하이퍼바이저별로 정리할 수 있으며, 각 단계별 상세 설명은 XEN 하이퍼바이저 기반 서버를 이용해서 진행하겠습니다.\nXEN 하이퍼바이저\rKVM 하이퍼바이저\r~# fdisk -l\r~# fdisk /dev/xvdb\r~# mkfs.xfs /dev/xvdb1\r- CentOS 5.x: mkfs.ext3 /dev/xvdb1\r- CentOS 6.x: mkfs.ext4 /dev/xvdb1\r- CentOS 7.x: mkfs.xfs /dev/xvdb1\r- Rocky Linux: mkfs.xfs /dev/xvdb1\r- Ubuntu : mkfs.ext4 /dev/xvdb1\r~# mkdir /mnt/data\r~# mount /dev/xvdb1 /mnt/data\r~# df -hT\r~# vim /etc/fstab\r### =============================\rUUID=1fd5s61f5d-*** 중략 ***-f84ew13 /mnt/data xfs defaults 1 2\r# 또는\r/dev/xvdb1 /mnt/data ext4 defaults 1 2\r### =============================\r~# fdisk -l\r~# fdisk /dev/vdb\r~# mkfs.xfs /dev/vdb1\r- CentOS 5.x: mkfs.ext3 /dev/vdb1\r- CentOS 6.x: mkfs.ext4 /dev/vdb1\r- CentOS 7.x: mkfs.xfs /dev/vdb1\r- Rocky Linux: mkfs.xfs /dev/vdb1\r- Ubuntu : mkfs.ext4 /dev/vdb1\r~# mkdir /mnt/data\r~# mount /dev/vdb1 /mnt/data\r~# df -hT\r~# vim /etc/fstab\r### =============================\rUUID=1fd5s61f5d-*** 중략 ***-f84ew13 /mnt/data xfs defaults 1 2\r# 또는\r/dev/xvdb1 /mnt/data ext4 defaults 1 2\r### =============================\r스토리지 생성, 할당 link우선은 네이버 클라우드 콘솔 [Server] - [Server]에서 해당 서버를 선택하고 [서버 관리 및 설정 변경] - [스토리지 생성]을 선택합니다.\n다음으로 [스토리지 생성] 화면에서 스토리지 종류, 이름, 적용서버, 크기 (최소 10GB, 최대 2000GB) 등을 선택하고 [추가] 버튼을 클릭합니다.\n앞에서 설정한 스토리지 정보를 다시 살펴보고 이상이 없으면 [확인] 버튼을 클릭합니다.\n추가된 스토리지는 [Server] - [Server] 리스트에서 해당 서버를 클릭해 상세정보에서 확인할 수 있습니다.\n스토리지 할당 확인 link네이버 클라우드 콘솔에서 할당한 스토리지를 확인하기 위해 putty를 실행해 서버에 접속합니다.\n이후 과정은 모두 서버에 접속한 상태에서 진행하게 됩니다.\nfdisk -l 명령어를 실행해보면 아래 화면처럼 /dev/xvdb 디스크가 할당된 것을 확인할 수 있습니다.\n~# fdisk -l\r디스크 파티션 link다음 명령어를 입력해 할당된 디스크에 파티션을 생성합니다.\n파티션 설정에는 기본인 MBR 방식과 2TB 이상의 디스크를 인식하기 위해 사용하는 GPT 방식이 있는데, 네이버 클라우드는 최대 2,000GB까지만 지원하므로 여기서는 기본방식인 MBR을 사용하겠습니다.\n~# fdisk /dev/xvdb\r파티션 생성 link파티션을 생성할 때는 여러 단계의 옵션이 있습니다. 일반적으로는 아래와 같은 단계로 진행하면 됩니다.\n파티션을 새로 생성하기 위해 ‘n’을 입력 생성할 파티션 타입에 따라 primary type이면 ‘p’, extended type이면 ‘e’를 입력.\n(primary type으로 생성하는 것이 일반적이며, primary 영역의 파티션이 부족할 경우 추가로 extended type으로 생성) 생성할 파티션 번호와 cylinder 영역을 입력 (일반적으로 추가할 disk 전체를 mount하게 되고, 이 경우 default값을 그대로 사용하므로 Enter 입력) ‘w’를 입력해 해당 구성을 적용. 파티션 생성 완료. 마지막으로 fdisk -l 명령어로 생성된 파티션을 다시 확인합니다.\n디스크가 /dev/xvdb1 장치로 인식된 것을 확인할 수 있습니다.\n디스크 포맷 link다음으로 파티션이 생성된 디스크를 포맷하면 되는데, OS별로 명령어가 다르므로 확인 후에 실행해야 합니다.\n여기서는 CentOS 7.x 기준으로 mkfs.xfs 명령어를 사용했습니다.\n~# mkfs.xfs /dev/xvdb1\r- CentOS 5.x: mkfs.ext3 /dev/xvdb1\r- CentOS 6.x: mkfs.ext4 /dev/xvdb1\r- CentOS 7.x: mkfs.xfs /dev/xvdb1\r- Rocky Linux: mkfs.xfs /dev/xvdb1\r- Ubuntu : mkfs.ext4 /dev/xvdb1\r디스크 마운트 link다음으로 디스크를 마운트할 포인트 즉, 디렉토리를 원하는 이름으로 생성하고 마운트를 합니다.\n아래에 있는 마운트 경로 (/mnt/data)는 예시입니다. 원하는 경로를 직접 설정하시면 됩니다.\n~# mkdir /mnt/data\r~# mount /dev/xvdb1 /mnt/data\r마운트된 내역을 확인합니다. ~# df -hT\r마운트 정보 등록 link마운트 정보는 설정에 저장하지 않으면 서버가 리부팅될 때 사라지기 때문에 fstab에 저장합니다.\n마운트 정보를 등록할 때 장치명을 사용하는 방법과 장치의 UUID를 사용하는 방법이 있는데, 경우에 따라서는 장치명이 변경될 수도 있어, 이를 대비해 가능하면 UUID로 등록합니다.\nUUID 확인 linkUUID를 확인하려면 blkid 명령어를 사용합니다.\n여기서 확인한 UUID를 별도로 복사해두었다가 fstab에 입력하게 됩니다.\n~# blkid /dev/xvdb1\rvi로 /etc/fstab 파일을 열면 다음과 같습니다.\n서버 생성과 함께 장착된 기본 디스크도 UUID로 입력된 것을 확인할 수 있습니다.\n~# vi /etc/fstab\r앞에서 확인하고 복사해둔 추가 디스크의 UUID와 기타 정보를 입력합니다.\n입력을 완료한 후 fstab 파일을 저장하고 빠져 나옵니다.\n(fstab에 입력할때 사용하는 디스크 정보 옵션에 대한 정리는 아래에서 다시 확인할 수 있습니다.)\n### /etc/fstab\rUUID=29f58417-*** 중략 ***38d0f /mnt/data xfs defaults 1 2\r# 또는\r/dev/xvdb1 /mnt/data ext4 defaults 1 2\rfstab 설정 상세정보 link/etc/fstab은 부팅 단계에서 마운트되어야 할 볼륨 정보들이 저장되는 곳입니다.\n(OS 이미지에 따라 파일 시스템이 다르기 때문에 주의해야 합니다.)\n파일의 각 항목이 의미하는 바는 아래와 같으며 각 항목은 Tab 또는 Space Bar로 구분합니다.\n(장치명) (마운트 포인트) (파일시스템 종류) (옵션) (dump 설정) (fsck 설정)\n장치명: 장치명은 장치의 UUID를 사용하거나 /dev/xvdb1와 같은 장치이름을 사용합니다.\n마운트 포인트: 볼륨을 마운트하고자 하는 위치입니다. 예시에서는 /mnt/data 디렉토리에 마운트했습니다.\n파일시스템 종류: OS별로 기본 파일시스템이 다르므로 알맞게 입력합니다.\nCentOS 5.x : ext3 CentOS 6.x : ext4 CentOS 7.x : xfs Rocky Linux : xfs Ubuntu Server / Desktop : ext4 옵션: 예시에서는 default 옵션을 사용하였으며, 해당 옵션에는 rw, nouser, auto, exec, suid 속성이 포함됩니다.\n각 속성의 내용은 다음과 같습니다. (필요한 옵션만 사용할 시, 각 옵션을 쉼표(,)로 구분하여 작성해주시면 됩니다.)\nauto : 부팅 시 자동 마운트 rw : 읽기, 쓰기 모두 가능하도록 마운트 nouser : root 계정만 마운트 가능 exec : 파일 실행을 허용 suid : SetUID와 SetGID를 허용 dump 설정: dump 명령으로 백업을 할 것인지에 대한 설정\n0: dump되지 않는 파일 시스템 1: dump 가능한 파일 시스템 fsck 설정: 부팅시에 fsck 명령으로 파일시스템에 대한 무결성 검사를 할 것인지에 대한 설정\n0 : 부팅 시 fsck 실행하지 않음 1 : 부팅 시 root 파일 시스템을 우선 체크 2 : 부팅 시 root 이외의 파일 시스템을 우선 체크 참고 URL link Ncloud 블록 스토리지 사용 가이드\nhttps://guide.ncloud-docs.com/docs/server-storage-vpc 문서 업데이트 내역 link\r날짜 내용 2021-06-04 문서 최초 생성 2023-11-23 스크린샷 업데이트, Rocky Linux 추가 2023-12-07 KVM 하이퍼바이저 서버 관련 내용 추가 "
            }
        );
    index.add(
            {
                id:  89 ,
                href: "\/docs\/compute\/server-storage\/storage-extend-guide-linux\/",
                title: "Ncloud 블록 스토리지(디스크) 크기 확장하는 방법 | Linux",
                description: "Ncloud (네이버 클라우드) Linux 서버 디스크 (블록 스토리지) 크기를 확장하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) 리눅스 환경 서버의 블록스토리지 볼륨 크기를 확장하고 적용하는 방법을 정리해보겠습니다.\n테스트 환경 link CentOS 7.8 Ubuntu 20.04 추가 블록스토리지 10GB OS 영역에서 사용하는 50G 블록스토리지 외에 아래와 같이 추가로 할당 된 10G의 블록스토리지의 크기를 변경하고 적용해보겠습니다.\n추가 블록 스토리지 할당 방법에 대한 가이드는 아래의 링크를 참조 바랍니다.\n"
            }
        );
    index.add(
            {
                id:  90 ,
                href: "\/docs\/compute\/server-storage\/storage-lvm-create\/",
                title: "Ncloud 블록 스토리지(디스크) LVM 구성하기 - Linux",
                description: "Ncloud (네이버 클라우드) Linux 서버 디스크 (블록 스토리지) LVM 구성하는 방법입니다",
                content: "개요 link네이버 클라우드 서버는 하나의 서버당 로컬 디스크 즉, 블록 스토리지(Block Storage)를 OS가 설치되는 기본 스토리지 1개 이외에 15개를 추가할 수 있으며, 각 스토리지 용량은 10GB ~2,000GB 까지 가능합니다.\n그리고, 2,000GB 이상을 사용해야 할 경우는 NAS 장비를 사용하거나 Object Storage를 활용하는 경우가 많지만, 상황에 따라서는 2,000GB를 초과하는 용량의 블록 스토리지를 사용해야 하는 경우도 있습니다.\n이럴때 사용하는 방법이 **LVM (Logical Volume Manager)**를 사용하여 여러 개의 스토리지를 합쳐서 대용량으로 사용하거나 합쳐진 대용량을 다시 필요한 용량으로 나누어서 사용하는 방법입니다.\n그래서 이번에는 리눅스 환경에서 LVM으로 대용량 스토리지를 생성하는 방법을 정리해보겠습니다.\n스토리지 생성 link2,000GB 이상의 용량을 필요로 할 때에 대한 내용이지만, 테스트를 위해 10GB 스토리지 2개를 생성하겠습니다.\nlvm-test-1, lvm-test-2 이름으로 생성된 스토리지 2개를 Ubuntu OS가 설치된 lvm-test-svr 서버에 연결했습니다.\n파티션 설정 link생성된 스토리지 2개에 각각 파티션을 설정합니다.\n파티션 설정에는 parted 명령어를 사용합니다.\n~# parted /dev/xvdb\r# (parted)\rmklabel gpt\rmkpart primary 0 100%\ri\rset 1 lvm on # 1번 파티션에 lvm 사용 가능하게 설정\rp\rquit\r~# parted /dev/xvdc\r# (parted)\rmklabel gpt\rmkpart primary 0 100%\ri\rset 1 lvm on # 1번 파티션에 lvm 사용 가능하게 설정\rp\rquit\r설정된 파티션들을 확인합니다.\n~# fdisk -l\rPhysical Volume 생성 link각 스토리지 장치에 Physical Volume을 생성합니다.\n~# pvcreate /dev/xvdb1\r~# pvcreate /dev/xvdc1\rPhysical Volume이 제대로 생성되었는지 확인합니다.\n~# pvdisplay\rVolume Group 생성 link준비된 두개의 Volume으로 하나의 Volume Group을 생성합니다.\n~# vgcreate VG01 /dev/xvdb1 /dev/xvdc1\r생성된 Volume Group을 확인합니다.\n~# vgdisplay\rLogical Volume 생성 link생성된 Volume Group 전체 크기를 사용하는 Logical Volume을 생성합니다.\n~# lvcreate --extents 100%FREE -n LV01 VG01\r생성된 Logical Volume을 확인합니다.\n~# lvdisplay\r포맷 link다음으로 포맷을 해야하는데, OS별로 명령어가 다르므로 확인 후에 실행해야 합니다.\n여기서는 Ubuntu 기준으로 mkfs.ext4 명령어를 사용했습니다.\n~# mkfs.ext4 /dev/VG01/LV01\r- CentOS 5.x: mkfs.ext3 /dev/VG01/LV01\r- CentOS 6.x: mkfs.ext4 /dev/VG01/LV01\r- CentOS 7.x: mkfs.xfs /dev/VG01/LV01\r- Ubuntu : mkfs.ext4 /dev/VG01/LV01\r마운트 link마운트를 하기 위해 우선 생성된 디스크 장치명을 확인합니다.\n~# fdisk -l\r다음으로 디스크를 마운트할 포인트 즉, 디렉토리를 원하는 이름으로 생성하고 마운트를 합니다.\n아래에 있는 마운트 경로 (/mnt/data)는 예시입니다. 원하는 경로를 직접 설정하시면 됩니다.\n~# mkdir /mnt/data\r~# mount /dev/mapper/VG01-LV01 /mnt/data\rfstab 설정 link새로 생성된 디스크를 부팅 후에도 인식할 수 있게 blkid 명령으로 UUID를 확인하고 fstab에 등록합니다.\n~# blkid |grep /dev/mapper/VG01-LV01\r~# vi /etc/fstab\rfstab 설정 상세정보 link/etc/fstab은 부팅 단계에서 마운트되어야 할 볼륨 정보들이 저장되는 곳입니다.\n(OS 이미지에 따라 파일 시스템이 다르기 때문에 주의해야 합니다.)\n파일의 각 항목이 의미하는 바는 아래와 같으며 각 항목은 Tab 또는 Space Bar로 구분합니다.\n(장치명) (마운트 포인트) (파일시스템 종류) (옵션) (dump 설정) (fsck 설정)\n장치명: 장치명은 장치의 UUID를 사용하거나 /dev/xvdb1와 같은 장치이름을 사용합니다.\n마운트 포인트: 볼륨을 마운트하고자 하는 위치입니다. 예시에서는 /mnt/data 디렉토리에 마운트했습니다.\n파일시스템 종류: OS별로 기본 파일시스템이 다르므로 알맞게 입력합니다.\nCentOS 5.x : ext3 CentOS 6.x : ext4 CentOS 7.x : xfs Ubuntu Server / Desktop : ext4 옵션: 예시에서는 default 옵션을 사용하였으며, 해당 옵션에는 rw, nouser, auto, exec, suid 속성이 포함됩니다.\n각 속성의 내용은 다음과 같습니다. (필요한 옵션만 사용할 시, 각 옵션을 쉼표(,)로 구분하여 작성해주시면 됩니다.)\nauto : 부팅 시 자동 마운트 rw : 읽기, 쓰기 모두 가능하도록 마운트 nouser : root 계정만 마운트 가능 exec : 파일 실행을 허용 suid : SetUID와 SetGID를 허용 dump 설정: dump 명령으로 백업을 할 것인지에 대한 설정\n0: dump되지 않는 파일 시스템 1: dump 가능한 파일 시스템 fsck 설정: 부팅시에 fsck 명령으로 파일시스템에 대한 무결성 검사를 할 것인지에 대한 설정\n0 : 부팅 시 fsck 실행하지 않음 1 : 부팅 시 root 파일 시스템을 우선 체크 2 : 부팅 시 root 이외의 파일 시스템을 우선 체크 참고 URL link Ncloud 블록 스토리지 가이드\nhttps://guide.ncloud-docs.com/docs/server-storage-vpc 문서 업데이트 내역 link\r날짜 내용 2021-07-06 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  91 ,
                href: "\/docs\/compute\/server-storage\/storage-add-detail-process-guide-windows\/",
                title: "Ncloud Windows 서버 스토리지(디스크) 추가 상세 가이드",
                description: "Ncloud (네이버 클라우드) Windows 서버 스토리지(디스크) 추가 상세 가이드입니다",
                content: "개요 linkNcloud (네이버 클라우드)는 스토리지 당 최대 2TB까지 확장할 수 있으며, 최대 16개의 스토리지를 이용할 수 있습니다.\n이번에는 Windows 서버에 스토리지 즉, 디스크를 추가하는 방법에 대해 정리해보겠습니다.\n테스트 환경 linkWindows Server 2016 (64-bit) English Edition 으로 진행 되었습니다. 추가 스토리지는 총 10G disk 총 4개 입니다.\n스토리지 생성 link 서버 \u003e 서버 관리 및 설정 변경 \u003e 스토리지생성 스토리지 생성에 필요한 내용을 입력합니다. 크기는 스토리지 하나 당 10GB~2000GB까지 사용할 수 있습니다. 사용 될 추가디스크를 생성합니다. 윈도우 서버 디스크 관리 link 디스크관리(윈도우키+r) : diskmgmt.msc 디스크 초기화 link initializeDisk를 선택하여 디스크를 초기화 합니다. 초기화 방식 선택 link 두 가지 방식 중 하나를 선택합니다. MBR과 GPT 차이 link MBR GTP 주파티션을 4개까지 생성 가능 주 파티션을 128개까지 생성 가능 디스크 용량 최대 2TB까지 인식 디스크 용량 최대 9.4ZB까지 인식 BIOS가 설치된 PC에서 사용 UEFI 또는 EFI가 설치된 PC에서 사용 가능 Windows 32비트와 64비트 사용 가능 Windows 32비트 사용 불가 볼륨 생성 link 새 단순 볼륨 생성하기 추가한 총 4개의 디스크 단순 볼륨 생성을 하였습니다. 디스크 추가 확인 link 아래와 같이 추가 생성한 디스크 추가가 완료되었습니다. 참고 URL link Ncloud 블록 스토리지 사용 가이드\nhttps://guide.ncloud-docs.com/docs/server-storage-vpc 문서 업데이트 내역 link\r날짜 내용 2023-06-15 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  92 ,
                href: "\/docs\/compute\/server-storage\/storage-extend-guide-windows\/",
                title: "Ncloud 블록 스토리지 (디스크) 크기 확장하는 방법 | Windows",
                description: "Ncloud (네이버 클라우드) Windows 서버 디스크 (블록 스토리지) 크기를 확장하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) 윈도우 환경 서버의 블록스토리지 볼륨 크기를 확장하고 적용하는 방법을 정리해보겠습니다.\n테스트 환경 link Windows Server 2019 (64-bit) English Edition 추가 블록스토리지 10GB OS 영역에서 사용하는 100G 블록스토리지 외에 아래와 같이 추가로 할당 된 10G의 블록스토리지의 크기를 변경하고 적용해보겠습니다.\n추가 블록 스토리지 할당 방법에 대한 가이드는 아래의 링크를 참조 바랍니다.\nWindows 스토리지(디스크) 추가 상세 가이드 스토리지 스냅샷 백업 link아래와 같이 [Console] - [Server] - [Storage]에서 크기를 변경할 스토리지를 선택하고 [스토리지 설정] - [스냅샷 생성] 메뉴를 선택합니다.\n{% include callout-v2.html type=“warning” level=“3” content=“블록스토리지의 크기를 변경하는 과정에 만에 하나 있을지 모르는 상황에 대비해서 해당 블록스토리지의 스냅샷을 생성해서 백업해 두는 것을 적극 권장합니다.” %}\n스냅샷 이름을 입력하고 스냅샷을 생성합니다.\n스토리지 크기 변경 link스냅샷 생성이 끝났으면 스토리지 크기를 변경하기 위해 [스토리지 설정] - [크기 변경] 메뉴를 선택합니다.\n서버 정지 알림 link스토리지 크기 변경은 서버가 정지된 상태에서만 가능하므로, 혹시 서버가 동작중인 경우 아래와 같은 알림이 나타납니다.\n서버 정지 link먼저 스토리지가 장착된 서버를 정지하겠습니다.\n크기 변경 link서버를 정지한 후 크기 변경 메뉴를 선택하면 아래와 같이 변경할 크기를 입력할 수 있습니다. 최대 2,000GB까지 가능합니다.\n{% include callout-v2.html type=“info” level=“2” content=“스토리지 크기는 확대만 가능하며, 축소 기능은 제공하지 않습니다.” %}\n변경할 크기를 입력하고 [확인] 버튼을 클릭하면 크기 변경 작업이 진행됩니다. 이후에 서버에서 해당 스토리지의 파티션 확장 등의 작업을 추가로 진행해야 정상적으로 사용할 수 있습니다.\n서버 디스크 파티션 확장 link서버에 접속해 Disk Management를 실행하면 아래와 같이 확장된 추가 블록스토리지의 모습이 보입니다.\nDisk Management linkDisk Management 툴은 아래의 방법으로 간단하게 실행할 수 있습니다.\n명령 실행 (윈도우키+r) : diskmgmt.msc 볼륨 확장 link기존에 할당되어 있던 10GB 볼륨을 선택하고 마우스 오른쪽 버튼을 클릭한 후 [Extend Volume] 메뉴를 선택합니다.\n볼륨 확장 팝업 창에서 [Next] 버튼을 클릭합니다.\nSelect Disks\n콘솔에서 추가한 10GB 스토리지가 추가 디스크로 선택되어 있습니다. 전체 용량을 모두 확장할 것이므로 특별한 수정 없이 [Next] 버튼을 클릭합니다.\n볼륨 확장 작업이 끝났으면 [Finish] 버튼을 클릭합니다.\n디스크 크기 확인 link작업 완료 후 확인해보면 기존 10GB에서 20GB로 확장된 것을 알 수 있습니다.\n참고 URL link Ncloud 블록 스토리지 크기 확장 가이드\nhttps://guide.ncloud-docs.com/docs/server-storage-modify-vpc#스토리지-변경 문서 업데이트 내역 link\r날짜 내용 2022-11-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  93 ,
                href: "\/docs\/compute\/autoscaling\/service-limit\/",
                title: "Auto Scaling 서비스 제한사항",
                description: "Ncloud (네이버 클라우드) Auto Scaling 서비스를 구성할 때 제한사항에 대한 정리입니다",
                content: "개요 link모든 클라우드 서비스의 핵심 중의 하나가 Auto Scaling이라고 할 수 있습니다. 네이버 클라우드도 예외가 아닌데, Auto Scaling을 설정할 때 몇가지 제한사항이 있어서 정리해보았습니다.\n스펙 및 서비스 환경 제한 사항 link서버 스펙이나 서비스 환경과 관련한 제한 사항은 다음과 같습니다.\n총 디스크 사이즈 150GB 이하 서버만 가능 Micro 서버는 불가 GPU 서버는 불가 베어메탈 서버는 불가 따라서 서버타입 기준으로 Auto Scaling 설정이 가능한 서버타입은 다음과 같습니다.\nClassic : Compact, Standard VPC : High CPU, Standard, High Memory 현재 [Auto Scaling] - [Launch Configuration] 화면과 가이드에 나오는 [High Memory 타입은 지원되지 않습니다]는 예전 메시지로 조만간 삭제될 예정이라고 합니다.\rOS 서버 이미지 제한 사항 linkcentos-7.8-64, ubuntu-18.04 이 2가지 OS 이미지는 개인 회원은 KR-1 1세대 서버에서 생성이 불가능한 이미지입니다. 2세대 서버를 선택하시거나 KR-2에서 생성해야 합니다.\n설정 제한 사항 link다음으로 Auto Scaling 설정을 할 때 생성 가능한 최대 서버 수 등의 설정 제한 사항은 다음과 같습니다.\n고객별 생성 가능한 Auto Scaling Group 최대 수: 100 고객별 생성 가능한 Launch Configuration 최대 수: 100 Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100 Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10 Auto Scaling Group당 생성 가능한 최대 서버 수: 30대 Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10 계정당 생성 가능한 최대 서버 대수 : 네이버 클라우드에서 한 계정당 생성할 수 있는 최대 서버 수 기본 50대입니다. 서버 수 한도를 조정하려면 고객지원으로 문의해야 합니다.\r참고 URL link Ncloud AutoScaling 기본 가이드\nhttps://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview 문서 업데이트 내역 link\r날짜 내용 2021-07-01 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  94 ,
                href: "\/docs\/compute\/autoscaling\/basic-guide-vpc\/",
                title: "VPC 환경에서 Auto Scaling 설정하는 방법",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 Auto Scaling 설정하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) VPC 환경에서 AutoScaling 설정하는 방법을 정리해보겠습니다.\nAutoScaling 서비스는 미리 등록한 설정에 따라 서버 수를 자동으로 증가 또는 감소시켜 안정적인 서비스를 유지하면서 비용을 절감할 수 있도록 해주는 서비스입니다.\n그런데, 언제 서버 수를 증가, 감소 시킬 것인 가에 대한 이벤트 설정이 Classic 환경의 경우 오토스케일 그룹에 속한 서버들의 평균값을 기준으로 하지만, VPC 환경의 경우 이 방법 말고도 특정 서버를 지정해서 해당 서버를 기준으로 이벤트 설정을 할 수도 있습니다.\n그래서 여기서는 사전에 준비된 서버를 기준으로 AutoScaling이 작동되는 것을 살펴보겠습니다.\n기준 서버 생성 linkAutoScaling 이벤트 설정의 기준이 되는 서버 1대를 아래와 같이 미리 생성하겠습니다.\n설정 순서 linkAuto Scaling 설정 순서를 요약하면 다음과 같습니다.\nAuto Scaling Launch Configuration 설정 Auto Scaling Group 설정 Cloud Insight Monitoring Event Rule 설정 Launch Configuration 설정 linkAuto Scaling 설정은 우선 [Auto Scaling] - [Launch Configuration]에서 [Launch Configuration 생성] 버튼을 클릭하는 것으로 시작합니다.\n서버 이미지 선택 link서버 이미지는 Ncloud(네이버 클라우드) 에서 제공하는 기본 이미지를 선택할 수도 있고, 기존에 사용하던 서버로 만들어 둔 [내 서버 이미지]를 사용할 수도 있습니다. 여기서는 기본 이미지를 사용하는 것으로 하겠습니다.\n현재 VPC 환경 AutoScaling에서 지원하는 Linux 서버 이미지 버전은 다음과 같습니다. ⁃ CentOS 7.3, 7.8 ⁃ Rocky Linux 8.6, 8.8 ⁃ Ubuntu 16.04, 18.04, 20.04\rWindows 서버 이미지 버전 link\r현재 AutoScaling에서 지원하는 Windows 서버 이미지 버전은 다음과 같습니다. ⁃ Windows Server 2016 64bit English Edition ⁃ Windows Server 2019 64bit English Edition\r서버 설정 link스토리지 종류와 서버 타입 등을 선택합니다.\n이름 설정 linkLaunch Configuration의 이름을 입력합니다.\n인증키 설정 link인증키는 기존에 보유하고 있던 인증키를 이용해도 되고, 새로운 인증키를 설정해도 됩니다.\n최종 확인 link지금까지 설정한 내용이 이상 없는지 최종 확인을 하고 이상 없으면 [Launch Configuration 생성] 버튼을 클릭합니다.\nAuto Scaling Group 설정 link다음으로 Auto Scaling Group을 생성합니다. [Auto Scaling] - [Auto Scaling Group]에서 [Auto Scaling Group 생성] 버튼을 클릭합니다.\nLaunch Configuration 선택 link위에서 생성했던 Launch Configuration을 선택합니다.\n그룹 설정 link여기서는 VPC와 Subnet 등의 네트워크 환경을 선택하고, 생성될 서버들의 이름과 최소, 최대 개수 등을 설정합니다.\n서버이름 Prefix : 최대7자까지 지정할 수 있고, 나머지 이름의 뒷부분은 영문,숫자의 조합으로 무작위로 자동 생성됩니다.\n서버 용량 : 최소, 최대, 기대 용량은 서버 대수를 의미하며 각각 0~30까지 입력 가능합니다.\n쿨다운 기본값 : 새로운 서버가 생성되었다고 해도, init script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. 즉, 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 반응하지 않고 무시하도록 설정한 기간입니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n헬스체크 보류기간 : 서버 인스턴스가 생성되어 상태가 ‘운영 중’으로 바뀌었더라도, 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. 이런 경우 헬스 체크 보류 기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버에 이상이 있다고 판단하지 않습니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n헬스체크 유형 : 헬스체크 유형은 [서버]와 [로드밸런서] 중에서 선택할 수 있습니다.\n로드밸런서 연결 link\rAuto Scaling으로 생성된 서버가 로드밸런서에 자동으로 연결되도록 하려면 [헬스 체크 유형]을 [로드밸런서]로 선택하고 [Target Group] 항목에서 원하는 로드밸런서의 Target Group을 선택하면 됩니다.\rVPC 환경에서 로드밸런서를 생성하는 방법은 아래 문서를 참고하시면 됩니다. ⁃ VPC 환경에서 Application Load Balancer 생성하는 방법\r네트워크 접근 설정 link네트워크 접근에 필요한 ACG를 설정하고 선택합니다.\n정책/일정 설정 link정책과 일정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있는데, 우선은 [정책 설정]에서 [서버 수 증가 정책]과 [서버 수 감소 정책]을 설정합니다.\n통보 설정 link서버가 생성될 때 또는 서버가 반납될 때 언제 통보를 받을 것인지 선택하고, 누가 언제 통보 받을 것인지 설정합니다.\n통보 대상 설정 link먼저 [통보대상 관리 그룹]을 선택하고, 다음으로 관리자와 통보 방법을 선택합니다.\n[통보대상 관리 그룹]이 설정되지 않았을 경우에는 [통보대상관리] 버튼을 클릭해 통보를 받을 대상의 그룹을 설정합니다.\n최종 확인 link지금까지 설정한 Auto Scaling Group 내역을 확인하고 이상이 없으면 [Auto Scaling Group 생성] 버튼을 클릭합니다.\nEvent Rule 설정 link지정한 서버를 모니터링 하다가 설정한 조건에 해당되면 즉, 지정한 Event가 발생하면 Auto Scaling 설정을 적용해 서버를 증가시키거나 감소시키기 위한 감시 규칙인 [Event Rule]을 설정합니다.\n서버 증가 Event Rule 생성 linkVPC에서는 [Cloud Insight]로 모니터링을 하게 되므로 Event Rule 설정도 [Cloud Insight(Monitoring)] - [Configuration] - [Event Rule]에서 [Event Rules 생성] 버튼을 클릭합니다.\n감시 상품 선택 linkCloud Insight는 Server 뿐만 아니라 Load Balancer, Object Storage도 감시할 수 있는데 여기서는 처음에 생성했던 서버를 감시할 것이니 [Server(VPC)]를 선택합니다.\n감시 대상 설정 link맨 처음에 생성했던 서버를 선택합니다.\n감시 항목 및 조건 설정 link감시 항목 설정에서 [전체 보기]를 선택하고, [SERVER] 탭에서 [Metric ID]를 [cpu]로 검색한 후 평균 CPU 사용률 항목인 [SERVER/avg_cpu_used_rto]에서 [Level]과 [Condition], [Method], [Duration]을 선택합니다.\n먼저 서버를 증가시키는 경우에 해당하는 감시 항목을 설정하겠습니다.\n아래의 설정 내용은 “평균 CPU 사용률이 1분간 50% 이상일 경우 경고 수준으로 이벤트 통보를 한다“라는 설정입니다.\n액션 설정 link앞에서 설정한 이벤트가 발생했을 경우 어떤 액션을 취할 것인지 설정하게 되는데 앞에서 [Auto Scaling Group] 설정에서 생성했던 정책을 선택하면 됩니다.\n여기서는 [CPU 사용률 50% 이상]인 경우이므로 서버를 증가시키는 정책을 선택합니다.\n최종 확인 link설정한 내용이 이상 없는지 최종 확인하고, 규칙 이름을 입력한 후에 [생성] 버튼을 클릭합니다.\n서버 감소 Event Rule 생성 link앞에서 생성한 [서버 증가 Event Rule]과 같은 방식으로 [서버 감소 Event Rule]을 생성합니다.\n아래의 설정 내용은 “평균 CPU 사용률이 1분간 10% 이하일 경우 정보 알림 수준으로 이벤트 통보를 한다“라는 설정입니다.\n액션 설정 link여기서는 [CPU 사용률 10% 이하]인 경우이므로 서버를 감소시키는 정책을 선택합니다.\n최종 확인 link설정한 내용이 이상 없는지 최종 확인하고, 규칙 이름을 입력한 후에 [생성] 버튼을 클릭합니다.\nEvent Rule 생성 완료 link서버 증가과 감소에 대한 Event Rule 2가지가 모두 생성된 것을 확인할 수 있습니다.\nStress Tool 설정 linkCPU 사용률에 따른 Auto Scaling 작동 여부를 테스트 하기 위해 서버에 Stress Tool을 설치해보겠습니다.\nEPEL 리포지토리 설정 linkStress Tool을 설치하기 위해서는 다음 명령어로 [EPEL 리포지토리]를 설정해야 합니다.\n~# yum -y install epel-release\rStress Tool 설치 link\r~# yum -y install stress\rStress Tool 실행 linkCPU 코어 개수 확인 linkCPU에 강제로 부하를 발생 시키기 위해서는 서버의 CPU 코어 개수를 확인해서 모든 코어에 부하를 발생시키는 것이 좋습니다.\nCPU 코어 개수를 확인하는 방법은 아래 명령어를 입력하면 됩니다.\n~# grep -c processor /proc/cpuinfo\r명령어 테스트 linkCPU에 부하를 주는 명령어를 테스트 해보겠습니다.\n~# stress --cpu 2 --timeout 60 --verbose\r위 옵션의 내용은 다음과 같습니다.\ncpu: 몇 개의 코어에 부하를 발생 시킬 것인가 timeout: 몇 초 동안 부하를 발생 시킬 것인가 verbose: 상세 로그를 표시 CPU 부하 발생 link부하 발생 테스트를 마쳤으니 실제 Auto Scaling 테스트를 위해 300초 즉, 5분 동안 부하를 발생 시켜보겠습니다.\n~# stress --cpu 2 --timeout 300 --verbose\r서버 증가 확인 linkStress Tool로 부하를 발생 시키고 서버 리스트를 확인해보면 아래와 같이 Auto Scaling 설정에서 지정한 대로 서버가 생성되고 있는 것을 확인할 수 있습니다.\nCPU 사용률 확인 link[Cloud Insight]에서 서버 사용률을 확인해 보면 아래와 같이 5분간 CPU 사용률이 100%까지 올라간 것을 확인할 수 있습니다.\n서버 반납 확인 linkStress Tool로 부하를 발생 시키도록 설정한 5분이 지난 후에 서버 리스트를 보면 Auto Scaling으로 생성되었던 서버가 반납되고 있는 것을 확인할 수 있습니다.\n이벤트 발생 확인 link[Cloud Insight] - [Event]에서 서버 증가, 감소 관련 이벤트가 제대로 발생했는지 아래와 같이 그래프와 리스트로 확인할 수 있습니다.\n이벤트 통보 확인 link이벤트 통보에서 설정한 대로 아래와 같이 Email로 Auto Scaling 이벤트 발생과 완료에 대한 통보 메일이 도착한 것을 확인할 수 있습니다.\n서비스 제한사항 linkAuto Scaling 설정과 서버 스펙 등에 대한 제한 사항을 정리해보겠습니다.\n스펙 및 서비스 환경 제한 사항 link 총 디스크 사이즈 150GB 이하 서버만 가능 Windows OS는 Windows 2016. 2019만 지원 내 서버 이미지의 경우, 원본 서버의 부팅 디스크 크기가 50GB인 경우만 지원(100GB 디스크에 대해서는 추후 지원 예정) 설정 제한 사항 link 고객별 생성 가능한 Auto Scaling Group 최대 수: 10 고객별 생성 가능한 Launch Configuration 최대 수: 100 Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100 Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10 Auto Scaling Group당 생성 가능한 최대 서버 수: 30대 Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10 상세 모니터링 linkNcloud(네이버 클라우드) 에서는 기본 모니터링 외에 [상세 모니터링]도 지원하는데, [상세 모니터링]에서는 좀 더 자세하고 다양한 모니터링 항목 (Extended Metric)을 지원합니다.\n예를 들어 CPU 사용과 관련한 모니터링 항목에서도 아래와 같이 [CPU idle ratio average] 항목들도 확인할 수 있습니다.\n또한, 위와 같이 [Server] 탭에서는 CPU들의 평균 값을 모니터링할 수 있는 것에 비해, 상세 모니터링을 적용하면 아래와 같이 [CPU] 탭에서 CPU 코어별로 각각 모니터링을 할 수도 있습니다.\n상세 모니터링 설정 link상세 모니터링을 적용하는 방법은 서버를 선택하고 [서버 관리 및 설정 변경] 메뉴에서 [상세 모니터링 설정 변경] 메뉴를 선택합니다.\n상세 모니터링 신청 link상세 모니터링 신청 팝업에서 [예] 버튼을 클릭하면 상세 모니터링이 적용됩니다. 상세 모니터링 신청 후 실제 데이터가 수집되기까지는 약간의 시간이 소요되므로 잠시 기다렸다 확인해보면 됩니다.\n용어 정리 linkAuto Scaling에서 사용되는 주요 용어들을 정리해보겠습니다.\n용어 설명 Scale-in / Scale-out Auto Scaling Group을 생성하여 고객이 설정한 Policy에 따라 사용하고 있는 가상 서버의 자동 확장(Scale-out) 및 자동 축소(Scale-in)하도록 제공합니다. Auto Scaling Group 여러 개의 서버 인스턴스들을 Auto Scaling Group 이라는 하나의 그룹으로 묶어 놓게 됩니다. Launch Configuration Auto Scaling Group에서 가상 서버를 시작 구성하는 데 사용하는 템플릿입니다. Auto Scaling Group을 생성할 때는 Launch Configuration을 지정해야 합니다. Auto Scaling Group의 최소 용량/최대 용량 Auto Scaling Group의 최소/최대 서버 수를 말합니다. 최소 서버 수의 경우, 항상 이 값과 같거나 이 값보다 더 큰 서버 수가 유지됩니다. 서버를 한 대도 보유하지 않을 수 있게 하려면 0으로 설정합니다. 기대 용량 (Desired Capacity) 서버의 수는 기대 용량값에 따라서 조정됩니다. 이 값은 최소 용량 이상, 최대 용량 이하여야 합니다. 이 값이 지정되어 있지 않으면 초기에 최소 용량만큼 서버를 생성합니다. 쿨다운 기본값(초) (Default Cooldown) Default Cooldown(초) 새로운 서버가 생성되었다고 해도, Init-Script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 무시하도록 설정한 기간입니다. 헬스체크 Auto Scaling Group의 가상 서버에 주기적인 상태 확인을 수행하여 상태가 비정상인 가상 서버를 식별하도록 Health Check를 합니다. 헬스체크 보류 기간 서버가 생성되어 ‘운영중’으로 변경되었더라도 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. 이런 경우 헬스 체크 보류기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버 헬스에 이상이 있다고 판단하지 않습니다. 헬스체크 유형 서버와 Load Balancer 둘 중에 선택할 수 있습니다. Auto Scaling Group 설정에서 Load Balancer 이름을 지정한 경우에는 헬스 체크 유형 역시 Load Balancer로 설정합니다. 이런 경우 Auto Scaling은 Load Balancer 헬스 체크 방식과 기준에 따라 서버의 상태를 판단합니다. 반납 정책 Auto Scaling 과정에서 추가된 서버에 대한 Scale-in 작업에 대해, 고객이 API 질의 형식으로먼저 반납할 서버를 지정할 수 있습니다. 기본 설정은 먼저 생성된 서버부터 반납합니다. Policy Auto Scaling이 일어나는 방식을 정의하고 있는데, 이를 ‘Policy’로 정의하고 있습니다. Auto Scale-out 이 발생할 때, 몇 대의 가상 서버를 늘릴 것인지, 반대로 Scale-in이 발생할 때 몇 대의 가상서버를 줄일 것인지를 정의합니다. 대수로 정의할 수 도 있고, %로 정의할 수도 있습니다. Basic Metric 기본적으로 제공되는 모니터링 항목 Extended Metric 상세모니터링을 신청하면 제공되는 모니터링 항목 참고 URL link Ncloud(네이버 클라우드) Auto Scaling 가이드\nhttps://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview\nClassic 환경에서 Auto Scaling 설정하기\n"
            }
        );
    index.add(
            {
                id:  95 ,
                href: "\/docs\/compute\/autoscaling\/basic-guide-classic\/",
                title: "Classic 환경에서 Auto Scaling 설정하는 방법",
                description: "Ncloud(네이버 클라우드) Classic 환경에서 Auto Scaling 설정하는 방법입니다",
                content: "개요 linkAutoScaling 서비스는 미리 등록한 설정에 따라 서버 수를 자동으로 증가 또는 감소시켜 안정적인 서비스를 유지하면서 비용을 절감할 수 있도록 해주는 서비스입니다.\n여기서는 네이버 클라우드 Classic 환경에서 AutoScaling 설정하는 방법을 정리해보겠습니다.\n기본 설정 linkAuto Scaling 설정은 우선 [Auto Scaling] - [Launch Configuration]에서\n[Launch Configuration 생성] 버튼을 클릭하는 것으로 시작합니다.\n서버 이미지 선택 link서버 이미지는 네이버 클라우드에서 제공하는 기본 이미지를 선택할 수도 있고, 기존 서버로 만들어 둔 [내 서버 이미지]를 사용할 수도 있습니다. 여기서는 기본 이미지를 사용하는 것으로 하겠습니다.\n현재 Classic 환경 AutoScaling에서 지원하는 Linux 서버 이미지 버전은 다음과 같습니다. ⁃ CentOS 7.3, 7.8 ⁃ Ubuntu 18.04\r서버 설정 link스토리지 종류와 서버 타입 등을 선택합니다.\n이름 설정 linkLaunch Configuration의 이름을 입력합니다.\n인증키 설정 link인증키는 기존에 보유하고 있던 인증키를 이용해도 되고, 새로운 인증키를 설정해도 됩니다.\n네트워크 접근 설정 (ACG) linkACG 설정도 기존에 보유하고 있던 ACG 중에서 선택해도 되고, 새로운 ACG를 생성해도 됩니다. 여기서는 새로운 ACG를 생성하는 방법으로 진행하겠습니다.\nACG 이름을 입력하고, [myIp]를 클릭, 허용할 포트를 입력한 후 [추가] 버튼을 클릭합니다.\n최종 확인 link지금까지 설정한 정보를 마지막으로 확인 한 후에 이상이 없으면 [Launch Configuration 생성] 버튼을 클릭합니다.\nGroup 생성 link다음으로 Auto Scaling Group을 생성합니다. [Auto Scaling] - [Auto Scaling Group]에서 [Auto Scaling Group 생성] 버튼을 클릭합니다.\nLaunch Configuration 선택 link위에서 생성했던 Launch Configuration을 선택합니다.\n그룹 설정 link여기서는 생성될 서버들의 이름과 최소, 최대 개수 등을 설정합니다.\nAuto Scaling Group당 최대 30대의 서버를 생성할 수 있고, Zone, NAT Gateway 설정은 생성 후 변경할 수 없으며, 변경이 필요하면 새로 생성하여 사용해야 합니다.\n서버이름 Prefix : 최대7자까지 지정할 수 있고, 나머지 이름의 뒷부분은 영문,숫자의 조합으로 무작위로 자동 생성됩니다.\n서버 용량 : 최소, 최대, 기대 용량은 서버 대수를 의미하며 각각 0~30까지 입력 가능합니다.\n쿨다운 기본값 : 새로운 서버가 생성되었다고 해도, init script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. 즉, 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 반응하지 않고 무시하도록 설정한 기간입니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n헬스체크 보류기간 : 서버 인스턴스가 생성되어 상태가 ‘운영 중’으로 바뀌었더라도, 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. 이런 경우 헬스 체크 보류 기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버에 이상이 있다고 판단하지 않습니다.\n값을 입력하지 않으면 기본값인 300초가 적용됩니다.\n정책/일정 설정 link정책과 일정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있습니다. 여기서는 [나중에 설정]으로 선택하고 아래쪽에서 다시 살펴보겠습니다.\n통보 설정 link통보 설정을 여기서 바로 설정할 수도 있고 나중에 설정할 수도 있습니다. 여기서는 [나중에 설정]으로 선택하고 아래쪽에서 다시 살펴보겠습니다.\n최종확인 link생성된 Group 설정값들을 마지막으로 확인하고 [Auto Scaling Group 생성] 버튼을 클릭합니다.\n서버 생성 확인 link위에서 Auto Scaling Group을 생성하면 아래와 같이 즉시 서버가 생성되는 것을 확인할 수 있습니다. 처음에는 [기대용량]에 입력한 개수만큼 서버가 생성됩니다.\n설정 관리 - 정책 link위에서 나중에 설정하기로 하고 넘어갔던 Auto Scaling Group의 정책, 일정, 이력, 통보 설정 등을 확인해보겠습니다.\n[Auto Scaling Group]에서 해당 그룹을 선택하고, [설정 및 관리] 버튼을 클릭합니다.\n정책 설정 link먼저 [정책] 탭을 선택하고, [생성] 버튼을 클릭합니다.\n우선 서버를 증가시킬 정책으로 increase라는 이름을 입력하고, 증가시킬 서버 개수를 입력 후 [추가] 옵션을 선택하고 [생성] 버튼을 클릭합니다.\n다음으로 서버를 감소시킬 정책으로 decrease라는 이름을 입력하고, 감소시킬 서버 개수를 입력 후 [반납] 옵션을 선택하고 [생성] 버튼을 클릭합니다.\n서버 증가, 감소를 위한 정책 2가지가 생성된 것을 확인할 수 있습니다.\n그룹 이벤트 설정 link위에서 설정한 정책이 언제 실행되게할 것인가 즉, 서버에 어떤 이벤트가 발생했을 때 정책을 실행할 것인가를 결정하는 그룹 이벤트를 설정합니다.\n그룹 이벤트 설정은 [Classic] - [Monitoring] - [Group Event Setting]에서 할 수 있으며, 위에서 만든 Auto Scaling 그룹을 선택하고 [그룹 이벤트 설정] 버튼을 클릭합니다.\n그룹 이벤트 설정 화면에 들어가면 위에서 만든 increase, decrease 2가지 정책이 리스트에 나타나는 것을 확인할 수 있습니다.\n정책이 발동되게 하는 이벤트는 여러가지가 있는데, 가장 많이 선택하는 것이 CPU 사용률입니다.\n여기서는 CPU 사용률(used)이 60% 이상일 때 increase 정책, CPU 사용률(used)이 30% 이하일 때 decrease 정책이 실행되도록 이벤트를 추가했습니다.\n설정 관리 - 일정 link위에서는 서버에 설정한 이벤트가 발생했을 때 정책이 발동되도록 했지만, 그 외에도 특정한 시간대에 사용자가 몰리는 피크 타임이 일정하다면 해당 시간 전후로 서버를 늘리거나 감소시키는 방법도 가능합니다.\n여기 [일정] 탭에서 해당 내용을 설정해두면 피크 타임에 미리 서버를 증가시켜서 좀 더 안정적인 서비스가 가능하게 설정할 수 있습니다.\n설정 관리 - 이력 link[이력] 탭에서는 서버가 생성되고 반납된 기록을 확인할 수 있습니다.\n설정 관리 - 통보 link[통보] 탭에서는 서버가 생성되거나 반납될 때 지정한 담당자에게 SMS나 Email로 통보하도록 설정할 수 있습니다.\n설정 관리 - 서버 link[서버] 탭은 현재 작동중인 서버 리스트를 확인할 수 있습니다.\n중지 - 서버삭제 link마지막으로, Auto Scaling을 중지하고, 작동중인 서버를 한번에 모두 삭제하는 방법을 확인해보겠습니다.\n[Auto Scaling] - [Auto Scaling Group]에서 해당 그룹을 선택하고 상단에 있는 [수정] 버튼을 클릭합니다.\n여기서 [최소 용량], [최대 용량], [기대 용량] 항목의 값을 모두 0으로 설정하면, 현재 작동중인 서버가 모두 반납되고, 더 이상 서버가 추가로 생성되지 않아서 Auto Scaling이 중지되게 됩니다.\n사실 [최소 용량], [기대 용량] 2가지 항목만 0으로 설정해도 되지만, 혹시나 모르는 상황을 위해서 깔끔하게 3가지 항목 모두 0으로 설정합니다.\n서비스 제한사항 linkAuto Scaling 설정과 서버 스펙 등에 대한 제한 사항을 정리해보겠습니다.\n스펙 및 서비스 환경 제한 사항 link 총 디스크 사이즈 150GB 이하 서버만 가능 Windows OS는 Windows 2016. 2019만 지원 내 서버 이미지의 경우, 원본 서버의 부팅 디스크 크기가 50GB인 경우만 지원(100GB 디스크에 대해서는 추후 지원 예정) 설정 제한 사항 link 고객별 생성 가능한 Auto Scaling Group 최대 수: 10 고객별 생성 가능한 Launch Configuration 최대 수: 100 Auto Scaling Group당 생성 가능한 스케줄(Scheduled Action) 최대 수: 100 Auto Scaling Group당 생성 가능한 Scaling Policy 최대 수: 10 Auto Scaling Group당 생성 가능한 최대 서버 수: 30대 Auto Scaling Group당 연결 가능한 Load Balancer 최대 수 : 10 용어 정리 linkAuto Scaling에서 사용되는 주요 용어들을 정리해보겠습니다.\n용어 설명 Scale-in / Scale-out Auto Scaling Group을 생성하여 고객이 설정한 Policy에 따라 사용하고 있는 가상 서버의 자동 확장(Scale-out) 및 자동 축소(Scale-in)하도록 제공합니다. Auto Scaling Group 여러 개의 서버 인스턴스들을 Auto Scaling Group 이라는 하나의 그룹으로 묶어 놓게 됩니다. Launch Configuration Auto Scaling Group에서 가상 서버를 시작 구성하는 데 사용하는 템플릿입니다. Auto Scaling Group을 생성할 때는 Launch Configuration을 지정해야 합니다. Auto Scaling Group의 최소 용량/최대 용량 Auto Scaling Group의 최소/최대 서버 수를 말합니다. 최소 서버 수의 경우, 항상 이 값과 같거나 이 값보다 더 큰 서버 수가 유지됩니다. 서버를 한 대도 보유하지 않을 수 있게 하려면 0으로 설정합니다. 기대 용량 (Desired Capacity) 서버의 수는 기대 용량값에 따라서 조정됩니다. 이 값은 최소 용량 이상, 최대 용량 이하여야 합니다. 이 값이 지정되어 있지 않으면 초기에 최소 용량만큼 서버를 생성합니다. 쿨다운 기본값(초) (Default Cooldown) Default Cooldown(초) 새로운 서버가 생성되었다고 해도, Init-Script 실행이나 업데이트 설치 등의 이유로 실제 서비스를 수행할 수 있을 정도로 준비되기까지는 시간이 소요될 수 있습니다. 쿨다운(Cooldown) 시간이란 실제 Scaling이 수행 중이거나 수행 완료된 이후에 모니터링 이벤트 알람이 발생하더라도 무시하도록 설정한 기간입니다. 헬스체크 Auto Scaling Group의 가상 서버에 주기적인 상태 확인을 수행하여 상태가 비정상인 가상 서버를 식별하도록 Health Check를 합니다. 헬스체크 보류 기간 서버가 생성되어 ‘운영중’으로 변경되었더라도 서버의 업데이트 설치 등 작업에 의해서 헬스 체크에 정상 응답하지 못하는 경우가 생길 수 있습니다. 이런 경우 헬스 체크 보류기간을 지정하면 해당 기간 동안에는 헬스 체크에 실패하더라도 서버 헬스에 이상이 있다고 판단하지 않습니다. 헬스체크 유형 서버와 Load Balancer 둘 중에 선택할 수 있습니다. Auto Scaling Group 설정에서 Load Balancer 이름을 지정한 경우에는 헬스 체크 유형 역시 Load Balancer로 설정합니다. 이런 경우 Auto Scaling은 Load Balancer 헬스 체크 방식과 기준에 따라 서버의 상태를 판단합니다. 반납 정책 Auto Scaling 과정에서 추가된 서버에 대한 Scale-in 작업에 대해, 고객이 API 질의 형식으로먼저 반납할 서버를 지정할 수 있습니다. 기본 설정은 먼저 생성된 서버부터 반납합니다. Policy Auto Scaling이 일어나는 방식을 정의하고 있는데, 이를 ‘Policy’로 정의하고 있습니다. Auto Scale-out 이 발생할 때, 몇 대의 가상 서버를 늘릴 것인지, 반대로 Scale-in이 발생할 때 몇 대의 가상서버를 줄일 것인지를 정의합니다. 대수로 정의할 수 도 있고, %로 정의할 수도 있습니다. 참고 URL link Ncloud(네이버 클라우드) Auto Scaling 가이드\nhttps://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview\nVPC 환경에서 Auto Scaling 설정하기\n"
            }
        );
    index.add(
            {
                id:  96 ,
                href: "\/docs\/compute\/autoscaling\/event-setting-guide\/",
                title: "Auto Scaling Group 이벤트 설정하는 방법",
                description: "Ncloud(네이버 클라우드) 서버에서 Auto Scaling Group 이벤트를 설정하는 방법입니다",
                content: "개요 link네이버 클라우드에서 AutoScaling을 설정할 때 중요한 것이 이벤트 설정입니다.\n예를 들어 CPU 사용률이 70%가 넘는 상태가 1분 이상 지속되면 서버를 늘리는 작업이 진행되도록 설정한다고 할 때, CPU가 70% 이상인 상태가 1분 이상 지속되는 이벤트가 발생하는지 체크하는 것을 말합니다.\n현재 네이버 클라우드 Console에서는 AutoScaling 그룹을 생성한 후에 바로 이 이벤트 설정을 하는 방법에 대한 메뉴나 링크가 없어서 그에 대한 내용을 정리해보겠습니다.\nAutoScaling Group 생성 linkAutoScaling 이벤트를 설정하려면 우선 AutoScaling Group을 생성해야 합니다.\nConsole - Auto Scaling - Auto Scaling Group 메뉴에서 설정할 수 있습니다.\nAutoScaling Group을 설정한 후에는 AutoScaling Group Event를 설정해야 하니 해당 기능이 있는 메뉴로 이동할 수 있도록 버튼이나 링크가 생겼으면 합니다.\nAutoScaling Group Event 설정 linkAutoScaling의 그룹 이벤트를 설정하는 곳은 Monitoring 메뉴에 있습니다.\nCPU 사용량 등의 서버 상태를 확인해야 하는 것이다 보니 Console - Monitoring - Group Event Setting 메뉴에서 관련된 이벤트 설정을 할 수 있습니다.\n아래 스샷에서 확인할 수 있듯이 앞에서 생성한 AutoScaling Group이 나타납니다. 만약 AutoScaling Group을 생성하지 않았다면 여기서는 아무런 설정도 할 수 없습니다.\n혹시 AutoScaling Group이 생성되지 않은 상태에서 이 메뉴에 들어오는 경우에는 AutoScaling Group 생성 페이지로 이동하는 버튼이나 링크가 추가되길 바랍니다.\n참고 URL link Ncloud AutoScaling 기본 가이드\nhttps://guide.ncloud-docs.com/docs/compute-autoscaling-autoscalingoverview 문서 업데이트 내역 link\r날짜 내용 2021-01-19 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  97 ,
                href: "\/docs\/compute\/lamp\/config-basic\/",
                title: "Ncloud LAMP 기본 환경 설정 정보",
                description: "Ncloud (네이버 클라우드) Classic 환경에서 제공하는 Application 이미지 중에서 LAMP의 기본 환경 설정 정보입니다",
                content: "LAMP 기본설정 linkNcloud(네이버 클라우드 플랫폼, 이하 네이버 클라우드)에서 제공하는 Application중에서 가장 대표적인 LAMP(Linux + Apache, Mysql|MariaDB, PHP)의 기본설정입니다.\nLAMP Application이미지는 Classic 환경에서만 이용 가능합니다.\rLAMP 홈디렉토리 link네이버 클라우드에서 Linux 서버를 세팅하게 되면 기본적으로 root 계정으로 접속이 됩니다. 그래서 LAMP 서비스의 홈디렉토리도 /root/lamp로 설정됩니다.\nLAMP 서비스 홈디렉토리 : /root/lamp\rLAMP 서비스 전체 재시작 link네이버 클라우드에서는 LAMP 전체 서비스를 빠르게 재시작할 수 있는 기능을 제공하고 있습니다.\nLAMP 서비스 전체 재시작 명령 : /root/lamp/lamp_restart.sh\r위 명령을 실행하면 Apache 와 mysql이 순서대로 재시작됩니다.\nLAMP 서비스 설치 상태 확인 link네이버 클라우드에서는 LAMP 서비스들의 설치 정보를 확인할 수 있는 기능도 제공하고 있습니다.\nLAMP 설치 상태와 정보 확인 명령 : /root/lamp/lamp_info.sh\r위 명령을 실행하면 LAMP의 기본 웹사이트 경로, 웹사이트 기본 디렉토리, mysql 초기 비번 안내, Apache 버전, mysql 버전, PHP와 Zend 버전 정보 등을 확인할 수 있습니다.\nLAMP 웹사이트 기본 디렉토리 link네이버 클라우드에서 제공하는 LAMP의 웹사이트 기본 디렉토리 위치는 다음과 같습니다.\n웹사이트 기본 디렉토리 : /ncp/data/www\r참고 URL link Ncloud Classic 환경 LAMP 가이드\nhttps://guide.ncloud-docs.com/docs/ko/server-lamp 문서 업데이트 내역 link\r날짜 내용 2020-12-03 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  98 ,
                href: "\/docs\/compute\/lamp\/config-ubuntu\/",
                title: "Ncloud LAMP 기본 명령어와 환경 설정 파일 위치 | Ubuntu",
                description: "Ncloud (네이버 클라우드) LAMP(Ubuntu) 기본 명령어와 환경 설정 파일 위치입니다",
                content: "Apache 시작, 중지, 재시작 linkApache 시작, 중지, 재시작 명령어는 OS별로 조금씩 다른데 Ubuntu의 경우에는 systemctl [stop|start|restart] {서비스명} 의 순서로 되어 있습니다.\nUbuntu link\r- 중지 : systemctl stop apache2\r- 시작 : systemctl start apache2\r- 재시작 : systemctl restart apache2\rmysql 시작, 중지, 재시작 linkmysql 시작, 중지, 재시작 명령어도 Apache와 마찬가지로 systemctl [stop|start|restart] {서비스명} 의 순서로 되어 있습니다.\nUbuntu link\r- 중지 : systemctl stop mysql\r- 시작 : systemctl start mysql\r- 재시작 : systemctl restart mysql\rApache 환경 설정 파일 linkApache의 기본 환경설정 파일은 CentOS의 경우 httpd.conf라는 파일로 간단하게 구성되어 있는데 Ubuntu의 경우에는 포트, 가상호스트, 로그 등 각각의 항목별로 파일이 나뉘어져 있습니다.\nUbuntu link\r- 기본 설정 : /etc/apache2/apache2.conf\r- 포트 설정 : /etc/apache2/ports.conf\r- 가상호스트 설정: /etc/apache2/sites-enabled/000-default.conf -\u003e /etc/apache2/sites-available/000-default.conf\r- 로그 : /var/log/apache2\r- 기타 옵션 설정 :\r/etc/apache2/mods-enabled/*.load -\u003e /etc/apache2/mods-available/*.load\r/etc/apache2/mods-enabled/*.conf -\u003e /etc/apache2/mods-available/*.conf\rPHP 환경 설정 파일 linkPHP의 환경 설정파일인 php.ini는 PHP버전에 해당 하는 디렉토리에 위치하고 있습니다.\nphp.ini : /etc/php/7.2/apache2/php.ini\rmysql 환경 설정 파일 linkmysql 환경 설정파일인 my.cnf는 OS버전과 관계없이 /etc/mysql/my.cnf 에 위치하고 있으며, 실제로는 /etc/alternatives/my.cnf로 링크되어 있습니다.\nmy.cnf : /etc/mysql/my.cnf -\u003e /etc/alternatives/my.cnf\r참고 URL link Ncloud Classic 환경 LAMP 가이드\nhttps://guide.ncloud-docs.com/docs/ko/server-lamp 문서 업데이트 내역 link\r날짜 내용 2020-11-13 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  99 ,
                href: "\/docs\/compute\/lamp\/config-centos\/",
                title: "Ncloud LAMP 기본 명령어와 환경 설정 파일 위치 | CentOS",
                description: "Ncloud (네이버 클라우드) LAMP(CentOS) 기본 명령어와 환경 설정 파일 위치입니다",
                content: "Apache 시작, 중지, 재시작 linkApache 시작, 중지, 재시작 명령어는 CentOS 6에서 사용하던 것이 CentOS 7이 되면서 변경되었습니다. CentOS 6.x 이하에서는 service {서비스명} [stop|start|restart] 순서였다면 CentOS 7.X 에서는 systemctl [stop|start|restart] {서비스명} 의 순서로 바뀌었습니다. 내용을 정리하면 다음과 같습니다.\nCentOS 6.x 이하 link\r- 중지 : service httpd stop\r- 시작 : service httpd start\r- 재시작 : service httpd restart\rCentOS 7.x link\r- 중지 : systemctl stop httpd\r- 시작 : systemctl start httpd\r- 재시작 : systemctl restart httpd\rmysql 시작, 중지, 재시작 linkmysql도 Apache와 마찬가지 방식으로 CentOS 6 이하와 CentOS 7에서 사용하는 명령어가 변경되었습니다.\nCentOS 6.x 이하 link\r- 중지 : service mysqld stop\r- 시작 : service mysqld start\r- 재시작 : service mysqld restart\rCentOS 7.x link\r- 중지 : systemctl stop mysqld\r- 시작 : systemctl start mysqld\r- 재시작 : systemctl restart mysqld\rApache 환경 설정 파일 linkApache의 환경 설정 파일은 CentOS의 버전과 관계없이 모두 동일합니다.\nhttpd.conf : /etc/httpd/conf/httpd.conf\rPHP 환경 설정 파일 linkPHP의 환경 설정파일인 php.ini는 PHP버전에 해당 하는 디렉토리에 위치하고 있습니다.\nphp.ini : /etc/php/7.2/apache2/php.ini\rmysql 환경 설정 파일 linkmysql 환경 설정파일인 my.cnf는 OS버전과 관계없이 /etc/mysql/my.cnf 에 위치하고 있으며, 실제로는 /etc/alternatives/my.cnf로 링크되어 있습니다.\nmy.cnf : /etc/mysql/my.cnf -\u003e /etc/alternatives/my.cnf\r참고 URL link Ncloud Classic 환경 LAMP 가이드\nhttps://guide.ncloud-docs.com/docs/ko/server-lamp 문서 업데이트 내역 link\r날짜 내용 2020-11-13 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  100 ,
                href: "\/docs\/compute\/nginx\/install-setting-guide-rocky-linux\/",
                title: "Rocky Linux에서 NginX 설치, 설정하는 방법",
                description: "Ncloud (네이버 클라우드) Rocky Linux 서버에 NginX를 Package로 설치하고 기본 설정을 하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) Rocky Linux (록키 리눅스) 서버에 NginX 최신 버전을 Package로 설치하고 기본 설정을 하는 방법에 대한 내용을 정리해보겠습니다.\n서버 환경 link\r⁃ OS: Rocky Linux 8.6 ⁃ NginX: NginX 1.23.1 ⁃ 테스트 사이트: nginx-test.com\r서버 준비 linkNcloud 콘솔에서 Rocky Linux 8.6 서버를 아래와 같이 준비했습니다.\n패키지 업데이트 link우선 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 해보겠습니다.\n~# dnf -y upgrade-minimal\rinfo\rdnf: Dandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 Fedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\n리포지토리 설정 파일 추가 linkNginX 최신버전(mainline)을 설치하기 위해서는 epel-release 리포지토리 패키지가 필요하고, epel-release 리포지토리 패키지를 설치하기 위해서는 Extras 저장소 설정 파일이 필요합니다.\n우선, Extras 저장소 설정 파일을 준비합니다. 이미 생성되어 있는 경우에는 다음 단계로 넘어가도 되고, 그렇지 않을 경우 아래와 같은 내용으로 파일을 생성합니다.\n~# vi /etc/yum.repos.d/Rocky-Extras.repo\r# Rocky-Extras.repo\r[extras]\rname=Rocky Linux $releasever - Extras\r#mirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch\u0026repo=extras-$releasever\rbaseurl=http://repo.ncloud.com/rocky/$releasever/extras/$basearch/os/\rgpgcheck=1\renabled=1\rcountme=1\rgpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\rEPEL 저장소 패키지 설치 link다음으로 epel-release 저장소 패키지를 설치하겠습니다.\n~# dnf -y install epel-release\rNginX 버전 선택 link설치할 NginX 버전 버전을 선택합니다.\nNginX 버전 리스트 link우선, Ncloud Rocky Linux 8.6에서 지원하는 NginX 버전을 확인합니다.\n리스트를 살펴보면 1.14가 기본 버전인 것을 알 수 있습니다.\n~# dnf module list nginx\rnginx 1.14 (default) nginx 1.16 nginx 1.18 nginx 1.20 nginx mainline 버전 활성화 정보 초기화 link다음으로 위에서 확인했던 nginx 버전 활성화 정보를 초기화 합니다. 현재 활성화 된 버전이 존재하느냐에 따라 나타나는 메시지가 다릅니다.\n~# dnf module reset nginx\r활성화 된 버전이 없을 때 활성화 된 버전이 있을 때 mainline 버전 활성화 link최신 버전인 mainline 버전을 활성화합니다.\n~# dnf module enable nginx:mainline\rNginX는 stable, mainline 두가지 버전이 있습니다. NginX의 공식 설명에 따르면 버그 수정이나 보안 패치 등은 항상 mainline 버전에 먼저 적용되기 때문에 mainline을 사용하는 것을 추천한다고 합니다. stable 버전을 사용하는 주된 경우는 third-party 모듈을 사용하고 있어서 신규 버전에서 호환성 문제가 발생할 가능성이 걱정될 때라고 합니다.\rNginX 설치 linkNginX를 설치합니다. 설치된 버전은 다음과 같습니다.\n~# dnf -y install nginx\r~# nginx -v\rNginX: 1.23.1 디렉토리 설정 link다음으로 홈으로 사용할 디렉토리를 생성하고, 해당 디렉토리의 소유권을 설정하겠습니다.\n그리고, NginX가 정상 작동하는지 확인해보기 위해 설치시에 포함된 index.html을 포함한 파일들을 홈 디렉토리로 복사합니다.\n# 테스트 사이트 홈 디렉토리 생성\r~# mkdir -p /ncloud/data/www/nginx-test/\r# 해당 디렉토리에 nginx에 권한 부여\r~# chown -R nginx:nginx /ncloud/data/www/nginx-test\r# nginx 샘플 페이지를 사이트 디렉토리로 복사\r~# cp /usr/share/nginx/html/*.* /ncloud/data/www/nginx-test/\r# 복사된 파일들 확인\r~# ls -al /ncloud/data/www/nginx-test/\r환경 설정 link설정 파일 위치 linkNginX 환경 설정 파일의 위치는 /etc/nginx/ 디렉토리입니다. tree 명령으로 해당 디렉토리에서 conf와 관련된 파일 리스트와 디렉토리 구조를 확인하면 다음과 같습니다.\n~# tree -P *conf* /etc/nginx/\r기본 설정 파일 link위에서 확인할 수 있는 파일들 중에서 기본 환경 설정 파일은 /etc/nginx/nginx.conf 입니다.\nnginx.conf 파일을 열어보면 아래와 같이 **server {…}**로 시작되는 사이트 설정에 관련된 부분도 있지만,\ninclude /etc/nginx/conf.d/*.conf 와 같이 conf.d 디렉토리에 있는 설정 파일을 모두 불러오도록 되어 있습니다.\n물론, 사이트 설정을 nginx.conf 파일에 직접 설정해도 되지만, 여러 개의 사이트를 설정해야 하는 경우도 생각해서 conf.d 디렉토리에 사이트 이름별로 환경 설정 파일을 별도로 만들어서 진행하도록 하겠습니다.\n~# vi /etc/nginx/nginx.conf\r기본 설정 주석 처리 linkserver {…} 부분을 모두 주석 처리합니다.\n환경 설정 파일 생성 linknginx-test.com 이라는 도메인의 사이트 설정을 nginx-test.conf 설정 파일을 생성해서 저장합니다.\n~# vi /etc/nginx/conf.d/nginx-test.conf\rserver {\rlisten 80;\rlisten [::]:80;\r# 사이트 도메인 설정\rserver_name nginx-test.com www.nginx-test.com;\r# 홈 디렉토리, 기본 문서 설정\rroot /ncloud/data/www/nginx-test;\rindex index.html index.htm;\r# 404 error 페이지 설정\rerror_page 404 /404.html;\rlocation = /404.html {\r}\r# 50x error 페이지 설정\rerror_page 500 502 503 504 /50x.html;\rlocation = /50x.html {\rroot /ncloud/data/www/nginx-test;\r}\r# .htaccess 파일 접근 금지 설정\rlocation ~ /\\.ht {\rdeny all;\r}\r}\rNginX 실행 link설정을 모두 마쳤으면 NginX를 시작하고 상태를 확인합니다.\n~# systemctl enable nginx\r~# systemctl start nginx\r~# systemctl status nginx\rhosts 파일 수정 link지금과 같이 테스트용으로 임의 설정한 도메인(nginx-test.com)으로 접속하게 될 경우에는 hosts 파일을 수정해야 합니다.\n실제 도메인을 사용할 경우에는 아래 과정이 필요 없기에 다음 단계로 바로 이동하시면 됩니다.\n윈도우 10에서 hosts 파일은 C:\\Windows\\System32\\drivers\\etc 에 존재하는데 직접 수정할 수가 없으므로 다음과 같은 단계를 거쳐야 합니다.\nC:\\Windows\\System32\\drivers\\etc\\hosts 파일을 임의의 작업 폴더 (예: D:\\Work)로 복사합니다. 복사한 hosts 파일을 수정해서 123.456.789.123 nginx-test.com 처럼 접속할 IP 주소와 도메인을 추가합니다. 수정한 파일을 C:\\Windows\\System32\\drivers\\etc 위치로 덮어쓰기 합니다. 덮어쓰기 할 때 관리자 권한이 필요하다는 안내 메시지가 나타나면 [계속] 버튼을 클릭합니다. 사이트 접속 linkNginX가 정상 작동하면 아래와 같이 서버 접속 화면을 확인할 수 있습니다.\n참고 URL link Rocky Linux NginX 설치 기본 가이드\nhttps://docs.rockylinux.org/guides/web/nginx-mainline/\nRocky Linux NginX Multi Site 설치 가이드\nhttps://docs.rockylinux.org/guides/web/nginx-multisite/\n문서 업데이트 내역 link\r날짜 내용 2023-06-29 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  101 ,
                href: "\/docs\/compute\/nginx\/install-setting-guide-ubuntu\/",
                title: "Ubuntu에서 NginX 설치, 설정하는 방법",
                description: "Ncloud (네이버 클라우드) Ubuntu 서버에 NginX를 Package로 설치하고 기본 설정을 하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) Ubuntu 서버에 NginX 최신 버전을 Package로 설치하고 기본 설정을 하는 방법에 대한 내용을 정리해보겠습니다.\n서버 환경 link\r⁃ OS: Ubuntu 20.04 ⁃ NginX: NginX 1.21.6\rNginX Signing Key 설정 linkNginX Package 설치에 필요한 Signing Key를 설정합니다.\ngnupg2 등 설치 link\r~# sudo apt install curl gnupg2 ca-certificates lsb-release ubuntu-keyring\rNginX Signing Key 가져오기 link\r~# curl https://nginx.org/keys/nginx_signing.key | gpg --dearmor \\\r| sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg \u003e/dev/null\rNginX Signing Key 검증 link위에서 가져온 Signing Key를 아래 명령어로 검증합니다.\n검증한 FingerPring 값이 573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 와 일치하는지 확인합니다.\n~# gpg --dry-run --quiet --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpg\rRepository 설정 linkNginX package를 다운 받아 설치하기 위해서는 Repository를 설정해야 합니다.\n아래 명령어로 리포지토리를 설정합니다. NginX의 stable, mainline 두가지 버전 중에서 여기서는 mainline 버전을 설치합니다.\nnginx-mainline link\r~# echo \"deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \\\rhttp://nginx.org/packages/mainline/ubuntu `lsb_release -cs` nginx\" \\\r| sudo tee /etc/apt/sources.list.d/nginx.list\rnginx-stable link\r~# echo \"deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \\\rhttp://nginx.org/packages/ubuntu `lsb_release -cs` nginx\" \\\r| sudo tee /etc/apt/sources.list.d/nginx.list\r{% include callout_v2.html type=“info” level=“2” content=“NginX는 stable, mainline 두가지 버전이 있습니다. NginX의 공식 설명에 따르면 버그 수정이나 보안 패치 등은 항상 mainline 버전에 먼저 적용되기 때문에 mainline을 사용하는 것을 추천한다고 합니다. stable 버전을 사용하는 주된 경우는 third-party 모듈을 사용하고 있어서 신규 버전에서 호환성 문제가 발생할 가능성이 걱정될 때라고 합니다.” %}\nRepository 우선 순위 설정 link배포판에 기본 설정된 리포지토리 보다 위에서 설정한 리포지토리를 우선하도록 설정합니다.\n~# echo -e \"Package: *\\nPin: origin nginx.org\\nPin: \\\rrelease o=nginx\\nPin-Priority: 900\\n\" | sudo tee /etc/apt/preferences.d/99nginx\rNginX 설치 link설정을 마쳤으면 apt로 NginX를 설치합니다.\n~# sudo apt update\r~# sudo apt install nginx\r디렉토리 설정 link다음으로 홈으로 사용할 디렉토리를 생성하고, 해당 디렉토리의 소유권을 설정하겠습니다.\n그리고, NginX가 정상 작동하는지 확인해보기 위해 설치시에 포함된 index.html을 홈 디렉토리로 복사합니다.\n~# mkdir -p /ncp/data/www\r~# chown -R nginx:nginx /ncp/data/www\r~# cp /usr/share/nginx/html/index.html /ncp/data/www/index.html\r~# ls -al /ncp/data/www\r환경 설정 link주로 변경할 환경 설정 파일은 /etc/nginx/conf.d/default.conf 입니다.\n~# vi /etc/nginx/conf.d/default.conf\r### Port와 Server Name 설정\r80이 아닌 다른 Port를 사용할 경우나 도메인을 설정하게 될 경우 2, 3 라인에 있는 아래 항목들을 수정하면 됩니다.\rserver_name localhost;\rserver_name nginx-test.com;\r홈 디렉토리, 기본 문서 설정 link앞에서 만들었던 홈 디렉토리 경로를 설정하고 기본 문서를 지정하는 곳입니다.\n# 변경 전\rlocation / {\rroot /usr/share/nginx/html;\rindex index.html index.htm;\r}\r# 변경 후\rroot /ncp/data/www;\rindex index.html index.htm;\rlocation / {\rtry_files $uri $uri/ = 404;\r}\rerror 페이지 설정 link404, 500 등의 error 페이지를 설정할 경우 아래 내용들을 수정하면 됩니다.\n# 변경 전\r#error_page 404 /404.html;\rlocation = /50x.html {\rroot /usr/share/nginx/html;\r}\r# 변경 후\rerror_page 404 /404.html;\rlocation = /50x.html {\rroot /ncp/data/www;\r}\r.htaccess 파일 접근 금지 설정 link.htaccess 파일에 대한 접근 금지를 설정할 경우 아래 내용을 주석 해제하면 됩니다.\n# 변경 전\r#location ~ /\\.ht {\r# deny all;\r#}\r# 변경 후\rlocation ~ /\\.ht {\rdeny all;\r}\rNginX 실행 link설정을 모두 마쳤으면 NginX를 시작하고 상태를 확인합니다.\n~# systemctl start nginx\r~# systemctl status nginx\r사이트 접속 linkNginX가 정상 작동하면 아래와 같이 서버 접속 화면을 확인할 수 있습니다.\n참고 URL link NginX Linux packages 설치 가이드\nhttp://nginx.org/en/linux_packages.html\nRocky Linux에서 NginX 설치, 설정하는 방법\n"
            }
        );
    index.add(
            {
                id:  102 ,
                href: "\/docs\/compute\/nginx\/install-setting-guide-centos\/",
                title: "CentOS에서 NginX 설치, 설정하는 방법",
                description: "Ncloud (네이버 클라우드) CentOS 서버에 NginX를 Package로 설치하고 기본 설정을 하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) CentOS 서버에 NginX 최신 버전을 Package로 설치하고 기본 설정을 하는 방법에 대한 내용을 정리해보겠습니다.\n서버 환경 link\r⁃ OS: CentOS 7.8 ⁃ NginX: NginX 1.21.5\ryum 유틸리티 설치 linkyum으로 NginX를 설치하기 전에 yum-utils를 먼저 설치합니다. 이미 설치 되어 있을 경우에는 아래와 같이 설치되어 있다는 메시지가 출력됩니다.\n~# yum install yum-utils\rRepository 설정 linkNginX package를 다운 받아 설치하기 위해서는 Repository를 설정해야 합니다. Repository 디렉토리에 nginx.repo 파일을 만들고 아래와 같은 내용을 입력합니다.\n~# vi /etc/yum.repos.d/nginx.repo\r[nginx-stable]\rname=nginx stable repo\rbaseurl=http://nginx.org/packages/centos/$releasever/$basearch/\rgpgcheck=1\renabled=1\rgpgkey=https://nginx.org/keys/nginx_signing.key\rmodule_hotfixes=true\r[nginx-mainline]\rname=nginx mainline repo\rbaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\rgpgcheck=1\renabled=0\rgpgkey=https://nginx.org/keys/nginx_signing.key\rmodule_hotfixes=true\r{% include callout_v2.html type=“info” level=“2” content=“NginX는 stable, mainline 두가지 버전이 있습니다. NginX의 공식 설명에 따르면 버그 수정이나 보안 패치 등은 항상 mainline 버전에 먼저 적용되기 때문에 mainline을 사용하는 것을 추천한다고 합니다. stable 버전을 사용하는 주된 경우는 third-party 모듈을 사용하고 있어서 신규 버전에서 호환성 문제가 발생할 가능성이 걱정될 때라고 합니다.” %}\n버전 선택 linkstable, mainline 두가지 버전 중에서 기본은 stable 버전입니다.\nstable 버전을 설치할 경우에는 다음 명령어는 건너띄어도 되고, mainline 버전을 설치하기 위해서는 아래 명령어로 설정을 변경해주어야 합니다.\n~# yum-config-manager --enable nginx-mainline\rNginX 설치 link설정을 마쳤으면 yum으로 NginX를 설치합니다.\n~# yum -y install nginx\r디렉토리 설정 link다음으로 홈으로 사용할 디렉토리를 생성하고, 해당 디렉토리의 소유권을 설정하겠습니다.\n그리고, NginX가 정상 작동하는지 확인해보기 위해 설치시에 포함된 index.html을 홈 디렉토리로 복사합니다.\n~# mkdir -p /ncp/data/www\r~# chown -R nginx:nginx /ncp/data/www\r~# cp /usr/share/nginx/html/index.html /ncp/data/www/index.html\r~# ls -al /ncp/data/www\r환경 설정 link주로 변경할 환경 설정 파일은 /etc/nginx/conf.d/default.conf 입니다.\n~# vi /etc/nginx/conf.d/default.conf\r### Port와 Server Name 설정\r80이 아닌 다른 Port를 사용할 경우나 도메인을 설정하게 될 경우 2, 3 라인에 있는 아래 항목들을 수정하면 됩니다.\rserver_name localhost;\rserver_name nginx-test.com;\r홈 디렉토리, 기본 문서 설정 link앞에서 만들었던 홈 디렉토리 경로를 설정하고 기본 문서를 지정하는 곳입니다.\n# 변경 전\rlocation / {\rroot /usr/share/nginx/html;\rindex index.html index.htm;\r}\r# 변경 후\rroot /ncp/data/www;\rindex index.html index.htm;\rlocation / {\rtry_files $uri $uri/ = 404;\r}\rerror 페이지 설정 link404, 500 등의 error 페이지를 설정할 경우 아래 내용들을 수정하면 됩니다.\n# 변경 전\r#error_page 404 /404.html;\rlocation = /50x.html {\rroot /usr/share/nginx/html;\r}\r# 변경 후\rerror_page 404 /404.html;\rlocation = /50x.html {\rroot /ncp/data/www;\r}\r.htaccess 파일 접근 금지 설정 link.htaccess 파일에 대한 접근 금지를 설정할 경우 아래 내용을 주석 해제하면 됩니다.\n# 변경 전\r#location ~ /\\.ht {\r# deny all;\r#}\r# 변경 후\rlocation ~ /\\.ht {\rdeny all;\r}\rNginX 실행 link설정을 모두 마쳤으면 NginX를 시작하고 상태를 확인합니다.\n~# systemctl start nginx\r~# systemctl status nginx\r사이트 접속 linkNginX가 정상 작동하면 아래와 같이 서버 접속 화면을 확인할 수 있습니다.\n참고 URL link NginX Linux packages 설치 가이드\nhttp://nginx.org/en/linux_packages.html\nRocky Linux에서 NginX 설치, 설정하는 방법\n"
            }
        );
    index.add(
            {
                id:  103 ,
                href: "\/docs\/compute\/nginx\/https-ssl-setting-guide-ubuntu\/",
                title: "Ubuntu에서 NginX SSL 인증서 설정하는 방법",
                description: "Ncloud (네이버 클라우드) Ubuntu 서버에 NginX SSL 인증서를 설정하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) Ubuntu 서버에서 NginX 최신 버전에 SSL 인증서를 설정하고, http로 접속 시에 https로 리다이렉트하는 방법에 대한 내용을 정리해보겠습니다.\n서버 환경 link\r⁃ OS: Ubuntu 20.04 ⁃ NginX: NginX 1.21.6 ⁃ SSL 인증서: 로컬 테스트용 인증서\rNginX 설치 linkUbuntu에 Nginx 최신 버전을 설치하는 방법은 아래 문서에서 확인하시면 됩니다.\n"
            }
        );
    index.add(
            {
                id:  104 ,
                href: "\/docs\/compute\/nginx\/https-ssl-setting-guide-centos\/",
                title: "CentOS에서 NginX SSL 인증서 설정하는 방법",
                description: "Ncloud (네이버 클라우드) CentOS 서버에 NginX SSL 인증서를 설정하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) CentOS 서버에서 NginX 최신 버전에 SSL 인증서를 설정하고, http로 접속 시에 https로 리다이렉트하는 방법에 대한 내용을 정리해보겠습니다.\n서버 환경 link\r⁃ OS: CentOS 7.8 ⁃ NginX: NginX 1.21.6 ⁃ SSL 인증서: 로컬 테스트용 인증서\rNginX 설치 linkCentOS에 Nginx 최신 버전을 설치하는 방법은 아래 문서에서 확인하시면 됩니다.\n"
            }
        );
    index.add(
            {
                id:  105 ,
                href: "\/docs\/compute\/nginx\/client-ip-logging-in-loadbalancer-guide\/",
                title: "Load Balancer에 연동된 NginX에서 Client IP 기록하고 확인하는 방법",
                description: "Ncloud (네이버 클라우드) Load Balancer에 연동된 NginX 웹서버에서 Client IP 기록하고 확인하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드)에서 Load Balancer에 연동된 NginX 웹서버를 사용할 때 Load Balancer IP가 아닌 실제 Client IP를 기록하고 확인하는 방법을 알아보겠습니다. 결론부터 이야기 하자면 NginX에서는 Apache와 달리 별도의 모듈 설치나 환경 설정 파일 수정 없이도 자동으로 실제 Client IP와 Load Balancer IP가 동시에 모두 기록됩니다. 어떻게 기록되는지 테스트 결과를 보면서 확인해보겠습니다.\n테스트 환경 link\r⁃ Server-1: CentOS 7.8 ⁃ Server-2: Ubuntu 20.04 ⁃ NginX: NginX 1.23.1 서버 준비 linkNcloud 콘솔에서 CentOS 7.8, Ubuntu 20.04 두 대의 서버를 아래와 같이 준비했습니다.\nNginX를 설치하는 방법은 아래 문서를 참고하시기 바랍니다. ⁃ Ubuntu에 NginX 설치하기\n⁃ CentOS에 NginX 설치하기\rLoad Balancer 준비 linkLoad Balancer도 [Application Load Balancer]를 [10.0.4.0] 대역으로 설정해서 준비했습니다.\nApplication Load Blancer 의 생성 가이드는 아래 문서를 참고하시기 바랍니다. ⁃ VPC 환경에서 Application Load Balancer 생성하기\rAccess Log 확인 linkNcloud의 상품인 [Cloud Log Analytics]에서 NginX의 로그를 확인해보면 아래와 같이 Log 내용에 앞쪽에는 [Load Balancer IP]가 기록되어 있고, 제일 뒤쪽에는 [실제 Client IP]가 기록되어 있는 것을 확인할 수 있습니다. 해당 서버들에는 오로지 NginX만 설치했고, 다른 모듈을 설치하거나 환경 설정 파일을 변경하지 않은 상태입니다.\n참고 URL link NginX Linux packages 설치 가이드\nhttp://nginx.org/en/linux_packages.html 문서 업데이트 내역 link\r날짜 내용 2023-05-23 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  106 ,
                href: "\/docs\/compute\/x-forwarded-for\/client-ip-logging-in-linux-apache-guide\/",
                title: "X-Forwarded-For를 이용해 Proxy, Load Balancer 환경에서 Client IP 기록하기",
                description: "Ncloud(네이버 클라우드)에서 X-Forwarded-For를 이용해 Proxy, Load Balancer 환경에서 Client IP 기록하기",
                content: "개요 linkX-Forwarded-For (XFF) 는 HTTP Header 중 하나로 Load Balancer(로드밸런서)나 Proxy Server를 통해 웹서버에 접속하는 Client의 IP 주소를 식별하는 표준 헤더입니다.\n웹서버나 WAS 앞쪽에 Load Balancer 혹은 Proxy Server 등이 위치하게 된다면 서버 접근 로그에는 Client IP가 아닌 Load Balancer 혹은 Proxy Server의 IP 주소가 기록됩니다. 이때 웹 어플리케이션에서 X-Forwarded-For 헤더를 이용하면 Client IP를 서버 접근 로그에 남길 수 있습니다.\n여기서는 Load Balancer와 연동된 CentOS와 Ubuntu, 그리고 Rocky Linux의 Apache 웹서버 환경에서 X-Forwarded-For 를 이용하여 Apache access_log에 Clinet의 IP를 저장하는 과정을 살펴보겠습니다.\n테스트 환경 link테스트는 CentOS, Ubuntu, Rocky Linux OS가 각각 설치된 서버를 Load Balancer와 연동한 후 Cloud Log Analytics에서 Apache access_log를 수집해 IP 주소를 확인하는 방식으로 진행하겠습니다.\nNetwork 환경 link VPC 대역 : 10.0.0.0/16 Subnet 대역 (Server) : 10.0.0.0/24 Subnet 대역 (Load Balancer) : 10.0.4.0/24 Server 환경 link xff-test-centos : CentOS 7.8 xff-test-ubuntu : Ubuntu 20.04 xff-test-rocky : Rocky Linux 8.6 테스트 서버 link위 서버 환경에서 정리한 대로 CentOS, Ubuntu, Rocky Linux 이렇게 3대의 서버를 준비했습니다. VPC 환경에서 서버 생성하는 방법은 아래 문서를 참고하시면 됩니다.\nVPC 환경에서 서버 생성하는 방법\r로드밸런서도 마찬가지로 준비하고, 서버와 연동까지 완료했습니다. VPC 환경에서 로드밸런서를 생성하는 방법은 아래 문서를 참고하시면 됩니다.\nVPC 환경에서 Application Load Balancer 생성하는 방법\r로드밸런서 상세 정보에서 [10.0.4.0/24]로 표시되는 서브넷 정보를 기억했다가 아래쪽에서 테스트할 때 확인해보겠습니다. 설정 전 테스트 link우선, X-Forwarded-For (XFF) 설정을 하기 전에 어떻게 기록이 남는지 확인해보겠습니다.\n아래와 같이 Load Balancer 주소로 접속해서 3대의 서버에 각각 접근하도록 합니다.\n위에서 소개한 Application Load Balancer 생성하는 방법을 그대로 따라하면 아래와 같은 메시지를 확인할 수 있습니다.\nApache 접속 로그 확인 linkApache 접속 로그 파일은 아래의 위치에 존재하지만, 저희는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해보겠습니다.\nCentOS : /var/log/httpd/access_log Ubuntu : /var/log/apache2/access.log Rocky Linux : /var/log/httpd/access_log Cloud Log Analytics 설정 가이드\rCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 **Load Balancer의 IP 대역 (10.0.4.xx)**이 기록된 것을 확인할 수 있습니다.\nRocky Linux는 아직 Cloud Log Analytics Agent를 지원하지 않아 서버에서 직접 로그를 확인해보았습니다. CentOS 설정 link이제 실제 Client IP가 기록 되도록 설정을 변경해보겠습니다.\n우선 CentOS에서는 httpd.conf 파일만 수정하면 됩니다.\n~# vim /etc/httpd/conf/httpd.conf\rhttpd.conf 파일 [log_config_module] 설정에 있는 LogFormat 항목에서 %h 를 %{X-Forwarded-For}i 로 수정합니다.\nhttpd.conf 수정 전 link\rLogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined\rhttpd.conf 수정 후 link\rLogFormat \"%{X-Forwarded-For}i %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined\rApache 재시작 linkhttpd.conf 파일 수정 후에 Apache를 재시작합니다. 로그 테스트는 Ubuntu까지 설정을 마친 후에 진행하겠습니다.\n~# systemctl restart httpd\rRocky Linux 설정 linkRocky Linux는 CentOS와 마찬가지로 /etc/httpd/conf/httpd.conf 파일에 있는 로그 관련 설정을 변경해주면 완료됩니다.\nUbuntu 설정 linkUbuntu에서는 apache2.conf 파일을 수정하기 전에 remoteip 모듈을 사용하도록 설정해줘야 합니다.\nremoteip 설정 link아래 명령어를 실행하면 remoteip 모듈이 활성화 됩니다.\n~# a2enmod remoteip\rremoteip.load 수정 link다음으로 remoteip.load 파일을 수정해서 아래쪽에 [RemoteIPHeader X-FORWARDED-FOR]을 추가 합니다.\n~# vim /etc/apache2/mods-enabled/remoteip.load\rremoteip.load 수정 전 LoadModule remoteip_module /usr/lib/apache2/modules/mod_remoteip.so\rremoteip.load 수정 후 LoadModule remoteip_module /usr/lib/apache2/modules/mod_remoteip.so\rRemoteIPHeader X-FORWARDED-FOR\rapache2.conf 수정 link다음으로 apache2.conf 파일을 수정합니다.\n~# vim /etc/apache2/apache2.conf\rapache2.conf LogFormat 부분에서 %h 를 %a 로 변경합니다.\napache2.conf 수정 전 LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined apache2.conf 수정 후 LogFormat \"%a %l %u %t \\\"%r\\\" %\u003es %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined Apache 재시작 link\r~# systemctl restart apache2\r설정 후 테스트 link위와 같이 CentOS, Ubuntu, Rocky Linux 3대 서버에서 설정을 모두 마친 후에 로드 밸런서 URL로 접속합니다.\n이후에 Cloud Log Analytics에서 로그를 확인해보면 아래와 같이 로드밸런서 IP가 아닌 실제 접속한 Client의 IP가 기록된 것을 확인할 수 있습니다.\nRocky Linux는 아직 Cloud Log Analytics Agent를 지원하지 않아 서버에서 직접 로그를 확인해보았습니다. 참고 URL link X-Forwarded-For 안내\nhttps://developer.mozilla.org/ko/docs/Web/HTTP/Headers/X-Forwarded-For 문서 업데이트 내역 link\r날짜 내용 2021-12-29 문서 최초 생성 2023-08-21 Rocky Linux 추가, 최신 OS 반영, 스크린샷 업데이트 "
            }
        );
    index.add(
            {
                id:  107 ,
                href: "\/docs\/compute\/x-forwarded-for\/client-ip-logging-in-windows-iis-guide\/",
                title: "IIS에서 X-Forwarded-For를 이용해 Client IP 기록하기",
                description: "Ncloud(네이버 클라우드)에서 X-Forwarded-For를 이용해 Proxy, Load Balancer 환경에서 Client IP를 Windows IIS Log에 기록하는 방법입니다",
                content: "개요 linkX-Forwarded-For (XFF) 는 HTTP Header 중 하나로 Load Balancer(로드밸런서)나 Proxy Server를 통해 웹서버에 접속하는 Client의 IP 주소를 식별하는 표준 헤더입니다.\n웹서버나 WAS 앞쪽에 Load Balancer 혹은 Proxy Server 등이 위치하게 된다면 서버 접근 로그에는 Client IP가 아닌 Load Balancer 혹은 Proxy Server의 IP 주소가 기록됩니다. 이때 웹 어플리케이션에서 X-Forwarded-For 헤더를 이용하면 Client IP를 서버 접근 로그에 남길 수 있습니다.\n여기서는 Load Balancer와 연동된 Windows Server의 IIS에서 X-Forwarded-For를 이용해 IIS(Internet Information Services) Log에 Clinet의 IP를 기록하는 과정을 살펴보겠습니다.\n테스트 환경 link테스트는 Windows 서버를 Load Balancer와 연동한 후 Cloud Log Analytics에서 IIS Log를 수집해 IP 주소를 확인하는 방식으로 진행하겠습니다.\nNetwork 환경 link VPC 대역 : 10.0.0.0/16 Subnet 대역 (Server) : 10.0.0.0/24 Subnet 대역 (Load Balancer) : 10.0.4.0/24 Server 환경 link Windows Server 2019 (64-bit) English Edition 테스트 서버 link위 서버 환경에서 정리한 대로 Windows 서버를 준비했습니다. VPC 환경에서 서버 생성하는 방법은 아래 문서를 참고하시면 됩니다.\nVPC 환경에서 서버 생성하는 방법\r로드밸런서도 마찬가지로 준비하고, 서버와 연동까지 완료했습니다. VPC 환경에서 로드밸런서를 생성하는 방법은 아래 문서를 참고하시면 됩니다.\nVPC 환경에서 Application Load Balancer 생성하는 방법\r로드밸런서 상세 정보에서 [10.0.4.0/24]로 표시되는 서브넷 정보를 기억했다가 아래쪽에서 테스트할 때 확인해보겠습니다. 설정 전 테스트 link우선, X-Forwarded-For (XFF) 설정을 하기 전에 어떻게 기록이 남는지 확인해보겠습니다.\nIIS 접속 로그 확인 linkWindows IIS 접속 로그를 [Cloud Log Analytics]에서 확인하는 방법은 아래 문서를 참고하시며 됩니다.\nCloud Log Analytics에서 Windows IIS Log 수집하는 방법\rCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 **Load Balancer의 IP 대역 (10.0.4.xx)**이 기록된 것을 확인할 수 있습니다.\nIIS 설정 link이제 실제 Client IP가 기록 되도록 설정을 변경해보겠습니다.\nIIS Manager를 실행시켜서 메뉴 중에 [Logging]을 선택합니다. [Logging] 화면에서 [Format]은 기본 값인 [W3C] 그대로 두고 [Log File] 항목의 [Select Fields] 버튼을 클릭합니다. [W3C Logging Fields] 팝업창에서 [Custom Fields] 항목의 [Add Field] 버튼을 클릭합니다. [Add Custom Field] 팝업창에서 [Field Name], [Source] 두가지 항목 모두에 [X-Forwarded-For]를 입력하고 [OK] 버튼을 클릭합니다. [Custom Fields]에 [X-Forwarded-For] 설정이 추가된 것을 확인할 수 있습니다. 팝업창을 닫고 [IIS Manager] - [Logging] 설정 화면 오른쪽에 있는 [Apply]를 클릭해서 변경된 설정을 적용합니다. 변경된 설정이 적용되었다는 메시지를 확인할 수 있습니다. 설정 후 테스트 link위와 같이 서버에서 설정을 모두 마친 후에 로드 밸런서 URL로 접속합니다.\n이후에 Cloud Log Analytics에서 로그를 확인해보면 아래와 같이 실제 접속한 Client의 IP가 추가로 기록된 것을 확인할 수 있습니다.\n참고 URL link X-Forwarded-For 안내\nhttps://developer.mozilla.org/ko/docs/Web/HTTP/Headers/X-Forwarded-For\nCloud Log Analytics에서 Windows IIS Log 수집하는 방법\nhttps://docs.3rdeyesys.com/management/ncloud-management-cloud-log-analytics-windows-iis-log-collect-guide.html\n문서 업데이트 내역 link\r날짜 내용 2023-11-17 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  108 ,
                href: "\/docs\/compute\/cloud-functions\/cf-create-using-dotnet-csharp-in-cmd\/",
                title: "Cloud Functions Action을 .Net (C#)을 사용하여 윈도우 명령프롬프트(cmd)에서 만드는 방법 ",
                description: "Ncloud (네이버 클라우드) Cloud Functions Action을 .Net (C#)을 사용하여 윈도우 명령프롬프트(cmd)에서 만드는 방법입니다",
                content: "개요 link네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어로는 Node.js, Python, Java, Swift, PHP, .Net, Go Language 등이 있는데\n다른 언어들은 네이버 클라우드 콘솔에서 직접 코드를 입력하면 되지만, Java는 로컬에서 작업 후 jar 파일로 .Net은 zip 파일로 압축해서 따로 등록해야 합니다.\n여기서는 윈도우 명령프롬프트(cmd)에서 .Net 그 중에서도 C#으로 Action을 만들고 zip 파일로 압축 후에 콘솔에 등록하고 테스트 하는 과정까지 정리해보겠습니다.\n.Net 설치 link네이버 클라우드 Cloud Functions는 .Net Standard 2.0 규격을 요구하는데, 이 규격을 지원하는 버전을 설치하려면 .Net 5.0 또는 .Net Core 2.1 이상을 설치하면 됩니다.\n가장 간단한 방법은 Visual Studio를 설치하는 방법이고 그 외에는 .Net 또는 .Net Core SDK만 별도로 설치하는 방법이 있습니다.\nVisual Studio 무료버전 : https://visualstudio.microsoft.com/ko/free-developer-offers/ .Net, .Net Core SDK : https://dotnet.microsoft.com/download 프로젝트 생성 linkCloudFunctionsTestConsole 라는 이름의 Class Library 프로젝트를 생성하면서 언어는 C#, 타겟 프레임워크는 .Net Standard 2.0으로 지정하는 명령어입니다.\n다음으로 생성된 프로젝트 폴더로 이동해서 Newtonsoft.Json이라는 Json 패키지를 설치합니다.\n:: 프로젝트 생성\rD:\\\u003edotnet new classlib -n CloudFunctionsTestConsole -lang \"C#\" -f netstandard2.0\r:: 폴더 이동\rD:\\\u003ecd CloudFunctionsTestConsole\r:: Json 패키지 설치\rD:\\CloudFunctionsTestConsole\u003edotnet add package Newtonsoft.Json\r실제 명령프롬프트(cmd)에서 위 명령을 실행해본 화면은 다음과 같습니다.\nHello.cs 작성 link이제 name이라는 파라미터를 json 형태로 받아서 출력해주는 Hello.cs 스크립트를 작성합니다.\nusing System;\rusing Newtonsoft.Json.Linq;\rnamespace CloudFunctionsTestConsole\r{\rpublic class Hello\r{\rpublic JObject Main(JObject args)\r{\rstring name = \"no name\";\rif (args.ContainsKey(\"name\")) {\rname = args[\"name\"].ToString();\r}\rJObject message = new JObject();\rmessage.Add(\"greeting\", new JValue($\"Hello, {name}!\"));\rreturn (message);\r}\r}\r}\r프로젝트 게시 link이제 위에서 작성한 스크립트를 publish폴더로 게시하고, zip 파일로 압축합니다.\n여기서 만든 zip 파일을 네이버 클라우드 콘솔에서 등록하게 됩니다.\n:: 프로젝트 게시\rD:\\CloudFunctionsTestConsole\u003edotnet publish -c Release -o publish\r:: 폴더 이동\rD:\\CloudFunctionsTestConsole\u003ecd publish\r:: 파일 압축\rD:\\CloudFunctionsTestConsole\\publish\u003ezip -r -0 CloudFunctionsTestConsole.zip *\r:: zip 명령이 실행되지 않을 경우 아래와 같이 윈도우 탐색기에서 직접 압축해도 됩니다.\rinfo\rzip 명령이 실행되지 않을 경우 아래와 같이 윈도우 탐색기에서 직접 압축해도 됩니다.\nCF 이용신청 link네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\nCF Action 생성 link액션 생성 link버튼을 선택해 액션을 생성합니다.\n트리거 선택 link액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n이름 입력 link액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n소스코드 언어 선택 link소스코드 언어 중에서 저희는 dotnet:2.2를 선택합니다.\n소스코드 업로드 link소스코드 타입은 코드와 파일이 있지만, java와 .Net은 파일 업로드만 가능합니다. 앞에서 만든 소스코드를 선택하고 업로드 합니다.\n소스코드가업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\nVPC 연결 정보 선택 linkVPC 환경에서는 연결할 VPC와 Subnet을 선택해야 합니다. Classic 환경에서는 다음 단계로 바로 이동하시면 됩니다.\n옵션 설정 link실행할 Main 함수의 이름을 {Assembly}::{Class Full Name}::{Method} 형태의 풀네임으로 입력합니다. 위에서 만든 Hello.cs에서는 CloudFunctionsTestConsole::CloudFunctionsTestConsole.Hello::Main 으로 입력합니다.\n액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n입력할 Main 함수 이름을 어떻게 적으면 되는지 한번 더 살펴보겠습니다.\n아래 소스코드 화면에서 보시면 namespace, class, Main 이렇게 이름이 적혀 있는 곳에서\n{ 1 }::{ 1 }.{ 2 }::{ 3 } 이렇게 연결해서 적으면 CloudFunctionsTestConsole::CloudFunctionsTestConsole.Hello::Main 이렇게 완성이 되고 이 이름을 Main 함수 이름 칸에 입력하시면 됩니다.\n생성 완료 link디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\nCF Action 실행 link이제 생성된 액션을 실행해보겠습니다. 액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고, 오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다. 파라미터는 json 형태로 입력하면 됩니다. 왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n오류 메시지 link위의 순서대로 진행을 하면 문제 없이 사용 가능한데, 이미 다른 방법으로 진행해보면서 오류 메시지를 경험하는 경우도 있을 듯하여 가장 많이 겪게 되는 오류 상황 2가지를 정리해보겠습니다.\nMain 함수 이름 입력 오류 link위에서 설명한 액션 Main 함수 이름을 올바르게 입력하지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\"error\" : \"main required format is \\\"Assembly::Type::Function\\\".\"\r상단에 설명한 [CF Action 생성] - [옵션 설정]에서 Main 함수 입력하는 부분을 참고하셔서 정확하게 입력하시면 문제가 해결됩니다.\n.Net 대상 프레임워크 오류 link네이버 클라우드 Cloud Functions은 .Net Standard 2.0 규약을 지원하고 있습니다.\n그런데 이 대상 프레임워크가 맞지 않으면 다음과 같은 오류 메시지가 나타납니다.\n\"error\" : \"Unable to locate requested type (\\\"CloudFunctionsTestConsole.Hello\\\").\"\r위 [프로젝트 생성]에서 설명한 것처럼 프로젝트 생성할 때 -f netstandard2.0 옵션을 반드시 넣어주셔어야 합니다.\n:: 프로젝트 생성\rD:\\\u003edotnet new classlib -n CloudFunctionsTestConsole -lang \"C#\" -f netstandard2.0\r"
            }
        );
    index.add(
            {
                id:  109 ,
                href: "\/docs\/compute\/cloud-functions\/cf-create-using-dotnet-csharp-in-visual-studio\/",
                title: "Cloud Functions Action을 .Net (C#)을 사용하여 Visual Studio에서 만드는 방법 ",
                description: "Ncloud (네이버 클라우드) Cloud Functions Action을 .Net (C#)을 사용하여 Visual Studio에서 만드는 방법입니다",
                content: "개요 link네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어로는 Node.js, Python, Java, Swift, PHP, .Net, Go Language 등이 있는데 다른 언어들은 네이버 클라우드 콘솔에서 직접 코드를 입력하면 되지만, Java는 로컬에서 작업 후 jar 파일로 .Net은 zip 파일로 압축해서 따로 등록해야 합니다.\n여기서는 Visual Studio에서 .Net 그 중에서도 C#으로 Action을 만들고 zip 파일로 압축 후에 콘솔에 등록하고 테스트 하는 과정까지 정리해보겠습니다.\n.Net 설치 link네이버 클라우드 Cloud Functions는 .Net Standard 2.0 규격을 요구하는데, 이 규격을 지원하는 버전을 설치하려면 .Net 5.0 또는 .Net Core 2.1 이상을 설치하면 됩니다.\n가장 간단한 방법은 Visual Studio를 설치하는 방법이고 그 외에는 .Net 또는 .Net Core SDK만 별도로 설치하는 방법이 있습니다.\n여기서는 Visual Studio를 이용할 것이기 때문에 Visual Studio를 설치하면 됩니다.\nVisual Studio 무료버전 : https://visualstudio.microsoft.com/ko/free-developer-offers/ .Net, .Net Core SDK : https://dotnet.microsoft.com/download 프로젝트 생성 link프로젝트 템플릿 선택 linkVisual Studio에서 제공하는 템플릿 중에서 C# Class library를 선택하니다.\n프로젝트 구성 link프로젝트 이름과 저장 위치 등을 입력합니다. 여기서는 CloudFunctionsTestVisualStudio 라는 이름으로 시작합니다.\n대상 프레임워크 지정 link대상 프레임워크는 .NET Standard 2.0으로 지정합니다.\n프로젝트 생성 후에 CloudFunctionsTestVisualStudio.csproj 파일을 열어보면 TargetFramework 값이 netstandard2.0으로 되어 있는 것을 확인할 수 있습니다.\njson 패키지 설치 link네이버 클라우드 Cloud Functions은 json 형식으로 파라미터를 입력받고 결과를 출력하기 때문에 NuGet 패키지 관리자를 이용해서 json 패키지를 설치합니다.\n프로젝트 선택하고 마우스 오른쪽 버튼을 클릭해서 NuGet 패키지 관리 메뉴를 선택합니다.\nNuGet 패키지 관리자 화면에서 json을 검색하고 Newtonsoft.Json 패키지를 선택, 설치를 합니다.\n패키지 설치가 완료된 상태입니다.\nHello.cs 작성 link이제 name이라는 파라미터를 json 형태로 받아서 출력해주는 Hello.cs 스크립트를 작성합니다.\nusing System;\rusing Newtonsoft.Json.Linq;\rnamespace CloudFunctionsTestConsole\r{\rpublic class Hello\r{\rpublic JObject Main(JObject args)\r{\rstring name = \"no name\";\rif (args.ContainsKey(\"name\")) {\rname = args[\"name\"].ToString();\r}\rJObject message = new JObject();\rmessage.Add(\"greeting\", new JValue($\"Hello, {name}!\"));\rreturn (message);\r}\r}\r}\r프로젝트 게시 link이제 위에서 작성한 스크립트를 게시하고, zip 파일로 압축합니다.\n여기서 만든 zip 파일을 네이버 클라우드 콘솔에서 등록하게 됩니다.\n[빌드]-[게시] 메뉴를 선택합니다.\n게시 대상은 폴더를 선택합니다.\n게시할 준비가 되었고 게시를 시작합니다.\n게시가 완료되었습니다.\n게시된 폴더에 가보면 .nupkg 파일이 생성되는데 저희는 이것을 이용하지 않고 상위 폴더에 있는 dll 파일을 사용합니다.\npublish 상위 폴더에 가면 .deps.json, .dll, .pdb 이렇게 3개 파일이 생성되어 있는 것을 확인할 수 있는데 Cloud Functions에서는 이 파일을 사용합니다.\n파일 압축 link탐색기에서 3개의 파일을 선택하고 압축합니다.\nCF 이용신청 link네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\nCF Action 생성 link액션 생성 link버튼을 선택해 액션을 생성합니다.\n트리거 선택 link액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n이름 입력 link액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n소스코드 언어 선택 link소스코드 언어 중에서 저희는 dotnet:2.2를 선택합니다.\n소스코드 업로드 link소스코드 타입은 코드와 파일이 있지만, java와 .Net은 파일 업로드만 가능합니다. 앞에서 만든 소스코드를 선택하고 업로드 합니다.\n소스코드가업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\nVPC 연결 정보 선택 linkVPC 환경에서는 연결할 VPC와 Subnet을 선택해야 합니다. Classic 환경에서는 다음 단계로 바로 이동하시면 됩니다.\n옵션 설정 link실행할 Main 함수의 이름을 {Assembly}::{Class Full Name}::{Method} 형태의 풀네임으로 입력합니다. 위에서 만든 Hello.cs에서는 CloudFunctionsTestVisualStudio::CloudFunctionsTestVisualStudio.Hello::Main 으로 입력합니다.\n액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\nMain 함수 이름 작성 방법 link입력할 Main 함수 이름을 어떻게 적으면 되는지 한번 더 살펴보겠습니다.\n아래 소스코드 화면에서 보시면 namespace, class, Main 이렇게 이름이 적혀 있는 곳에서\n{ 1 }::{ 1 }.{ 2 }::{ 3 } 이렇게 연결해서 적으면 CloudFunctionsTestVisualStudio::CloudFunctionsTestVisualStudio.Hello::Main 이렇게 완성이 되고\n이 이름을 Main 함수 이름 칸에 입력하시면 됩니다.\n생성 완료 link디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\nCF Action 실행 link이제 생성된 액션을 실행해보겠습니다. 액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고, 오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다. 파라미터는 json 형태로 입력하면 됩니다. 왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n오류 메시지 link위의 순서대로 진행을 하면 문제 없이 사용 가능한데, 이미 다른 방법으로 진행해보면서 오류 메시지를 경험하는 경우도 있을 듯하여 가장 많이 겪게 되는 오류 상황 2가지를 정리해보겠습니다.\nreport\rMain 함수 이름 입력 오류: 액션 Main 함수 이름을 올바르게 입력하지 않으면 다음과 같은 오류 메시지가 나타납니다.\"error\" : \"main required format is \\\"Assembly::Type::Function\\\".\"\n상단에 설명한 [CF Action 생성] - [옵션 설정]에서 Main 함수 입력하는 부분을 참고하셔서 정확하게 입력하시면 문제가 해결됩니다.\nreport\r.Net 대상 프레임워크 오류: 네이버 클라우드 Cloud Functions은 .Net Standard 2.0 규약을 지원하고 있습니다. 그런데 이 대상 프레임워크가 맞지 않으면 다음과 같은 오류 메시지가 나타납니다.\"error\" : \"Unable to locate requested type (\\\"CloudFunctionsTestVisualStudio.Hello\\\").\"\n위 [프로젝트 생성]에서 설명한 것처럼 프로젝트 생성할 때 대상 프레임워크를 .NET Standard 2.0으로 지정해야 합니다.\n"
            }
        );
    index.add(
            {
                id:  110 ,
                href: "\/docs\/compute\/cloud-functions\/php-smtp-via-gmail-with-phpmailer\/",
                title: "Cloud Functions에서 PHPMailer를 사용하여 gmail을 통해 SMTP로 메일 발송하는 방법  ",
                description: "Ncloud (네이버 클라우드) Cloud Functions에서 PHPMailer를 사용하여 gmail을 통해 SMTP로 메일 발송하는 방법입니다",
                content: "개요 link네이버 클라우드 Cloud Functions에서 Action을 만들 수 있는 언어중에서 PHP를 이용하여 SMTP로 메일을 발송하는 방법을 소개하려고 합니다.\n메일 발송을 위한 솔루션은 PHPMailer를 이용하고, 발송 서버는 gmail을 이용하는 과정을 정리해보겠습니다.\nPHPMailer 다운로드 linkPHP에서 SMTP를 이용한 메일을 발송하려고 할 때 흔히 사용하는 것이 PHPMailer입니다.\nPHPMailer는 GitHub에 있는 사이트로 가서 Code를 선택하고 Download ZIP을 클릭하면 다운받을 수 있습니다.\n일반적인 Linux서버에서 사용하는 경우라면 composer를 이용해서 설치하면 되겠지만 Cloud Functions에는 zip 파일로 소스코드를 업로드 해야 하기에 다운로드 받겠습니다.\nhttps://github.com/PHPMailer/PHPMailer\n다운받은 zip파일을 압축해제하면 아래와 같은 파일과 폴더를 확인할 수 있는데 여기서는 src, language 두 폴더만 사용합니다.\n메일발송 코드 작성 linkPHPMailer에서 제공하는 샘플코드를 참고해서 꼭 필요한 코드만 적었습니다. 파일은 index.php로 저장합니다.\n추가로 필요한 코드가 있으면 아래 링크에 있는 PHPMailer 샘플코드를 참고하시면 되겠습니다.\nhttps://github.com/PHPMailer/PHPMailer/blob/master/examples/gmail.phps\n\u003c?php\ruse PHPMailer\\PHPMailer\\PHPMailer;\ruse PHPMailer\\PHPMailer\\SMTP;\ruse PHPMailer\\PHPMailer\\Exception;\rrequire 'src/Exception.php';\rrequire 'src/PHPMailer.php';\rrequire 'src/SMTP.php';\rfunction main(array $args) : array\r{\r$gmail_user_name = 'gmail 계정';\r$gmail_app_password = '앱 비밀번호';\r$from_name = '발신자 이름';\t$from_email = '발신자 메일주소';\r$to_name = $args[\"to_name\"] ?? $from_name; //수신자 이름\r$to_email = $args[\"to_email\"] ?? $from_email; //수신자 메일주소\r$result = \"\";\r$result_msg = \"\";\rtry {\r$mail = new PHPMailer();\r$mail-\u003eisSMTP();\r$mail-\u003eSMTPDebug = SMTP::DEBUG_SERVER;\r$mail-\u003eHost = 'smtp.gmail.com';\r$mail-\u003ePort = 587;\r$mail-\u003eSMTPSecure = PHPMailer::ENCRYPTION_STARTTLS;\r$mail-\u003eSMTPAuth = true;\r$mail-\u003esetLanguage(\"ko\", \"language/\");\r$mail-\u003eCharSet = PHPMailer::CHARSET_UTF8;\r$mail-\u003eUsername = $gmail_user_name;\r$mail-\u003ePassword = $gmail_app_password;\r$mail-\u003esetFrom($from_email, $from_name);\r$mail-\u003eaddAddress($to_email, $to_name);\r$mail-\u003eSubject = 'PHPMailer GMail SMTP test';\r$mail-\u003eBody = 'Cloud Functions에서 PHPMailer로 발송한 메일';\rif (!$mail-\u003esend()) {\t$result = \"fail\";\r$result_msg = $mail-\u003eErrorInfo;\t} else {\r$result = \"success\";\r$result_msg = 'Message sent!';\t}\r}\rcatch(Exception $e)\r{\r$result = \"error\";\r$result_msg = $e-\u003egetMessage();\r}\rreturn [$result =\u003e $result_msg];\r}\r?\u003e\rreport\r보안 이슈: 위 소스코드에서 알아보기 쉽게 password 라는 변수명을 사용하기는 했지만, 여러 상황에서 해킹 관련 이슈(예: grep 명령어를 사용해 password 정보가 포함된 파일 검색)가 발생할 수 있으니 실제 서비스에서는 password 라는 단어 대신에 다른 단어를 사용하기를 추천 드립니다. $gmail_app_password 뿐만 아니라 $mail-\u003ePassword 가 포함된 PHPMailer.php 소스도 함께 수정하시면 더욱 안전할 수 있습니다\"\n앱 비밀번호 link위 소스코드에서 gmail에 로그인할 계정과 비밀번호를 적는 부분에서 앱 비밀번호를 관심있게 보셔야 합니다.\n$gmail_user_name = 'gmail 계정';\r$gmail_app_password = '앱 비밀번호';\r외부앱이나 서버에서 gmail 즉 google 계정에 로그인 인증을 하려면 2단계 인증을 설정하고, 앱 비밀번호를 생성해서 사용해야 합니다. 예전에는 보안 수준이 낮은 앱의 액세스 허용 옵션으로 가능했었지만, 지금은 그렇게 하면 인증이 실패하는 경우가 많습니다. 앱 비밀번호 설정하는 방법 문서를 참고하시면 되겠습니다.\nCloud Functions 함수와 파라미터 link이번 메일 발송 기능 함수는 메일 수신자 이름과 메일 주소를 json 형식의 파라미터로 전달 받고, 결과를 json 형식으로 리턴하는 구조로 되어 있습니다. 아래와 같이 만약 파라미터가 없을 경우에는 발신자 이름과 메일주소와 동일한 기본값으로 설정했습니다.\nfunction main(array $args) : array\r{\r$to_name = $args[\"to_name\"] ?? $from_name; //수신자 이름\r$to_email = $args[\"to_email\"] ?? $from_email; //수신자 메일주소\rreturn [$result =\u003e $result_msg];\r}\r디버깅 레벨 설정 link메일 발송 코드가 실행되는 과정에 여러 오류가 발생할 수 있는데, 오류가 발생했을 때 오류 메시지를 확인할 수 있도록 디버깅 레벨을 다음 코드로 설정하고 있습니다.\n테스트가 끝나고 실제 서비스에 사용할 때는 DEBUG_OFF 옵션으로 변경하시기 바랍니다.\n$mail-\u003eSMTPDebug = SMTP::DEBUG_SERVER;\r//SMTP::DEBUG_OFF = off (for production use)\r//SMTP::DEBUG_CLIENT = client messages\r//SMTP::DEBUG_SERVER = client and server messages\r//SMTP::DEBUG_CONNECTION = As DEBUG_SERVER plus connection status\r//SMTP::DEBUG_LOWLEVEL = Low-level data output, all messages\r언어와 CharSet 설정 link코드가 실행되면서 나타날 수 있는 각 종 오류메시지를 표시할 언어와 메일 내용의 CharSet을 설정하는 코드입니다.\n$mail-\u003esetLanguage(\"ko\", \"language/\");\r$mail-\u003eCharSet = PHPMailer::CHARSET_UTF8;\r소스코드 Zip 파일로 압축 link위에서 작성한 소스코드를 index.php로 저장하고 클래스 파일들이 들어있는 src 폴더와 언어 파일이 들어있는 laguage 파일과 함께 zip 파일로 압축합니다.\nCF 이용신청 link네이버 클라우드 콘솔에서 Cloud Functions에 들어가 이용신청을 합니다.\nCF Action 생성 link액션 생성 link버튼을 선택해 액션을 생성합니다.\n트리거 선택 link액션을 생성하기 전에 트리거 조건을 설정해야 하는데, 여기서는 트리거 설정 없이 액션 만들기를 선택하겠습니다.\n이름 입력 link액션의 이름은 특별한 규칙이 없으니 알아보기 쉬운 것으로 입력하면 됩니다.\n### 소스코드 언어 선택\r소스코드 언어 중에서 php는 7.1, 7.3이 있는데 둘 중에 편하신대로 선택하시면 됩니다.\r소스코드 업로드 link소스코드 타입은 코드 직접 입력과 파일 업로드가 가능한데, 앞에서 만든 소스코드를 선택하고 업로드 합니다.\n소스코드가 업로드 되었습니다. 등록된 소스코드는 나중에 다운로드 할 수도 있고 다른 파일을 재업로드 할 수도 있습니다.\n네트워크 환경 설정 linkVPC 환경에서는 NAT Gateway를 이용해야 하기 때문에 네트워크 환경을 설정해야 합니다.\nClassic 환경에서는 다음 단계인 옵션 설정으로 바로 이동하시면 됩니다.\nVPC 연결 정보 선택 link연결할 VPC와 Subnet을 선택합니다.\nVPC 생성 link혹시 VPC를 생성하지 않았거나 새로운 VPC에서 실행하려고 할 경우에는 VPC생성 버튼을 클릭해서 새 창에서 VPC를 생성합니다. VPC는 논리적으로 격리된 네트워크 공간을 뜻하며, IP 주소 범위는, private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\nhttps://console.ncloud.com/vpc-network/vpc\nSubnet 생성 link사용할 수 있는 Subnet이 없거나 새로 생성할 경우 Subnet 생성 버튼을 클릭합니다.\n이름은 알아보기 쉽게 [ cf-phpmailer-smtp-subnet ]으로 입력했습니다.\nSubnet의 IP 주소 범위는 VPC 주소 범위 이하로만 지정이 가능하며, private 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /16~/28 범위여야 합니다.\n위에서 VPC IP주소 범위가 [ 192.168.0.0/16 ]이었기에 Subnet IP주소 범위는 [ 192.168.0.0/24 ]로 설정했습니다.\n여기서 중요한 것이 [Ineteget Gateway 전용여부] 항목입니다.\nCloud Functions는 Private Subnet에서만 작동하므로 N (Private)을 선택하셔야 합니다.\n용도는 일반으로 선택하시면 됩니다.\nhttps://console.ncloud.com/vpc-network/subnet\nNAT Gateway 생성 link위에서 생성한 Subnet이 Private이기 때문에 Cloud Functions으로 메일을 발송 즉, 외부와 통신을 하기 위해서는 NAT Gateway를 만들고 적용해주어야 합니다.\n이름은 [ cf-phpmailer-smtp-natgateway ]로 입력했습니다.\nhttps://console.ncloud.com/vpc-network/natgw\nRoute Table 설정 link이제 Cloud Functions이 속한 Subnet이 NAT Gateway를 거쳐서 외부로 나갈 수 있도록 Route Table을 설정합니다.\nVPC를 만들때 자동으로 생성된 2개의 Route Table중에서 private table을 선택하고 연관 Subnet 탭을 보시면 위에서 생성했던 [ cf-phpmailer-smtp-subnet ]을 확인할 수 있습니다.\nhttps://console.ncloud.com/vpc-network/routeTable\n이제 Routes 생성 버튼을 클릭하고 설정 값들을 입력, 선택하고 생성 버튼을 클릭합니다.\nDestination : 0.0.0.0/0 입력 Target Type : NATGW 선택 Target Name : cf-phpmailer-smtp-natgateway 선택 생성 버튼을 클릭하고 나면 설정이 추가된 것을 확인할 수 있습니다. 이제 확인 버튼을 클릭해서 창을 닫습니다.\n창을 닫고 나면 설정이 추가된 것을 Routes 탭에서 확인할 수 있습니다.\nVPC관련 설정이 끝났으면 이전 창으로 돌아가서 다음 단계인 [ 옵션 설정 ]을 확인하시면 됩니다.\n옵션 설정 link실행할 Main 함수의 이름은 main으로 그대로 두시고, 액션 메모리와 Timeout은 기본으로 두셔도 되고 익숙해진 이후에 상황에 맞게 조정하시면 됩니다.\n생성 완료 link디폴트 파라미터의 경우 필요하실 경우 설정하시면 됩니다.\n모든 준비가 끝났으면 생성 버튼을 클릭하여 액션을 생성합니다.\nCF Action 실행 link이제 생성된 액션을 실행해보겠습니다. 액션의 기본정보 화면에서는 액션 실행과 수정, 삭제를 할 수 있고, 모니터링 화면에서는 액션이 실행된 통계 정보를 확인할 수 있습니다.\n액션 실행화면 왼쪽에는 파라미터를 입력할 수 있고, 오른쪽에는 결과가 나오는데 전체 결과 메시지를 확인하거나 결과만 보기 옵션으로 최종 성공 실패에 대한 결과 메시지만 볼 수도 있습니다.\n우선은 파라미터 없이 실행해 보았고, 무사히 성공한 결과가 나왔습니다.\n이번에는 파라미터를 입력하고 액션을 실행해보았습니다. 파라미터는 json 형태로 입력하면 됩니다. 왼쪽 창에서 입력한 파라미터가 결과에 잘 반영되어 나왔습니다.\n결과만 보기 옵션을 끄고 실행하면 이렇게 스크롤 해야만 전체를 확인할 수 있을 정도로 긴 결과 메시지가 나타납니다.\n발송메일 확인 link메일함에서 확인해보면 이렇게 메일이 무사히 도착한 것을 확인할 수 있습니다.\n오류 메시지 link위에서 앱 비밀번호를 사용해야 한다고 했는데 혹시 앱 비밀번호를 사용하지 않았을 경우 다음과 같은 오류 메시지가 나타나는 경우가 있습니다.\nThe SMTP server requires a secure connection or the client was not authenticated.\rThe server response was: 5.7.0 Authentication Required.\r이 문제, 인증 오류 메시지를 해결하려면 앱 비밀번호 설정하는 방법 문서 내용대로 설정을 하시면 해결됩니다.\n"
            }
        );
    index.add(
            {
                id:  111 ,
                href: "\/docs\/compute\/classic\/windows-server-image-copy-to-vpc\/",
                title: "Classic 환경 Windows 서버 이미지를 VPC 환경으로 복제하는 방법",
                description: "Ncloud (네이버 클라우드) Classic 환경 Windows 서버 이미지를 VPC 환경으로 복제하는 방법입니다",
                content: "개요 link네이버 클라우드 Classic 환경의 Windows 서버 이미지를 VPC 환경으로 복제하려면 몇가지 사전 작업과 조건이 있습니다. 이 사전 작업과 조건을 차례대로 정리해보겠습니다.\nOS 조건 확인 linkClassic 환경의 서버 이미지를 VPC 환경으로 복제하는 것이므로 VPC에서 지원하는 OS만 복제 가능합니다.\n즉, 현재 네이버 클라우드 VPC 환경에서 지원하는 Windows OS 버전은\nWindows Server 2016 (64-bit) English Edition 하나이기 때문에 2016 R2 등의 OS를 사용 중이라면 VPC에서 지원하지 않아 복제가 불가능하니 VPC에서 지원할 때까지 작업을 보류하셔야 합니다.\n사전 작업 확인 link우선 사전 작업이 어떤 것이 있는지 확인해 보기 위해 Windows 서버 이미지를 하나 만들어서 상단에 있는 [VPC로 복제] 버튼을 클릭해 봅니다.\n안내 팝업에는 다음과 같은 작업이 필요하다고 적혀 있습니다.\n백신 솔루션 확인 및 필요시 백신 삭제 백신 상태 확인 스크립트 실행 내 서버 이미지 다시 생성 후 VPC 복제 기능 사용 백신 삭제 linkWindows 서버에 설치된 백신 솔루션을 확인해서, ApexOne 또는 OfficeScan이라면 백신 삭제가 필요하며, 그 외 솔루션은 삭제하지 않아도 됩니다.\nApexOne 삭제방법 link 제어판 -\u003e 프로그램 추가제거로 이동 후 **‘Trend Micro Apex One Security Agent’**를 선택하고, 삭제합니다. C:\\Program Files (x86) 경로의 Trend Micro\\Security Agent 폴더를 삭제합니다.\n(삭제되지 않는 파일은 그대로 두셔도 됩니다) OfficeScan 삭제방법 link 제어판 -\u003e 프로그램 추가제거로 이동 후 **‘Trend Micro officescan Security Agent’**를 선택하고, 삭제합니다. C:\\Program Files (x86) 경로의 Trend Micro\\Security Agent 폴더를 삭제합니다. 그 외 솔루션 link 백신 삭제 불필요 백신상태 확인 link백신이 모두 정상적으로 제거되었는지 확인하는 툴을 실행합니다.\n백신상태 확인 Tool 다운로드 linkWindows PowerShell을 열고, 다음의 명령어를 실행하면 바탕화면에 Tool이 다운로드 됩니다.\ncd c:\\users\\Administrator\\Desktop Invoke-WebRequest http://init.ncloud.com/vpcporting/real/ncp_vac_chk.exe -outfile ncp_vac_chk.exe\r백신상태 확인 Tool 실행 link바탕화면에 다운로드 된 ncp_vac_chk.exe 파일을 관리자 권한으로 실행합니다.\n백신상태 확인 체크 결과 확인 link백신상태 확인이 정상적으로 수행되면 바탕화면에 notifyFreeAntiVirusRemoved, result 파일 2개가 생성되며, 백신상태 확인이 비정상으로 수행되면 result 파일 1개만 생성이 됩니다.\nnotifyFreeAntiVirusRemoved 파일이 생성되지 않거나 해당 파일의 내용이 OK가 아닌 경우 백신상태 확인이 정상적으로 완료되지 못한 경우이므로 백신솔루션에 따라 필요시 백신이 잘 제거되었는지 다시 한번 더 체크 후 해당 Tool을 실행해야 합니다.\n백신상태 확인이 정상적으로 완료되지 않고 문제가 지속되면 result 파일을 첨부하여 네이버 클라우드 고객센터에 문의하셔야 합니다.\n서버 이미지 복제 link서버 이미지 재 생성 link위에서 백신상태 확인 체크가 정상적으로 완료되었다면, 서버 이미지를 다시 생성합니다.\n서버 이미지 VPC로 복제 link[콘솔] - [Classic] - [Server] - [Server Image]에서 새로 생성한 이미지를 선택하고 상단의 [VPC 로 복제] 버튼을 클릭합니다.\n위에서도 설명했듯이 현재는 Windows Server 2016 (64-bit) English Edition 버전만 지원합니다.\n복제되는 신규 서버 이미지 이름을 입력하고 [생성] 버튼을 클릭합니다.\n실제 VPC 환경에 복제 진행 중인 이미지가 표시되기까지는 다소 시간이 걸릴 수 있으니 잠시 기다리시면 확인하실 수 있습니다.\n복제된 서버 이미지 확인 link복제가 완료된 서버 이미지의 상세 정보를 살펴보면 Classic 복제 여부 항목이 Y로 표시되는 것을 확인할 수 있습니다.\n서버 생성 linkClassic 환경에서 VPC 환경으로 복제된 서버 이미지로 새로운 서버가 생성되는지 확인해보겠습니다.\n이미지를 선택하고 [서버 생성] 버튼을 클릭해서 서버 생성화면에서 정보를 입력하고 서버를 생성합니다.\n정상적으로 생성된 서버를 확인할 수 있습니다.\n참고 URL link Ncloud Classic 환경 Windows 서버 이미지를 VPC 환경으로 복제\nhttps://guide.ncloud-docs.com/docs/server-serverimage-classic#windows-서버-이미지-복제 문서 업데이트 내역 link\r날짜 내용 2021-05-31 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  112 ,
                href: "\/docs\/compute\/server-spec-change-limit\/",
                title: "Ncloud 서버 스펙 변경 제한 사항",
                description: "Ncloud (네이버 클라우드) 서버들의 스펙을 변경하는 방법과 제한사항에 대한 내용입니다",
                content: "개요 linkNcloud (네이버 클라우드)에서는 기본적으로 서버 타입 간의 스펙 변경을 지원하지 않고, 동일한 타입 내에서의 스펙 변경만 지원합니다.\n다른 타입의 스펙으로 변경하려면 [내 서버 이미지] 기능을 이용해서 서버 이미지를 생성한 다음, 다른 타입으로 서버를 새로 만들어야 합니다. 이때 IP 주소는 변경됩니다.\r타입 간 스펙 변경이 가능한 경우 : 타입간 스펙 변경은 대부분은 불가능하나 Compact 타입과 Standard 타입 간에는 스펙 변경을 할 수 있습니다.\rVPC 환경의 경우 Standard, High Cpu, High Memory 서버들간에 스펙 변경이 되는 경우도 있습니다. 다만, 모든 서버가 스펙 변경이 가능한 것이 아니라 서버가 생성된 인프라에 따라 해당 기능이 지원되지 않을 수도 있습니다.\r문서 업데이트 내역 link\r날짜 내용 2021-07-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  113 ,
                href: "\/docs\/compute\/server-operation-stop-price\/",
                title: "Ncloud 서버 정지 시 요금할인",
                description: "Ncloud (네이버 클라우드)에서 서버 정지 시 요금할인 횟수와 서버 정지 기한에 대한 안내입니다",
                content: "개요 link네이버 클라우드에서는 서버를 정지할 경우 일부 타입을 제외한 대부분의 서버에 대해 운영체제 설치를 위해 제공된 기본 디스크 요금만 청구가 되어 요금 할인이 됩니다.\n추가 요금이 청구되는 서비스 link공인 IP, 로드밸런서, 추가 디스크, Security Monitoring, 추가 Network Interface 등 서버에 연결된 다른 유료 서비스의 경우 서버가 정지되어도 정상 청구됩니다.\n요금 할인 횟수와 서버 정지 기한 link 요금이 할인되는 서버의 경우 1회 최대 90일, 12개월 누적 최대 180일까지만 서버를 정지할 수 있습니다. 서버 정기 가능 기한을 넘긴 서버는 고객에게 통보 후 서버를 반납하게 됩니다. 서버를 반납하게 될 때 서버에 저장된 데이터는 네이버 클라우드에서 30일간 직접 백업하여 보관 후 삭제하게 됩니다. 요금 할인이 적용되지 않는 서버 타입 link일부 서버들은 서버를 정지해도 요금 할인이 되지 않고, 서버가 가동 중일 때와 동일한 요금이 청구됩니다. 할인이 적용되지 않는 서버 타입은 다음과 같습니다.\nMicro 서버 High Memory 서버 GPU 서버 Virtual Dedicated Server Baremetal 서버 문서 업데이트 내역 link\r날짜 내용 2020-11-13 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  114 ,
                href: "\/docs\/compute\/pip-python-install-on-centos6\/",
                title: "CentOS 6에서 pip - Python 설치하기",
                description: "Ncloud (네이버 클라우드) CentOS 6.x에서 Repository를 변경해 pip - Python을 설치하는 방법입니다",
                content: "개요 link2020년 12월 01일부로 CentOS6의 기술지원이 공식 종료되었습니다.\nyum을 이용한 패키지 설치, 업데이트 등을 할 수 없는 상황이기에 pip, Python등의 설치가 원활하지 않습니다. 그래서 pip설치에 필요한 CentOS6.x의 yum 명령을 수행하려면 먼저 아래의 가이드대로 Repository mirror를 변경하는 Script를 다운받아 설치해야 그 다음 단계를 진행할 수 있습니다.\n목적 link지원이 종료된 CentOS6에서 굳이 pip를 설치하려고 하는 이유는 DB 백업 파일을 aws cli를 이용해서 Object Storage에 저장하기 위해서 입니다.\n매 일정 시간에 DB나 소스 파일을 백업하고 백업된 파일을 Object Storage에 백업-동기화 하는 작업을 aws cli를 이용해서 처리하게 됩니다.\nRepository 변경 link이 Repository 변경 스트립트는 네이버 클라우드에서 공식 제공하는 스크립트입니다.\nwget http://repo.ncloud.com/etc/patch/Add-CentOS-Vault-Repo.sh\rbash Add-CentOS-Vault-Repo.sh\ryum install zsh\r필요 패키지들 설치 link\ryum -y groupinstall 'Development Tools'\ryum -y install openssl-devel* ncurses-devel* zlib*.x86_64\ryum update curl nss\rPython 설치 linkCentOS6에는 Python 2.6이 설치되어 있습니다.\n하지만, 위에서 설명한 대로 CentOS 6에 대한 지원이 종료되면서 일반적인 방법으로는 pip를 설치할 수 없습니다.\n몇가지 상황을 테스트 해본 결과 Python 2.7과 Python 3.5에서는 pip를 설치할 수 있는 방법을 찾았고, 그래서 여기서는 Python 3.5.10을 설치하겠습니다.\n# Python 3.5 설치 압축파일 다운로드\rwget https://www.python.org/ftp/python/3.5.10/Python-3.5.10.tgz\r# Python 설치파일 압축해제 후 설치\rtar vxzf Python-3.5.10.tgz\rcd Python-3.5.10\r./configure\rmake\rmake install\r# Python 설치 확인\rwhich python3\r# Python 버전 확인\rpython3 -V\rPIP 설치 linkpip설치 파일도 위에서 설치한 Python 버전에 맞는 설치파일을 다운받아서 설치해야 문제없이 설치됩니다.\n현재까지 문제 없는 것으로 확인된 버전은 2.7과 3.5 입니다.\ncurl -O https://bootstrap.pypa.io/3.5/get-pip.py\rpython3 get-pip.py\r이후에 aws cli설치나 Object Storage 백업과 관련된 내용은 CentOS에서 mysql DB를 Object Storage로 자동 백업하기 문서를 참고하시기 바랍니다.\n설치 오류 상황과 해결 방법 linkpip를 설치하는 과정에 발생하는 몇가지 오류 상황과 그에 따른 해결방법을 정리해보겠습니다.\n{% include warning.html title=“curl: (35) SSL connect error” content=“pip 설치파일을 다운 받기 위해 curl을 실행할 때 발생하는 오류 메시지로 위쪽에서 필요 패키지들 설치할 때 있었던 다음 명령을 실행하면 해결됩니다.” %}\nyum update curl nss\r{% include warning.html title=“SyntaxError: invalid syntax” content=“pip를 설치할 때 Python 버전이 일치하지 않는 등의 이유로 발생하는 문제입니다. 위에서 설명했던 대로 Python 버전과 일치하는 pip 설치 파일을 다운 받으면 됩니다.” %}\n# 오류가 발생하는 경로\rcurl -O https://bootstrap.pypa.io/get-pip.py\r# 해결방법 : 경로 중간에 Python 버전을 추가\rcurl -O https://bootstrap.pypa.io/{Python 버전}/get-pip.py\r# 오류 없는 버전 예시\rcurl -O https://bootstrap.pypa.io/2.7/get-pip.py\rcurl -O https://bootstrap.pypa.io/3.5/get-pip.py\r문서 업데이트 내역 link\r날짜 내용 2021-01-26 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  115 ,
                href: "\/docs\/compute\/install-package-by-change-repository-in-private-network\/",
                title: "외부 네트워크에 연결할 수 없는 환경에서 Repository를 변경해 리눅스 패키지 설치하기",
                description: "Ncloud (네이버 클라우드)에서 외부 네트워크에 연결할 수 없는 환경에서 Repository를 변경해 리눅스 패키지 설치하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) Secure Zone이나 VPC 환경의 Private Network처럼 외부와 통신이 단절된 환경에서 리눅스 패키지를 설치해야 할 때 repository 경로를 네이버 클라우드 내부 repository로 바꾸면 문제없이 패키지 설치를 할 수 있습니다. 여기서는 OS별로, Classic/VPC 환경별로 변경하는 방법을 정리해보겠습니다.\nCentOS linkCentOS는 /etc/yum.repos.d/CentOS-Base.repo 를 열어보면 아래 repository주소를 확인할 수 있습니다.\n~# vi /etc/yum.repos.d/CentOS-Base.repo\r### Classic 환경 - CentOS\r네이버 클라우드 Classic 환경 CentOS에서 repository 주소는 미러 사이트가 기본으로 설정 되어 있는 것을 확인할 수 있습니다.\r하지만 현재 서버는 Secure Zone 등 외부와 통신이 되지 않는 상태이므로 이대로는 패키지 설치를 할 수 없습니다. 이때 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 접속하도록 mirrorlist를 주석처리하고, baseurl을 주석해제하고, 경로를 수정해주면 됩니다.\n## 원본\rmirrorlist=http://mirrorlist.centos.org/?release=$releaserver\u0026arch=$basearch....\r#baseurl=http://mirror.centos.org/centos/$releaserver/extras/$basearch/\r## 수정\r#mirrorlist=http://mirrorlist.centos.org/?release=$releaserver\u0026arch=$basearch....\rbaseurl=http://mirror.ncloud.com/centos/$releaserver/extras/$basearch/\r변경 후 패키지 설치 테스트를 해봅니다.\n~# yum -y install httpd\r웹서버 설치가 문제없이 되는 것을 확인할 수 있습니다.\nsed 명령어 사용 linksed 명령어를 사용하면 더욱 편하게 변경할 수 있습니다.\n## mirrorlist 주석처리\r~# sed -i 's/mirrorlist=/#mirrorlist=/g' /etc/yum.repos.d/CentOS-Base.repo\r## baseurl 주석해제, 경로수정\r~# sed -i 's/#baseurl=http:\\/\\/mirror.centos.org\\/centos/baseurl=http:\\/\\/mirror.ncloud.com\\/centos/g' /etc/yum.repos.d/CentOS-Base.repo\rVPC 환경 - CentOS link네이버 클라우드 VPC 환경은 이미 repository 경로가 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 설정되어 있으므로 별도로 수정할 필요가 없습니다.\nUbuntu linkUbuntu는 /etc/apt/sources.list 에서 repository list 를 확인할 수 있습니다.\n다만, 기본 미러사이트 주소가 Classic, VPC 두 환경이 다르게 설정되어 있습니다.\nClassic : kr.archive.ubuntu.com VPC : archive.ubuntu.com ~# vi /etc/apt/sources.list\rClassic 환경 - Ubuntu link\rVPC 환경 - Ubuntu link\r현재 서버는 Secure Zone 또는 Private Network 등 외부와 통신이 되지 않는 상태이므로 이대로는 패키지 설치를 할 수 없습니다. 이때 네이버 클라우드 내부 repository ( mirror.ncloud.com )로 접속하도록 경로를 수정해주면 됩니다.\n## Classic 환경 - Ubuntu\rkr.archive.ubuntu.com --\u003e mirror.ncloud.com (변경)\rsecurity.ubuntu.com --\u003e mirror.ncloud.com (변경)\r## VPC 환경 - Ubuntu\rarchive.ubuntu.conm --\u003e mirror.ncloud.com (변경)\r/etc/apt/sources.list 에서 위와 같이 변경-저장한 후에 apt update 를 해주면 변경해준 Ncloud 내부 repository에서 패키지 리스트를 가져와 설치를 합니다.\n설치 된 repository를 테스트 하기 위해 apt install 을 사용하여 패키지 다운로드를 해보면 Ncloud 내부 repository에서 패키지 설치가 진행되는 것을 확인 할 수 있습니다.\n~# apt -y install apache2\rUbuntu 또한 sed 명령어로 간단하게 변경할 수 있습니다.\n## Classic 환경 - Ubuntu\rsed -i 's/kr.archive.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\rsed -i 's/security.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\r## VPC 환경 - Ubuntu\rsed -i 's/archive.ubuntu.com/mirror.ncloud.com/g' /etc/apt/sources.list\r참고 URL link CentOS mirror 사이트 안내\nhttps://www.centos.org/download/mirrors/\"\nUbuntu mirror 사이트 안내\nhttps://launchpad.net/ubuntu/+archivemirrors\n문서 업데이트 내역 link\r날짜 내용 2021-10-25 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  116 ,
                href: "\/docs\/storage\/ncloud-storage-compare\/",
                title: "Ncloud에서 제공하는 스토리지들의 요금과 특징 비교",
                description: "Ncloud(네이버 클라우드)에서 제공하는 여러 스토리지들의 요금과 특징을 비교해보았습니다",
                content: "개요 linkNcloud에서 제공하는 스토리지들의 주요 기능과 용도를 QnA 형식으로 비교 정리해보겠습니다.\n비교 대상 스토리지 link Block Storage Object Storage NAS Archive Storage 가격 비교 link 스토리지 구분 과금 단위 시간 당 요금 500G 기준 요금 기타 사항 Block Storage HDD 10G 0.8원 40원 SDD 10G 1.6원 80원 NAS 500G 50원 50원 Object Storage 1PB 이하 1G 0.039원 19.5원 트래픽, API요청수 요금 별도 1PB 초과 1G 0.036원 18원 트래픽, API요청수 요금 별도 Archive Storage 1G 0.0076원 3.8원 트래픽, API요청수 요금 별도 QnA link\r서버에 디스크를 추가하고 싶을 때는 어떤 스토리지를 사용하면 되나요?\rBlock Storage를 사용하면 됩니다. Console - Server - 서버 상세 정보 - 스토리지 생성 메뉴에서 스토리지를 추가하고 서버에 마운트해서 사용하시면 됩니다.\r서버당 디스크는 최대 얼마까지 추가할 수 있나요?\rBlock Storage를 사용하면 됩니다. Ncloud(네이버 클라우드)에서 서버에 직접 추가되는 디스크는 Block Storage로 최대 2,000GB를 지원하며, 서버 1대당 최대 16개의 스토리지를 추가할 수 있습니다.\r디스크를 추가할 수 없는 서버도 있나요?\rNcloud(네이버 클라우드)에서 서버에 직접 추가되는 디스크는 Block Storage로 Micro 타입의 서버, Bare Metal 서버, Application Server Launcher는 Block Storage를 추가할 수 없습니다.\r여러 서버에서 공용으로 사용할 스토리지가 필요합니다.\rNAS 서비스를 이용하시면 됩니다. 서버 간 데이터 공유, 대용량 스토리지, 유연한 용량 확대/축소, 스냅샷 백업 등 NAS 서비스의 주요 기능을 활용해 안전하고 편리하게 데이터를 관리할 수 있습니다. 특히, 프로토콜에 따른 인증 설정으로 높은 보안성을 제공하고, 이중화된 Controller 및 Disk Array Raid 구성으로 강력한 서비스 안정성을 확보하고 있습니다.\r유저가 업로드 하는 이미지를 저장하고 싶습니다.\rBlock Storage, Object Storage, NAS 모두 가능합니다만 용도에 따라 선택하시면 되겠습니다. 매우 빠른 응답 속도가 필요하면 Block Storage. 저렴한 비용과 여러 서버에서 동시에 이미지를 저장해야 한다면 Object Storage.\r백업 자료를 오랜기간 보관해 두고 싶습니다.\rArchive Storage를 이용하시면 됩니다. Archive Storage는 높은 내구성과 저렴한 비용이 특징인 데이터 아카이빙 및 장기 백업에 최적화된 스토리지 서비스입니다.\rAWS S3와 비슷한 스토리지는 어떤 건가요?\rObject Storage입니다. Ncloud(네이버 클라우드)의 Object Storage는 AWS의 S3에서 사용하는 API와 호환이 되므로 쉽게 사용하실 수 있습니다.\rCDN를 서비스를 이용하려면 어떤 스토리지를 사용해야 하나요?\rObject Storage를 사용하시면 됩니다. 물론 CDN의 원본 서버로 설정할 수 있는 것은 자체 웹 서버 및 네이버 클라우드 Object Storage, Server 등이 있는데, 그 중에서도 Object Storage를 사용하시는 것이 가장 쉽고 안정적입니다. Object Storage에 파일을 저장하고 나서, CDN+ 또는 GCDN, Global Edge 상품과 연동하시면 됩니다.\r문서 업데이트 내역 link\r날짜 내용 2020-12-28 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  117 ,
                href: "\/docs\/storage\/object-storage\/services-required-integrating-with-object-storage\/",
                title: "Object Storage와 연동이 필수인 서비스",
                description: "Ncloud(네이버 클라우드) Object Storage와 연동이 필수인 서비스를 정리해보았습니다",
                content: "개요 link네이버 클라우드의 수 많은 서비스들 중에는 Object Storage가 설정, 준비되어 있어야 하는 서비스들, 즉, Object Storage와 연동이 필수인 서비스들이 여럿 있습니다.\n어떤 서비스들이 이에 해당하는지 정리해보겠습니다.\n연동 필수 서비스 linkObject Storage와 연동이 필수인 서비스들에는 AI-Application Service와 Media 관련 서비스들이 많습니다.\nCLOVA Speech CLOVA Dubbing VOD Transcoder VOD Station Video Player Image Optimizer SourceBuild Cloud Hadoop Data Analytics Service 연동 선택 서비스 linkObject Storage와 반드시 연동해야 하는 것은 아니지만, Object Storage를 이용하면 훨씬 편하고, 빠르고 안정적으로 서비스 가능한 경우도 있습니다.\nCDN+ Global CDN 문서 업데이트 내역 link\r날짜 내용 2021-02-16 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  118 ,
                href: "\/docs\/storage\/object-storage\/lifecycle-management-guide\/",
                title: "Object Storage Lifecycle Management 관리대상 설정 방법",
                description: "Ncloud(네이버 클라우드) Object Storage Lifecycle Management 관리대상 설정 방법입니다",
                content: "개요 link네이버 클라우드 Object Storage에 저장된 Object 즉, 파일들의 Lifecycle(수명주기)를 설정할 때 관리대상이 되는 Object를 결정하는 규칙에 대해 정리해보겠습니다.\nLifecycle Management(수명주기) 정책설정 link수명주기 정책 설정은 크게 정책, 관리대상, 이동위치 3가지 항목으로 구성됩니다.\n정책 link정책 유형은 다음의 3가지가 있습니다.\n만료 삭제 : 설정된 기간이 지난 파일을 삭제 이관 : 설정된 기간이 지난 파일을 Archive Storage로 이동 이관 후 삭제 : 설정된 기간이 지난 파일을 Archive Storage로 이동한 후 Object Storage에서 삭제 그리고 이동 시점은 파일이 Object Storage에 저장-생성된 후 경과한 일자를 기준으로 하며 1일 ~ 3,650일 사이의 값을 입력합니다.\n관리대상 (Source) link관리대상의 버킷(Bucket)을 선택하고 Object 이름의 규칙을 접두어 방식으로 입력합니다.\n이동위치 (Target) link이동할 위치는 Archive Storage로 고정이며, Archive Storage의 컨테이너(버킷)을 선택하고 세부경로 즉, 폴더를 입력합니다.\n세부경로에 아무것도 입력하지 않으면 Source 즉, Object Storage의 위치, 폴더 구조 그대로 이동됩니다.\n관리대상(Source) Object 이름 규칙 link\r네이버 클라우드에서 채택하고 있는 규칙은 접두어 방식입니다. 예를 들어 규칙을 ncp라고 설정하면 이름이 ncp로 시작되는 모든 파일과 폴더가 대상이 됩니다. 하지만, 접두어 규칙이기 때문에 img_ncp_01.png 처럼 파일명 중간이나 끝에 ncp가 들어간 파일과 폴더는 대상이 아닙니다.\r그리고 2단계 인증을 사용하게 되면 기존의 보안 수준이 낮은 앱의 액세스 설정을 사용할 수 없습니다.\rObject 이름 규칙의 특수 문자 사용 link\r⁃ \u003c \u003e : \" \\ | ? * % 는 사용할수 없습니다. ⁃ /는 첫 글자에 사용할 수 없습니다. ⁃ //처럼 /는 연속해서 사용할 수 없습니다.\r적용 예시 link아래 스샷처럼 폴더와 파일이 저장되어 있다고 가정하고 예를 들어보겠습니다.\n다른 항목들은 동일하고, 관리대상(Source) Object 이름 규칙에 따라 어떤 결과가 나오지는 확인해보겠습니다.\n물론 아래의 예시들에서 공통적으로 위에서 지정한 수명주기 날짜에 해당하는 파일들만 이동하게 됩니다.\n- 3rdeyesys\r- img_01.png\r- screenshot_01.png\r- 3rdeyesys_img\r- img_02.png\r- ncp\r- - 3rdeyesys_biz.png\r- ncp_server_acg_classic.png\r- ncp_server_acg_vpc_inbound.png\r- vpc_acg_nacl_ncp.png\r이렇게 3rdeyesys, 3rdeyesys_img 2개의 폴더에는 각각 파일이 존재하고, ncp 폴더에는 아무것도 없습니다. 그리고 4개 파일이 루트에 저장되어 있습니다.\nObject 이름 규칙(접두어) : 3rdeyesys link이 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n즉, 3rdeyesys로 시작하는 파일과 폴더 아래에 있는 파일까지 모두 이동하게 됩니다.\n- 3rdeyesys\r- img_01.png\r- screenshot_01.png\r- 3rdeyesys_img\r- img_02.png\r- 3rdeyesys_biz.png\rObject 이름 규칙(접두어) : ncp link이 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n위의 경우와 다르게 ncp 폴더는 이동하지 않는데 그 이유는 ncp 폴더 아래에 아무 파일도 없기 때문에 이동할 파일이 없어 폴더도 이동하지 않습니다.\n- ncp_server_acg_classic.png\r- ncp_server_acg_vpc_inbound.png\r마찬가지로 ncp 폴더 아래에 파일이 존재하더라도 위에서 지정한 수명주기 날짜에 해당하는 파일이 없는 경우에도 ncp 폴더는 이동하지 않습니다.\n또한 접두어 방식이기 때문에 파일명 중간에 ncp가 들어간 vpc_acg_nacl_ncp.png 파일은 해당되지 않아서 이동하지 않습니다.\nObject 이름 규칙(접두어) : 3rdeyesys/ link이렇게 뒤에 “/“를 입력하여 폴더라고 명시한 경우에 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n- 3rdeyesys\r- img_01.png\r- screenshot_01.png\r즉, 끝에 “/“를 입력했기 때문에 3rdeyesys로 시작하는 폴더만 대상이 되어 다른 파일은 이동하지 않습니다.\nObject 이름 규칙(접두어) : 3rdeyesys/img link이렇게 폴더와 파일명 접두어까지 함께 입력한 경우 Archive Storage로 이동하는 파일과 폴더는 다음과 같습니다.\n- 3rdeyesys\r- img_01.png\r즉, 3rdeyesys 폴더 아래에 있는 파일들 중에서 img로 시작하는 이름을 가진 파일만 이동하게 됩니다.\nObject 이름 규칙(접두어) : 아무것도 입력하지 않았을 때 link아무것도 입력하지 않았을 때는 모든 파일과 폴더 아래에 있는 파일들이 이동하게 됩니다.\n물론 마찬가지로 수명주기 날짜에 해당하는 파일만 이동하게되고, 폴더 아래에 해당하는 파일이 없을 경우 해동 폴더는 이동하지 않습니다.\n정책 실행 시간 linkLifecycle Management(수명주기) 정책 실행시간은 아래와 같습니다.\n01:00~02:00, 07:00~08:00, 13:00~14:00, 19:00~20:00\n(※ 파일용량이 클 경우 일부 변동될 수 있음) 예시) 정책 유형(이관), 이동 시점(생성 후 1일)로 정책을 생성하고, 대상 파일이 15시에 업로드 되었다면 다음 날 19~20시 사이에 이관 완료.\n참고 URL link Object Storage 수명주기 가이드\nhttps://guide.ncloud-docs.com/docs/objectstorage-use-lifecycle 문서 업데이트 내역 link\r날짜 내용 2021-02-16 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  119 ,
                href: "\/docs\/storage\/object-storage\/how-to-access-using-aws-cli\/",
                title: "AWS CLI 버전 2를 이용한 Object Storage 접속 방법",
                description: "AWS CLI 버전 2를 설치하고 Ncloud(네이버 클라우드) Object Storage에 접속하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) Object Storage는 AWS의 스토리지 서비스 S3와 호환이 되도록 설계되어 있습니다.\n그래서 Object Storage에 접속, 관리할 때 AWS의 CLI(Command Line Interface)를 사용할 수 있는데 그 중에서 AWS CLI 버전 2의 설치와 사용방법에 대해 정리해보겠습니다.\nAWS CLI 버전 2 설치 link\rinfo\rAWS CLI 버전 1에서는 설치와 실행에 Python과 PIP를 이용하는 방법이 주로 사용되었지만, AWS CLI 버전 2에서는 Python 임베디드 버전이 포함되어 있어 별도로 설치할 필요가 없기에 설치 파일도 ZIP 압축 파일 형태로 제공됩니다.\n설치 파일 다운로드 linkAWS CLI 버전 2 설치 파일을 awscliv2.zip 이름으로 다운로드 합니다.\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\r압축 풀기 linkunzip으로 압축을 풀겠습니다.\nunzip awscliv2.zip\r설치 link아래 명령으로 쉽게 설치할 수 있습니다.\n./aws/install\r버전 확인 link설치가 완료된 후 버전을 확인해보면 아래와 같이 AWS CLI 버전과 임베디드된 Python 버전도 확인할 수 있습니다.\naws --version\rAPI 인증키 생성 link다음으로 접속에 필요한 인증키를 Ncloud (네이버 클라우드) 포탈 - 마이페이지 - 계정관리 - 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\nAWS CLI 환경 설정 link이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목은 입력하지 않으셔도 됩니다.\naws configure\rAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\rAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\rDefault region name [None]: [Enter]\rDefault output format [None]: [Enter]\rObject Storage 접속 link이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# Object Storage에 존재하는 전체 버킷 리스트를 조회하는 명령어입니다.\raws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\r# s3 ls 명령으로 Object Storage에 존재하는 aws-cli-test 버킷에 있는 오브젝트 리스트를 조회하는 예시입니다.\raws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls s3://aws-cli-test\r# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어 예시입니다.\raws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\rAWS CLI 업데이트 link설치된 AWS CLI를 최신 버전으로 업데이트 하려면 아래 명령어를 사용하면 됩니다. 최신 버전이 설치된 상태에서는 아래 스샷처럼 이미 최신 버전과 동일한 버전이 설치되어 있다는 메시지가 나타납니다.\n./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli --update\rAWS CLI 삭제 link설치된 AWS CLI를 삭제하려면 아래의 단계대로 진행하시면 됩니다.\nsymlink 삭제 link\rrm /usr/local/bin/aws\rrm /usr/local/bin/aws_completer\r설치 디렉토리 삭제 link\rrm -rf /usr/local/aws-cli\r설정 정보 삭제 (선택 사항) linkAWS CLI 환경 설정 정보는 서버 내의 모든 AWS SDK 및 AWS CLI에서 공유되므로 더 이상 사용하지 않는다면 삭제하시면 됩니다.\nrm -rf ~/.aws/\r참고 URL link AWS CLI 버전 2 가이드\nhttps://docs.aws.amazon.com/ko_kr/cli/latest/userguide/cli-chap-welcome.html\nNcloud Object Storage CLI 가이드\nhttps://cli.ncloud-docs.com/docs/guide-objectstorage\n문서 업데이트 내역 link\r날짜 내용 2023-05-09 AWS CLI 버전2로 업그레이드 "
            }
        );
    index.add(
            {
                id:  120 ,
                href: "\/docs\/storage\/object-storage\/data-auto-transfer-to-archive-storage\/",
                title: "Object Storage 데이터를 Archive Storage로 자동으로 이동시키는 방법",
                description: "Ncloud(네이버 클라우드) Object Storage 데이터를 Archive Storage로 자동으로 이동시키는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) Object Storage는 일반 디스크인 Block Storage나 NAS에 비해 가격도 1/2 ~ 1/4정도이면서도 안정적이기 때문에 데이터 저장 특히 백업 용도로 많이 사용합니다.\n그럼에도 불구하고 많이 양의 데이터가 저장되면 비용에 대한 부담이 생길 수 밖에 없는데, 이럴 때 Archive Storage를 이용하면 Object Storage의 1/5정도로 비용이 줄어들기에 매우 효과적입니다.\n그래서 이번에는 Object Storage에 있는 데이터를 Archive Storage로 이동시키는 즉, 이관하는 방법에 대해 정리해보겠습니다.\n스토리지 가격 비교 link위 개요에서도 간단하게 설명했지만, Archive Storage는 Object Storage에 비해 비용이 1/5 정도입니다.\n이 두가지 뿐만 아니라 여러 스토리지들의 가격과 용도에 대한 비교는 아래 문서에서 확인할 수 있습니다.\n"
            }
        );
    index.add(
            {
                id:  121 ,
                href: "\/docs\/storage\/object-storage\/bucket-access-log-management-guide\/",
                title: "Object Storage 버킷 접근 로그 확인하는 방법",
                description: "Ncloud(네이버 클라우드)의 Object Storage 버킷 이용, 접근 로그를 확인하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) Object Storage에 존재하는 오브젝트, 즉 파일을 호출, 접근한 기록이나 오브젝트를 업로드한 로그를 확인하는 방법을 정리해보겠습니다.\n버킷 생성 link우선, 테스트에 사용할 버킷과 로그를 저장할 버킷을 생성하고, 테스트용 버킷에는 파일 몇개를 업로드 해두었습니다.\nobject-bucket-test: 테스트용 버킷 object-bucket-test-log: 로그를 저장할 버킷 로그 설정 link로그를 설정하는 방법은 버킷을 선택하고, 옆에 있는 [ ] 아이콘을 클릭하면 나타나는 메뉴에서 [로그 관리]를 선택합니다.\n로그 관리 설정 link[로그 관리] 설정 팝업에서 로그를 저장할 버킷을 선택하고, 로그 파일의 Prefix를 입력한 후 [+ 추가] 버튼을 클릭합니다.\n설정 항목이 추가 되었으면 [확인] 버튼을 클릭해서 설정을 저장합니다. 로그 생성 규칙 link\r⁃ 접근 로그 관리를 설정하면 매시간 15~55분에 이전 1시간 동안의 로그가 생성됩니다. ⁃ 예시: 17시 00분 00초~17시 59분 59초의 로그는 18시 15~55분에 생성\r로그 생성 link위에서 확인한 로그 생성 규칙처럼 일정한 시간이 지난 후에 아래와 같이 로그가 생성된 것을 확인할 수 있습니다.\n로그 예시 link생성된 로그를 다운로드 받아서 확인해보면 아래와 같은 JSON 형식으로 구성된 것을 확인할 수 있습니다.\n(로그 내용이 길이서 중요한 부분만 표시하고 나머지는 생략했습니다.)\n{\r\"container_id\": \"5d3******e-9****-***2-a***0-54******f9b\", \"container_name\": \"object-bucket-test\", \"container_region\": \"KR\", \"format\": 1, \"headers\": { \"Accept-Encoding\": [\"gzip, deflate, br\"] }, \"https\": {\r\"cipher_suite\": \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\", \"protocol\": \"TLSv1.2\"\r}, \"object_name\": \"3rdeyesys-1.png\", \"remote_address\": \"123.123.123.123\", \"stat\": { }, \"status\": 200, \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML) Chrome/115.0.0.0\"\r}\r로그 통합 저장 link또한, 여러 버킷의 접근 로그를 하나의 버킷에 통합해서 저장할 수도 있습니다.\n아래와 같이 또 다른 버킷에서 [로그 관리] 설정을 추가하면서 로그를 저장할 버킷은 위에서 설정했던 버킷과 동일한 버킷으로 지정했습니다.\n그리고 일정 시간이 지난 후에 확인해보면 아래와 같이 2개의 다른 버킷의 접근 로그가 저장된 것을 확인할 수 있습니다. 로그 설정 삭제 link접근 로그를 더 이상 기록하고 싶지 않을 경우에는 아래와 같이 로그 관리 설정에서 [삭제] 버튼을 클릭해서 설정을 모두 지우시면 됩니다.\n일본 리전 link일본 리전의 경우 다른 리전과 몇가지 내용들이 다르게 설정, 저장됩니다.\n로그가 기록되는데에는 10분 ~ 수시간까지 소요될 수 있습니다. 로그에 저장되는 항목 개수가 다른 리전보다 적습니다. 참고 URL link Ncloud Object Storage 버킷 사용 가이드\nhttps://guide.ncloud-docs.com/docs/objectstorage-use-bucket\nNcloud Object Storage 버킷 로그 관리 상세 가이드\nhttps://guide.ncloud-docs.com/docs/objectstorage-use-bucket#로그-관리\n문서 업데이트 내역 link\r날짜 내용 2023-08-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  122 ,
                href: "\/docs\/storage\/object-storage\/cors\/setting-cors-on-bucket\/",
                title: "Object Storage Bucket에 CORS 설정하기",
                description: "Ncloud(네이버 클라우드)의 Object Storage Bucket에 CORS를 설정하는 방법입니다",
                content: "개요 linkObject Storage를 이용해 서비스 개발을 하다 보면 CORS 와 관련된 오류와 종종 마주치게 되는데, 테스트 버킷과 사이트를 생성해서 해결 방법을 알아보겠습니다. 그리고, Ncloud(네이버 클라우드) Object Storage의 CORS 설정은 콘솔이 아닌, CLI와 외부 Client Tool 등을 사용해야 하는데 각각의 방법을 차례로 소개합니다.\ninfo\rCORS(Cross-Origin Resource Sharing)는 웹 애플리케션이 서비스되는 도메인에서 다른 도메인에 있는 리소스를 접근해야 할 때 리소스에 대한 접근 허용, 제한 등에 대한 방법을 정의합니다.\n테스트 방법 link Object Storage에 cors-test 라는 이름의 버킷 생성 http://cors-test.com 라는 테스트 사이트 준비 버킷에 http://cors-test.com 도메인에서 접속 가능하도록 CORS 설정 Javascript를 이용해 cors-test 버킷에 있는 파일이 호출되는지 확인 버킷 CORS 설정을 변경하여 http://cors-test.com 도메인에서는 접속하지 못하게 설정 cors-test 버킷에 있는 파일 호출이 차단되는지 확인 CORS 구성 요소 linkCORS는 아래와 같은 요소들로 구성되어 있습니다.\nAllowedHeader : 리소스를 요청할 때 사용할 수 있는 Header AllowedMethod : 리소스를 요청할 때 허용된 Method AllowedOrigin : 접근 허용된 Origin 도메인 ExposeHeader : 응답에서 접근이 허용된 Header MaxAgeSeconds : 지정한 리소스에 해당하는 프리플라이트(pre-flight) OPTIONS 요청에 대한 최대 응답 시간 CLI 사용 linkNcloud는 Object Storage CLI 접속 시 AWS CLI를 이용해 접속하게 되는데, 자세한 사용 방법은 아래 링크 문서에서 확인 가능합니다.\nhttps://docs.3rdeyesys.com/docs/storage/object-storage/how-to-access-using-aws-cli/\rjson 파일 생성 linkCLI를 사용하기 위해 먼저 간단하게 GET, PUT Method로 접근가능 하게 하는 CORS 설정을 입력한 별도의 json 파일을 생성 합니다. 여기서는 cors-test.json 이라는 이름으로 저장하겠습니다.\n{\r\"CORSRules\": [\r{\r\"AllowedHeaders\": [\r\"*\"\r],\r\"AllowedMethods\": [\r\"GET\",\r\"PUT\"\r],\r\"AllowedOrigins\": [\r\"http://cors-test.com\"\r], \"MaxAgeSeconds\": 3000\r}\r]\r}\rjson 형식에 대해서는 아래의 링크를 참조 합니다.\nAWS - CORS 구성\rjson파일을 생성 하였으면 아래와 같은 형식으로 CORS 규칙 설정을 버킷에 적용하는 명령어를 입력 합니다. 여기서는 테스트를 위해 미리 [cors-test] 라는 이름의 버킷을 생성해두었습니다.\n# CORS 설정 입력 명령어 형식\raws --endpoint-url=https://kr.object.ncloudstorage.com s3api put-bucket-cors --bucket \u003c버킷이름\u003e --cors-configuration file://\r# 예제\raws --endpoint-url=https://kr.object.ncloudstorage.com s3api put-bucket-cors --bucket cors-test --cors-configuration file://cors-test.json\r그런 다음 제대로 적용되었는지 확인 하기 위해 버킷의 CORS 설정을 확인하는 명령어를 실행합니다.\n# CORS 설정 조회 명령어 형식\raws --endpoint-url=https://kr.object.ncloudstorage.com s3api get-bucket-cors --bucket \u003c버킷이름\u003e\r# 예제\raws --endpoint-url=https://kr.object.ncloudstorage.com s3api get-bucket-cors --bucket cors-test\rS3 Browser 사용 link외부 Client Tool중에서 CORS 설정이 가능한 것은 S3 Browser 이며, 자세한 사용 방법은 아래의 링크 문서를 참고하시기 바랍니다.\nObject Storage 접속용 Windows Client Tool - S3 Browser\rS3 브라우저에 접속 하신다음 CORS 설정 대상의 버킷에서 오른쪽 마우스 버튼을 클릭 합니다.\nCORS Configuration 클릭하여 CORS 설정을 오픈하면 처음에는 아무 값도 설정되어 있지 않습니다.\nXML 형식의 설정 준비 link마찬가지로 GET, PUT Method로 접근 가능한 설정을 이번에는 XML 형식으로 입력하고 [Apply] 버튼을 클릭해서 적용합니다.\n*\rGET\rPUT http://cors-test.com 3000\r접속 테스트 link정상 접속 확인 link설정을 마친 후 Javascript를 사용해서 cors-test 버킷에 있는 파일을 호출해보면 아래와 같이 문제 없이 접속되는 것을 확인할 수 있습니다.\nCORS 변경 link접속 차단을 테스트 하기 위해 CORS 설정에서 AllowedOrigin 값을 임의의 http://example.com 으로 변경하겠습니다.\n접속 차단 확인 link설정을 변경한 후에 접속을 해보면 이전과는 다르게 아래와 같은 메시지가 나타나면서 접속이 차단된 것을 확인할 수 있습니다.\nreport\rerror: Access to XMLHttpRequest at ‘https://kr.object.ncloudstorage.com/cors-test/cors-test.txt' from origin ’http://cors-test.com’ has been blocked by CORS policy: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.\nCORS 예시 link예시 1 link아래 예시는 http://*.cors-test.com 즉, cors-test.com 도메인을 가진 모든 하위 도메인에 대해 허용할 요청 Method와 허용할 응답 헤더 값을 정의했습니다.\n{\r\"CORSRules\": [\r{ \"AllowedHeaders\": [\r\"*\"\r],\r\"AllowedMethods\": [\r\"PUT\",\r\"POST\",\r\"DELETE\"\r],\r\"AllowedOrigins\": [\r\"http://*.cors-test.com\"\r],\r\"ExposeHeaders\": [\r\"x-amz-server-side-encryption\",\r\"x-amz-request-id\",\r\"x-amz-id-2\"\r],\r\"MaxAgeSeconds\": 3000\r}\r]\r}\r* PUT\rPOST\rDELETE\rhttp://*.cors-test.com x-amz-server-side-encryption\rx-amz-request-id\rx-amz-id-2\r3000\r예제 2 link아래 예제 2는 2가지 도메인에 대해 각각 다른 규칙을 정의했습니다.\n먼저 http로 접속하는 www.cors-test.com 도메인에 대해서는 GET 방식의 요청만 허용하고,\n다음 https로 접속하는 api.cors-test.com 도메인에 대해서는 PUT, POST, DELETE 요청을 허용하는 규칙입니다.\n{\r\"CORSRules\": [\r{\r\"AllowedHeaders\": [\r\"*\"\r],\r\"AllowedMethods\": [\r\"PUT\",\r\"POST\",\r\"DELETE\"\r],\r\"AllowedOrigins\": [\r\"https://api.cors-test.com\"\r]\r},\r{\r\"AllowedMethods\": [\r\"GET\"\r],\r\"AllowedOrigins\": [\r\"http://www.cors-test.com\"\r]\r}\r]\r}\r*\rPUT\rPOST\rDELETE\rhttp://api.cors-test.com\rGET\rhttp://www.cors-test.com\r문서 업데이트 내역 link\r날짜 내용 2023-02-23 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  123 ,
                href: "\/docs\/storage\/object-storage\/cors\/setting-cors-on-bucket-using-api-sdk\/",
                title: "Object Storage에서 CORS를 SDK for S3 API로 설정하기",
                description: "Ncloud(네이버 클라우드)의 Object Storage Bucket CORS를 AWS SDK for S3 API로 설정하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Object Storage Bucket CORS를 AWS S3에서 제공하는 [SDK for S3 API]로 설정하는 방법을 소개합니다. 여기서 소개할 SDK는 [Python용 SDK for S3 API]와 [PHP용 SDK for S3 API] 두가지입니다.\nCORS 설정 기본 방법 linkObject Storage Bucket에 CORS를 설정하는 기본 방법인 CLI와 외부 Client Tool에 대한 것은 아래 문서에서 확인 가능합니다.\n⁃ Object Storage Bucket에 CORS 설정하기 - CLI \u0026 Client Tool\rPython용 SDK for S3 API linkSDK 설치 linkPython용 SDK를 설치하는 방법은 기본 설치방법과 특정 버전을 설치하는 방법이 있습니다.\n# 기본 설치\rpip install boto3\r# 특정 버전 설치\rpip install boto3==1.6.19\r예제 코드 link아래 예제 코드는 버킷에 CORS를 설정하는 방법과 설정된 CORS를 조회하는 방법입니다.\nimport boto3\rservice_name = 's3'\rendpoint_url = 'https://kr.object.ncloudstorage.com'\rregion_name = 'kr-standard'\raccess_key = '{ACCESS_KEY_ID}'\rsecret_key = '{SECRET_KEY}'\rif __name__ == \"__main__\":\rs3 = boto3.client(service_name, endpoint_url=endpoint_url,\raws_access_key_id=access_key, aws_secret_access_key=secret_key)\rbucket_name = '{버킷명}'\r# Define the configuration rules\rcors_configuration = {\r'CORSRules': [{\r'AllowedHeaders': ['*'],\r'AllowedMethods': ['GET', 'PUT'],\r'AllowedOrigins': ['http://cors-test.com'],\r'MaxAgeSeconds': 3000\r}]\r}\r# Set CORS configuration\rresponse = s3.put_bucket_cors(Bucket=bucket_name, CORSConfiguration=cors_configuration)\rprint(response['ResponseMetadata'])\r# Get CORS configuration\rresponse = s3.get_bucket_cors(Bucket=bucket_name)\rprint(response['CORSRules'])\r예제 코드 실행 결과 link\rPHP용 SDK for S3 API linkPHP용 SDK는 아래 2가지 방법 중에서 한가지를 선택해서 사용할 수 있습니다.\n1. SDK 설치 link우선 composer를 이용해서 설치하는 방법입니다.\ncomposer require aws/aws-sdk-php\r설치 후에 아래 코드를 추가해서 SDK를 불러옵니다. \u003c?php\rrequire '{경로}/vendor/autoload.php';\r?\u003e\r2. SDK 다운로드 link2번째 방법은 SDK Zip파일을 다운로드 받아 사용하는 방법입니다.\n⁃ PHP용 SDK Zip 파일 다운로드\r압축을 풀고 필요한 경로에 복사한 후 아래 코드를 추가해서 SDK를 불러옵니다. \u003c?php require '{경로}/aws-autoloader.php';\r?\u003e\r예제 코드 link아래 예제 코드는 버킷에 CORS를 설정하는 방법과 설정된 CORS를 조회하는 방법입니다.\n\u003c?php\ruse Aws\\S3\\S3Client;\ruse Aws\\Exception\\AwsException;\r$s3Client = new S3Client ([\r'endpoint' =\u003e 'https://kr.object.ncloudstorage.com',\r'region' =\u003e 'kr-standard',\r'credentials' =\u003e array(\r'key' =\u003e '{ACCESS_KEY_ID}',\r'secret' =\u003e '{SECRET_KEY}'\r),\r'version' =\u003e 'latest'\r]);\r$bucketName = \"{버킷명}\";\r# Set CORS configuration\rtry {\r$result = $s3Client-\u003eputBucketCors([\r'Bucket' =\u003e $bucketName, // REQUIRED\r'CORSConfiguration' =\u003e [ // REQUIRED\r'CORSRules' =\u003e [ // REQUIRED\r[\r'AllowedHeaders' =\u003e ['*'],\r'AllowedMethods' =\u003e ['GET', 'PUT'], // REQUIRED\r'AllowedOrigins' =\u003e ['http://cors-test.com'], // REQUIRED\r'ExposeHeaders' =\u003e [],\r'MaxAgeSeconds' =\u003e 3000\r],\r],\r]\r]);\rvar_dump($result[\"@metadata\"]);\r} catch (AwsException $e) { // output error message if fails\rerror_log($e-\u003egetMessage());\r}\recho(\"\");\r# Get CORS configuration\rtry {\r$result = $s3Client-\u003egetBucketCors([\r'Bucket' =\u003e $bucketName, // REQUIRED\r]);\rvar_dump($result[\"CORSRules\"]);\r} catch (AwsException $e) { // output error message if fails\rerror_log($e-\u003egetMessage());\r}\r?\u003e\r예제 코드 실행 결과 link\r참고 URL link Ncloud Python용 AWS SDK (Boto3) 가이드\nhttps://guide.ncloud-docs.com/docs/storage-storage-8-2\nPHP용 AWS SDK 가이드\nhttps://aws.amazon.com/ko/sdk-for-php/\n문서 업데이트 내역 link\r날짜 내용 2023-03-06 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  124 ,
                href: "\/docs\/storage\/object-storage\/content-type\/mimetype-contenttype-setting-error-troubleshotting\/",
                title: "Object Storage에서 Content-Type 설정 문제로 html, 이미지 파일이 다운로드되는 문제 해결 방법",
                description: "Ncloud(네이버 클라우드)의 Object Storage에서 html, 이미지 파일이 화면에 출력되지 않고 다운로드 되는 문제 해결방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) Object Storage에 html 파일이나 이미지 파일을 올려두고 사용하는 경우가 많습니다.\n그런데 간혹, 웹브라우저나 앱에서 해당 파일을 호출 했을 때 html 페이지나 이미지 파일이 화면에 표시되지 않고 다운로드 되는 현상이 발생하기도 합니다.\n이것은 Object Storage에 파일이 등록될 때 파일의 속성을 나타내는 메타 데이터 중에서 파일의 종류를 구분하기 위한 MIME Type에 대한 정보를 담고 있는 Content-Type 항목이 제대로 설정되지 않아서 발생하는 문제입니다. 아래에서 이에 대한 내용을 자세히 정리해보겠습니다.\n메타 데이터 link메타 데이터는 파일의 속성이나 정보를 나타내는 값으로 Ncloud Object Storage에서는 파일 수정 날짜, 파일 크기 등의 기본으로 설정되는 시스템 메타 데이터와 사용자가 임의로 정의하는 유저 메타 데이터로 구분할 수 있으며 아래와 같이 Console 화면에서 확인할 수 있습니다.\nMIME Type (Media Type) linkMIME은 [Multipurpose Internet Mail Extensions]의 약자로 이메일 전송을 위해 만들어진 인터넷 표준 형식으로, MIME Type이란 이메일로 전송되는 컨텐츠나 파일의 종류를 구분하기 위해 정의된 형식입니다. 최근에는 Media Type으로 표현하는 경우도 있습니다.\nContent-Type link[Content-Type]은 MIME Type으로 정의된 컨텐츠나 파일을 전송할 때 프로토콜의 Header 값에 정의되는 속성입니다. Content-Type Header와 MIME Type은 이메일에 사용하기 위해 정의되었으나, 지금은 HTTP와 같은 다른 인터넷 프로토콜에서 널리 사용하고 있으며, MIME Type 등록은 IANA(Internet Assigned Numbers Authority)에서 관리하고 있습니다.\nNcloud Object Storage에서도 업로드 된 파일의 종류에 대한 정보를 Content-Type 속성으로 정의하고 있습니다.\r오류 상황 link예를 들어 Object Storage에 등록된 이미지 파일에 대한 Content-Type 속성이 제대로 정의되지 않았을 경우 아래와 같이 이미지 파일을 호출했을 때 이미지가 화면에 표시되지 않고 다운로드 되는 현상이 나타납니다.\n메타 데이터 변경 link문제를 해결하기 위해서는 메타 데이터에 있는 [Content-Type]을 변경해야 하므로, 아래와 같이 콘솔 [Object Storage] - [Bucket Management]에서 해당 파일을 선택하고 [편집] - [메타 데이터 변경] 메뉴를 선택합니다.\n[메타 데이터 관리] 팝업창에서 [Content-Type] 항목에 있는 [수정] 버튼을 클릭합니다.\n이미지나 html 문서에 맞는 값을 입력합니다. 여기서는 png 이미지 파일이므로 [image/png]를 입력했습니다.\nhtml의 경우는 [text/html]이며 기타 다양한 파일들의 MIME Type은 문서의 아래쪽에서 정리해보겠습니다.\n[Content-Type] 값 변경 후에 브라우저의 캐시를 지우고 다시 호출해보면 아래와 같이 이미지가 정상적으로 나타나는 것을 확인할 수 있습니다.\nMIME Type 종류 link전체 MIME Type 중에서 자주 사용되는 Type을 정리해보면 다음과 같습니다.\n파일 종류 MIME Type . aac audio/aac . avi video/x-msvideo . bin application/octet-stream . csh application/x-csh . css text/css . csv text/csv . doc application/msword . docx application/vnd.openxmlformats-officedocument.wordprocessingml.document . gif image/gif . html text/html . ico image/x-icon . ics text/calendar . jar application/java-archive . jpg image/jpeg . js text/javascript . json application/json . md text/markdown . oga audio/ogg . ogv video/ogg . pdf application/pdf . png image/png . ppt application/vnd.ms-powerpoint . pptx application/vnd.openxmlformats-officedocument.presentationml.presentation . rar application/x-rar-compressed . sh application/x-sh . svg image/svg+xml . tar application/x-tar . ttf application/x-font-ttf . txt text/plain . wav audio/x-wav . webp image/webp . woff application/x-font-woff . xls application/vnd.ms-excel . xlsx application/vnd.openxmlformats-officedocument.spreadsheetml.sheet . xml application/xml . zip application/zip 참고 URL link Ncloud Object Storage 기본 가이드\nhttps://guide.ncloud-docs.com/docs/storage-storage-6-1\nMIME Type 안내\nhttps://developer.mozilla.org/ko/docs/Web/HTTP/Basics_of_HTTP/MIME_types\nObject Storage 파일의 Content-Type 일괄 적용, 변경하는 방법\n"
            }
        );
    index.add(
            {
                id:  125 ,
                href: "\/docs\/storage\/object-storage\/content-type\/contenttype-bulk-change-guide\/",
                title: "Object Storage 파일의 Content-Type 일괄 적용, 변경하는 방법",
                description: "Ncloud(네이버 클라우드)의 Object Storage에서 파일의 Content-Type을 일괄 적용하거나, 변경하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) Object Storage에서 업로드하는 파일의 Content-Type을 업로드 시에 일괄 적용하거나, 이미 업로드된 다수의 파일의 Content-Type을 일괄 변경하는 방법을 정리해보겠습니다.\n테스트 순서 link일괄 적용, 변경 테스트는 다음과 같은 순서로 진행보겠습니다.\n다수의 txt 파일을 업로드 하면서 [Content-Type]을 [application/octet-stream]으로 일괄 설정 업로드된 파일의 [Content-Type]이 [application/octet-stream]인지 확인 AWS CLI를 이용해서 파일들의 [Content-Type]을 [text/plain]으로 일괄 변경 파일의 [Content-Type]이 [text/plain]으로 변경되었는지 확인 CloudBerry Explorer를 이용해 파일들의 [Content-Type]을 [application/octet-stream]으로 일괄 변경 파일의 [Content-Type]이 [application/octet-stream]으로 변경되었는지 확인 업로드 시에 일괄 적용 link[Console] - [Object Storage] - [Bucket Management]에서 버킷을 선택하고 [파일 올리기] 버튼을 클릭합니다.\n업로드 팝업에서 파일을 선택하기 전에 먼저 [권한 및 메타 데이터 설정] 버튼을 클릭합니다.\n메타 데이터 설정 link[권한 및 메타 데이터 설정] 팝업에서 [메타 데이터 관리] 탭을 선택하고 [Content-Type] 키워드에 테스트용으로 [application/octet-stream]을 입력하고 [메타데이터 추가] 버튼을 클릭합니다.\n파일 업로드 link[Content-Type] 설정을 마쳤으면 업로드할 파일을 선택하고 [전송 시작] 버튼을 클릭합니다.\nContent-Type 확인 link변경된 [Content-Type]을 확인하기 위해 파일 하나를 선택하고, [편집] - [메타 데이터 변경] 메뉴를 선택합니다.\n메타 데이터 관리 팝업에서 [Content-Type]이 [application/octet-stream]으로 적용된 것을 확인할 수 있습니다.\nAWS CLI로 일괄 변경 linkNcloud Object Storage는 AWS S3와 호환되는 스토리지이므로 AWS CLI로 관리 가능합니다.\nAWS CLI를 이용해서 Object Storage를 관리하는 방법은 아래 문서에서 확인할 수 있습니다.\ninfo\rAWS CLI를 이용한 Object Storage 접속 방법\n파일 리스트 조회 link먼저 현재 Object Storage 버킷에 존재하는 파일 리스트를 조회하면 위에서 업로드 했던 5개의 파일을 확인할 수 있습니다.\naws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls s3://content-type-test/ --recursive --human-readable\rContent-Type 변경 link이제 [Content-Type]을 [text/plain]으로 변경해보겠습니다.\naws --endpoint-url=https://kr.object.ncloudstorage.com s3 cp s3://content-type-test/test/ s3://content-type-test/test/ --recursive --content-type text/plain --metadata-directive REPLACE Content-Type 확인 link위에서 확인했던 방법대로 [Console]에서 파일을 선택하고 [Content-Type]을 확인해보면 [text/plain]인 것을 알 수 있습니다.\nCloudBerry Explorer를 사용해 일괄 변경 linkObject Storage를 관리하기 편한 여러가지 Client Tool중에서 [CloudBerry Explorer]를 사용해서 [Content-Type]을 변경해보겠습니다.\n[CloudBerry Explorer] 사용방법은 아래 문서에서 확인 가능합니다.\nObject Storage 접속용 Windows Client Tool - CloudBerry Explorer 사용 방법\r[CloudBerry Explorer]로 Object Storage에 접속한 후 위에서 업로드 했던 파일들을 모두 선택하고 마우스 오른쪽 버튼을 클릭하면 나타나는 메뉴에서 [Set HTTP Headers]를 선택합니다.\nContent-Type 일괄 변경 link[Http Headers] 설정 팝업에서 [Add] 버튼을 클릭하고 [Http Header]에서는 [Content-Type]을, [Value]에서는 [application/octet-stream]을 선택합니다.\n선택한 값을 확인하고, 아래쪽 옵션에서는 기본값 그대로 두고, [OK] 버튼을 클릭합니다.\nContent-Type 확인 link위에서 확인했던 방법대로 [Console]에서 파일을 선택하고 [Content-Type]을 확인해보면 [application/octet-stream]인 것을 알 수 있습니다.\nCyberduck을 사용해 일괄 변경 link또 다른 Client Tool중의 하나인 [Cyberduck]을 사용할 경우는 아래와 같이 파일을 모두 선택하고, 상단의 [정보 가져오기] 버튼을 클릭하고, [메타데이터] 탭에서 [Content-Type]을 변경할 수 있습니다.\nObject Storage 접속용 Windows, MacOS Client Tool - Cyberduck 사용 방법\r참고 URL link Ncloud Object Storage 기본 가이드\nhttps://guide.ncloud-docs.com/docs/storage-storage-6-1\nMIME Type 안내\nhttps://developer.mozilla.org/ko/docs/Web/HTTP/Basics_of_HTTP/MIME_types\nObject Storage에서 Content-Type 설정 문제로 html, 이미지 파일이 다운로드되는 문제 해결 방법\n"
            }
        );
    index.add(
            {
                id:  126 ,
                href: "\/docs\/storage\/object-storage\/client-tool\/s3-client-tool-cloudberry-explorer\/",
                title: "Object Storage 접속용 Windows Client Tool | CloudBerry Explorer",
                description: "Ncloud(네이버 클라우드) Object Storage 접속용 Windows Client Tool - CloudBerry Explorer 사용 방법입니다",
                content: "개요 link네이버 클라우드의 Object Storage에 접속, 관리하는 방법은 aws cli 등 여러가지 있지만 Windows PC에서 간편하게 접속해서 관리할 수 있는 클라이언트 툴이 몇개 있습니다.\n그 중에서 가장 많이 사용되는 것이 바로 CloudBerry Explorer 인데, 사용법에 대해 간단히 정리해보겠습니다.\nCloudBerry Explorer linkCloudBerry Explorer의 정식 명칭은 CloudBerry Explorer Freeware for Amazon S3입니다.\n이 버전은 무료버전이며 더 많은 기능이 포함된 유료 버전도 있습니다. 그리고 Amazon S3 뿐만 아니라 Microsoft Azur, Google Cloud 등을 위한 버전도 따로 있습니다.\n상세한 정보와 다운로드는 아래 링크에서 확인하시면 됩니다.\nhttps://www.msp360.com/explorer/windows.aspx 사용법 link프로그램을 다운 받아서 설치하고, 실행을 하면 여러 종류의 스토리지 중에서 원하는 것을 선택하게 됩니다.\n이 클라이언트는 AWS S3를 위한 것이지만, 많은 스토리지들이 S3와 호환되는 구조로 만들어졌기 때문에 공통으로 사용 가능합니다. 이용 가능한 스토리지 리스트는 마지막에서 정리해보겠습니다.\n여기에 아직 네이버 클라우드는 리스트에 없기 때문에 저희는 S3 Compatible을 선택하면 됩니다.\nDisplay name: 여기는 알아보기 쉬운 이름을 적으면 됩니다. 예를 들어 Naver Cloud Service point: 여기는 네이버 클라우드의 endpoint-url을 적습니다. kr.object.ncloudstorage.com Access key: 여기는 Access Key ID Secret key: 여기는 Secret Key 네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\r계정 정보를 입력하고 접속을 하면 왼쪽에 로컬PC 폴더가, 오른쪽에 버킷 리스트가 나타나고 원하는 버킷을 선택해서 들어가면 다음처럼 파일들을 확인할 수 있습니다.\nObject Storage에 있는 파일을 로컬PC로 가져오려면 원하는 파일을 선택하고 마우스 오른쪽 버튼을 눌러서 Copy 명령을 선택하면 됩니다.\n그 외 여러 가지 기능들이 있는데 그리 어려운 기능은 아니므로 직접 사용해보시면 금방 알 수 있습니다.\n마지막으로 CloudBerry Explorer Freeware for Amazon S3로 접속 가능한 클라우드 스토리지 리스트를 확인해보겠습니다.\nAmazon S3 Amazon S3 (China) Amazon Glacier Amazon Glacier (China) Amazon Cloud Drive Alibaba S3 Compatible Akaza Aruba Cloud Backblaze B3 Caringo CenturyLink Cisco Cloudian Connectria Constant DDN dinCloud DreamObjects Dunkel Easy Storage Exoscale GreenQloud HGST Hitachi HostEurope IDC Frontier LeoNovus (S3) Mandic NetApp NiftyCloud Numergy QNAP Revera Scality Seeweb SwiftStack (S3) ThinkOn Tiscali Verizon vCloud Air (EMC) Walrus Zettagrid Wasabi 참고 URL link Object Storage 접속용 Windows Client Tool | S3 Browser\n"
            }
        );
    index.add(
            {
                id:  127 ,
                href: "\/docs\/storage\/object-storage\/client-tool\/s3-client-tool-cyberduck\/",
                title: "Object Storage 접속용 Windows Client Tool | Cyberduck",
                description: "Ncloud(네이버 클라우드) Object Storage 접속용 Windows Client Tool - Cyberduck 사용 방법입니다",
                content: "개요 link네이버 클라우드 Object Storage에 접속해서 파일을 업로드, 다운로드 등의 관리를 할 수 있는 클라이언트 툴중에서 이번에는 Cyberduck이라는 무료 제품을 소개하려고 합니다.\nObject Storage는 AWS S3와 호환되기 때문에 S3를 지원하는 Cyberduck도 사용할 수 있는데 Cyberduck은 S3뿐만 아니라 FTP, SFTP, WebDAV, Amazon S3, OpenStack Swift, Backblaze B2, Microsoft Azure \u0026 OneDrive, Google Drive, Dropbox 등에도 접속 가능합니다.\n설치파일 다운로드 linkCyberduck은 윈도우용과 macOS용 프로그램을 제공하고 있어, 원하는 제품을 다운 받으면 됩니다.\nhttps://cyberduck.io/download/ 설치 link설치할 디렉토리를 선택하고, Cyberduck을 설치합니다.\n접속정보 확인 linkCyberduck을 실행하고 새 연결을 메뉴를 선택하면 스토리지에 접속 정보를 입력하는 창이 나타납니다.\n여기서 필요한 정보는 서버 접속용 Endpoint URL, API 인증키 (접근 키 ID, Secret Access Key)가 필요한데, 관련된 정보는 아래쪽에서 다시 확인해보겠습니다.\nAPI 인증키 생성 linkCyberduck으로 Object Storage에 접속하기 위해서는 API 인증키가 필요합니다. API 인증키는 네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져와야 하며, 아직 만들어진 Key가 없다면 새로 만들어야 합니다.\nhttps://www.ncloud.com/mypage/manage/authkey 스토리지 접속 linkObject Storage에 접속하기 위해 위에서 확인한 API 인증키를 이용하여 다음의 정보를 입력해야 합니다.\n# 서버: kr.object.ncloudstorage.com\r# 접근 키 ID: 네이버 클라우드 Access Key ID\r# Secret Access Key: 네이버 클라우드 Secret Key\r# 다른 해외 리전의 Object Storage 서버 주소는 다음과 같습니다.\r# 미국: us.object.ncloudstorage.com\r# 싱가포르: sg.object.ncloudstorage.com\r# 일본: jp.object.ncloudstorage.com\r# 독일: de.object.ncloudstorage.com\rObject Storage에 접속하면 이미 생성된 Bucket이 있을 경우 아래와 같이 Bucket 리스트가 나타납니다.\n업로드 linkObject Storage에 파일을 업로드 하기 위해서는 먼저 Bucket이 생성되어 있어야 합니다.\nBucket (버킷) 생성 link이미 Bucket을 만들었다면 그대로 사용하시면 되고, 새로 만드실 경우에는 [파일]-[새 폴더] 메뉴를 이용하시면 됩니다.\n파일 업로드 link업로드할 대상 Bucket을 선택하고 마우스 오른쪽 버튼을 클릭하면 업로드 메뉴를 확인할 수 있습니다.\n파일 선택창에서 원하는 파일을 선택하면 되고, 파일이 여러개일 경우 다중 선택도 가능합니다.\n전송결과 화면\n업로드 완료 화면\n권한설정 linkObject Storage에 업로드한 파일을 외부에서 접근해야 하는 경우에는 파일에 대한 권한을 변경해야 합니다.\n권한을 변경할 파일을 선택하고 마우스 오른쪽 버튼을 클릭하면 [정보] 메뉴를 확인할 수 있습니다.\n파일정보 팝업창에서 [권한] 메뉴를 선택하시면 왼쪽 아래에서 권한 설정 기능에서 [모두]를 선택합니다.\n[모두]에 대한 권한을 READ로 선택합니다.\n여러 파일의 권한을 동시에 변경할 경우 해당 파일들을 전부 선택하고 권한을 변경할 수도 있습니다.\n다운로드 linkObject Storage에 저장된 파일을 로컬로 다운로드 받을 경우에는 대상 파일을 선택하고 마우스 오른쪽 버튼을 클릭하여 [지정된 위치로 내려받기] 메뉴를 선택합니다.\n다운로드 받을 폴더를 선택합니다.\n다운로드가 완료되었습니다.\n동기화 link이번에는 업로드, 다운로드가 아닌, 로컬 폴더와 Object Storage에 있는 Bucket을 서로 동기화 하는 기능에 대해 확인해보겠습니다.\n동기화할 Bucket을 선택하고 마우스 오른쪽 버튼을 클릭해 동기화 메뉴를 선택합니다.\n다음으로 동기화할 로컬 폴더를 선택합니다.\n이제 동기화를 시작할 준비가 되었습니다. 동기화 창에서 [계속] 버튼을 클릭해 동기화를 시작합니다.\n동기화가 완료되었지만 화면에서는 즉시 반영이 되지 않습니다. Bucket을 선택하고 마우스 오른쪽 버튼을 선택해 [다시보기] 메뉴를 선택하면 새로 고침이 되면서 동기화된 파일을 확인할 수 있습니다.\n삭제 linkBucket이나 파일을 삭제할 경우에는 대상 파일 등을 선택하고 마우스 오른쪽 버튼을 클릭해 [삭제] 메뉴를 선택합니다.\n삭제 기능은 한번 더 정말 삭제할 것인지 확인하는 단계가 있습니다.\n## 환경설정\rCyberduck의 환경설정에서 중요한 것들을 살펴 보겠습니다. 위쪽 메뉴에서 [편집]-[환경설정]을 선택합니다.\n환경설정 중에서 우선 [전송]-[일반]에 들어가시면 다운로드와 업로드에 대한 설정을 할 수 있습니다.\n여기서는 기본 다운로드 폴더를 설정할 수 있고, 업로드할 때 파일명이 겹칠 경우 덮어쓸 것인지, 물어보기 할 것인지 설정할 수 있습니다.\n[전송]-[권한] 설정에서는 업로드 되는 파일의 기본 권한을 원하는 설정으로 변경할 수 있습니다.\n[전송]-[필터] 설정에서는 다운로드와 업로드 할 때 특정 형식이나 확장자의 파일을 건너띄기 할 수 있는 정규식 기반의 설정을 제공합니다.\n[대역폭] 설정에서는 업로드와 다운로드할 때의 네트워크의 대역폭을 설정할 수 있습니다.\n평가 link마지막으로 Cyberduck 클라이언트 툴의 장점과 단점을 정리해보겠습니다.\n장점 link 무료제품으로 상업적인 용도로도 사용 가능하다. S3와 그 호환 스토리지 뿐만 아니라 FTP, Dropbox, Google Drive 등 다양한 방식의 접속을 지원한다. 메뉴가 한글화 되어 있다. 단점 link 인터페이스가 탐색기 형식이 아니라서 업로드, 다운로드할 때 불편하다. 제공되는 접속용 프로필이 다양하지 않아서 서버 정보를 일일이 입력해야 한다. 스토리지 \u003c–\u003e 스토리지 방식의 파일 전송을 지원하지 않는다. 참고 URL link Object Storage 접속용 Windows Client Tool | S3 Browser\n"
            }
        );
    index.add(
            {
                id:  128 ,
                href: "\/docs\/storage\/object-storage\/client-tool\/s3-client-tool-s3browser\/",
                title: "Object Storage 접속용 Windows Client Tool | S3 Browser",
                description: "Ncloud(네이버 클라우드) Object Storage 접속용 Windows Client Tool - S3 Browser 사용 방법입니다",
                content: "개요 link네이버 클라우드의 Object Storage에 접속, 관리하는 방법은 aws cli 등 여러가지 있지만 Windows PC에서 간편하게 접속해서 관리할 수 있는 클라이언트 툴이 몇개 있습니다.\n그 중에서 이번에는 S3 Browser의 사용법에 대해 간단히 정리해보겠습니다.\nS3 Browser linkS3 Browser는 Amazon S3 and Amazon CloudFront를 위한 클라이언트입니다 이 버전은 무료버전이기는 하지만, 정확히는 personal use only, non-commecial use only라고 명시되어 있습니다.\n그래서 라이선스와 관계없이 사용 가능하고, 더 많은 기능이 포함된 유료 버전도 있습니다.\n상세한 정보와 다운로드는 아래 링크에서 확인하시면 됩니다.\nhttps://s3browser.com/ 사용법 link프로그램을 다운 받아서 설치하고, 실행을 하면 여러 종류의 스토리지 중에서 원하는 것을 선택하게 됩니다.\n이 클라이언트는 AWS S3를 위한 것으로 CloudBerry Explorer와는 다르게 AWS의 다양한 S3 서비스들만 접속이 가능한데, 이용 가능한 스토리지 리스트는 마지막에서 정리해보겠습니다.\nAccount Type은 S3 Compatible Storage를 선택하면 됩니다.\nAccount name: 여기는 알아보기 쉬운 이름을 적으면 됩니다. 예를 들어 Naver Cloud REST Endpoint: 여기는 네이버 클라우드의 endpoint-url을 적습니다. kr.object.ncloudstorage.com Access Key ID: 여기는 Access Key ID Secret Access Key: 여기는 Secret Key 네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\r계정 정보를 입력하고 접속을 하면 버킷 리스트가 나타나고 원하는 버킷을 선택해서 들어가면 다음처럼 파일들을 확인할 수 있습니다.\nObject Storage에 있는 파일을 로컬PC로 가져오려면 원하는 파일을 선택하고 마우스 오른쪽 버튼을 눌러서 Download 명령을 선택하면 됩니다.\n그 외 여러 가지 기능들이 있는데 그리 어려운 기능은 아니므로 직접 사용해보시면 금방 알 수 있습니다.\n마지막으로 S3 Browser로 접속 가능한 S3 리스트를 확인해보겠습니다.\nAmazon S3 Storage S3 Compatible Storage Amazon S3 in China Amazon S3 GovCloud Storage Amazon S3 GovCloud Storage (FIPS 140-2) Amazon S3 via EC2 IAM Role Amazon S3 via AssumeRole Amazon S3 (Credentials from Environment Variables) Amazon S3 (Credentials from AWS Config or Credential file) 업로드하는 파일 권한 자동 적용 linkS3 Browser를 이용해 파일을 업로드할 때 업로드하는 파일의 권한을 자동으로 적용하는 방법에 대해 살펴보겠습니다.\n우선 S3 Browser에서 [Tools] - [Option] 메뉴를 클릭합니다.\n[Option] 메뉴에 보면 여러 옵션들이 있는데 아래 스샷에서 표시한 2가지 옵션이 중요합니다. 각각에 대한 설명은 아래쪽에서 다시 정리해보겠습니다. 버킷(Bucket) 권한 상속 link[Inherit permissions from parent bucket] 옵션은 버킷(Bucket)에 업로드 되는 파일들은 버킷(Bucket)의 권한을 상속 받게 하는 옵션입니다.\n예를 들어 버킷(Bucket)의 권한이 [All User]에게 [Read] 권한이라면 이 옵션을 선택해두면 이 버킷(Bucket)에 업로드 되는 모든 파일은 [All User]에게 [Read] 권한을 가지게 됩니다.\n권한 유지 link[Preserve permissions when overwriting existing files] 옵션은 이미 버킷(Bucket)에 존재하는 파일을 다시 업로드 해서 덮어 쓰기를 할 경우 기존의 권한을 유지하도록 하는 옵션입니다.\n참고 URL link S3 Browser 홈페이지\nhttps://s3browser.com/\nS3 Browser S3-Compatible Storages 설정 가이드\nhttps://s3browser.com/s3-compatible-storage.aspx\nObject Storage 접속용 Windows Client Tool | Cyberduck\n"
            }
        );
    index.add(
            {
                id:  129 ,
                href: "\/docs\/storage\/archive-storage\/api-access-token-create\/",
                title: "PHP로 Archive Storage API 인증 토큰 생성하는 방법",
                description: "Ncloud(네이버 클라우드)에서 PHP로 Archive Storage API 인증 토큰 생성하는 방법입니다",
                content: "개요 link네이버 클라우드(Ncloud) Archive Storage API를 이용하려고 할 때 먼저 인증 토큰을 생성하고 생성된 토큰을 이용해서 API로 Archive Storage에 접근해야 합니다. 여기서는 PHP로 API 인증 토큰을 생성하는 방법에 대해 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\nAPI 정보 link OpenStack Swift API : 2.15.1 (Pike) OpenStack Keystone V3 API : v3.8 인증 토큰 생성 코드 link\r\u003c?php\r// 전송해야 할 설정값\r$ncloud_accesskey = \"네이버 클라우드 AccessKey\";\r$ncloud_secretkey = \"네이버 클라우드 SecretKey\";\r$ncloud_domain_id = \"Archive Storage 도메인 ID\";\r$ncloud_project_id = \"Archive Storage 프로젝트 ID\";\r$api_server = \"https://kr.archive.ncloudstorage.com:5000\";\r$api_url = \"/v3/auth/tokens\";\t// http 호출 헤더값 설정\r$http_header = array();\r$http_header[0] = \"Content-Type: application/json\";\r// 전송할 값들을 배열 형태로 저장한다\r$postvars = [\r\"auth\"=\u003e [\r\"identity\"=\u003e [\r\"methods\"=\u003e [\r\"password\"\r],\r\"password\"=\u003e [\r\"user\"=\u003e [\r\"name\"=\u003e $ncloud_accesskey,\r\"password\"=\u003e $ncloud_secretkey,\r\"domain\"=\u003e [\r\"id\"=\u003e $ncloud_domain_id\r]\r]\r]\r],\r\"scope\"=\u003e [\r\"project\"=\u003e [\r\"id\"=\u003e $ncloud_project_id\r]\r]\r]\r];\r// 배열 형태로 저장한 값들을 json 형태로 변환해서 전송\r$json_portvars = json_encode($postvars);\r// api 호출\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\tcurl_setopt($ch, CURLOPT_POST, TRUE); //POST 방식으로 호출\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\rcurl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\rcurl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\r$response = curl_exec($ch);\rcurl_close($ch);\rif ($response)\r{\r// X-Subject-Token 토큰 값은 request body가 아닌 header로 전달되므로\r// header를 분리해서 배열에 저장한다 $headers = array();\r$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\rforeach (explode(\"\\r\\n\", $header_text) as $i =\u003e $line) {\rif ($i === 0)\r{\r$headers[\"http_code\"] = $line;\r}\relse\r{\rlist ($key, $value) = explode(\": \", $line);\r$headers[$key] = $value;\r}\r}\r// 인증 토큰 확인\r$x_auth_token = $headers[\"X-Subject-Token\"]; echo($x_auth_token);\r//var_dump($headers);\r//echo(\"\");\r//var_dump($response);\r} else {\recho \"Curl error: \" . curl_error($ch);\r}\r?\u003e\r코드 상세 설명 linkAPI 인증 Key 생성 link[Sub Account] - [Sub Accounts]에서 본인의 계정을 선택하고, [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나는데[추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\nreport\r메인 계정은 최대 권한을 가지기 때문에 메인 계정으로 생성한 API도 메인 계정과 동일한 최대 권한을 가지게 됩니다. 그러므로 메인 계정으로 API Key를 생성하게 되면 이 Key가 유출되었을 때 심각한 문제가 생기기 때문에 반드시 서브 계정에서 API Key를 생성해야 합니다.\nArchive Storage API 이용 정보 link\r$ncloud_domain_id = \"Archive Storage 도메인 ID\";\r$ncloud_project_id = \"Archive Storage 프로젝트 ID\";\rArchive Storage API 이용을 위한 Domain ID와 Project ID는 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n[API 이용 정보 확인] 창에서 Domain ID와 Project ID를 확인하고, PHP 소스코드에 입력합니다.\nAPI 서버와 URL 설정 link\r$api_server = \"https://kr.archive.ncloudstorage.com:5000\";\r$api_url = \"/v3/auth/tokens\";\rArchive Storage API 서버와 토큰 생성을 위한 URL 정보는 위와 같습니다.\nHTTP 호출 header 값 설정 link\r$http_header = array();\r$http_header[0] = \"Content-Type: application/json\";\rHTTP header에는 json 형태로 호출한다는 것을 설정합니다.\n전송할 값 설정 link\r// 전송할 값들을 배열 형태로 저장\r$postvars = [\r\"auth\"=\u003e [\r\"identity\"=\u003e [\r\"methods\"=\u003e [\r\"password\"\r],\r\"password\"=\u003e [\r\"user\"=\u003e [\r\"name\"=\u003e $ncloud_accesskey,\r\"password\"=\u003e $ncloud_secretkey,\r\"domain\"=\u003e [\r\"id\"=\u003e $ncloud_domain_id\r]\r]\r]\r],\r\"scope\"=\u003e [\r\"project\"=\u003e [\r\"id\"=\u003e $ncloud_project_id\r]\r]\r]\r];\r// 배열 형태로 저장한 값들을 json 형태로 변환해서 전송\r$json_portvars = json_encode($postvars);\r네이버 클라우드 AccessKey, SecretKey, Archive Storage 도메인 ID, 프로젝트 ID를 전송하기 위해 지정된 형태의 배열로 저장한 후에 json 형태로 변환합니다. 물론 처음부터 json 형태로 저장해도 됩니다.\nAPI 호출 link\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\tcurl_setopt($ch, CURLOPT_POST, TRUE); //POST 방식으로 호출\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\rcurl_setopt($ch, CURLOPT_HEADER, TRUE); //response에 header 값도 수신\rcurl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\r$response = curl_exec($ch);\rcurl_close($ch);\r이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\ncurl_setopt($ch, CURLOPT_HEADER, TRUE); 는 Response에 body 뿐만 아니라 header 값도 수신하기 위해 설정합니다.\nAPI 인증 토큰 분리 link\rif ($response)\r{\r$headers = array();\r$header_text = substr($response, 0, strpos($response, \"\\r\\n\\r\\n\"));\rforeach (explode(\"\\r\\n\", $header_text) as $i =\u003e $line) {\rif ($i === 0)\r{\r$headers[\"http_code\"] = $line;\r}\relse\r{\rlist ($key, $value) = explode(\": \", $line);\r$headers[$key] = $value;\r}\r}\r// 인증 토큰 확인\r$x_auth_token = $headers[\"X-Subject-Token\"]; echo($x_auth_token);\r//var_dump($headers);\r//echo(\"\");\r//var_dump($response);\r} API 인증 토큰값은 X-Subject-Token이라는 이름으로 request body가 아닌 header로 전달되므로 header를 분리해서 배열에 저장합니다. 실제 전송되는 header 값은 아래와 같은 형태입니다.\nHTTP/1.1 201 Created Date: Thu, 11 Nov 2021 07:59:32 GMT Server: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips mod_wsgi/3.4 Python/2.7.5 X-Subject-Token: gAAAAABhjM1lbeTW3Vq......중간 생략 ......txWYsWGrC1siPt8CE0rs_KgNMTQ Vary: X-Auth-Token x-openstack-request-id: req-1ce......중간 생략 ......a85eb5b Content-Length: 1762 Content-Type: application/json\r인증 토큰 유효 시간 linkAPI 인증 토큰의 유효 시간은 24시간이고 삭제 요청을 호출하면 삭제할 수 있습니다.\n참고 URL link Archive Storage API 기본 가이드\nhttps://api.ncloud-docs.com/docs/common-archivestorageapi-archivestorageapi\nOpenStack Keystone V3 API 가이드\nhttps://docs.openstack.org/api-ref/identity/v3/\n문서 업데이트 내역 link\r날짜 내용 2021-11-11 문서 최초 생성 2024-01-31 API 인증 Key 생성 방법 안내 변경 "
            }
        );
    index.add(
            {
                id:  130 ,
                href: "\/docs\/storage\/archive-storage\/api-get-container-list-by-php\/",
                title: "PHP로 Archive Storage API 호출하기 - 컨테이너(버킷) 오브젝트 목록 조회",
                description: "Ncloud(네이버 클라우드)에서 Archive Storage API 호출하기 - 컨테이너(버킷) 오브젝트 목록 조회하는 방법입니다",
                content: "개요 link네이버 클라우드(Ncloud) Archive Storage API를 이용해서 컨테이너(버킷)에 있는 오브젝트 전체 목록을 PHP로 조회하는 방법에 대해 정리해보겠습니다.\nAPI 정보 link OpenStack Swift API : 2.15.1 (Pike) OpenStack Keystone V3 API : v3.8 인증 토큰 생성 linkArchive Storage API를 호출할 때는 먼저 인증 토큰을 생성해야 하는데, 생성 방법은 내용이 다소 긴 관계로 다른 문서에서 자세히 설명해두었습니다. 아래 문서를 참고 하시기 바랍니다.\n"
            }
        );
    index.add(
            {
                id:  131 ,
                href: "\/docs\/storage\/archive-storage\/cli-guide-windows\/",
                title: "Archive Storage CLI 사용 가이드 | Windows 환경",
                description: "Ncloud(네이버 클라우드) Archive Storage CLI를 Windows 환경에서 사용하는 방법에 대한 가이드입니다",
                content: "개요 link네이버 클라우드(Ncloud) Archive Storage CLI를 Windows 환경에서 사용하는 방법에 대해 정리해보겠습니다.\nCLI 정보 linkArchive Storage가 OepnStack으로 구성되어 있고, Client는 Python 기반의 Client를 사용하게 됩니다.\npython-keystoneclient : 3.17.0 python-swiftclient : 3.6.0 Python 다운로드 link먼저 Python을 다운로드 합니다. 권장하는 버전은 3.6 이상입니다. 여기서는 3.9를 설치하겠습니다.\nhttps://www.python.org/downloads/ Python 설치 linkPATH 추가 linkPython 설치 시작화면에 PATH에 python을 추가하는 옵션이 있습니다.\n“Add Python 3.9 to PATH” 옵션을 선택하고 설치를 시작하면 됩니다.\nPATH 문자 길이 제한 해제 linkWindows에는 기본설정에 파일경로가 최대 260자로 제한되어 있는데, 이 제한을 풀것인지 확인하는 과정입니다.\n“Disable path length limit” 옵션이 나오는데, 특별한 문제가 없다면 해제하고 가면 됩니다.\nCLI Client 설치 linkpython-keystoneclient : 3.17.0 설치 link우선 OepnStack 서비스의 인증을 담당하는 KeyStone Client를 설치합니다.\npip install python-keystoneclient==3.17.0\rpython-swiftclient : 3.6.0 설치 link다음으로 실제 명령을 수행하는 Swift Client를 설치합니다.\npip install python-swiftclient==3.6.0\rClient 설치 오류 linkPython Clinet를 설치하는 도중에 아래와 같은 메시지가 나타나면서 오류가 발생하는 경우가 있습니다. Microsoft Visual C++ Build Tools 등이 설치되어 있지 않아서 인데 설치하는 방법 2가지 중에서 하나를 선택해서 설치하시면 됩니다.\nreport\rerror: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\" : https://visualstudio.microsoft.com/downloads/\nreport\rfatal error C1083: 포함 파일을 열 수 없습니다. ‘basetsd.h’ : No such file or directory error: command ‘C:\\Program Files (x86)\\Microsoft Visual Studio\\……. …..\\cl.exe’ failed with exit code 2\n방법 1 : Build Tools 직접 설치 link첫번째 방법은 Build Tools를 따로 설치하는 방법입니다. 아래 링크에서 [Microsoft Build Tools 2015 업데이트3]를 다운로드 받아서 설치하시면 되는데, [Visual Studio]가 설치되어 있는 경우에는 설치가 실패하기도 합니다.\n이때는 아래에 나오는 두번째 방법으로 설치하시면 됩니다.\nhttps://visualstudio.microsoft.com/ko/vs/older-downloads/ 방법 2 : Visual Studio Installer 설치 linkVisual Studio가 설치되어 있는 경우에는 위 1번 방법으로 설치가 되지 않는 경우가 있으므로 Visual Studio Installer에서 설치하도록 하겠습니다.\n[Visual Studio Installer]를 실행하셔서 설치된 Visual Studio 메뉴의 [수정] 버튼을 클릭합니다.\n나타난 화면에서 [C++를 사용한 데스크톱 개발]을 선택하시고 오른쪽 [설치 세부정보]에서 다음 2가지를 선택해서 설치하시면 됩니다.\nMSVC vXXX - VS 20XX C++ x64/x86 빌드 도구 Windows 10 SDK 인증 토큰 생성 linkCLI Client가 모두 설치되었으면 이제 접속을 위한 인증 토큰을 생성해야 합니다. 인증 토큰을 생성하는 명령어는 다음과 같은데 여기에 필요한 값이 4가지 있습니다.\nswift --os-auth-url https://kr.archive.ncloudstorage.com:5000/v3 --auth-version 3 --os-username {access_key_id} --os-password {secret_key} --os-user-domain-id {domain_id} --os-project-id {project_id} auth\r### 네이버 클라우드 API 인증키 : access_key_id, secret_key\r두가지 Key는 네이버 클라우드 API 인증키로 [네이버 클라우드 포탈] -\u003e [마이페이지] -\u003e [계정관리] -\u003e [인증키 관리] - [API 인증키 관리] 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\rArchive Storage API 정보: domain_id, project_id link두가지 id 값은 Archive Storage API 이용을 위한 Domain ID와 Project ID로 [네이버 클라우드 포탈] - [Archive Storage]에서 [API 이용 정보 확인] 버튼을 클릭하면 확인할 수 있습니다.\n[API 이용 정보 확인] 창에서 Domain ID와 Project ID를 확인하고, 인증토큰 생성 코드에 입력합니다.\n위에서 확인한 설정 값 4가지를 추가해서 인증토큰 생성 명령을 실행하면 아래와 같이 생성된 인증토큰이 출력됩니다.\nexport OS_STORAGE_URL=https://kr.archive.ncloudstorage.com/v1/AUTH_{project_id}\rexport OS_AUTH_TOKEN={인증 토큰}\r인증 토큰 유효 시간 linkAPI 인증 토큰의 유효 시간은 24시간이고 삭제 요청을 호출하면 삭제할 수 있습니다.\n환경 변수 설정 link위에서 생성된 인증토큰과 URL을 환경 변수에 설정합니다. Windows에서는 export 명령을 set로 변경해서 실행합니다.\nset OS_STORAGE_URL=https://kr.archive.ncloudstorage.com/v1/AUTH_{project_id}\rset OS_AUTH_TOKEN={인증 토큰}\r컨테이너(버킷) 조회 link현재 Archive Storage에 생성되어 있는 컨테이너(버킷)을 확인할 수 있는 명령어는 다음과 같습니다.\nswift list\r컨테이너(버킷)의 모든 오브젝트 조회 link특정 컨테이너(버킷)의 모든 오브젝트 목록을 확인하는 명령어는 마지막에 컨테이너(버킷) 이름을 적어주면 됩니다.\nswift list {컨테이너(버킷) 이름}\r파일 업로드 link파일 업로드 명령은 특정 파일을 업로드 하는 명령과 폴더를 통째로 업로드 하는 명령을 각각 확인해보겠습니다.\n폴더 업로드 link폴더를 통째로 업로드 하는 명령은 다음과 같습니다.\nswift upload {컨테이너(버킷) 이름} --object-name {저장할 Archive Storage 폴더명} {로컬PC 폴더명}\r폴더 파일을 업로드 후에 list 명령어로 컨테이너(버킷)의 오브젝트 목록을 확인할 수 있습니다.\n개별 파일 업로드 link특정 파일을 업로드 하려면 다음처럼 명령을 실행하면 됩니다.\nswift upload {컨테이너(버킷) 이름} --object-name {저장할 Archive Storage 폴더명/저장할 파일명} {로컬PC 파일 경로}\r마찬가지로 파일을 업로드 후에 list 명령어로 확인해보시면 됩니다.\n파일 삭제 link파일 삭제도 개별 파일 삭제와 폴더 삭제 2가지로 나누어서 확인해보겠습니다.\n개별 파일 삭제 link특정 파일을 삭제하는 명령은 다음과 같습니다.\nswift delete {컨테이너(버킷) 이름} {Archive Storage 파일 전체 경로}\r폴더 삭제 link폴더 전체를 삭제하는 명령은 prefix 옵션이 들어갑니다.\nswift delete {컨테이너(버킷) 이름} --prefix {Archive Storage 폴더 경로}\r파일 다운로드 link파일 다운로드는 개별 파일 다운로드와 폴더 다운로드 그리고, 컨테이너(버킷) 파일 전체 다운로드를 실행해 보고, 로컬PC에서 다운로드 된 것을 확인해보겠습니다.\n개별 파일 다운로드 link개별 파일 다운로드에는 output 옵션이 필요합니다.\nswift download {컨테이너(버킷) 이름} --output {저장할 로컬PC 파일 전체 경로} {Archive Storage 파일 전체 경로}\r로컬PC에서 확인을 해보면 아래와 같이 다운로드된 파일을 확인할 수 있습니다.\n폴더 다운로드 link폴더 다운로드에는 output-dir 옵션이 필요합니다.\nswift download {컨테이너(버킷) 이름} --output-dir {저장할 로컬PC 폴더 경로} {Archive Storage 폴더 경로}\r로컬PC에서 확인을 해보면 아래와 같이 폴더가 다운로드 된 것을 확인할 수 있습니다.\n컨테이너(버킷) 전체 다운로드 link컨테이너(버킷)에 있는 모든 파일을 다운로드 할 때는 아래와 같이 폴더 다운로드 명령에서 마지막에 있는 파일명이나 폴더명 파라미터를 지우시면 됩니다.\nswift download {컨테이너(버킷) 이름} --output-dir {저장할 로컬PC 폴더 경로}\r로컬PC에서 확인을 해보면 폴더와 파일이 모두 다운로드 된 것을 확인할 수 있습니다.\n주의 사항 linkArchive Storage CLI를 사용해야 하는 이유 link마지막으로 Archive Storage를 관리할 때는 AWS S3용 Client Tool (ex, CloudBerry Explorer, S3 Browser) 대신에 Archive Storage CLI를 사용해야 하는 이유에 대해 정리해보겠습니다.\n네이버 클라우드(Ncloud) Archive Storage는 Object Storage의 데이터를 장기 백업하기 위한 용도 등으로 주로 사용되다 보니 Object Storage와 비슷한 시스템이라고 오해하는 경우가 많습니다. 하지만, Object Storage가 AWS S3와 호환되는 시스템 구조로 되어 있는 것에 반해, Archive Storage는 OpenStack 기반의 시스템 구조로 되어 있어 전혀 다르다고 보시면 됩니다.\n그러다 보니, Object Storage를 관리하는데 자주 사용되는 AWS S3용 Client Tool (ex, CloudBerry Explorer, S3 Browser) 등을 Archive Storage를 관리할 때도 사용하는 경우가 있는데, 가급적 사용하지 않는 것이 좋습니다.\r왜냐하면 AWS S3용 Client Tool로 Archive Storage에서 업로드, 다운로드, 삭제, 이름변경 등의 작업을 진행하면 해당 파일에 문제가 생기거나 때로는 컨테이너(버킷) 데이터 전체에 문제가 생길 수도 있기 때문입니다.\r혹시나 AWS S3용 Client Tool을 사용하더라도 파일(오브젝트)을 조회하는 용도 정도로만 한정해서 사용하는 것을 추천합니다. 물론 파일 조회도 가능하면 Archive Storage용의 CLI나 API를 이용하는 것이 좋습니다.\n참고 URL link Archive Storage CLI 가이드\nhttps://cli.ncloud-docs.com/docs/guide-archivestorage\nOpenStack CLI 가이드\nhttps://docs.openstack.org/ocata/cli-reference/swift.html\n문서 업데이트 내역 link\r날짜 내용 2021-11-19 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  132 ,
                href: "\/docs\/storage\/backup\/service-basic-guide\/",
                title: "Ncloud 백업 서비스 기본 가이드",
                description: "Ncloud(네이버 클라우드)의 서버 파일과 데이터베이스 데이터 등을 백업할 수 있는 백업 서비스 상품의 기본 가이드입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 기존에 별도의 신청서를 작성해서 사용하던 Managed Backup의 대체 상품으로 출시된 콘솔에서 바로 이용할 수 있는 Backup 상품의 기본 가이드를 알아보도록 하겠습니다.\n서비스 특징 link 다양한 플랫폼 및 데이터베이스 지원: Linux, Windows 계열 등 다양한 버전의 운영 체제를 지원하며 OS의 데이터 영역 및 서버에 설치된 데이터베이스의 온라인 백업이 가능합니다. 간편한 설치와 백업 단위 선택: 네이버 클라우드 웹 콘솔에서 간단한 설정을 통해 백업을 받고자 하는 리소스에 에이전트의 설치부터 백업 정책 구성까지 완료할 수 있습니다. 소산 백업 지원: 기존에 수행한 백업 데이터를 지리적으로 떨어진 다른 존으로 이중화하여 데이터 안정성을 더욱 향상시킬 수 있습니다. 리포트 기능 제공: 백업 혹은 복구에 대한 작업 결과를 일간/월간 단위 보고서로 확인할 수 있고 이메일로 리포팅을 받을 수 있습니다. 제약 사항 linkBackup 서비스의 제약 사항은 다음과 같습니다.\n백업 가능 대상 link 서버: Data 영역 DB: 서버 설치형DB (MSSQL, MySQL, PostgreSQL) 백업 가능한 데이터 크기 link 계정당 1TB 이용 요금 linkBackup 서비스는 유료 서비스로 이용 요금은 기본료, 데이터 저장량, 복원 요금, 네트워크 전송 요금을 합산해 부과됩니다.\n기본료: 백업 대상 소스 서버 대수당 요금 부과 데이터 저장량: 백업된 데이터 저장량에 대해 월 평균 사용량에 대한 스토리지 요금 부과 복구 요금: 백업본 복구시 복구대상이 되는 원본 데이터 전체 용량에 대한 요금 부과 네트워크 전송 요금: 백업 및 복구간 발생한 존간/리전간 네트워크 전송 요금 부과 ⁃ 데이터 저장량은 월 평균 사용량 기준입니다. ⁃ 복구 요금은 원본(소스) 용량 기준으로 당월 수행한 전체 복구 작업에 대한 총량 기준으로 요금이 부과됩니다. ⁃ 동일 존 내에서 백업 수행 및 복구 시 네트워크 전송 요금은 무료입니다.\r백업 서비스 지원 버전 link\r구분\r지원 범위\r비고\rMSSQL Server\r2005, 2008, 2008R2, 2012, 2014, 2016, 2017, 2019\rx86, x64\rMySQL\r5.5, 5.6, 5.7, 8.x\nMaria DB 5.5, 10.0, 10.1~10.6\rRedhat/CentOS 6.x~8.x : x86, x64\nUbuntu 14.0 ~ 20.04 : x64\rPostgreSQL\r9.2 ~ 14.x\rRedhat/CentOS 5.x : x86, x64\nRedhat/CentOS 6.x ~ 8.x : x64\nUbuntu 12.04 ~ 22.04 : x86, x64\rWindows File System\r7, 8, 8.1, 10, 2008, 2008 R2, 2016, 2019, 2022\rx86, x64\rLinux File System\rRedhat/CentOS : 5.x ~ 8.x\nUbuntu 8.04 ~ 21.04\rRedhat/CentOS 5.x ~ 7.x : x86, x64\nRedhat/CentOS 8.x : x64\r상세 가이드 link "
            }
        );
    index.add(
            {
                id:  133 ,
                href: "\/docs\/storage\/backup\/service-detail-guide-linux-data\/",
                title: "Ncloud 백업 서비스 상세 가이드 - Linux Data",
                description: "Ncloud(네이버 클라우드)의 백업 서비스 상품을 이용해 리눅스 데이터 영역을 백업하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Backup 상품은 기존에 별도의 신청서를 작성해서 사용하던 [Managed Backup]의 대체 상품으로 출시된, 콘솔에서 바로 이용할 수 있는 상품으로 이 백업 상품을 이용해 리눅스 파일 데이터를 백업하는 방법을 알아보도록 하겠습니다.\n상품위치 linkBackup 상품은 [Console] - [Services] - [Storage]에 있습니다.\n테스트 서버 link백업을 테스트할 리눅스 서버를 아래와 같이 미리 준비했습니다.\n그리고, 백업과 복원에 필요한 디렉토리를 다음과 같이 생성했습니다.\n백업할 디렉토리: /backup-data 복원할 디렉토리: /restore 리소스 생성 link먼저 백업 혹은 복구를 수행할 대상 서버를 설정합니다.\nBackup 탭에서 [Backup] - [Resource]로 이동해서 [리소스 생성] 버튼을 클릭합니다.\n리소스 생성 방법 link 리소스 이름을 입력합니다. 백업 서버가 소속된 존(zone)을 선택합니다. 백업 대상이 되는 서버를 리소스에 등록합니다. 서버가 위치한 zone 선택 및 대상 서버를 선택하며 파일백업 및 데이터베이스 백업 여부에 따라 체크박스를 선택합니다. 에이전트 설치에 사용될 아이디 및 비밀번호를 입력합니다. report\r주의: 아이디는 백업 대상 서버의 root 계정 또는 백업 및 리스토어가 진행되는 디렉터리와 파일에 대한 소유권한을 가진 계정을 입력해야 합니다.\n아이디와 비밀번호는 에이전트 설치를 위해 백업 대상 서버 접속 시 일회성으로 사용하며, 별도로 저장되지 않습니다.\r내용 최종 확인 후 리소스 생성을 클릭합니다.\n백업 에이전트 설치 확인 link리소스가 생성 되면서 백업 에이전트가 설치되는데 정상적으로 설치가 완료되면 [생성 완료]라는 메시지가 나타납니다.\n(에이전트 설치는 대략 5분 정도의 시간이 걸리며, 상단의 [새로 고침] 버튼을 클릭하면 확인할 수 있습니다.)\n에이전트 설치 실패\n아이디/비번을 잘못 입력했거나 기타의 이유로 에이전트 설치가 실패했을 경우에는 [추가] 버튼을 클릭해서 다시 설치하면 됩니다.\n저장소 생성 link다음으로 백업 데이터를 저장할 저장소를 만들고 관리합니다.\nBackup 탭에서 [Backup] - [Storage]로 이동하여 저장소 생성을 클릭합니다.\n저장소 이름과 백업 저장소가 위치할 존(zone)을 지정 후 다음을 클릭해서 저장소를 생성합니다.\n소산 백업용 스토리지 추가 생성 link추후 Remote Backup 메뉴에서 소산 백업(이중화 백업)에 사용할 스토리지를 미리 추가로 생성하도록 하겠습니다.\n현재 KR-2존에 생성한 스토리지는 그대로 두고 KR-1존에 test2-backup-storage라는 이름으로 추가 생성했습니다.\n정책 생성 link다음은 저장소에 대한 정책을 설정 및 관리합니다.\nBackup 탭에서 [Backup] - [Policy]로 이동하여 정책 생성을 클릭합니다.\n정책 생성\n정책 이름, 보관 주기, 생성한 저장소가 위치한 존을 선택한 후 [연결 저장소]가 맞는지 확인 후 정책을 생성합니다.\n보관 기간은 백업 주기의 최소 2배 이상으로 설정해야 합니다. ⁃ 일간 백업 : 최소 7일 이상\n⁃ 주간 백업 : 최소 14일 이상\n⁃ 월간 백업 : 최소 60일 이상\r작업 생성 link다음으로 에이전트가 설치된 리소스와 사전에 설정한 저장소 및 정책 등을 활용하여 실제 백업을 수행하는 작업을 생성하고 관리합니다.\nBackup 탭에서 [Backup] - [Job]으로 이동하여 작업 생성을 클릭합니다.\n작업 이름과 대상 리소스(서버) 백업 유형 및 백업 대상 디렉터리 지정을 한 후 Policy 메뉴에서 생성한 백업 정책을 선택합니다.\nreport\r주의: Job과 Policy는 1:1 매핑만 가능합니다.\n일정 생성 link마지막으로 작업을 수행하는 일정에 대해 계획하고 관리합니다.\nBackup 탭에서 [Backup] - [Schedule]로 이동하여 일정 생성을 클릭합니다.\n일정 이름과 job에서 등록한 서버 백업 작업을 선택 후 백업 방식, 주기, 시작 요일과 시간을 구성한 후 일정을 생성합니다.\n소산 백업 (이중화 백업) link백업 상품의 소산 백업을 이용해 기존에 수행한 백업 데이터를 지리적으로 떨어진 다른 존으로 이중화할 수 있습니다.\nBackup 탭에서 [Backup] - [Remote Backup] 으로 이동하여 소산 설정을 클릭합니다.\n소산 이름, job에서 등록한 작업 선택, 소산 저장소가 위치한 존 선택, 보관 주기, 소산 백업 주기를 설정 후 소산 백업 일정을 등록합니다.\n소산 일정에 백업 작업이 완료되어 있지 않은 경우, 다음 소산 일정에 소산이 수행됩니다.\r백업 완료 확인 link기본 백업과 소산 백업까지 모두 완료되면 아래와 같이 [Report] 메뉴에서 결과를 확인할 수 있습니다.\n복원 link복원 기능을 이용하면 위에서 백업한 데이터를 Restore 메뉴에서 원하는 시점의 특정 데이터를 선택해서 원하는 리소스에 복원할 수 있습니다.\n[Job]에서 설정한 /backup-data 디렉터리에 저장되어 있는 파일들을 /restore 디렉터리로 복원을 진행해 보겠습니다. 현재 /restore 디렉터리는 비어있는 상태입니다.\nBackup 탭에서 [Restore]로 이동하여 복원 설정을 클릭합니다.\n복원 설정에서는 백업된 데이터 중 어떤 데이터로 복원할 것인지에 대한 세부항목을 선택합니다.\n복원 시점은 [가장 최근 백업 시점] 또는 백업된 데이터들 중에서 [직접 지정]도 가능합니다.\n복원 대상은 Job에서 설정한 디렉터리를 선택하고 [다음]을 클릭합니다.\n타깃 설정에서는 백업한 데이터를 복원할 서버와 디렉터리를 지정하고 다음을 클릭합니다.\n최종 내용을 확인 후 복원 시작을 클릭합니다.\n복원 시작 후 복원 상태 확인이 가능합니다.\n작업이 종료되면 /restore 경로에 데이터가 정상적으로 복원된 것을 확인할 수 있습니다.\nReport link백업 혹은 복구에 대한 작업 결과를 일간/월간 단위의 보고서로 확인할 수 있습니다.\nBackup 탭에서 [Report] 로 이동하여 확인합니다.\nBackup Report에서 발생하는 이벤트는 이메일 수신 신청으로 메일로 알림을 받도록 설정이 가능합니다.\n항목에서 담당자 이름 및 메일 주소를 확인하고 [추가] 버튼을 클릭한 후 저장합니다.\n등록이 완료되면 아래와 같이 메일로 리포트를 받아보실 수 있으며 매일 오전 10시 일간 리포트와 매월 1일 월간 리포트가 전송됩니다.\n백업 리소스 삭제 link더 이상 백업 서비스를 이용하지 않게 되어 백업 리소스를 삭제하려면 위에서 생성했던 순서의 반대로 삭제를 진행해야 합니다.\n우선, [Backup] - [Resource]에서 해당 리소스를 선택하고 [리소스 삭제] 버튼을 클릭해보겠습니다.\n그러면 다음과 같이 리소스와 함께 설치-생성되었던 [Agent], [Job], [Schedule], [Remote Backup]를 먼저 삭제해야 한다는 안내 메시지가 나타납니다.\n⁃ 백업 리소스 삭제는 아래와 같이 생성 순서와 반대로 삭제해야 합니다. ⁃ [Remote Backup] ==\u003e [Schedule] ==\u003e [Job] ==\u003e [Agent] ==\u003e [Resource]\r참고 URL link Ncloud 백업 상품 가이드\nhttps://guide.ncloud-docs.com/docs/backup-overview 문서 업데이트 내역 link\r날짜 내용 2023-01-04 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  134 ,
                href: "\/docs\/storage\/backup\/service-detail-guide-windows-data\/",
                title: "Ncloud 백업 서비스 상세 가이드 - Windows Data",
                description: "Ncloud(네이버 클라우드)의 백업 서비스 상품을 이용해 Windows 데이터 영역을 백업하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Backup 상품은 기존에 별도의 신청서를 작성해서 사용하던 [Managed Backup]의 대체 상품으로 출시된, 콘솔에서 바로 이용할 수 있는 상품으로 이 백업 상품을 이용해 Windows 파일 데이터를 백업하는 방법을 알아보도록 하겠습니다.\n상품위치 linkBackup 상품은 [Console] - [Services] - [Storage]에 있습니다.\n테스트 서버 link백업을 테스트할 리눅스 서버를 아래와 같이 미리 준비했습니다.\n그리고, 백업과 복원에 필요한 디렉토리를 다음과 같이 생성했습니다.\n백업할 디렉토리: C:\\Backup-Data 복원할 디렉토리: C:\\Restore 리소스 생성 link먼저 백업 혹은 복구를 수행할 대상 서버를 설정합니다.\nBackup 탭에서 [Backup] - [Resource]로 이동해서 [리소스 생성] 버튼을 클릭합니다.\n리소스 생성 방법 link 리소스 이름을 입력합니다. 백업 서버가 소속된 존(zone)을 선택합니다. 백업 대상이 되는 서버를 리소스에 선택합니다. 호스트 이름에는 백업 대상 서버의 이름을 입력합니다. 서버가 위치한 zone 선택 및 대상 서버를 선택하며 파일백업 및 데이터베이스 백업 여부에 따라 체크박스를 선택합니다. 에이전트 설치에 사용될 아이디 및 비밀번호를 입력합니다. report\r주의: 아이디는 백업 대상 서버의 Administrator 계정 또는 백업 및 리스토어 수행 시 해당 디렉터리와 파일에 대한 접근 권한을 가지고 있는 user 계정을 입력해야합니다.\n아이디와 비밀번호는 에이전트 설치를 위해 백업 대상 서버 접속 시 일회성으로 사용하며, 별도로 저장되지 않습니다.\r내용 최종 확인 후 리소스 생성을 클릭합니다.\n백업 에이전트 설치 확인 link리소스가 생성 되면서 백업 에이전트가 설치되는데 정상적으로 설치가 완료되면 [생성 완료]라는 메시지가 나타납니다.\n(에이전트 설치는 대략 5분 정도의 시간이 걸리며, 상단의 [새로 고침] 버튼을 클릭하면 확인할 수 있습니다.)\n에이전트 설치 실패\n아이디/비번을 잘못 입력했거나 기타의 이유로 에이전트 설치가 실패했을 경우에는 [추가] 버튼을 클릭해서 다시 설치하면 됩니다.\n저장소 생성 link다음으로 백업 데이터를 저장할 저장소를 만들고 관리합니다.\nBackup 탭에서 [Backup] - [Storage]로 이동하여 저장소 생성을 클릭합니다.\n저장소 이름과 백업 저장소가 위치할 존(zone)을 지정 후 다음을 클릭해서 저장소를 생성합니다.\n소산 백업용 스토리지 추가 생성 link추후 Remote Backup 메뉴에서 소산 백업(이중화 백업)에 사용할 스토리지를 미리 추가로 생성하도록 하겠습니다.\n현재 KR-2존에 생성한 스토리지는 그대로 두고 KR-1존에 test2-backup-storage라는 이름으로 추가 생성했습니다.\n정책 생성 link다음은 저장소에 대한 정책을 설정 및 관리합니다.\nBackup 탭에서 [Backup] - [Policy]로 이동하여 정책 생성을 클릭합니다.\n정책 생성\n정책 이름, 보관 주기, 생성한 저장소가 위치한 존을 선택한 후 [연결 저장소]가 맞는지 확인 후 정책을 생성합니다.\n보관 기간은 백업 주기의 최소 2배 이상으로 설정해야 합니다. ⁃ 일간 백업 : 최소 7일 이상\n⁃ 주간 백업 : 최소 14일 이상\n⁃ 월간 백업 : 최소 60일 이상\r작업 생성 link다음으로 에이전트가 설치된 리소스와 사전에 설정한 저장소 및 정책 등을 활용하여 실제 백업을 수행하는 작업을 생성하고 관리합니다.\nBackup 탭에서 [Backup] - [Job]으로 이동하여 작업 생성을 클릭합니다.\n작업 이름과 대상 리소스(서버) 백업 유형 및 백업 대상 디렉터리 지정을 한 후 Policy 메뉴에서 생성한 백업 정책을 선택합니다.\nreport\r주의: Job과 Policy는 1:1 매핑만 가능합니다.\n일정 생성 link마지막으로 작업을 수행하는 일정에 대해 계획하고 관리합니다.\nBackup 탭에서 [Backup] - [Schedule]로 이동하여 일정 생성을 클릭합니다.\n일정 이름과 job에서 등록한 서버 백업 작업을 선택 후 백업 방식, 주기, 시작 요일과 시간을 구성한 후 일정을 생성합니다.\n소산 백업 (이중화 백업) link백업 상품의 소산 백업을 이용해 기존에 수행한 백업 데이터를 지리적으로 떨어진 다른 존으로 이중화할 수 있습니다.\nBackup 탭에서 [Backup] - [Remote Backup] 으로 이동하여 소산 설정을 클릭합니다.\n소산 이름, job에서 등록한 작업 선택, 소산 저장소가 위치한 존 선택, 보관 주기, 소산 백업 주기를 설정 후 소산 백업 일정을 등록합니다.\n소산 일정에 백업 작업이 완료되어 있지 않은 경우, 다음 소산 일정에 소산이 수행됩니다.\r백업 완료 확인 link기본 백업과 소산 백업까지 모두 완료되면 아래와 같이 [Report] 메뉴에서 결과를 확인할 수 있습니다.\n복원 link복원 기능을 이용하면 위에서 백업한 데이터를 Restore 메뉴에서 원하는 시점의 특정 데이터를 선택해서 원하는 리소스에 복원할 수 있습니다.\n[Job]에서 설정한 C:\\Backup-Data 디렉터리에 저장되어 있는 파일들을 C:\\Restore 디렉터리로 복원을 진행해 보겠습니다. 현재 /Restore 디렉터리는 비어있는 상태입니다.\nBackup 탭에서 [Restore]로 이동하여 복원 설정을 클릭합니다.\n복원 설정에서는 백업된 데이터 중 어떤 데이터로 복원할 것인지에 대한 세부항목을 선택합니다.\n복원 시점은 [가장 최근 백업 시점] 또는 백업된 데이터들 중에서 [직접 지정]도 가능합니다.\n복원 대상은 Job에서 설정한 디렉터리를 선택하고 [다음]을 클릭합니다.\n타깃 설정에서는 백업한 데이터를 복원할 서버와 디렉터리를 지정하고 다음을 클릭합니다.\n최종 내용을 확인 후 복원 시작을 클릭합니다.\n복원 시작 후 복원 상태 확인이 가능합니다.\n작업이 종료되면 /restore 경로에 데이터가 정상적으로 복원된 것을 확인할 수 있습니다.\nReport link백업 혹은 복구에 대한 작업 결과를 일간/월간 단위의 보고서로 확인할 수 있습니다.\nBackup 탭에서 [Report] 로 이동하여 확인합니다.\nBackup Report에서 발생하는 이벤트는 이메일 수신 신청으로 메일로 알림을 받도록 설정이 가능합니다.\n항목에서 담당자 이름 및 메일 주소를 확인하고 [추가] 버튼을 클릭한 후 저장합니다.\n등록이 완료되면 아래와 같이 메일로 리포트를 받아보실 수 있으며 매일 오전 10시 일간 리포트와 매월 1일 월간 리포트가 전송됩니다.\n백업 리소스 삭제 link더 이상 백업 서비스를 이용하지 않게 되어 백업 리소스를 삭제하려면 위에서 생성했던 순서의 반대로 삭제를 진행해야 합니다.\n우선, [Backup] - [Resource]에서 해당 리소스를 선택하고 [리소스 삭제] 버튼을 클릭해보겠습니다.\n그러면 다음과 같이 리소스와 함께 설치-생성되었던 [Agent], [Job], [Schedule], [Remote Backup]를 먼저 삭제해야 한다는 안내 메시지가 나타납니다.\n⁃ 백업 리소스 삭제는 아래와 같이 생성 순서와 반대로 삭제해야 합니다. ⁃ [Remote Backup] ==\u003e [Schedule] ==\u003e [Job] ==\u003e [Agent] ==\u003e [Resource]\r참고 URL link Ncloud 백업 상품 가이드\nhttps://guide.ncloud-docs.com/docs/backup-overview 문서 업데이트 내역 link\r날짜 내용 2023-01-06 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  135 ,
                href: "\/docs\/storage\/nas\/linux-mount-guide\/",
                title: "NAS 볼륨을 생성하고 Linux 서버에 마운트하기 가이드",
                description: "Ncloud(네이버 클라우드) VPC환경에서 NAS 볼륨을 생성하고 Linux 서버에 마운트하기 가이드입니다",
                content: "개요 linkNAS (Network Attached Storage)는 다수의 서버, 사용자가 함께 사용하는 네트워크 저장공간으로, 서버 간 데이터 공유, 대용량 스토리지, 유연한 용량 확대/축소, 스냅샷 백업 등이 필요한 경우에 주로 사용하며, 네이버 클라우드 NAS 서비스의 주요 기능을 활용해 안전하고 편리하게 데이터를 관리할 수 있습니다.\n이번 가이드에서는 NAS 볼륨을 생성하고, Linux 즉, CentOS와 Ubuntu 서버에 마운트하는 방법을 정리해보겠습니다.\n특징 link 용량: 500GB ~ 10,000GB까지 가능하며, 확장은 100GB단위로 가능 접근제어 설정 가능 스냅샷 설정: 자동생성의 경우 최대 7개까지 보관 가능 볼륨 암호화: 볼륨 단위로 AES-256 알고리즘 기반의 암호화 키를 사용하여 FIPS-140-2 레벨 1 수준의 암호화를 제공 모니터링 및 이벤트 설정 가능 VPC-Subnet 생성 linkVPC 생성 linkVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\nSubnet 생성 linkSubnet 설정은 [Public]과 [일반]을 선택합니다.\n서버 생성 linkNAS 볼륨을 마운트할 서버 2개를 CentOS 7.8과 Ubuntu 18.04로 생성합니다.\nNAS 생성 link[NAS] - [Volume]에서 [NAS 볼륨 생성] 버튼을 클릭합니다.\nNAS 볼륨 이름과 용량을 입력하고, 리눅스용 프로토콜인 NFS를 선택합니다. CIFS는 윈도우용 프로토콜입니다.\n용량은 500GB ~ 10,000GB까지 가능하며, 100GB단위로 추가할 수 있습니다.\nNFS 접근 제어 설정 linkNFS 접근 제어 설정에서는 NAS 볼륨을 마운트할 장비를 선택해서 ACL(네트워그 접근제어) 설정을 하게 됩니다.\nNAS 볼륨을 마운트할 장비를 선택하고, [ \u003e ] 버튼을 클릭해 오른쪽으로 이동시킵니다.\n마지막으로 설정 내용을 확인하고 [볼륨 생성] 버튼을 클릭합니다.\nCentOS 설정 linkNFS 관련 패키지 설치 linkNAS 볼륨을 서버에 마운트하기 위해 우선 서버에 NFS 프로토콜 관련 패키지를 설치합니다.\nyum install nfs-utils\rNAS 볼륨 마운트하기 linkNAS 볼륨을 마운트할 디렉토리를 생성하고 {NAS 볼륨 마운트 정보}를 이용해 마운트한 후에 상태를 확인합니다.\n네이버 클라우드에서는 안정성이 높은 NFS v3(-o vers=3)로 마운트하여 사용할 것을 권고하고 있습니다.\nmkdir /nas\rmount -t nfs -o vers=3 {NAS 볼륨 마운트 정보} /nas\rdf -Th\rfstab 설정 link부팅 후에도 마운트가 될 수 있도록 /etc/fstab 파일에 추가합니다.\nUbuntu 설정 linkNFS 관련 패키지 설치 link우분투에서도 우선 NFS 관련 패키지를 설치합니다.\napt install nfs-common -y\rNAS 마운트하기 linkNAS 볼륨을 마운트할 디렉토리를 생성하고 {NAS 볼륨 마운트 정보}를 이용해 마운트한 후에 상태를 확인합니다.\n네이버 클라우드에서는 안정성이 높은 NFS v3(-o vers=3)로 마운트하여 사용할 것을 권고하고 있습니다.\nmkdir /nas\rmount -t nfs -o vers=3 {NAS 볼륨 마운트 정보} /nas\rdf -Th\rfstab 설정 link부팅 후에도 마운트가 될 수 있도록 /etc/fstab 파일에 추가합니다.\n이벤트 설정 link이벤트 설정에서는 NAS 볼륨 사용량 임계치를 설정하고 이벤트 발생 시 SMS나 Email로 통보를 받습니다.\n볼륨 설정에서 이벤트 설정을 클릭합니다.\n이벤트 통보 방법과 휴대폰 또는 이메일 등을 입력하고 설정을 완료합니다.\n참고 URL link Ncloud NAS 상품 가이드\nhttps://guide.ncloud-docs.com/docs/nas-overview 문서 업데이트 내역 link\r날짜 내용 2021-07-27 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  136 ,
                href: "\/docs\/networking\/ncloud-service-port-info\/",
                title: "Ncloud 주요 서비스 포트(Port) 정보",
                description: "Ncloud(네이버 클라우드) 주요 서비스 포트(Port) 정보입니다",
                content: "포트(Port) 정보 link네이버 클라우드 주요 서비스들에서 사용하는 포트(Port) 정보를 정리해보았습니다.\n네이버 클라우드에서 사용하는 포트이므로 일부 서비스의 경우 일반적으로 사용되는 포트와 조금 다른 경우도 있을 수 있습니다.\n22 : SSH 80 : http 443 : https 1433 : mssql 3000 : Node.js Express 3306 : mysql 3389 : 윈도 원격데스크톱 5432 : PostgreSQL 5672 : RabbitMQ 5985 : Packer 6379 : Redis 8001 : CUBRID 8080 : Ambari 8081 : Hue 8388 : Shadowsocks 서버 9736 : Jeus WebAdmin 10090 : Pinpoint 서버 11313 : Hugo 서버 15672 : RabbitMQ Management UI 18080 : Tomcat, Jenkins 18088 : Superset 18888 : TensorFlow Jupyter Notebook 18889 : TensorBoard 27017 : MongoDB 50070 : HDFS NameNode 문서 업데이트 내역 link\r날짜 내용 2021-01-14 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  137 ,
                href: "\/docs\/networking\/find-my-ip-address\/",
                title: "내 IP 주소 확인하기",
                description: "현재 접속한 기기의 공인(Public) IP 주소는 다음과 같습니다",
                content: "\rIPv4 link111.222.333.444처럼 우리가 일반적으로 알고 있는 IPv4는 32비트로 구성된 IP 주소 체계로 이론적으로는 2^32 즉, 4,294,967,296개의 IP주소를 부여할 수 있습니다.\n2011년 전세계 IP주소를 관리하고 있는 IANA(Internet Assigned Numbers Authority)에서 인터넷에 연결되는 기기가 급속도로 증가하면서 할당할 수 있는 IP주소가 고갈되어 감에 따라 IPv4의 신규 할당을 공식 종료했고, 그로 인해 신규 IP주소 체계인 IPv6에 대한 관심이 높아졌습니다.\nIPv6 linkIPv6는 ae06:2610:122a:2002:1849:2874:27c1:18f6 처럼 128비트로 구성된 신규 IP 주소 체계로 이론적으로는 2^128 개의 IP 주소를 부여할 수 있어 IP 주소의 부족은 없을 것이라고 이야기 되고 있습니다.\nPrivate IP (사설 아이피) 대역 link국제 인터넷 표준화 기구(IETF)에서 정한 RFC 1918 표준에 따라 IP 주소, 최상위 도메인 등을 관리하는 단체인 IANA(Internet Assigned Numbers Authority)가 아래의 주소를 사설 IP 대역으로 지정해두고 있습니다.\nA Class: 10.0.0.0 - 10.255.255.255 (10.0.0.0/8) B Class: 172.16.0.0 - 172.31.255.255 (172.16.0.0/12) C Class: 192.168.0.0 - 192.168.255.255 (192.168.0.0/16) Ncloud (네이버 클라우드)의 VPC(Virtual Private Cloud)는 퍼블릭 클라우드 상에 논리적으로 완전하게 분리된 고객전용 네트워크를 제공하는 서비스로, 위에서 설명한 RFC 1918 표준에 따른 최대 /16의 IP 네트워크 공간을 제공하고 있습니다.\r문서 업데이트 내역 link\r날짜 내용 2022-07-07 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  138 ,
                href: "\/docs\/networking\/loadbalancer\/classic-loadbalancer-acg-setting\/",
                title: "Classic환경 Load Balancer 운영을 위한 ACG 설정 방법",
                description: "Ncloud(네이버 클라우드) Classic환경 Load Balancer 운영을 위한 ACG 설정 방법입니다",
                content: "개요 linkLoad Balancer가 정상적으로 동작하기 위해서는 Load Balancer –\u003e Server의 지정된 포트로 접근할 수 있어야 합니다.\n그러기 위해서는 Server의 ACG에 Load Balancer가 접근할 수 있도록 권한을 설정해주어야 하는데, 여기서는 네이버 클라우드의 Classic Load Balancer를 운영할 때 ACG 설정을 어떻게 하는가에 대한 내용을 정리해보겠습니다.\n서버연결 실패 상황 link서버 등록하고 Load Balancer의 다른 설정들을 모두 올바르게 했는데도 아래와 같이 서버연결 상태가 실패로 나타나고 Load Balancer는 동작이 정지되는 경우가 있습니다.\n이런 경우가 바로 ACG에 Load Balancer의 접근 권한을 설정하지 않았을 때 입니다.\nACG 권한 설정 linkACG에 Load Balancer가 접근할 수 있도록 권한을 설정하려면 접근소스에 아래와 같이 입력합니다.\n접근소스 : ncloud-load-balancer\r그 외에 프로토콜과 허용포트도 지정된 정보를 입력하고 추가를 하면 됩니다.\n서버연결 성공 linkACG에 접근권한을 설정하고 나서 잠시 기다리면 Load Balancer가 서버에 접근시도를 하고 정상 접근이 되면서 서버연결 상태가 성공으로 바뀌고 Load Balancer도 정상 작동하게 됩니다.\n참고 URL link Ncloud Classic 환경 Load Balancer 가이드\nhttps://guide.ncloud-docs.com/docs/loadbalancer-start-classic 문서 업데이트 내역 link\r날짜 내용 2021-01-14 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  139 ,
                href: "\/docs\/networking\/loadbalancer\/vpc-loadbalancer-type\/",
                title: "VPC 환경 Load Balancer 상품군의 종류와 변화",
                description: "Ncloud(네이버 클라우드) VPC 환경 Load Balancer 상품군의 종류와 변화입니다",
                content: "개요 linkLoad Balancer는 수신 트래픽을 다수의 서버로 분산시키는 서비스로서, 수신 트래픽을 등록된 멤버 서버로 분산시켜 가용성을 높이고 시스템 가동률을 조절하는 역할을 수행합니다.\nVPC 플랫폼에서는 Network Load Balancer / Application Load Balancer / Network Proxy Load Balancer 가 제공되어 서비스에 적합한 로드밸런서를 선택할 수 있습니다.\n종류 link Application Load Balancer\nHTTP 및 HTTPS 트래픽을 사용하는 웹 애플리케이션을 위한 유연한 기능을 제공\nNetwork Load Balancer\nDSR(Direct Server Return) 구조의 고성능, 대규모 네트워크 연결에 적합한 로드밸런서로 고정 IP를 제공\nNetwork Proxy Load Balancer\nTCP 세련 유지에 최적화 되어 있으며, Network Load Balancer와 다르게 DSR를 지원하지 않으며, Load Balander가 세션을 관리.\nKR존/서브넷 별 LB 생성지역 지정 가능 : VPC 환경에서는 내가 원하는 KR존의 특정 서브넷에 LB생성 가능, KR-1/2 존에 각각 생성하여 고가용성을 확보 할 수 있다.\rLB 선택 기준 및 기능 비교 link 기능 Network LB Network Proxy LB Application 프로토콜 TCP TCP, TLS HTTP/HTTPS 상태확인 O O O 로깅 X O O DSR O X X 동일 인스턴스의\n여러 포트로\n로드밸런싱 X X O HTTP 2.0 N/A N/A O 경로기반 라우팅 N/A N/A O (출시 예정) SSL Offload X O O 고정 세션 X O O 참고 URL link Ncloud VPC 환경 Load Balancer 가이드\nhttps://guide.ncloud-docs.com/docs/loadbalancer-start-vpc 문서 업데이트 내역 link\r날짜 내용 2020-12-01 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  140 ,
                href: "\/docs\/networking\/loadbalancer\/vpc-application-loadbalancer-guide\/",
                title: "VPC 환경에서 Application Load Balancer 생성하기",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 Application Load Balancer 생성하기 가이드입니다",
                content: "개요 link네이버 클라우드 VPC 환경의 대표적인 Load Balancer인 Application Load Balancer 를 생성하는 가이드입니다.\nVPC와 Subnet을 생성하고, 테스트를 위한 서버 2대를 CentOS와 Ubuntu 각각 1대씩 준비해서 Application Load Balancer와 연결하고 접속해보는 과정까지 정리해보겠습니다.\nVPC 생성 linkVPC 환경에서는 먼저 VPC를 먼저 생성해야 하며, 이미 만들어진 VPC가 있다면 그대로 이용하셔도 됩니다.\nVPC의 IP 주소 범위는 private 대역 (10.0.0.0/8, 172.160.0./12, 192.168.0.0/16) 내에서 /16 ~ /28 범위여야 합니다.\n여기서는 192.168.0.0/16 범위의 VPC를 생성하겠습니다.\nSubnet 생성 linkLoad Balancer를 생성할 때 Server와는 다른 Subnet을 사용해야 정상 작동합니다.\n그래서 여기서도 Load Balancer용 Subnet과 테스트 Server용 Subnet을 각각 생성하도록 하겠습니다.\nLoad Balancer용 Subnet 생성 linkLoad Balancer는 Private Subnet에 위치해야 하므로 192.168.1.0/24 IP 대역에 Internet Gateway 전용 여부 옵션은 N (Private)을 선택합니다.\nServer용 Subnet 생성 link일반 서버용 Subnet은 192.168.2.0/24 IP 대역에 Internet Gateway 전용 여부 옵션은 Y (Public)을 선택합니다.\n테스트용 Server 생성 link테스트를 위한 서버는 위에서 생성했던 192.168.2.0/24 IP 대역의 Subnet을 선택하고 Network Interface도 동일한 Subnet을 선택합니다.\nLoad Balancer를 테스트 하기 위한 서버이므로 2대를 생성하면서 1대는 CentOS, 나머지 1대는 Ubunt로 생성하겠습니다.\nTarget Group 생성 link[VPC] - [Load Balancer] - [Target Group]에서 Load Balancer가 바라보게 될 Target Group를 설정합니다.\n여기서는 HTTP 프로토콜과 80 포트를 선택하겠습니다.\n다음으로 Health Check 설정에서는 HTTP, 80포트, HEAD Method를 선택합니다.\n마지막으로 Target 즉, 대상이 되는 서버 2대 (lb-test-ubuntu, lb-test-centos)를 선택하고, 적용 Target쪽으로 이동시키는 버튼을 클릭합니다.\n대상 서버들이 적용 Target으로 설정된 모습입니다. 이후에는 전체 설정을 다시 확인하고 생성 완료를 하면 됩니다.\nLoad Balancer 생성 link네이버 클라우드 VPC 환경에서 제공하는 Load Balancer는 애플리케이션 로드밸런서, 네트워크 로드밸런서, 네트워크 프록시 로드밸런서 이렇게 3가지가 있습니다.\n그 중에서 가장 많이 사용하는 HTTP, HTTPS 트래픽을 사용하는 웹 애플리케이션용 Application Load Balancer를 생성하겠습니다.\nNetwork는 Public IP, Subnet은 앞에서 생성했던 192.168.1.0/24 대역의 Subnet을 선택합니다.\n리스너 설정에서 프로토콜은 HTTP, 포트는 80을 선택하고 [추가] 버튼을 클릭합니다.\nTarget Group은 앞에서 생성했던 test-tg을 선택하면, 아래에 해당 Target Group의 설정이 표시됩니다.\n다음으로 전체 설정을 다시 확인하고 최종 생성하기 버튼을 클릭하면 Load Balancer가 생성됩니다.\nACG 설정 linkLoad Balancer가 정상 작동하기 위해서는 [Server] - [ACG]에서 [Inbound 규칙]에 Load Balancer용 Subnet 대역인 192.168.1.0/24 대역의 80 포트를 허용포트로 설정해 줍니다.\nServer 웹서버 설정 linkApplication Load Balancer를 테스트 하기 위해서는 테스트 Server에 웹서버가 설정되어 있어야 하는데, 네이버 클라우드 VPC 환경에서는 LAMP, LEMP 등의 웹서버가 설정된 이미지를 제공하지 않습니다.\n그래서 기본 OS만 설치된 서버에 Apache 웹서버와 php를 설치하도록 하겠습니다. 설치 작업은 아래와 같이 Ubuntu와 CentOS 각각 스크립트를 만들어서 한번에 설치하는 방법을 사용했는데, 필요에 따라서는 하나씩 별도로 설치하셔도 됩니다.\nUbuntu에 Apache, PHP 설치하기 스크립트 linkApache와 PHP를 설치하고 기본문서 index.html에 서버의 호스트명을 출력하는 스크립트를 적용합니다.\n사용한 OS는 Ubuntu 16.04 입니다.\n#!/bin/bash\rapt update\rapt install apache2 apt install php\rapt install libapache2-mod-php\rsystemctl start apache2\rcd /var/www/html\recho \"\u003c?php\" \u003e index.html\recho \"echo \\\"Your server name is \\\".(gethostname()).\\\"\n\\\";\" \u003e\u003e index.html\recho \"?\u003e\" \u003e\u003e index.html\recho AddType application/x-httpd-php .php .php3 .php4 .php5 .html .htm .inc \u003e\u003e phpadd\rcat phpadd \u003e\u003e /etc/apache2/apache2.conf\rsystemctl restart apache2\rsystemctl enable apache2\rsystemctl status apache2\rCentOS에 Apache, PHP 설치하기 스크립트 link사용한 OS는 CentOS 7.3 입니다.\n#!/bin/bash\ryum -y install httpd php\rsystemctl start httpd\rcd /var/www/html\recho \"\u003c?php\" \u003e index.html\recho \"echo \\\"Your server name is \\\".(gethostname()).\\\"\n\\\";\" \u003e\u003e index.html\recho \"?\u003e\" \u003e\u003e index.html\recho AddType application/x-httpd-php .php .php3 .php4 .php5 .html .htm .inc \u003e\u003e phpadd\rcat phpadd \u003e\u003e /etc/httpd/conf/httpd.conf\rsystemctl restart httpd\rsystemctl enable httpd\rsystemctl status httpd\r접속 테스트 link앞에서 생성했던 Load Balancer 정보에서 접속 정보용 주소를 확인하고 복사합니다.\n복사한 Load Balancer 주소를 웹브라우저에 입력하고 계속 새로 고침을 해보면 아래와 같이 CentOS 서버와 Ubuntu에 접속될 때 마다 해당 서버의 호스트명이 출력되면서 Load Balancer가 정상 작동하는 것을 확인할 수 있습니다.\n참고 URL link Ncloud Application Load Balancer 가이드\nhttps://guide.ncloud-docs.com/docs/loadbalancer-application-vpc\nNcloud Target Group 가이드\nhttps://guide.ncloud-docs.com/docs/loadbalancer-targetscreen-vpc\n문서 업데이트 내역 link\r날짜 내용 2022-08-04 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  141 ,
                href: "\/docs\/networking\/loadbalancer\/lb-redirect-http-to-https\/",
                title: "LoadBalancer에 http로 접속 시에 https로 리다이렉트 시키는 방법",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 LoadBalancer에 http로 접속 시에 https로 리다이렉트 시키는 방법입니다",
                content: "개요 linkNcloud에서는 웹서버에 인증서를 설치하지 않고 Application LoadBlancer에 인증서를 추가 할수 있습니다.\nLoadBalancer에 에 인증서를 두고 로드밸런서에서 HTTPS/443 요청을 받아 서버의 80 포트와 통신을 하게 되는 구조입니다. 이럴 경우 HTTPS 접속만 허용되어 HTTP 요청을 못 받을수 있는데 HTTP로 접속할시 로드밸런서에서 HTTPS로 리다이렉트 시키는 방법을 알아보겠습니다.\n테스트환경 사전준비 link 웹서버: httpd 패키지를 설치 후 간단한 index.html 생성, 80포트를 오픈 Target group: 웹서버를 포함하는 HTTP protocol 과 80 port 설정 로드밸런서: 리스너를 HTTPS protocol 과 443 port로 설정 DNS 및 인증서: 테스트에 사용할 인증서와 DNS(test1.3rdeyesys.com) 등록 서버생성과 Application Load Balancer 의 생성 가이드는 아래 문서를 참고하시기 바랍니다.\nVPC 환경에서 서버 생성 VPC 환경에서 Application Load Balancer 생성하기 HTTPS와 HTTP 접속 link로드밸런서 생성시 HTTPS/443 요청은 받을수 있게 설정하고, HTTP/80 요청을 설정하지않아 test1.3rdeyesys.com 요청은 받을수 있지만 HTTP/80 요청은 연결이 불가한 상태임을 확인할 수 있습니다.\nHTTPS/433 접속 상태 확인 link\rHTTP/80 접속 상태 확인 link\r리스너 추가 link로드밸런서 생성시 설정한 HTTPS/443 요청 외에 HTTP/80 요청도 받을 수 있게 로드밸런서에서 HTTP/80 요청을 받을 새로운 리스너를 설정합니다.\n로드밸런서를 선택하고 상단의 [리스너 설정 변경] 버튼을 클릭합니다.\n[리스너 추가] 버튼을 클릭합니다.\nHTTP 프로토콜 항목란에 80포트, Target Group 항목란에 80 으로 설정하여 확인버튼을 눌러 마무리 합니다.\n다음과 같이 80 to 80 으로 리스너가 추가되어 HTTP/80 요청에도 응답하여 페이지를 띄울수 있습니다.\nHTTP/80 요청은 로드밸런서를 거쳐 그대로 서버의 80 포트와 통신하기에 보안상에 문제가 생길수 있습니다. 그러므로 Application LoadBalancer의 기능을 이용하여 HTTP/80으로 들어오는 요청을 HTTPS/443으로 Redirection 하겠습니다.\r규칙 추가 linkHTTP로 생성한 리스너를 선택하고 [규칙 조회/변경] 버튼을 클릭합니다.\n다음으로 [규칙 추가] 버튼을 클릭합니다.\n다음의 항목들을 설정합니다.\n우선순위: 규칙을 적용할 순번을 정할수 있습니다. 조건: Host Header 와 Path Pattern 를 선택 할수 있습니다. (본 테스트 에서는 Host Header 기반을 사용하였습니다.) 액션: Target group과 Redierction 을 선택할 수 있습니다. (Redierction 선택합니다.) {% include callout_v2.html type=“success” content=\"- 우선순위는 적당한 순번의 숫자를 넣습니다.\n조건에서 호스트 헤더를 선택후 리디렉션할 도메인 명을 입력한뒤 +추가 버튼을 눌러 추가합니다. 액션에서 Redirection 을 선택 Protocol은 HTTPS 로 Port는 443으로 설정하고 확인을 눌러 규칙을 추가합니다. 그 외 사용환경에 맞게 규칙을 설정해 사용합니다.\" %} ⁃ 우선순위는 적당한 순번의 숫자를 넣습니다.\n⁃ 조건에서 호스트 헤더를 선택후 리디렉션할 도메인 명을 입력한뒤 +추가 버튼을 눌러 추가합니다.\n⁃ 액션에서 Redirection 을 선택 Protocol은 HTTPS 로 Port는 443으로 설정하고 확인을 눌러 규칙을 추가합니다. ⁃ 그 외 사용환경에 맞게 규칙을 설정해 사용합니다.\r설정된 규칙들을 확인 합니다.\n최종 테스트 link이제 다시 HTTP로 도메인 주소를 접속 해보면 규칙에 추가된 Host Header 기반으로 HTTPS로 Redirection 되는 모습을 확인 할수가 있습니다.\nHTTP/80 으로 접속시도 link\rHTTPS/443 으로 Redirection 확인 link\r문서 업데이트 내역 link\r날짜 내용 2022-03-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  142 ,
                href: "\/docs\/networking\/loadbalancer\/application-loadbalancer-access-log\/",
                title: "로드밸런서(Application Load Balancer) 접속 로그 확인하는 방법",
                description: "Ncloud(네이버 클라우드) 로드밸런서(Application Load Balancer) 접속 로그 확인하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) VPC 환경의 대표적인 로드밸런서(Load Balancer)인 애플리케이션 로드밸런서(Application Load Balancer)의 접속 로그를 확인하는 방법에 대해 정리해보겠습니다.\n테스트 준비 link 서버 생성: 록키 리눅스 (Rocky Linux 8.6) 로드밸런서 생성: 애플리케이션 로드밸런서(Application Load Balancer) 서버와 로드밸런서 연결 서버 생성 link테스트용 서버는 Rocky Linux 8.6 서버로 생성했습니다.\n로드밸런서 생성 linkApplication Load Balancer를 생성하고 테스트용 서버와 연결까지 마쳤습니다.\nApplication Load Blancer 의 생성 가이드는 아래 문서를 참고하시기 바랍니다. VPC 환경에서 Application Load Balancer 생성하기 접속 로그 수집 활성화 link로드밸런서의 접속 로그를 수집하려면 접속 로그 수집 기능을 활성화 해야 합니다. 생성된 로드밸런서를 선택하고 [로드밸런서 설정 변경] 버튼을 클릭합니다.\n[로드밸런서 설정 변경] 팝업창에서 [액세스 로그 수집] 항목이 [비활성] 상태인 것을 확인할 수 있습니다. 여기서 [설정] 버튼을 클릭합니다. [액세스 로그 수집]을 활성화할 것인지 한번 더 확인하는 창이 뜨는데 [확인] 버튼을 클릭합니다. [로드밸런서 설정 변경] 팝업창에서 [액세스 로그 수집] 항목이 [활성] 상태로 변경된 것을 확인할 수 있습니다. 접속 테스트 link웹브라우저에서 로드밸런서 주소로 접속해서 정상 작동하는지 확인했습니다.\n로드밸런서 접속 로그 확인 link로드밸런서 접속 로그는 Ncloud 서비스 중에서 [Cloud Log Analytics]에서 확인할 수 있습니다.\n[Cloud Log Analytics] - [Search] - [로그 종류 선택]에서 [application_loadbalancer_access] 필드를 선택하고 [Log 발생시간]을 상황에 맞에 선택한 후에 검색을 하면 아래 스샷과 같이 접속로그를 확인할 수 있습니다.\n참고 URL link VPC 환경에서 Application Load Balancer 생성하기\n"
            }
        );
    index.add(
            {
                id:  143 ,
                href: "\/docs\/networking\/loadbalancer\/lb-certificate-change\/",
                title: "로드밸런서(Load Balancer) 인증서 교체하는 방법",
                description: "Ncloud(네이버 클라우드) 로드밸런서(Load Balancer) 인증서를 교체하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) 로드밸런서(Load Balancer)에는 HTTPS 서비스가 필요할 때 로드밸런서에 인증서를 추가 하여 사용 할 수 있습니다.\n이때 인증서 만료, 멀티도메인 인증서로 교체 등의 여러가지 이유로 로드밸런서에 있는 기존의 인증서를 새로운 인증서로 교체해야 하는 경우가 있는데 VPC, Classic 환경별로 인증서를 교체하는 방법을 정리해보겠습니다.\n테스트 인증서 준비 link인증서 교체 테스트를 위한 테스트용 인증서 2개를 미리 준비했습니다.\ntest1: 현재 적용중인 인증서 test2: 새로 교체할 인증서 VPC 환경 link우선 VPC 환경에서 로드밸런서 인증서를 교체하는 방법을 정리해보겠습니다.\n인증서를 변경 할 로드밸런서를 선택한 후 [리스너 설정 변경] 클릭 합니다.\n현재 테스트용 ’test1’ 인증서가 적용되어 있는 리스너를 선택 한 후 [인증서 변경]을 클릭합니다. [default 인증서 선택] 항목에서 교체할 인증서인 test2를 선택한 후 [변경] 버튼을 클릭합니다. 인증서 변경 팝업에서 [변경] 버튼을 클릭합니다. 그런 후에 다시 [리스너 설정 변경] 화면으로 돌아오면 아래와 같이 인증서가 test2로 변경된 것을 확인할 수 있습니다. Classic 환경 link다음으로는 Classic 환경에서 로드밸런서 인증서를 교체하는 방법을 정리해보겠습니다.\n인증서를 변경할 로드밸런서를 선택 후 [로드밸런서 설정 변경]을 클릭 합니다.\n[SSL Certificate] 항목을 보면 LB에 적용 되어있는 인증서가 test1임을 확인 할 수가 있습니다.\n이제 새로운 인증서를 적용 하기 위해 [삭제] 버튼을 클릭해 기존에 설정 해두었던 로드밸런서 설정을 삭제 합니다. 기존 설정을 삭제하고 나면 [SSL Certificate] 항목에 아래와 같이 인증서 정보가 사라진 것을 확인할 수 있습니다.\n다음으로 기존과 동일한 설정(로드밸런서 포트가 443)을 입력하고 [추가] 버튼을 클릭합니다. [추가] 버튼을 클릭하면 [SSL Certificate 입력] 팝업이 나타나는데 여기서 [SSL Certificate 선택] 옵션에서 test2를 선택하고 [확인] 버튼을 클릭합니다. 그러면 아래와 같이 기존에 설정되어 있던 ’tes1’ 인등서가 ’test2’ 인증서로 변경 되어 있는 것을 확인 할 수 있습니다. 참고 URL link VPC 환경에서 Application Load Balancer 생성하기\n"
            }
        );
    index.add(
            {
                id:  144 ,
                href: "\/docs\/networking\/loadbalancer\/proxy-portocol\/client-ip-logging-on-rocky-linux\/",
                title: "Proxy Protocol을 이용해 Client IP 확인하기 | Rocky Linux",
                description: "Ncloud(네이버 클라우드) Network Proxy Load Balancer의 Proxy Protocol을 이용해 Rocky Linux 서버에서 클라이언트 IP 주소를 확인하는 방법입니다",
                content: "개요 linkNcloud Load Balancer는 HTTP, HTTPS, TCP, SSL 이렇게 4가지의 프로토콜을 지원합니다.\n그런데, Load Balancer를 사용하면서 Client IP를 확인하려고 할 때 http, https 통신의 경우 X-Forwarded-For 헤더값이 지원되기에 Client IP를 확인할 수 있지만, TCP 통신의 경우 X-Forwarded-For 헤더를 사용할 수 없기에 Client IP를 확인하기 위해서는 Proxy Protocol 옵션을 활성화 시켜야 합니다.\n여기서는 Ncloud Network Proxy Load Balancer의 TCP 프로토콜을 사용하면서 Proxy Protocol 옵션을 활성화시켜 Rocky Linux 서버에서 Client IP를 기록하는 방법을 소개하겠습니다.\n테스트 환경 link VPC 환경 Rocky Linux 8.6 Apache 2.4.6 Network Proxy Load Balancer Protocol/Port: TCP/80 Rocky Linux 서버 설치 link서버를 생성하고 Apache 웹서버와 개발용 추가 모듈이 포함된 httpd-devel 패키지를 설치하고 간단한 웹페이지를 만들어 접속해 보겠습니다.\nVPC 환경에서 서버 생성하는 방법 dnf -y install httpd httpd-devel\rTarget Group 설정 link우선 Load Balancer를 생성하기 전에 Load Balancer에서 사용할 Target Group을 [Load Balancer] - [Target Group]에서 생성합니다.\nTarget Group 생성\nTarget Group의 이름를 입력하고 Target 유형은 [VPC Server]를 선택, 다음으로 VPC 대역을 선택합니다.\n그리고, 프로토콜은 PROXY_TCP를 선택하고, 포트는 80포트를 사용하겠습니다. Health Check 설정\nHealth Check 할 프로토콜은 TCP를 선택합니다. Target 추가\n앞에서 생성했던 서버를 선택하고 [적용 Target]쪽으로 이동시킵니다. 설정 확인\n설정 정보를 최종 확인하고 이상이 없으면 Target Group을 생성합니다. 생성된 Target Group를 확인할 수 있습니다. Network Proxy Load Balancer 생성 link[Load Balancer]에서 [로드밸런서 생성] 버튼을 클릭하고 [네트워크 프록시 로드밸런서]를 선택합니다.\n로드밸런서 설정\n필요한 로드밸런서 설정을 선택하는데, 그 중에서 서브넷은 혹시 생성되어 있지 않으면 [서브넷 생성] 버튼을 클릭해 로드밸런서 전용 서브넷을 생성한 후에 다시 돌아옵니다. 여기서는 [10.0.4.0/24] 대역으로 설정했습니다. 리스너 설정\n리스너는 TCP 프로토콜에 80 포트를 선택하고 추가합니다. Target Group 선택\nTarget Group는 위쪽에서 생성한 [Proxy-Protocol-TG] 을 선택합니다. 선택하면 해당 Target Group 설정 내용을 바로 확인할 수 있습니다. 설정 확인\n선택한 설정을 최종 확인하고 이상이 없으면 [로드밸런서 생성] 버튼을 클릭합니다. 생성 확인\n생성된 로드밸런서의 정보를 확인합니다. 특히 접속 정보와 서브넷은 이후 테스트에 사용되므로 꼭 기억하거나 메모해 두는 것이 좋습니다. ACG 설정 link로드밸런서 → 서버 접속이 가능하도록 서버 ACG에 규칙을 추가합니다.\n서버에 적용된 ACG의 규칙 설정 화면에서 프로토콜은 TCP, 접근소스는 로드밸런서 IP 대역인 10.0.4.0/24, 포트는 80을 입력하고 추가합니다.\n로드밸런서 접속 테스트 link위에서 생성된 로드밸런서 접속 주소로 접속을 해보면 아래와 같은 화면을 확인할 수 있습니다.\nApache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하고, 원래는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해아야 하지만, Rocky Linux는 아직 Cloud Log Analytics Agent를 지원하지 않아 서버에서 직접 로그를 확인해보았습니다.\nRocky Linux Apache 로그파일 위치 : /var/log/httpd/access_log\nApache 접속 로그를 확인해보면 위에서 설정했던 **Load Balancer의 IP 대역 (10.0.4.xx)**이 기록된 것을 확인할 수 있습니다.\n다음에는 로드밸런서 IP가 아닌 실제 Client IP가 기록되도록 설정을 변경해 보겠습니다.\ncat /var/log/httpd/access_log\rProxy Protocol 설정 link이제 실제 Client IP가 기록되도록 Proxy Protocol을 설정해보겠습니다.\n[Load Balancer] - [Target Group]에서 위에서 생성했던 Target Group를 선택하고 [TargetGroup 설정] 버튼을 클릭합니다.\nTarget Group 설정 화면에서 [ProxyProtocol] 옵션을 체크하고 확인 버튼을 클릭합니다.\n위에서 정상적으로 접속이 되었던 로드밸런서 주소로 접속하면 [Bad Request] 메시지가 뜨는 것을 확인할 수 있습니다.\n다음으로는 서버 설정을 변경해야 합니다.\nApache 모듈 설치 linkProxy Protocol을 사용할 때 필요한 Apache 모듈을 Rocky Linux 서버에 설치하겠습니다.\nmod_myfixip 모듈 다운로드\n아래 명령어로 mod_myfixip.c 파일을 다운로드 받습니다. 정상적으로 다운로드가 완료되면 ‘mod_myfixip.c’ saved 라는 메시지를 확인할 수 있습니다. # Apache 2.4\rwget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache24-modules/master/mod_myfixip.c\r# Apache 2.2\r# wget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache22-modules/master/mod_myfixip.c\r모듈 설치\n이어서 /{아파치가 설치된 경로}/bin/apxs -c -i mod_myfixip.c 명령어로 모듈을 설치합니다. /usr/bin/apxs -c -i mod_myfixip.c\rhttpd.conf 설정 변경\n모듈 설치가 완료된 후에 httpd.conf 파일을 열어서 제일 아래쪽에 아래 코드를 추가합니다.\nRewriteIPAllow 항목에는 로드밸런서 IP 대역 (ex: 192.168.0.0/16, 10.31.0.0/16 등)을 입력합니다.\n여기서는 위에서 설정했던 로드밸런서 IP 대역인 10.0.4.0/24를 입력했습니다. vim /etc/httpd/conf/httpd.conf\rLoadModule myfixip_module modules/mod_myfixip.so\rRewriteIPResetHeader off\rRewriteIPAllow 10.0.4.0/24\rApache 재시작\n설정을 마친 후에 Apache를 재시작합니다. systemctl restart httpd\r최종 접속 테스트 link모든 설정을 모두 마친 후에 서버에 접속해봅니다.\n최종 접속 로그 확인 linkApache 접속 로그를 다시 확인해보면 이번에는 로드밸런서 IP가 아닌 Client IP가 기록된 것을 확인할 수 있습니다.\n참고 URL link Proxy Protocol 설정하기\nhttps://guide.ncloud-docs.com/docs/loadbalancer-targetgroup-vpc#proxy-protocol-설정\nUbuntu 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n"
            }
        );
    index.add(
            {
                id:  145 ,
                href: "\/docs\/networking\/loadbalancer\/proxy-portocol\/client-ip-logging-on-ubuntu\/",
                title: "Proxy Protocol을 이용해 Client IP 확인하기 | Ubuntu",
                description: "Ncloud(네이버 클라우드) Network Proxy Load Balancer의 Proxy Protocol을 이용해 Ubuntu 서버에서 클라이언트 IP 주소를 확인하는 방법입니다",
                content: "개요 linkNcloud Load Balancer는 HTTP, HTTPS, TCP, SSL 이렇게 4가지의 프로토콜을 지원합니다.\n그런데, Load Balancer를 사용하면서 Client IP를 확인하려고 할 때 http, https 통신의 경우 X-Forwarded-For 헤더값이 지원되기에 Client IP를 확인할 수 있지만, TCP 통신의 경우 X-Forwarded-For 헤더를 사용할 수 없기에 Client IP를 확인하기 위해서는 Proxy Protocol 옵션을 활성화 시켜야 합니다.\n여기서는 Ncloud Network Proxy Load Balancer의 TCP 프로토콜을 사용하면서 Proxy Protocol 옵션을 활성화시켜 Ubuntu 서버에서 Client IP를 기록하는 방법을 소개하겠습니다.\n테스트 환경 link VPC 환경 Ubuntu 18.04 Apache 2.4.6 Network Proxy Load Balancer Protocol/Port: TCP/80 Ubuntu 서버 설치 link서버를 생성하고 Apache 웹서버와 개발용 추가 모듈이 포함된 apache2-dev 패키지를 설치하고 간단한 웹페이지를 만들어 접속해 보았습니다.\n⁃ VPC 환경에서 서버 생성하는 방법\rapt-get update\rapt-get -y install apache2 apache2-dev\rTarget Group 설정 link우선 Load Balancer를 생성하기 전에 Load Balancer에서 사용할 Target Group을 [Load Balancer] - [Target Group]에서 생성합니다.\nTarget Group 생성\nTarget Group의 이름를 입력하고 Target 유형은 [VPC Server]를 선택, 다음으로 VPC 대역을 선택합니다.\n그리고, 프로토콜은 PROXY_TCP를 선택하고, 포트는 80포트를 사용하겠습니다. Health Check 설정\nHealth Check 할 프로토콜은 TCP를 선택합니다. Target 추가\n앞에서 생성했던 서버 2대를 선택하고 [적용 Target]쪽으로 이동시킵니다. 설정 확인\n설정 정보를 최종 확인하고 이상이 없으면 Target Group을 생성합니다. 생성된 Target Group를 확인할 수 있습니다.\nNetwork Proxy Load Balancer 생성 link[Load Balancer]에서 [로드밸런서 생성] 버튼을 클릭하고 [네트워크 프록시 로드밸런서]를 선택합니다.\n로드밸런서 설정\n필요한 로드밸런서 설정을 선택하는데, 그 중에서 서브넷은 혹시 생성되어 있지 않으면 [서브넷 생성] 버튼을 클릭해 로드밸런서 전용 서브넷을 생성한 후에 다시 돌아옵니다. 여기서는 [10.0.4.0/24] 대역으로 설정했습니다. 리스너 설정\n리스너는 TCP 프로토콜에 80 포트를 선택하고 추가합니다. Target Group 선택\nTarget Group는 위쪽에서 생성한 [Proxy-Protocol-TG] 을 선택합니다. 선택하면 해당 Target Group 설정 내용을 바로 확인할 수 있습니다. 설정 확인\n선택한 설정을 최종 확인하고 이상이 없으면 [로드밸런서 생성] 버튼을 클릭합니다. 생성 확인\n생성된 로드밸런서의 정보를 확인합니다. 특히 접속 정보와 서브넷은 이후 테스트에 사용되므로 꼭 기억하거나 메모해 두는 것이 좋습니다. ACG 설정 link로드밸런서 → 서버 접속이 가능하도록 서버 ACG에 규칙을 추가합니다.\n서버에 적용된 ACG의 규칙 설정 화면에서 프로토콜은 TCP, 접근소스는 로드밸런서 IP 대역인 10.0.4.0/24, 포트는 80을 입력하고 추가합니다.\n로드밸런서 접속 테스트 link위에서 생성된 로드밸런서 접속 주소로 접속을 해보면 아래와 같은 화면을 확인할 수 있습니다.\nApache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하지만, 저희는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해보겠습니다. Ubuntu Apache 로그파일 위치 : /var/log/apache2/access.log ⁃ Cloud Log Analytics 설정 가이드\rCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 **Load Balancer의 IP 대역 (10.0.4.xx)**이 기록된 것을 확인할 수 있습니다.\n다음으로는 로드밸런서 IP가 아닌 실제 Client IP가 기록되도록 설정을 변경해 보겠습니다.\nProxy Protocol 설정 link이제 실제 Client IP가 기록되도록 Proxy Protocol을 설정해보겠습니다.\n[Load Balancer] - [Target Group]에서 위에서 생성했던 Target Group를 선택하고 [TargetGroup 설정] 버튼을 클릭합니다.\nTarget Group 설정 화면에서 [ProxyProtocol] 옵션을 체크하고 확인 버튼을 클릭합니다.\n위에서 정상적으로 접속이 되었던 로드밸런서 주소로 접속하면 [Bad Request] 메시지가 뜨는 것을 확인할 수 있습니다.\n다음으로는 서버 설정을 변경해야 합니다.\nApache 모듈 설치 linkProxy Protocol을 사용할 때 필요한 Apache 모듈을 Ubuntu 서버에 설치하겠습니다.\nmod_myfixip 모듈 다운로드\n아래 명령어로 mod_myfixip.c 파일을 다운로드 받습니다. 정상적으로 다운로드가 완료되면 ‘mod_myfixip.c’ saved 라는 메시지를 확인할 수 있습니다. wget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache24-modules/master/mod_myfixip.c\r모듈 설치\n이어서 apxs2 -c -i mod_myfixip.c 명령어로 모듈을 설치합니다. apxs2 -c -i mod_myfixip.c\rmyfixip.load 파일 생성\nmod_myfixip 모듈을 로드하기 위한 파일을 생성하고, LoadModule 관련 코드를 추가합니다. vi /etc/apache2/mods-available/myfixip.load\rLoadModule myfixip_module /usr/lib/apache2/modules/mod_myfixip.so\rmyfixip.conf 파일 생성\nmod_myfixip 모듈 환경 설정 파일을 생성하고 모듈 관련 코드를 추가합니다.\nRewriteIPAllow 항목에는 로드밸런서 IP 대역 (ex: 192.168.0.0/16, 10.31.0.0/16 등)을 입력합니다.\n여기서는 위에서 설정했던 로드밸런서 IP 대역인 10.0.4.0/24를 입력했습니다. vi /etc/apache2/mods-available/myfixip.conf\rRewriteIPResetHeader off\rRewriteIPAllow 10.0.4.0/24\r모듈 설치, Apache 재시작\n다음 명령으로 myfixip 모듈을 설치하고 Apache를 재시작합니다. a2enmod myfixip\rsystemctl restart apache2\r최종 접속 테스트 link모든 설정을 모두 마친 후에 서버에 접속해봅니다.\n최종 접속 로그 확인 link접속 로그를 다시 확인해보면 이번에는 로드밸런서 IP가 아닌 Client IP가 기록된 것을 확인할 수 있습니다.\n참고 URL link Proxy Protocol 설정하기\nhttps://guide.ncloud-docs.com/docs/loadbalancer-targetgroup-vpc#proxy-protocol-설정\nUbuntu 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n"
            }
        );
    index.add(
            {
                id:  146 ,
                href: "\/docs\/networking\/loadbalancer\/proxy-portocol\/client-ip-logging-on-centos\/",
                title: "Proxy Protocol을 이용해 Client IP 확인하기 | CentOS",
                description: "Ncloud(네이버 클라우드) Network Proxy Load Balancer의 Proxy Protocol을 이용해 CentOS 서버에서 클라이언트 IP 주소를 확인하는 방법입니다",
                content: "개요 linkNcloud Load Balancer는 HTTP, HTTPS, TCP, SSL 이렇게 4가지의 프로토콜을 지원합니다.\n그런데, Load Balancer를 사용하면서 Client IP를 확인하려고 할 때 http, https 통신의 경우 X-Forwarded-For 헤더값이 지원되기에 Client IP를 확인할 수 있지만, TCP 통신의 경우 X-Forwarded-For 헤더를 사용할 수 없기에 Client IP를 확인하기 위해서는 Proxy Protocol 옵션을 활성화 시켜야 합니다.\n여기서는 Ncloud Network Proxy Load Balancer의 TCP 프로토콜을 사용하면서 Proxy Protocol 옵션을 활성화시켜 CentOS 서버에서 Client IP를 기록하는 방법을 소개하겠습니다.\n테스트 환경 link VPC 환경 CentOS 7.8 Apache 2.4.6 Network Proxy Load Balancer Protocol/Port: TCP/80 CentOS 서버 설치 link서버를 생성하고 Apache 웹서버와 개발용 추가 모듈이 포함된 httpd-devel 패키지를 설치하고 간단한 웹페이지를 만들어 접속해 보았습니다.\n⁃ VPC 환경에서 서버 생성하는 방법\ryum -y install httpd httpd-devel\rTarget Group 설정 link우선 Load Balancer를 생성하기 전에 Load Balancer에서 사용할 Target Group을 [Load Balancer] - [Target Group]에서 생성합니다.\nTarget Group 생성\nTarget Group의 이름를 입력하고 Target 유형은 [VPC Server]를 선택, 다음으로 VPC 대역을 선택합니다.\n그리고, 프로토콜은 PROXY_TCP를 선택하고, 포트는 80포트를 사용하겠습니다. Health Check 설정\nHealth Check 할 프로토콜은 TCP를 선택합니다. Target 추가\n앞에서 생성했던 서버 2대를 선택하고 [적용 Target]쪽으로 이동시킵니다. 설정 확인\n설정 정보를 최종 확인하고 이상이 없으면 Target Group을 생성합니다. 생성된 Target Group를 확인할 수 있습니다.\nNetwork Proxy Load Balancer 생성 link[Load Balancer]에서 [로드밸런서 생성] 버튼을 클릭하고 [네트워크 프록시 로드밸런서]를 선택합니다.\n로드밸런서 설정\n필요한 로드밸런서 설정을 선택하는데, 그 중에서 서브넷은 혹시 생성되어 있지 않으면 [서브넷 생성] 버튼을 클릭해 로드밸런서 전용 서브넷을 생성한 후에 다시 돌아옵니다. 여기서는 [10.0.4.0/24] 대역으로 설정했습니다. 리스너 설정\n리스너는 TCP 프로토콜에 80 포트를 선택하고 추가합니다. **Target Group 선택\nTarget Group는 위쪽에서 생성한 [Proxy-Protocol-TG] 을 선택합니다. 선택하면 해당 Target Group 설정 내용을 바로 확인할 수 있습니다. 설정 확인\n선택한 설정을 최종 확인하고 이상이 없으면 [로드밸런서 생성] 버튼을 클릭합니다. 생성 확인\n생성된 로드밸런서의 정보를 확인합니다. 특히 접속 정보와 서브넷은 이후 테스트에 사용되므로 꼭 기억하거나 메모해 두는 것이 좋습니다. ACG 설정 link로드밸런서 → 서버 접속이 가능하도록 서버 ACG에 규칙을 추가합니다.\n서버에 적용된 ACG의 규칙 설정 화면에서 프로토콜은 TCP, 접근소스는 로드밸런서 IP 대역인 10.0.4.0/24, 포트는 80을 입력하고 추가합니다.\n로드밸런서 접속 테스트 link위에서 생성된 로드밸런서 접속 주소로 접속을 해보면 아래와 같은 화면을 확인할 수 있습니다.\nApache 접속 로그 확인\nApache 접속 로그 파일은 아래의 위치에 존재하지만, 저희는 네이버 클라우드 (Ncloud)의 상품 중 하나인 Cloud Log Analytics에서 로그를 수집해서 확인해보겠습니다. CentOS Apache 로그파일 위치 : /var/log/httpd/access_log ⁃ Cloud Log Analytics 설정 가이드\rCloud Log Analytics에서 수집한 로그를 확인해보면 위에서 설정했던 **Load Balancer의 IP 대역 (10.0.4.xx)**이 기록된 것을 확인할 수 있습니다.\n다음에는 로드밸런서 IP가 아닌 실제 Client IP가 기록되도록 설정을 변경해 보겠습니다.\nProxy Protocol 설정 link이제 실제 Client IP가 기록되도록 Proxy Protocol을 설정해보겠습니다.\n[Load Balancer] - [Target Group]에서 위에서 생성했던 Target Group를 선택하고 [TargetGroup 설정] 버튼을 클릭합니다.\nTarget Group 설정 화면에서 [ProxyProtocol] 옵션을 체크하고 확인 버튼을 클릭합니다.\n위에서 정상적으로 접속이 되었던 로드밸런서 주소로 접속하면 [Bad Request] 메시지가 뜨는 것을 확인할 수 있습니다.\n다음으로는 서버 설정을 변경해야 합니다.\nApache 모듈 설치 linkProxy Protocol을 사용할 때 필요한 Apache 모듈을 CentOS 서버에 설치하겠습니다.\nmod_myfixip 모듈 다운로드\n아래 명령어로 mod_myfixip.c 파일을 다운로드 받습니다. 정상적으로 다운로드가 완료되면 ‘mod_myfixip.c’ saved 라는 메시지를 확인할 수 있습니다. wget --no-check-certificate https://raw.githubusercontent.com/ggrandes/apache24-modules/master/mod_myfixip.c\r모듈 설치\n이어서 /{아파치가 설치된 경로}/bin/apxs -c -i mod_myfixip.c 명령어로 모듈을 설치합니다. /usr/bin/apxs -c -i mod_myfixip.c\rhttpd.conf 설정 변경\n모듈 설치가 완료된 후에 httpd.conf 파일을 열어서 제일 아래쪽에 아래 코드를 추가합니다.\nRewriteIPAllow 항목에는 로드밸런서 IP 대역 (ex: 192.168.0.0/16, 10.31.0.0/16 등)을 입력합니다.\n여기서는 위에서 설정했던 로드밸런서 IP 대역인 10.0.4.0/24를 입력했습니다. vi /etc/httpd/conf/httpd.conf\rLoadModule myfixip_module modules/mod_myfixip.so\rRewriteIPResetHeader off\rRewriteIPAllow 10.0.4.0/24\rApache 재시작\n설정을 마친 후에 Apache를 재시작합니다. systemctl restart httpd\r최종 접속 테스트 link모든 설정을 모두 마친 후에 서버에 접속해봅니다.\n최종 접속 로그 확인 link접속 로그를 다시 확인해보면 이번에는 로드밸런서 IP가 아닌 Client IP가 기록된 것을 확인할 수 있습니다.\n참고 URL link Proxy Protocol 설정하기\nhttps://guide.ncloud-docs.com/docs/loadbalancer-targetgroup-vpc#proxy-protocol-설정\nUbuntu 서버에서 Proxy Protocol을 이용해 Client IP 확인하기\n"
            }
        );
    index.add(
            {
                id:  147 ,
                href: "\/docs\/networking\/dns\/global-dns-guide\/",
                title: "Global DNS 사용 가이드 - 도메인 추가",
                description: "Ncloud(네이버 클라우드) Global DNS 사용 가이드 - 도메인 추가 방법입니다",
                content: "개요 linkDNS 서버는 개인이 직접 운영하기 어려운데, 네이버 클라우드 Global DNS를 이용하면 도메인 설정 등을 쉽고 편하게 사용할 수 있습니다.\n도메인 추가 link네이버 클라우드는 도메인 구매/등록을 지원 하지 않습니다. 그러므로 가비아, 아이네임즈, 닷네임코리아 등 전문 도메인 등록 기관에서 도메인을 구입 하셔야 합니다.\n새로 구입한 도메인 혹은 기존 도메인을 [네이버 클라우드 콘솔] - [Networking] - [Global DNS] 메뉴에서 [도메인 추가] 버튼을 클릭해 도메인주소를 입력합니다.\n다음과 같이 생성된 도메인 정보에서 네임서버의 주소를 확인합니다.\n도메인을 구입한 등록기관 사이트에서 해당 도메인의 네임서버를 위에서 확인한 네이버 클라우드 Global DNS에서 제공하는 네임서버 정보로 등록합니다.\n레코드 추가 link레코드를 추가하려면 도메인 정보에서 [레코드 추가]를 클릭합니다.\n추가하려고 하는 레코드 즉, 호스트명과 IP 주소를 입력합니다,\n추가된 레코드를 도메인 정보에서 아래와 같이 확인한 후, [설정 적용] 버튼을 클릭합니다.\n[배포] 버튼을 클릭해 변경된 정보를 배포-적용합니다.\n네이버 클라우드 네임서버를 클라이언트의 DNS로 설정하지 않은 경우, 레코드의 추가/변경 내역이 반영되는데 전파시간이 소요될 수 있습니다.\n참고 URL link Ncloud Global DNS 가이드\nhttps://guide.ncloud-docs.com/docs/ko/globaldns-overview 문서 업데이트 내역 link\r날짜 내용 2021-05-27 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  148 ,
                href: "\/docs\/networking\/dns\/global-dns-configure-long-txt-record\/",
                title: "DNS 설정에서 255자 이상의 TXT 레코드(SPF, DKIM, DMARC 등) 등록하는 방법",
                description: "DNS 설정에서 255자 이상의 TXT 레코드(SPF, DKIM, DMARC 등) 등록하는 방법입니다",
                content: "개요 linkDNS 설정할 때 TXT 레코드의 설정 값은 일반적으로 255자로 제한되어 있습니다. 하지만 메일 발신 도메인 인증을 위한 SPF, DKIM 레코드의 설정 값은 255자를 넘는 경우가 많은데 이때 이런 255자 이상의 문자열을 등록할 수 있는 방법에 대해 대표적인 DNS 서비스 업체별로 확인해보겠습니다.\nNcloud Global DNS link우선 Ncloud(네이버 클라우드)의 DNS 서비스인 [Global DNS]는 다른 DNS 제공 업체와 다르게 255자가 넘는 경우에도 자동으로 문자열을 분리해서 등록해줍니다.\n그러므로 Ncloud(네이버 클라우드)에서는 TXT 레코드 값의 길이를 신경쓰지 않고 편하게 등록하시면 됩니다.\n레코드 등록 예시 link아래와 같이 예시로 255자가 넘는 DKIM 정보를 [Global DNS]에 등록했습니다. 등록하면서 문자열을 나누지 않고 전체를 하나의 문자열로 등록했습니다.\nDNS 레코드 정보 조회 예시 link위에서 예시로 등록한 레코드 정보를 아래와 같이 확인해보면 레코드 문자열이 자동으로 255자 이하로 나누어서 표시되는 것을 확인할 수 있습니다.\nnslookup -q=txt ***._domainkey.조회할도메인\rAWS Route53 linkAWS Route53에서는 255자를 초과하는 값의 경우 각각 255자 이하의 문자열로 나누어서 각 문자열을 큰따옴표로 묶어서 등록해야 합니다. 이때 각 문자열 사이에 줄바꿈을 입력하면 안됩니다.\n예시 link 원본 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Long_String_Record_ThjBJHkMghJbG” 수정 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Lo\" \"ng_String_Record_ThjBJHkMghJbG” Google Cloud DNS linkGoogle Cloud Platform의 Cloud DNS에서도 AWS와 마찬가지로 255자를 초과하는 값의 경우 각각 255자 이하의 문자열로 나누어서 각 문자열을 큰따옴표로 묶어서 등록해야 합니다. 이때 각 문자열 사이에 줄바꿈을 입력하면 안됩니다.\n예시 link 원본 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Long_String_Record_ThjBJHkMghJbG” 수정 문자열: “v=DKIM1;p=BHIUKuk…..YubhjfvF_Very_Lo\" \"ng_String_Record_ThjBJHkMghJbG” 참고 URL link Ncloud Global DNS 가이드\nhttps://guide.ncloud-docs.com/docs/globaldns-overview\nNcloud Cloud Outbound Mailer 도메인 보안 인증\nhttps://guide.ncloud-docs.com/docs/cloudoutboundmailer-use-domain#도메인-보안\nAWS Route53에서 255자 보다 긴 TXT 레코드 구성하기\nhttps://repost.aws/ko/knowledge-center/route-53-configure-long-spf-txt-records\nGCP Cloud DNS 레코드 추가 가이드\nhttps://cloud.google.com/dns/docs/records?hl=ko#record_type\n문서 업데이트 내역 link\r날짜 내용 2024-01-10 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  149 ,
                href: "\/docs\/networking\/natgateway\/vpc-natgateway-routetable\/",
                title: "VPC 환경에서 NAT Gateway 설정하기",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 NAT Gateway 설정하기 가이드입니다",
                content: "개요 linkNAT Gateway는 비공인 IP를 가진 다수의 서버들이 대표 공인 IP를 이용해 외부와 통신을 할 수 있도록 도와주는 네트워킹 서비스입니다.\n그리고, 일반적으로 서버에 직접 공인 IP를 부여하는 것과 달리 외부에서 서버로의 직접 접근은 허용하지 않기 때문에 높은 수준의 보안을 유지할 수 있는 것이 특징입니다.\n여기서는 VPC 환경에서 NAT Gateway를 어떻게 구성하고, NAT Gateway를 적용하기 전과 후의 외부와 통신 상태에 대해 확인해보도록 하겠습니다.\nNAT Gateway 특징 link[NAT Gateway]는 생성 시 [공인 NAT Gateway]와 [사설 NAT Gateway]를 선택할 수 있습니다. 존당 5개까지 생성이 가능하며, 각 NAT Gateway의 특징은 다음과 같습니다.\n공인 NAT Gateway link 사설 IP와 공인 IP를 둘 다 가지고 있습니다. 인터넷 outbound 통신을 할 때 Public IP에서 할당된 공인 IP를 사용합니다. VPC 내부에서 NAT Gateway를 통해 통신할 경우 할당된 사설 IP를 사용합니다. 할당된 공인 IP는 NAT Gateway를 삭제 시 재사용이 가능합니다. 사설 NAT Gateway link 사설 IP만 가지고 있습니다. VPC 내부에서 NAT Gateway를 통해 통신할 경우 할당된 사설 IP를 사용합니다. VPC 서비스 위치 link[VPC] 서비스는 [Console] - [Networking]에 위치해 있습니다.\n그리고, 아래 스샷에서 확인할 수 있듯이 [VPC]에는 [VPC], [Subnet], [Network ACL], [NAT Gateway], [Route Table], [VPC Peering], [Virtual Private Gateway] 등의 하부 서비스 메뉴가 있습니다.\nVPC 생성 link먼저 VPC를 생성합니다. IP주소 범위는 10.0.0.0/16으로 정하겠습니다.\nSubnet 생성 linkSubnet은 아래와 같이 총 3가지를 준비하겠습니다.\nNAT Gateway 동작 테스트를 위해 서버용 Public, Private Subnet NAT Gateway를 배치할 NAT Gateway 전용 Subnet Public Subnet 생성 linkPublic Subnet의 IP 범위는 10.0.0.0/24로 설정하겠습니다.\nPrivate Subnet 생성 linkPrivate Subnet의 IP 범위는 10.0.1.0/24로 설정하겠습니다.\nNAT Gateway 전용 Subnet linkNAT Gateway 전용 Subnet은 Subnet 생성 화면에서 아래쪽 용도 설정에서 [NatGateway]를 선택합니다.\nACG 설정 link테스트를 위한 ACG (Access Control Group)를 생성하고 설정합니다.\nInbound 설정 linkInbound 규칙에는 Public, Private Subnet과 SSH 접속을 위한 로컬PC IP를 허용하고, Ping 테스트를 위한 ICMP도 허용합니다.\nOutbound 설정 linkOutbound 규칙은 TCP, UDP, ICMP 모두 전체 허용으로 추가합니다.\n서버 생성 link테스트를 위해 Public, Private 각각의 Subnet에 1대씩 서버를 설정하고 Public 서버에는 공인 IP도 할당합니다.\nPublic -\u003e Private 서버 접속 확인 linkPublic Subnet에 있는 서버에서 Private Subnet에 있는 서버로 통신이 가능한 것을 확인할 수 있습니다.\n다음 단계에서 Private 서버로 SSH로 접속하기 위한 사전 확인 단계입니다.\nPrivate 서버 외부 접속 여부 확인 linkPublic 서버에서 Private 서버로 SSH로 접속한 후에 Private 서버에서 외부로 통신이 되는 것을 확인해보면 불가능한 것을 확인할 수 있습니다.\n이후 단계에서 NAT Gateway를 설정하고 Private 서버에서 외부와 통신이 가능한지 확인해보겠습니다.\nRoute Table 설정 확인 linkNAT Gateway를 위한 Route Table 설정을 추가하기 전에 현재 상태의 Route Table 설정을 확인해보겠습니다.\nPublic Subnet의 Route Table 설정 확인 link위에서 Public Subnet의 서버와 Private Subnet의 서버가 통신이 가능했던 것은 VPC와 Subnet이 생성될때 Route Table이 생성되면서 VPC 내부 통신을 위한 규칙 (10.0.0.0/16 LOCAL)이 기본으로 설정되기 때문입니다.\n그리고 Public의 경우 외부 통신을 위한 INTERNET GATEWAY가 추가되어 있는 것을 확인할 수 있습니다.\nPrivate Subnet의 Route Table 설정 확인 link반면에 Private의 경우는 VPC 내부 통신을 위한 LOCAL만 설정된 것을 확인 할 수 있습니다.\nRoute Table 설정 화면에 들어가도 Target Type에 LOCAL만 선택할 수 있는 것을 확인할 수 있습니다.\nNAT Gateway 생성 link[NAT Gateway]는 별도의 메뉴가 있지 않고, [Networking] - [VPC] 서비스 내에 하부 서비스로 존재합니다. 그러면 이제 [NAT Gateway 생성] 버튼을 클릭합니다.\n이름을 입력하고 서비스 상황에 따라 유형을 [공인] 또는 [사설]을 선택한 후, VPC와 위에서 생성했던 전용 Subnet을 선택하고, NAT Gateway를 생성합니다. 그리고 마지막으로 Route Table에 NATGW 설정을 추가해야 완료되는데, 관련 설정은 아래에서 확인 가능합니다.\nRoute Table 설정 link앞에서 LOCAL 항목만 존재했던 Private Subnet의 Route Table 설정 화면에 가보면 Target Type에 NATGW가 추가된 것을 확인할 수 있습니다.\n목적지(Destination)에 0.0.0.0/0을 입력하고, Target Type을 NATGW를 선택하고 생성 버튼을 클릭합니다.\n외부 접속 테스트 link마지막으로 다시 한번 Private 서버에서 외부 통신이 가능한지 ping 테스트를 해보면, 아래 화면과 같이 정상적으로 통신이 되는 것을 확인할 수 있습니다.\n고려사항 link{% include warning.html title=“요금” content=“NAT Gateway는 사용하지 않고 생성만 해두어도 요금이 부과됩니다. (데이터 처리요금 별도)” %}\n생성 후 보유 시간에 따라 요금이 부과되는데 1개당 56원/시간 입니다. 그러므로 1달간 보유하고만 있다고 가정할 때 비용을 계산해보면 24시간 * 30일 * 56원 = 40,320원 그러므로 사용하지 않는 NAT Gatway는 반드시 삭제하기를 추천드립니다.\n참고 URL link NAT Gateway 가이드\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailenatgw\nNAT Gateway 특징과 비교\nhttps://m.blog.naver.com/n_cloudplatform/221173116642\n문서 업데이트 내역 link\r날짜 내용 2021-07-13 문서 최초 생성 2023-05-16 NAT Gateway 전용 Subnet 업데이트 "
            }
        );
    index.add(
            {
                id:  150 ,
                href: "\/docs\/networking\/vpc\/ncloud-vpc-overview\/",
                title: "Ncloud VPC 구성요소",
                description: "Ncloud(네이버 클라우드) VPC를 구성하는 요소들에 대한 설명으로 네이버 클라우드 파트너 테크데이에서 발표된 내용입니다",
                content: "개요 link이 문서는 VPC를 구성하는 요소들에 대한 설명으로 네이버 클라우드 파트너 테크데이에서 발표된 내용을 정리한 것입니다.\nVPC linkVPC(Virtual Private Cloud)는 퍼블릭 클라우드 상에 논리적으로 완전하게 분리된 고객전용 네트워크를 제공하는 서비스. 최대 /16의 IP 네트워크 공간을 제공 (IP 대역: RFC 1918).\n@ RFC 1918 IP대역\r10.0.0.0/8 (10.0.0.0 - 10.255.255.255) 172.16.0.0/12 (172.16.0.0 - 172.31.255.255) 192.168.0.0/16 (192.168.0.0 - 192.168.255.255)\rSubnet (Internet Gateway) link할당된 VPC를 용도에 맞게 네트워크 공간을 세분화 하여 사용.\n/16 ~ /28의 네트워크 주소 할당이 가능.\nPublic Subet 생성 시 Internet Gateway가 연결됨.\nNAT Gateway linkNetwork Address Translation의 약자로, 폐쇄된 네트워크에서 외부와의 인터넷 동신 시 사용하는 게이트웨이.\nRoute Table link네트워크 경로를 설정할 수 있는 기능을 제공. VPC 내부 통신을 위한 Local은 기본적으로 설정.\nACG link서버에서 인바운드/아웃바운드의 네트워크 접근제어를 지원하며 Stateful 기반으로 동작.\nNACL linkNetwork Access Control List의 약자로, Subnet에서 인바운드/아웃바운드의 네트워크 접근제어를 지원하며 Stateless 기반으로 동작.\nVirtual Private Gateway linkCloud Connect와 IPSec VPN에 연결되는 네이버 클라우드의 VPC측 연결 접점으로서 Cloud Connect와 IPSec VPN 연결을 지원.\nVPC Peering linkVPC간 사설연결을 보장하는 기능으로, 일반적인 VPC \u003c-\u003e VPC 간의 통신은 인터넷을 통하게 되고, 이는 과다한 요금 발생 및 성능 저하를 일으킬 수 있음.\nVPC Peering을 이용하면 보다 안전한 사설 IP기반의 통신이 가능함.\nVPC Peering은 단방향 통신을 제공하기 때문에 양방향 통신을 원하면 Src -\u003e Dest 별로 각각 1개씩, 두개의 정책을 모두 적용해야 함.\n참고 URL link Ncloud VPC Overview\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcoverview 문서 업데이트 내역 link\r날짜 내용 2020-11-30 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  151 ,
                href: "\/docs\/networking\/vpc\/acg-nacl-compare\/",
                title: "Ncloud NACL과 ACG 비교",
                description: "Ncloud(네이버 클라우드) NACL과 ACG 비교 정보입니다",
                content: "개요 link네이버 클라우드에서는 VPC의 보안을 강화하기 위해 ACG와 NACL의 두 가지 보안 정책을 제공하고 있습니다.\nNACL : Network Access Control List는 Subnet의 Inbound 및 Outbound 트래픽을 제어 ACG : Access Control Group은 서버의 NIC별 Inbound 및 Outbound 트래픽을 제어 NACL vs ACG link 구분 NACL ACG 적용 대상 Subnet의 접근 제어 서버의 접근 제어 지원 규칙 허용 및 거부 (Allow / Deny) 허용 (Allow) 상태 저장 여부 상태 비저장(Stateless)\n(반환 트래픽이 규칙에 의해\n명시적으로 허용되어야 함) 상태 저장(Stateful)\n(규칙에 관계없이 반환 트래픽이\n자동으로 허용됨) 적용 방법 Subnet 단위로 적용\n(Subnet 별 1개만 허용) 서버의 NIC에 ACG 정책 적용 참고 URL link Ncloud NACL 가이드 https://guide.ncloud-docs.com/docs/vpc-nacl-vpc 문서 업데이트 내역 link\r날짜 내용 2020-12-01 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  152 ,
                href: "\/docs\/networking\/vpc\/subnet-natgateway-compare\/",
                title: "Subnet과 NAT Gateway 비교",
                description: "Ncloud(네이버 클라우드) Subnet 과 NAT Gateway 비교 정보입니다",
                content: "개요 link네이버 클라우드에서는 VPC의 보안을 강화하기 위해 두 가지 서브넷을 제공하고 있습니다.\nPublic Subnet : 인터넷과 자유로운 통신이 필요할 때 사용할 수 있는 서브넷으로 Interget GW를 통해 외부와 통신 Private Subnet : 보안상 외부에서 서버에 접근하는 것을 막아야 할 때 사용하는 서브넷으로 NAT GW를 통해 외부와 통신 Public vs Private Subnet link 구분 Public Subnet Private Subnet 용도 인터넷 연결이 필요할 때 외부 접속을 최소화 해야 할 때 지원 리소스 서버 서버, 로드밸런서 인터넷 연결 시\n필요한 리소스 Internet Gateway (Default) NAT Gateway 참고 URL link Ncloud NAT Gateway 가이드 https://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailenatgw 문서 업데이트 내역 link\r날짜 내용 2020-12-01 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  153 ,
                href: "\/docs\/networking\/vpc\/vpc-peering-guide\/",
                title: "VPC Peering 생성 가이드",
                description: "Ncloud(네이버 클라우드)에서 분리되어 있는 VPC간의 통신이 필요할때 사용할 수 있는 서비스 VPC Peering 생성 가이드입니다",
                content: "개요 linkVPC(virtual Private Cloud)는 퍼블릭클라우드상에서 제공되는 사설 가상 네트워크 입니다. 계정당 3개의 VPC를 만들수 있으며 다른 VPC 네트워크와 논리적으로 분리되어 있어 독립적인 네트워크 환경을 구현할 수 있습니다.\n그런데, 간혹 VPC 환경에서 분리되어 있는 VPC간의 통신이 필요할때가 있는데 이때 사용할 수 있는 서비스가 [VPC Peering] 입니다.\nVPC Peering은 공인 아이피를 거치지 않고 Ncloud 내부 네트워크를 이용하여 VPN없이 VPC간 통신을 할수 있게 해주는 서비스 입니다.\nVPC 생성 link우선 테스트에 사용할 VPC로 [test-vpc], [test2-vpc] 이렇게 2개를 준비했습니다.\nSubnet 생성 link이제 각 VPC에 서브넷을 생성합니다. [test-vpc]에는 [test-subnet(192.168.10.0/24)]으로 생성합니다.\n[test2-vpc]에는 [test2-subnet(172.16.10.0/24)]으로 생성합니다.\n생성된 Subnet은 다음과 같습니다.\nVPC Peering 생성 link네이버 클라우드(Ncloud) 콘솔에서 [Networking] -\u003e [VPC] -\u003e [VPCPeering] 메뉴로 이동해서 [VPC peerig 생성] 버튼을 클릭합니다.\n① 이름을 적고 ② 요청 VPC는 [testVPC]를 선택 ③ 수락 VPC는 [내계정], [test2VPC]를 선택 설정이 끝났으면 생성버튼을 클릭합니다.\n{% include callout_v2.html type=“success” level=“1” content=“다른 계정의 VPC와 연결하는 경우는 아래쪽에서 살펴보겠습니다.” %}\n마지막으로 VPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n[test-vpc] -\u003e [test2-vpc]로 설정된 VPC Peering을 아래와 같이 확인할 수 있습니다.\n역방향 설정 추가 link그런데 VPC peering은 단방향 통신이기에 TCP, ICMP 등의 양방향 통신을 하는 프로토콜을 이용하려면 역방향 즉, [test2-vpc] -\u003e [test-vpc]로 설정된 VPC Peering도 추가해야 합니다.\n① 이름을 적고 ② 요청 VPC에는 test2VPC를 선택 ③ 수락 VPC에는 testVPC를 선택 VPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n아래와 같이 [test-vpc] -\u003e [test2-vpc] , [test2-vpc] -\u003e [test-vpc] 2가지 VPC Peering을 모두 생성했으므로 양방향 통신이 가능하게 되었습니다.\nRoute Table 설정 link이제 통신할 서브넷 혹은 서버의 아이피를 Route Table 설정에 추가 합니다. 여기서는 서브넷을 추가하도록 하겠습니다.\n우선 [VPC] - [Route Table]에서, [test-vpc-default-public-table]의 [Routes 설정]을 클릭합니다.\nDestination에는 [test2-subnet]의 아이피 대역을 입력 (서버의 아이피로 입력해도 됨) Target Type은 [VPCPEERING]을 선택 Target Name은 [test-vpc-peering]을 선택 다음으로 [test2-vpc-default-public-table]의 [Routes 설정]을 클릭합니다.\nDestination에는 [test-subnet]의 아이피 대역을 입력 (서버의 아이피로 입력해도 됨) Target Type은 [VPCPEERING]을 선택 Target Name은 [test2-vpc-peering]을 선택 서버 준비 link아래와 같이 테스트로 사용할 서버 2대를 준비했습니다.\n테스트는 [test-vpc]에 위치한 [test-vpc-peering-svr]서버 -\u003e [test2-vpc]에 위치한 [test2-vpc-peering-svr]로 접속 시도를 해보겠습니다.\nACG 설정 linkACG를 설정하지 않고 [test-vpc-peering-svr] -\u003e [test2-vpc-peering-svr]로 접속 시도를 하면 접속이 되지 않는 것을 확인할 수 있습니다.\n[test2-vpc-peering-svr]로 접속할 것이므로 해당 서버에 설정된 acg인 [test2-vpc-default-acg]를 선택하고 [ACG 설정] 버튼을 클릭합니다.\n접근소스에는 [test-vpc-peering-svr] 서버의 subnet 대역인 [192.168.10.0/24]를 입력하고, 포트는 22번 포트를 입력하고 추가해서 적용합니다.\n접속 테스트 linkACG 설정까지 완료하고 나서 다시 접속 테스트를 해보면 아래와 같이 접속이 잘 되는 것을 확인할 수 있습니다.\n다른 계정 VPC 연결 link위에서는 동일한 내 계정에 생성된 VPC들 간의 Peering을 살펴보았는데, 아래에서는 다른 계정에 생성된 VPC와 연결할 때의 화면을 살펴보겠습니다.\nVPC Peering 생성 화면에서 [다른 계정]을 선택하면 아래와 같이 [로그인 ID (이메일)], [VPC ID], [VPC 이름]을 입력하게 됩니다.\n마찬가지로 VPC Peering 요청 내용을 확인하고 [확인] 버튼을 클릭합니다.\n다음으로 수락을 요청받은 다른 계정의 VPC Peering 화면에 가면 요청 내용을 확인할 수 있고, 요청 응답에서 [수락] 버튼을 클릭합니다.\n한번 더 VPC Peering 연결 요청을 수락할 것인지 확인하는 창이 나타납니다.\n수락하고 나면 역방향의 VPC Peering 연결을 생성해야 한다는 안내와 함께 역방향 VPC Peering 생성 화면이 나타납니다.\n역방향은 위의 설정과 반대로 진행하면 되고, 그 이후에는 내 계정에서 설정했던 것과 마찬가지로 설정하시면 완료됩니다.\n제한사항 link\r⁃ VPC Peering은 연결하려는 VPC들의 IP주소 대역이 달라야 합니다. ⁃ 일치되거나 중첩되는 대역이 있으면 설정되지 않습니다.\r⁃ VPC Peering은 단방향입니다. ⁃ TCP등 양방향 통신을 해야 하는 경우에는 요청 / 수락 VPC를 맞바꾸어 역방향 Peering도 추가 생성해야 합니다.\r⁃ VPC Peering은 전이적 연결 관계를 지원하지 않습니다. ⁃ 즉, Peering된 VPC를 통하여 다른 VPC 혹은 외부로 통신하는 것은 불가능 합니다.\r⁃ VPC Peering은 동일한 리전 내 VPC 끼리만 연결할 수 있습니다.\r참고 URL link VPC Peering 가이드\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcdetailedpeering\nVPC Peering 설정 시나리오\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcuserscenario4\n문서 업데이트 내역 link\r날짜 내용 2021-11-25 문서 최초 생성 2023-11-03 스크린샷 업데이트 "
            }
        );
    index.add(
            {
                id:  154 ,
                href: "\/docs\/networking\/ipsecvpn\/ipsecvpn-fortigate-configure-guide\/",
                title: "Ncloud VPC환경 IPsecVPN과 FortiGate 장비 연동 가이드",
                description: "Ncloud(네이버 클라우드) VPC 환경의 IPsecVPN 상품을 온프레미스 FortiGate 장비와 연동하여 IPsec VPN 환경을 구성하는 방법입니다",
                content: "구성 환경 link Platform : VPC 서버 OS : CentOS 7.8 클라이언트 OS : Windows 11 Pro 온프레미스 VPN 장비 : FortiGate 30E VPC - IPsecVPN 네이버 클라우드 설정 link1. 서버생성 linkPlatform에서 VPC를 선택 후 서버를 생성합니다. 서버 생성에 대한 자세한 사항은 해당 문서에서 다루지 않습니다. 서버 생성 가이드 참고 부탁드립니다.\n(※실습은 VPC, Subnet, 서버 생성이 완료된상태로 진행됩니다.)\n2. Virtual Private Gateway 생성 link콘솔 → VPC → Virtual Private Gateway\n이름입력 및 VPC를 선택하고 생성합니다.\n생성 후 현재 상태는 미사용중이 맞습니다. 다음으로 넘어갑니다.\n3. Virtual Private Gateway Group 생성 link콘솔 → VPC → Virtual Private Gateway → Virtual Private Gateway Group\n이름설정 및 VPC, Default 여부 선택하여 추가하고 생성합니다.\nGroup생성이 완료되면 2번항목에서 생성한 Virtual Private Gateway도 운영중으로 변경됩니다.\n4. Route Table 설정 link콘솔 → VPC → Route Table\nVPC를 생성하면 아래와같이 default로 해당 VPC의 Public, Private Table이 기본으로 생성되어있습니다.\nIPsecVPN 연결을위해 생성한 서버가 소속된 default-table에 목적지인 사무실대역을 추가하여 경로를 지정합니다.\n5. IPsec VPN Gateway 생성 link콘솔 → IPsec VPN → IPsec VPN Gateway\n이름 및 Group를 선택하고 생성합니다.\n생성완료되어 상태가 운영중이면 다음으로 넘어갑니다.\n6. IPsecVPN Tunnel 생성 link콘솔 → IPsecVPN → IPsecVPN Tunnel\nVPN 연결 정보 입력 후 다음으로 넘어갑니다.\n(※ 아래 입력한 정보는 임의 설정값입니다.)\n최종 입력 정보를 확인 후 생성합니다.\n생성된 정보를 확인하여 상태가 운영중이면 다음으로 넘어갑니다.\nFortiGate IPsec VPN 장비설정 link1. 가상사설망 생성 linkFortiGate → 가상사설망 IPsec Wizard → Custom\nTemplate Type은 Custom으로 진행합니다.\n네이버 클라우드에서 생성한 IPsecVPN Tunnel 정보와 동일하게 설정합니다. 서로의 정보가 하나라도 다를경우 연결에 실패할 수 있습니다.\n네이버 클라우드 IPseVPN Gateway 공인 IP 확인\n콘솔 → IPsec VPN → IPsec VPN Gateway\n계속하여 FortiGate VPN 장비 정보 입력하겠습니다.\n2. 라우팅 설정 linkFortiGate → 네트워크 → 정적 경로 → 새로 생성\nInterface 부분부터 위에서 생성한 test-vpn을 선택합니다.\n목적지로 가기위한 정보 입력 후 생성합니다.\n3. 정책설정 linkLocal\u003eVPN, VPN\u003eLocal의 접근을 제어하기위한 설정을 합니다.\n(가이드에서는 all로 설정하고 진행하겠습니다)\nFortiGate → Policy \u0026 Objects → IPv4 Policy → 새로 생성\nLoca l\u003e VPN 정보 입력 후 생성\nVPN \u003e Local 정보 입력 후 생성\n4. VPN 모니터링 linkFortiGate → 모니터 → IPsec 모니터 → Bring UP\nBring UP하여 상태가 Down에서 UP 으로 변경되면 정상적으로 연결이 완료되었습니다.\nACG 설정 linkVPN연결이 되어도 아래와같이 Ping테스트에 실패하게됩니다. 이유는 네이버클라우드 서버는 ACG 정책에 따라 접근이 통제되므로 추가 설정이 필요합니다.\n콘솔 → Server → ACG → ACG 선택 → ACG 설정\n사무실PC에서 네이버클라우드 서버로 ping 테스트를 위해 서버에 매핑된 ACG에 아래와 같이 사무실의 사설대역을 입력하고 추가합니다.\n접근소스에 프로토콜 - ICMP, 접근소스 - 사무실의 사설대역으로 추가합니다.\n이후 핑테스트결과 아래와같이 정상적으로 통신이가능합니다.\n※ 추가로 프로토콜 - TCP, 접근소스 - 사무실 사설대역, 허용포트 22를추가하면 아래와같이 서버에 접근이 가능합니다.\n문서 업데이트 내역 link\r날짜 내용 2022-09-28 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  155 ,
                href: "\/docs\/database\/ncloud-database-type-compare\/",
                title: "Ncloud 설치형 DB서버와 관리형 Cloud DB 비교",
                description: "Ncloud(네이버 클라우드)의 설치형 DB서버와 관리형 Cloud DB를 비교한 내용을 정리해보았습니다",
                content: "개요 link서버에 DB가 설치된 상태로 제공되는 설치형 DB서버와 Cloud 형태로 제공되는 관리형 DB서버는 어떤 특징과 차이점이 있는지 확인합니다. 더불어 비용 비교와 함께 각각의 DB서버를 어떤 경우에 사용하면 좋은지 예시를 통해 DB서버 선택에 도움을 드리고자 합니다.\n설치형 DB 특징 link 저렴한 비용 DB관련 아주 세부적인 부분까지 직접 설정 가능 관리형 Cloud DB 특징 link 빠르고 손쉬운 설치 네이버 클라우드에서 검증된 최적화 설정 자동으로 증가하는 데이터 스토리지 (MSSQL : 2TB까지, Mysql : 6000GB까지) 장애 발생시 자동 Fail-over를 통한 장애 최소화를 할 수 있는 탁월한 가용성 제공 읽기 부하 분산을 위한 읽기 전용 Slave 5개까지 지원 자동화된 DB 백업, 최대 30일까지 보관 성능 모니터링과 알람 원하는 시간을 선택하여 DB 자동 복원 (Mysql) 1분 단위의 쿼리 레벨 성능 분석을 지원 (MSSQL) 비용 전체 비교 link DB 서버 스펙 : Standard(2 vCPU, 4GB 메모리, 100GB 디스크) DB 구분 설치형 DB (서버 비용 포함) 관리형 Cloud for DB mysql 69,000원/월 115,200원/월 MSSQL 379,000원/월 614,880원/월 비용 비교 상세 (Mysql) link설치형 link 69,000원/월 : 서버 비용 + DB 무료 관리형 Cloud link-115,200원/월 : 160원(시간당) * 24시간(1일) * 30일(한달)\n비용 비교 상세 (MSSQL) link설치형 link 379,000원/월 : 69,000원(서버) + 20,000원(서버 Windows 라이선스) + 290,000원(MSSQL 라이선스) 관리형 Cloud link 614,880원/월 : 854원 (시간당) * 24시간(1일) * 30일(한달) warning\rHA 구성 시 요금 적용: 관리형 Cloud for MSSQL에서 HA (Principal-Mirror 구성) 구성을 할 경우, DBMS 라이선스 요금은 마스터/슬레이브 서버에만 적용됩니다.\n설치형 DB서버를 사용하면 좋은 경우 link 사내에 DB전문가가 있을 경우 서비스에 최적화된 DB설정을 하고 싶은 경우 장애 시 자동 Fail-over가 굳이 필요하지 않은 경우 DB백업을 원하는 방식으로 직접 하고 싶은 경우 DB 사이즈가 일정 크기 이상으로 늘어나는 것을 원하지 않는 경우 서비스 안정성 보다 비용 절감이 더 중요한 경우 관리형 Cloud DB를 사용하면 좋은 경우 link 장애 시 자동 Fail-over를 통해 서비스 중지 시간을 최소로 하고 싶을 경우 DB의 읽기 요청이 많아서 읽기 전용 DB를 마련했을 때 효과가 큰 경우 DB백업과 디스크 용량 증설 등이 특별한 작업 없이 자동으로 진행되길 원하는 경우 비용보다 서비스 안정성이 더 중요한 경우 DB전문가가 없는 경우 참고 URL link Ncloud Database 상품 소개\nhttps://www.ncloud.com/product/database 문서 업데이트 내역 link\r날짜 내용 2021-01-26 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  156 ,
                href: "\/docs\/database\/mysql-mariadb\/classic-mysql-root-password-set-update\/",
                title: "Classic 환경 설치형 MySQL DB에서 root Password 설정, 변경하는 방법",
                description: "Ncloud(네이버 클라우드) Classic 환경 설치형 MySQL DB에서 root Password 설정, 변경하는 방법입니다",
                content: "개요 link네이버 클라우드에서는 MySQL Password 정책에 따라 처음 MySQL DB를 설치할 때 root의 초기 패스워드가 설정되지 않습니다. 그러므로 보안 침해 방지를 위해 설치 후에 root Password를 설정한 후에 DB를 사용하는 것이 안전합니다.\n여기서는 Classic환경에서 MySQL 5.6과 5.7 버전의 root Password를 설정, 변경하는 방법에 대해 정리해보겠습니다.\nMySQL 버전 link네이버 클라우드 Classic환경에서 지원하는 설치형 MySQL 버전은 5.6과 5.7 입니다.\n{% include callout_v2.html type=“success” level=“2” content=“Ncloud는 Classic환경에서는 DB 서버 이미지를 제공하지만, VPC 환경에서는 제공하지 않습니다. 그러므로 VPC 환경에서 DB서버를 사용하려면 OS에 사용자가 직접 DB를 설치해서 사용하는 방법과 Cloud DB를 사용하는 방법 중에서 선택해야 합니다.” %}\nMySQL 5.6 설정 link우선 mysql 5.6 DB서버를 생성한 후 root 계정의 패스워드 상태를 확인해봅니다. 그 이후에 패스워드를 설정합니다.\n#mysql 접속\rmysql -u root\r#계정 정보 조회\rmysql\u003e select host, user, password from mysql.user;\r#패스워드 설정-변경\rmysql\u003e set password = password('패스워드');\r#변경된 패스워드 조회\rmysql\u003e select host, user, password from mysql.user;\r초기 패스워드가 설정되어있지 않기 때문에 -p 옵션을 사용하지 않고 바로 접속 해서 user 테이블에 있는 계정 정보를 확인해보면 password 값이 비어 있는 것을 확인할 수 있습니다.\n패스워드를 설정하고 다시 확인을 해보면 localhost의 root 계정에 패스워드가 설정된 것을 확인할 수 있습니다.\nreport\r계정 구분: Mysql의 계정은 host-user 두개를 합쳐서 키로 사용하게 되어 있습니다. 같은 user라도 접속하는 host 값이 다르면 별도의 계정처럼 인식합니다.\n그런데 위에서 사용한 **set password = password(‘패스워드’)**는 localhost@root에 대해서만 패스워드를 설정-변경합니다.\n만약 외부에서 접속하기 위해 특정 IP를 추가했다거나 외부 접속을 모두 허용하기 위해 host에 %값을 설정했을 경우에는 패스워드가 설정-변경되지 않습니다. 이때 사용하는 방법은 아래와 같습니다.\nmysql\u003e update mysql.user set password = password('패스워드') where user = 'root';\rmysql\u003e select host, user, password from mysql.user;\r쿼리를 실행한 후에 조회를 해보면 user값이 root인 모든 계정의 password 값이 동일하게 설정된 것을 확인할 수 있습니다.\nMySQL 5.7 설정 link마찬가지로 mysql 5.7 DB서버를 생성한 후 root 계정의 패스워드 상태를 확인해봅니다. 그 이후에 패스워드를 설정합니다.\nMySQL 5.7은 패스워드 칼럼이 password가 아니고 authentication_string로 변경되었습니다.\n#mysql 접속\rmysql -u root\r#계정 정보 조회\rmysql\u003e select host, user, authentication_string from mysql.user;\r#패스워드 설정-변경\rmysql\u003e ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '패스워드';\r#변경된 패스워드 조회\rmysql\u003e select host, user, authentication_string from mysql.user;\r초기 패스워드가 설정되어있지 않기 때문에 -p 옵션을 사용하지 않고 바로 접속 해서 user 테이블에 있는 계정 정보를 확인해보면 password 값이 비어 있는 것을 확인할 수 있습니다.\n이때 MySQL 5.6 이하 버전처럼 update 명령어로 authentication_string 칼럼 값을 변경하려고 해도 적용되지 않습니다.\n위에 적은 것처럼 ALTER 명령으로 변경해야 적용되니 주의해야 합니다.\nMySQL 패스워드 정책 linkMySQL은 아래와 같이 기본 패스워드 정책이 설정되어 있습니다. 그러므로 패스워드 설정 시에는 아래 조건에 맞게 입력하셔야 합니다.\n최소 길이 8자 이상 특수문자 1개 이상 숫자 1개 이상 대소문자 조합 1개 이상 MySQL DB에 접속해서 아래와 같이 설정된 정책을 조회할 수 있습니다.\nmysql\u003e SHOW VARIABLES LIKE 'validate_password%';\r참고 URL link 설치형 MySQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-1-1\nMySQL 패스워드 정책 가이드\nhttps://dev.mysql.com/doc/refman/5.7/en/validate-password-options-variables.html\n문서 업데이트 내역 link\r날짜 내용 2021-08-05 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  157 ,
                href: "\/docs\/database\/mysql-mariadb\/install\/mysql-57-install-on-rocky-linux\/",
                title: "MySQL 5.7 설치하는 방법 | Rocky Linux",
                description: "Ncloud(네이버 클라우드) Rocky Linux 서버에 MySQL 5.7 설치하는 방법에 대한 가이드입니다",
                content: "개요 link록키 리눅스(Rocky Linux)는 기본 데이터베이스가 MariaDB인데, 상황에 따라 MySQL이 필요한 경우가 있습니다. 이번에는 그 중에서 MySQL 5.7 버전을 설치하는 방법을 정리해보겠습니다.\n서버 준비 link우선 Rocky Linux 서버를 준비합니다.\nRocky Linux 소개 link록키 리눅스에 대한 간략한 소개는 아래 문서에서 확인할 수 있습니다.\n⁃ Ncloud에서 제공하는 록키 리눅스(Rocky Linux) 서버 소개\r패키지 업데이트 link우선 패키지 업데이트를 해보겠습니다.\ndnf -y upgrade-minimal\rinfo\rdnf: Dandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 Fedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\nMySQL Community 패키지 설치 linkMySQL 5.7 버전이 포함된 가장 최근의 Repository 설치 패키지는 mysql80-community-release-el7-10.noarch.rpm 입니다.\ndnf -y install https://dev.mysql.com/get/mysql80-community-release-el7-10.noarch.rpm\rMySQL 5.7 버전 리포지토리 활성화 link버전 활성화 정보 초기화 link\rdnf module reset mysql\r기본 MySQL 버전 비활성화 link\rdnf module disable mysql\rMySQL 버전 확인 link설치된 리포지토리에서 MySQL 버전을 확인해보면 5.7과 8.0이 존재하는 것을 확인할 수 있습니다.\ndnf repolist all | grep mysql\rMySQL 5.7 버전 활성화 link설치된 MySQL Community 패키지에서 MySQL 8.0 버전은 비활성화 하고, 5.7 버전을 활성화 합니다.\ndnf config-manager --disable mysql80-community\rdnf config-manager --enable mysql57-community\rMySQL 5.7 설치 linkMySQL 5.7 서버를 설치합니다.\ndnf -y install mysql-community-server\rMySQL 초기화 link아래 명령어로 기본 데이터베이스 생성 등의 초기화 작업을 진행합니다. 다만 여기서는 초기화 할 때 –initialize-insecure 옵션으로 비밀번호는 설정하지 않고 아래쪽 MySQL 보안 설정 단계에서 [mysql_secure_installation] 명령으로 설정하도록 하겠습니다.\nmysqld --initialize-insecure --user=mysql\rMySQL 데몬 시작 link초기화를 마쳤으면 MySQL 데몬을 시작합니다.\nsystemctl start mysqld\rMySQL 보안 설정 link[mysql_secure_installation]은 MySQL의 기본 보안을 설정하는 명령으로, 설정되는 항목은 다음과 같습니다.\nroot 계정 패스워드 설정 원격 호스트에서 root 계정 접속 차단 익명 계정 삭제 테스트 DB 등 삭제 mysql_secure_installation\r비밀번호를 설정할 때 비밀번호 유효성 검사 플러그인을 사용할 것인지 선택할 수 있는데 [Y]를 입력합니다. 비밀번호 정책 수준 선택 link제공되는 비밀번호 정책 수준은 [LOW], [MEDIUM], [STRONG]의 3가지가 있습니다.\nLOW: 8자 이상 MEDIUM: 8자 이상, 숫자-대소문자-특수문자 포함 STRONG: 8자 이상, 숫자-대소문자-특수문자 포함, dictionary file에 포함된 단어 사용 불가 여기서는 1을 입력해서 MEDIUM을 선택하겠습니다.\n패스워드를 입력하면 패스워드의 복잡성 강도를 점수로 측정해주는데 이번 테스트에서는 100점을 받았습니다.\n그리고, 방금 입력했던 패스워드를 그대로 사용할 것인지 확인하는데 [Y]를 입력합니다.\n(혹시 입력했던 비밀번호를 변경하고 싶을 경우는 [N]를 입력합니다.) 익명 계정 삭제 link다음으로 Anonymous Users 즉, 익명 계정들을 삭제할 것인지 묻는데 [Y]를 입력합니다.\n원격 호스트에서 root 계정 접속 차단 link다음은 로컬이 아닌 원격에서 root 계정 로그인을 차단할 것인지 묻는데 [Y]를 입력합니다.\n테스트 DB 등 삭제 link테스트 DB 등을 삭제할 것인지 묻는데 여기서도 [Y]를 입력합니다.\n설정 저장 link마지막으로 지금까지 선택한 설정을 모두 적용할 것인지 묻는데 [Y]를 입력합니다.\nMySQL 접속 link위에서 설정했던 비번으로 접속해보면 [5.7.43 MySQL Community Server]인 것을 확인할 수 있습니다.\nmysql -u root -p\r참고 URL link MySQL Yum Repository 다운로드 페이지\nhttps://dev.mysql.com/downloads/repo/yum/\nInstalling MySQL on Linux Using the MySQL Yum Repository\nhttps://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html\nRocky Linux 서버에 MySQL 8.0 최신 버전 설치하는 방법\n"
            }
        );
    index.add(
            {
                id:  158 ,
                href: "\/docs\/database\/mysql-mariadb\/install\/mysql-8-latest-version-install-on-rocky-linux\/",
                title: "MySQL 8.0 최신 버전 설치하는 방법 | Rocky Linux",
                description: "Ncloud(네이버 클라우드) Rocky Linux 서버에 MySQL 8.0 최신 버전 설치하는 방법에 대한 가이드입니다",
                content: "개요 link록키 리눅스(Rocky Linux)는 기본 데이터베이스가 MariaDB인데, 상황에 따라 MySQL이 필요한 경우가 있습니다. 이번에는 그 중에서 MySQL 8.0 최신 버전을 설치하는 방법을 정리해보겠습니다.\n서버 준비 link우선 Rocky Linux 서버를 준비합니다.\nRocky Linux 소개 link록키 리눅스에 대한 간략한 소개는 아래 문서에서 확인할 수 있습니다.\n⁃ Ncloud에서 제공하는 록키 리눅스(Rocky Linux) 서버 소개\r패키지 업데이트 link우선 패키지 업데이트를 해보겠습니다.\ndnf -y upgrade-minimal\rinfo\rdnf: Dandified YUM의 약자인 dnf는 기존의 yum 패키지 관리자가 갖고 있던 여러 단점들을 수정, 업그레이드해서 Fedora 18 이후 버전에서 사용되고 있으며, Rocky Linux도 마찬가지로 dnf를 기본 패키지 관리자로 사용하고 있습니다. 물론 호환성을 위해서 yum 명령어도 사용할 수 있습니다.\nMySQL Community 최신 패키지 확인 linkMySQL Community Yum(Dnf) 최신 패키지는 아래 주소에서 확인할 수 있습니다.\nRocky Linux는 CentOS 8 기반으로 만들어졌으므로 아래 다운로드 페이지에서 Red Hat Enterprise Linux 8 기반의 mysql80-community-release-el8-{버전}.noarch.rpm 리파지토리 버전을 확인합니다.\n2023-09-04 기준으로는 [mysql80-community-release-el8-8.noarch.rpm] 인것을 확인할 수 있습니다.\n⁃ https://dev.mysql.com/downloads/repo/yum/\rMySQL Community 패키지 설치 link위에서 확인한 MySQL 8.0의 최신 Repository 설치 패키지는 [mysql80-community-release-el8-8.noarch.rpm] 입니다.\ndnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-8.noarch.rpm\rMySQL 8.0 버전 리포지토리 활성화 link버전 활성화 정보 초기화 link\rdnf module reset mysql\r기본 MySQL 버전 비활성화 link\rdnf module disable mysql\rMySQL 8.0 버전 확인 link설치된 MySQL Community 패키지에 포함된 MySQL 버전을 확인해보겠습니다.\nmysql80-community-release-el8-{버전}.noarch.rpm 버전부터는 8.0 버전만 있고, 5.7 버전은 포함되어 있지 않습니다.\ndnf repolist all | grep mysql\rMySQL 8.0 설치 linkMySQL 8.0 서버를 설치합니다.\ndnf -y install mysql-community-server\rMySQL 초기화 link아래 명령어로 기본 데이터베이스 생성 등의 초기화 작업을 진행합니다. 다만 여기서는 초기화 할 때 –initialize-insecure 옵션으로 비밀번호는 설정하지 않고 아래쪽 MySQL 보안 설정 단계에서 [mysql_secure_installation] 명령으로 설정하도록 하겠습니다.\nmysqld --initialize-insecure --user=mysql\rMySQL 데몬 시작 link초기화를 마쳤으면 MySQL 데몬을 시작합니다.\nsystemctl start mysqld\rMySQL 보안 설정 link[mysql_secure_installation]은 MySQL의 기본 보안을 설정하는 명령으로, 설정되는 항목은 다음과 같습니다.\nroot 계정 패스워드 설정 원격 호스트에서 root 계정 접속 차단 익명 계정 삭제 테스트 DB 등 삭제 mysql_secure_installation\r비밀번호를 설정할 때 비밀번호 유효성 검사 플러그인을 사용할 것인지 선택할 수 있는데 [Y]를 입력합니다. 비밀번호 정책 수준 선택 link제공되는 비밀번호 정책 수준은 [LOW], [MEDIUM], [STRONG]의 3가지가 있습니다.\nLOW: 8자 이상 MEDIUM: 8자 이상, 숫자-대소문자-특수문자 포함 STRONG: 8자 이상, 숫자-대소문자-특수문자 포함, dictionary file에 포함된 단어 사용 불가 여기서는 1을 입력해서 MEDIUM을 선택하겠습니다.\n패스워드를 입력하면 패스워드의 복잡성 강도를 점수로 측정해주는데 이번 테스트에서는 100점을 받았습니다.\n그리고, 방금 입력했던 패스워드를 그대로 사용할 것인지 확인하는데 [Y]를 입력합니다.\n(혹시 입력했던 비밀번호를 변경하고 싶을 경우는 [N]를 입력합니다.) 익명 계정 삭제 link다음으로 Anonymous Users 즉, 익명 계정들을 삭제할 것인지 묻는데 [Y]를 입력합니다.\n원격 호스트에서 root 계정 접속 차단 link다음은 로컬이 아닌 원격에서 root 계정 로그인을 차단할 것인지 묻는데 [Y]를 입력합니다.\n테스트 DB 등 삭제 link테스트 DB 등을 삭제할 것인지 묻는데 여기서도 [Y]를 입력합니다.\n설정 저장 link마지막으로 지금까지 선택한 설정을 모두 적용할 것인지 묻는데 [Y]를 입력합니다.\nMySQL 접속 link위에서 설정했던 비번으로 접속해보면 [8.0.34 MySQL Community Server]인 것을 확인할 수 있습니다.\nmysql -u root -p\r참고 URL link MySQL Yum Repository 다운로드 페이지\nhttps://dev.mysql.com/downloads/repo/yum/\nInstalling MySQL on Linux Using the MySQL Yum Repository\nhttps://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html\nRocky Linux 서버에 MySQL 5.7 설치하는 방법\n"
            }
        );
    index.add(
            {
                id:  159 ,
                href: "\/docs\/database\/mysql-mariadb\/install\/mysql-datadir-change-install-guide\/",
                title: "MySQL 데이터 저장 디렉토리(datadir) 위치를 변경해서 설치하는 방법",
                description: "Ncloud(네이버 클라우드) 서버에 MySQL 데이터 저장 디렉토리(datadir) 위치를 변경해서 설치하는 방법에 대한 가이드입니다",
                content: "개요 linkNcloud(네이버 클라우드) 서버에 MySQL을 설치할 때 MySQL 데이터 저장 디렉토리(datadir) 위치를 변경해서 설치하는 방법을 정리해보겠습니다.\n테스트 환경 link 서버: Rocky Linux 8.8 DB: MySQL 8.0 MySQL 설치 link아래와 같은 순서대로 MySQL 8.0 최신 버전을 설치합니다.\ndnf -y upgrade-minimal\rdnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-9.noarch.rpm\rdnf module reset mysql\rdnf module disable mysql\rdnf -y install mysql-community-server\r데이터 저장 디렉토리 생성 linkDB 데이터를 저장할 임의의 디렉토리를 생성합니다. /database/mysql 과 같이 생성하고 실제 저장되는 디렉토리는 mysql로 하겠습니다.\nmkdir -p /database/mysql\r디렉토리 소유권 변경 link실제 저장되는 디렉토리인 [mysql]에 대한 소유권을 변경해야 하는데, 변경하기 전에 현재 상태를 확인해보면 아래와 같이 root:root로 되어 있는 것을 알 수 있습니다.\n아래 명령으로 mysql 디렉토리에 대한 소유권을 mysql:mysql로 변경합니다.\nchown -R mysql:mysql /database/mysql/\r환경 설정 변경 link환경 설정 파일 my.cnf 파일을 열어서 [mysqld] 항목에 있는 [datadir], [socket] 두가지의 설정을 위에서 생성한 [/database/mysql/] 디렉토리로 변경합니다. 그리고 아래쪽에 로컬에서 접속하기 위한 [client] 항목에 대한 [socket] 설정도 추가합니다.\nvim /etc/my.cnf\r# mysqld용 설정 변경 (위에서 생성한 디렉토리)\r[mysqld]\rdatadir=/database/mysql\rsocket=/database/mysql/mysql.sock\r# 선택사항: CharacterSet, Collation 설정 추가\rcharacter-set-server = utf8mb4\rcollation-server = utf8mb4_unicode_ci\rinit-connect='SET NAMES utf8mb4'\rskip-character-set-client-handshake\r# 로컬에서 접속하기 위한 client 용 설정 추가\r[client]\rsocket=/database/mysql/mysql.sock\r# 선택사항: CharacterSet 설정 추가\rdefault-character-set=utf8mb4\rMySQL 초기화 link아래 명령어로 기본 데이터베이스 생성 등의 초기화 작업을 진행합니다. 이때 위에서 생성한 [/database/mysql/] 디렉토리에서 초기화가 진행됩니다.\n초기화 한 후에 디렉토리를 살펴보면 아래와 같이 기본 데이터 베이스 등이 정상적으로 생성된 것을 확인할 수 있습니다.\nmysqld --initialize-insecure --user=mysql\rls -al /database/mysql\rMySQL 데몬 시작 link초기화를 마쳤으면 MySQL 데몬을 시작합니다.\nsystemctl start mysqld\rMySQL 보안 설정 link[mysql_secure_installation]은 MySQL의 기본 보안을 설정하는 명령으로, 설정되는 항목은 다음과 같습니다.\nroot 계정 패스워드 설정 원격 호스트에서 root 계정 접속 차단 익명 계정 삭제 테스트 DB 등 삭제 mysql_secure_installation\rMySQL 접속 link위에서 설정했던 비번으로 접속해보면 [8.0.35 MySQL Community Server]인 것을 확인할 수 있습니다.\n[show databases] 명령으로 데이터베이스를 확인해보면 기본 데이터베이스 등 각종 시스템 데이터베이스가 모두 정상적으로 나타나는 것을 알 수 있습니다.\nmysql -u root -p\rmysql\u003e show databases;\r테스트 DB 생성 link데이터베이스 생성도 문제 없이 잘되는지 확인해보기 위해 [testdb]를 생성하고, 확인해보겠습니다.\nmysql\u003e CREATE DATABASE testdb;\rmysql\u003e show databases;\r디렉토리 확인 link변경해서 설치한 디렉토리에도 [testdb]가 제대로 생성되었는지 확인해보니 아래 화면처럼 정상적으로 생성된 것을 알 수 있습니다.\nls -al /database/mysql\r참고 URL link MySQL Yum Repository 다운로드 페이지\nhttps://dev.mysql.com/downloads/repo/yum/\nInstalling MySQL on Linux Using the MySQL Yum Repository\nhttps://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html\nRocky Linux 서버에 MySQL 8.0 최신 버전 설치하는 방법\n"
            }
        );
    index.add(
            {
                id:  160 ,
                href: "\/docs\/database\/mysql-mariadb\/configure\/config-file-my-cnf-position\/",
                title: "Mysql, MariaDB 환경설정 파일 my.cnf 위치",
                description: "Ncloud(네이버 클라우드) Mysql, MariaDB 환경설정 파일 my.cnf 위치 안내입니다",
                content: "개요 linkNcloud (네이버 클라우드)에서 Mysql MariaDB 환경설정 파일인 my.cnf 파일이 CentOS, Ubuntu, Rocky Linux OS 별로 어떤 경로에 위치하고 있는지 정리해보겠습니다.\nRocky Linux link우선, 록키 리눅스부터 살펴보겠습니다.\nMySQL linkRocky Linux에서 MySQL은 my.cnf 파일이 /etc/ 바로 밑에 위치합니다.\n/etc/my.cnf\rMariaDB linkRocky Linux에서는 mariadb-server.cnf 파일입니다.\n/etc/my.cnf.d/mariadb-server.cnf\rMariaDB에서도 my.cnf 파일이 /etc/ 바로 밑에 위치하기는 하지만, 실제로 /etc/my.cnf 파일을 열어보면 다음과 같이 my.cnf.d 디렉토리에 있는 파일을 include만 하게 되어 있습니다.\n즉, my.cnf 파일에 설정을 추가해도 되지만 가능하면 하위의 각각의 설정 파일에 추가하는 것이 좋습니다.\n/etc/my.cnf.d/mariadb-server.cnf 파일을 열어 보면 다음과 같이 구성 되어 있습니다. Ubuntu linkUbuntu에서는 my.cnf 파일이 /etc/mysql 밑에 위치합니다.\n/etc/mysql/my.cnf\rMySQL linkUbuntu 20.04, MySQL 8.0에서는 아래의 3가지 파일을 주로 확인하면 되겠습니다.\n/etc/mysql/my.cnf\r/etc/mysql/mysql.conf.d/mysql.cnf\r/etc/mysql/mysql.conf.d/mysqld.cnf\r먼저 /etc/mysql/my.cnf 파일을 열어 보면 다음과 같이 conf.d 디렉토리와 mysql.conf.d 디렉토리에 있는 파일을 include 하도록 되어 있습니다.\n/etc/mysql/ 디렉토리의 파일과 서브 디렉토리 구조를 살펴보면 다음과 같습니다. 여기서 mysql.conf.d 디렉토리에 있는 mysql.cnf 파일과 mysqld.cnf 파일을 살펴보겠습니다.\n/etc/mysql/mysql.conf.d/mysql.cnf\n이 파일을 열어 보면 다음과 같이 [The MySQL database client configuration file]이라고 되어 있습니다.\n즉, MySQL Client 관련 설정은 이곳에 지정하면 되겠습니다. /etc/mysql/mysql.conf.d/mysqld.cnf\n이 파일을 열어 보면 다음과 같이 [The MySQL database server configuration file]이라고 되어 있습니다.\n즉, MySQL Server 관련 설정은 이곳에 지정하면 되겠습니다. MariaDB linkUbuntu 20.04, MariaDB 10.3에서는 아래의 4가지 파일을 주로 확인하면 되겠습니다.\n/etc/mysql/my.cnf\r/etc/mysql/mariadb.cnf\r/etc/mysql/mariadb.conf.d/50-client.cnf\r/etc/mysql/mariadb.conf.d/50-server.cnf\r그런데, /etc/mysql/my.cnf 파일의 정보를 확인해보면 결국 /etc/mysql/mariadb.cnf 파일의 심볼릭 링크라는 것을 알 수 있습니다. 그러므로 /etc/mysql/mariadb.cnf 파일을 살펴보겠습니다.\n/etc/mysql/mariadb.cnf 파일을 열어 보면 다음과 같이 conf.d 디렉토리와 mariadb.conf.d 디렉토리에 있는 파일을 include 하도록 되어 있습니다.\n/etc/mysql/ 디렉토리의 파일과 서브 디렉토리 구조를 살펴보면 다음과 같습니다.\n여기서 mariadb.conf.d 디렉토리에 있는 50-client.cnf 파일과 50-server.cnf 파일을 살펴보겠습니다.\n/etc/mysql/mariadb.conf.d/50-client.cnf\n이 파일을 열어 보면 다음과 같이 [This group is read by the client library]이라고 되어 있습니다.\n즉, MariaDB Client 관련 설정은 이곳에 지정하면 되겠습니다. /etc/mysql/mariadb.conf.d/50-server.cnf\n이 파일을 열어 보면 다음과 같이 [These groups are read by MariaDB server]이라고 되어 있습니다.\n즉, MariaDB Server 관련 설정은 이곳에 지정하면 되겠습니다. CentOS link마지막으로 CentOS를 살펴보겠습니다.\nMySQL linkMySQL은 my.cnf 파일이 /etc/ 바로 밑에 위치합니다.\n/etc/my.cnf\rMariaDB linkMariaDB에서도 my.cnf 파일이 /etc/ 바로 밑에 위치하기는 하지만, 실제로 /etc/my.cnf 파일을 열어보면 다음과 같이 my.cnf.d 디렉토리에 있는 파일을 include만 하게 되어 있습니다.\n즉, my.cnf 파일에 설정을 추가해도 되지만 가능하면 하위의 각각의 설정 파일에 추가하는 것이 좋습니다.\n/etc/my.cnf.d/server.cnf\r/etc/my.cnf.d/server.cnf 파일을 열어 보면 다음과 같이 구성 되어 있습니다. 참고 URL link Ncloud MySQL 서버 이미지 사용 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-1-1\nNcloud MariaDB 서버 이미지 사용 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-7-1\n문서 업데이트 내역 link\r날짜 내용 2021-02-23 문서 최초 생성 2023-04-28 Rocky Linux 내용 추가 "
            }
        );
    index.add(
            {
                id:  161 ,
                href: "\/docs\/database\/mysql-mariadb\/configure\/config-bind-address-position\/",
                title: "Mysql, mariadb 외부접속을 위한 환경설정 bind-address 위치",
                description: "Ncloud(네이버 클라우드) Mysql, mariadb 외부접속을 위한 환경설정 bind-address 위치 안내입니다",
                content: "개요 link네이버 클라우드 DB중에서 mysql과 mariadb를 외부에서 접속하기 위해서는 여러 설정이 필요한데 그 중에서 bind-address 설정 항목이 어느 파일에 위치하고 있는지 정리해보겠습니다.\nOS중에서 CentOS는 기본 설정이 허용이지만, Ubuntu는 기본 설정이 localhost 만 접속 가능하도록 되어 있기 때문에 외부 접속을 허용해주기 위해서는 bind-address 설정을 수정해야 합니다. 그래서 여기서는 Ubuntu에 대해서만 살펴보겠습니다.\nmysql 5.6 linkmysql 5.6에서는 bind-address 설정이 /etc/mysql/my.cnf 파일에 있습니다.\nOS는 Ubuntu 14.04만 제공됩니다.\nmysql 5.7 linkmysql 5.7에서는 bind-address 설정이 /etc/mysql/mysql.conf.d/mysqld.cnf 파일에 있습니다.\nOS는 Ubuntu 14.04와 16.04 두 버전이 있는데 모두 동일합니다.\nmariaDB linkmariaDB는 10.2 버전만 있으며 bind-address 설정이 /etc/mysql/my.cnf 파일에 있습니다.\nOS는 Ubuntu 16.04만 제공됩니다.\n기타 - mariaDB CentOS link그 외에 mysql의 경우 CentOS는 개요에서 말씀드렸듯이 기본적으로 외부 접속을 차단하는 bind-address 항목이 존재하지 않는데 mariaDB의 경우 외부 접속을 차단하지는 않지만, bind-address 항목이 주석처리된 상태로 포함되어 있습니다.\n혹시나 차단하고 싶을 경우 사용하기 쉽게 미리 준비해둔 것으로 보입니다. 주석처리된 bind-address의 위치는 /etc/my.cnf.d/server.cnf 입니다.\n참고 URL link Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\nhttps://docs.3rdeyesys.com/database/ncloud_database_mariadb_access_from_remote_ubuntu/\nUbuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\nhttps://docs.3rdeyesys.com/database/ncloud_database_mariadb_access_from_remote_centos/\n문서 업데이트 내역 link\r날짜 내용 2021-02-24 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  162 ,
                href: "\/docs\/database\/mysql-mariadb\/configure\/config-mariadb-access-from-remote-ubuntu\/",
                title: "mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL | Ubuntu",
                description: "Ncloud(네이버 클라우드) Ubuntu 서버에서 mariaDB 외부접속 허용하는 방법과 HeidiSQL으로 원격접속하는 방법입니다",
                content: "개요 link네이버 클라우드 Ubuntu에서 mariaDB 외부접속을 허용하고, mariaDB용 클라이언트 HeidiSQL을 이용해서 원격접속하는 방법을 정리해보겠습니다.\n여기서 원격접속이라 함은 SSH의 Tunnels를 이용하지 않고, 외부 클라이언트 등을 이용한 직접 접속을 뜻합니다.\n계정 비밀번호 생성 link여기서는 네이버 클라우드에서 서버를 생성했을 때 자동으로 설정되는 root 계정을 이용한 방법을 정리하게 됩니다.\n네이버 클라우드에서는 처음 mariaDB를 설치하면 root 계정에 비밀번호가 설정되어 있지 않습니다.\n# mariadb 실행\rmysql\r# 비밀번호 설정\rMariaDB [(None)]\u003e set password=password('비밀번호');\r계정 권한 부여 link외부에서 해당 계정(여기서는 root)으로 접속할 수 있도록 계정에 권한을 부여하는 쿼리입니다.\nMariaDB [(None)]\u003e GRANT ALL PRIVILEGES ON *.* to 'root'@'%' IDENTIFIED BY '비밀번호';\r환경설정 파일 수정 linkmariaDB의 환경설정 파일 위치는 /etc/mysql/my.cnf 입니다.\nCentOS와 달리 Ubuntu에서 mariaDB는 기본적으로 외부 IP에 대한 접속이 차단되어 있고, 127.0.0.1 즉, localhost만 접속이 허용되어 있는 상태입니다.\nvi /etc/mysql/my.cnf\r아래는 환경 설정 파일의 일부입니다.\n# MariaDB database server configuration file.\r#\r# 중략 #\r[mysqld]\r#\r# * Basic Settings\r#\rport = 3306\rbasedir = /usr\rdatadir = /var/lib/mysql\rtmpdir = /tmp\r#\r# Instead of skip-networking the default is now to listen only on\r# localhost which is more compatible and is not less secure.\rbind-address = 127.0.0.1\r#\r위 환경설정 파일중에서 bind-address 항목을 주석처리하면 외부에서 접속이 가능합니다.\n# bind-address = 127.0.0.1\r# 다른 방법\rbind-address = 0.0.0.0\r# 특정 IP만 허용\rbind-address = 허용할 IP 리스트\rbind-address = 192.168.1.1,10.0.0.1\rDB 재시작 link\rsystemctl restart mysql.service\rACG 포트 추가 link네이버 클라우드 ACG에 mariaDB가 사용하는 포트 3306을 추가해줍니다.\nHeidiSQL 다운로드 linkmariaDB용 클라이언트 중에서 대표적인 HeidiSQL을 사용합니다.\n다운로드 경로 : https://www.heidisql.com/download.php\nHeidiSQL 설정 linkHeidiSQL를 실행하면 DB접속을 위한 세션관리자가 먼저 나타납니다.\n왼쪽 하단의 [신규] 버튼을 누르고 서버 IP, 사용자, 암호를 입력하고 열기 버튼을 누르면 DB에 접속할 수 있습니다.\nDB 접속 linkmariaDB 접속에 성공하면 아래와 같은 화면을 볼 수 있습니다.\n참고 URL link CentOS에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n"
            }
        );
    index.add(
            {
                id:  163 ,
                href: "\/docs\/database\/mysql-mariadb\/configure\/config-mariadb-access-from-remote-centos\/",
                title: "mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL | CentOS",
                description: "Ncloud(네이버 클라우드) CentOS 서버에서 mariaDB 외부접속 허용하는 방법과 HeidiSQL으로 원격접속하는 방법입니다",
                content: "개요 link네이버 클라우드 CentOS에서 mariaDB 외부접속을 허용하고, mariaDB용 클라이언트 HeidiSQL을 이용해서 원격접속하는 방법을 정리해보겠습니다.\n여기서 원격접속이라 함은 SSH의 Tunnels를 이용하지 않고, 외부 클라이언트 등을 이용한 직접 접속을 뜻합니다.\nCentOS는 Ubuntu와 달리 mariaDB 환경설정 파일 my.cnf에서 외부 IP에서 접근이 막혀 있지 않기에 환경설정 파일은 수정하지 않습니다.\n계정 비밀번호 생성 link여기서는 네이버 클라우드에서 서버를 생성했을 때 자동으로 설정되는 root 계정을 이용한 방법을 정리하게 됩니다.\n네이버 클라우드에서는 처음 mariaDB를 설치하면 root 계정에 비밀번호가 설정되어 있지 않습니다.\n# mariadb 실행\r~# mysql\r# 비밀번호 설정\rMariaDB [(None)]\u003e set password=password('비밀번호');\r계정 권한 부여 link외부에서 해당 계정(여기서는 root)으로 접속할 수 있도록 계정에 권한을 부여하는 쿼리입니다.\nMariaDB [(None)]\u003e GRANT ALL PRIVILEGES ON *.* to 'root'@'%' IDENTIFIED BY '비밀번호';\rACG 포트 추가 link네이버 클라우드 ACG에 mariaDB가 사용하는 포트 3306을 추가해줍니다.\nHeidiSQL 다운로드 linkmariaDB용 클라이언트 중에서 대표적인 HeidiSQL을 사용합니다.\n다운로드 경로 : https://www.heidisql.com/download.php\nHeidiSQL 설정 linkHeidiSQL를 실행하면 DB접속을 위한 세션관리자가 먼저 나타납니다.\n왼쪽 하단의 [신규] 버튼을 누르고 서버 IP, 사용자, 암호를 입력하고 열기 버튼을 누르면 DB에 접속할 수 있습니다.\nDB 접속 linkmariaDB 접속에 성공하면 아래와 같은 화면을 볼 수 있습니다.\n참고 URL link Ubuntu에서 mariaDB 외부접속 허용, 원격접속하기 with HeidiSQL\n"
            }
        );
    index.add(
            {
                id:  164 ,
                href: "\/docs\/database\/mysql-mariadb\/backup\/mysql-auto-backup\/",
                title: "MySQL DB 자동백업 방법",
                description: "MySQL DB를 지정된 시간에 자동으로 백업하는 방법입니다",
                content: "개요 link매일 일정한 시간에 MySQL DB를 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n백업 폴더 생성 link루트에 /data_backup 폴더를 만들고 그 아래에 db 폴더를 생성합니다.\nmkdir /data_backup\rmkdir /data_backup/db\rMySQL DB 백업 스크립트 작성 link\rvi /bin/db_backup.sh\r#!/bin/bash\rDATE=$(date +%Y%m%d%H%M%S)\rBACKUP_DIR=/data_backup/db/\r# 전체 DB를 백업할 경우\rmysqldump -u root -p디비패스워드 --all-databases \u003e $BACKUP_DIR\"backup_\"$DATE.sql\r# 특정 DB를 백업할 경우\r# mysqldump -u root -p디비패스워드 --databases DB명 \u003e $BACKUP_DIR\"backup_\"$DATE.sql\rfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\r# DATE=$(date +%Y%m%d%H%M%S)는 백업할 파일명을 # 202001224505 와 같은 형식으로 저장할 수 있게 날짜를 변수로 담습니다. # find $BACKUP_DIR -ctime +7 -exec rm -f {} \\; # 여기서 -ctime +7은 7일이 지난 백업 파일을 찾아서 삭제하기 위한 코드입니다. # 추가로 분 단위로 설정하려고 할 때는 아래와 같이 # -cmin +10 처럼 작성하면 10분이 지난 파일을 찾아서 삭제하게 됩니다.\r# find $BACKUP_DIR -cmin +10 -exec rm -f {} \\;\r# 백업 스크립트에 실행 권한을 부여합니다.\rchmod 755 /bin/db_backup.sh\r스케쥴링을 위한 crontab 설정 link\rcrontab -e\r# 매일 새벽 6시에 백업이 진행됩니다.\r00 06 * * * /bin/db_backup.sh\r그 외 시간 설정 방법 link\r# 30분 마다 실행\r*/30 * * * * /bin/db_backup.sh\r# 매주 일요일 새벽 6시에 실행\r0 06 * * 0 /bin/db_backup.sh\r# 매월 1일 새벽 6시에 실행\r0 06 1 * * /bin/db_backup.sh\r# 매년 12월 31일 새벽 6시에 실행\r0 06 31 12 * /bin/db_backup.sh\r문서 업데이트 내역 link\r날짜 내용 2021-06-11 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  165 ,
                href: "\/docs\/database\/mysql-mariadb\/backup\/mysql-auto-backup-to-object-storage-ubuntu\/",
                title: "MySQL DB를 Object Storage로 자동 백업하기 | Ubuntu",
                description: "Ncloud(네이버 클라우드) Ubuntu에서 MySQL DB를 Object Storage로 자동 백업하는 방법입니다",
                content: "개요 link네이버 클라우드 Ubuntu에서 설치형 mysql DB를 매일 일정한 시간에 Object Storage로 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n순서는 로컬에 백업 파일 생성 후에 Object Storage로 저장하는 단계로 진행됩니다.\n백업 폴더 생성 link\rmkdir /data_backup\rmkdir /data_backup/db\rmysql DB 로컬 백업 스크립트 작성 link우선은 mysql DB를 로컬에 백업 받는 스크립트를 작성합니다.\nvi /bin/db_backup.sh\r#!/bin/bash\rDATE=$(date +%Y%m%d%H%M%S)\rBACKUP_DIR=/data_backup/db/\r# 전체 DB를 백업할 경우\rmysqldump -u root -p디비패스워드 --all-databases \u003e $BACKUP_DIR\"backup_\"$DATE.sql\r# 특정 DB를 백업할 경우\r# mysqldump -u root -p디비패스워드 --databases DB명 \u003e $BACKUP_DIR\"backup_\"$DATE.sql\rfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\r# 백업 파일을 202001224505 와 같은 형식으로 저장하고, 생성된지 7일이 지난 백업 파일을 삭제하는 코드입니다.\r# 백업 스크립트에 실행 권한을 부여합니다.\rchmod 755 /bin/db_backup.sh\rpip 설치 linkaws cli를 설치하려면 pip가 먼저 설치되어 있어야 합니다.\n혹시 이미 pip가 설치되어 있다면 아래에 있는 AWS CLI설치로 바로 이동하시면 되겠습니다.\napt install python-pip\rCentOS 6.x 버전은 기술지원 종료로 인해 위 방법대로 설치가 되지 않습니다. 아래 문서의 방법대로 설치하면 됩니다.\n⁃ CentOS6에서 pip - Python 설치하기\rAWS CLI 설치 link네이버 클라우드의 설명에 따르면 aws cli 1.16이후 버전은 일부 기능을 사용할 수 없어서 1.15버전을 사용한다고 합니다.\npip install awscli==1.15.85\rAPI 인증키 생성 link네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\nAWS CLI 환경 설정 link이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목을 입력하지 않으셔도 됩니다.\naws configure\rAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\rAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\rDefault region name [None]: [Enter]\rDefault output format [None]: [Enter]\rObject Storage Bucket 생성 linkObject Storage에 data-back-up Bucket을 생성하고 그 아래에 db 폴더를 생성합니다.\nObject Storage 접속 테스트 link이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# s3 ls 명령으로 Object Storage에 존재하는 버킷 리스트를 조회합니다.\raws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\r2021-01-21 15:34:07 data-back-up\rmysql DB 백업 스크립트 수정 link이제 위 단계에서 만들었던 DB 로컬 백업 스크립트에 DB백업 파일을 Object Storage로 백업-동기화 하는 명령을 추가하겠습니다.\nvi /bin/db_backup.sh\r#!/bin/bash\rDATE=$(date +%Y%m%d%H%M%S)\rBACKUP_DIR=/data_backup/db/\r# 전체 DB를 백업할 경우\rmysqldump -u root -p디비패스워드 --all-databases \u003e $BACKUP_DIR\"backup_\"$DATE.sql\r# 특정 DB를 백업할 경우\r# mysqldump -u root -p디비패스워드 --databases DB명 \u003e $BACKUP_DIR\"backup_\"$DATE.sql\rfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\r# 여기서부터 추가되는 명령입니다.\r# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어입니다.\r# aws 명령어를 crontab에서 실행하기 위해 aws 파일의 전체 경로를 적어줍니다\r/usr/local/bin/aws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\r여기서 db 폴더만 백업-동기화를 하는 것이 아닌 상위 폴더인 /data_backup/ 폴더부터 백업-동기화를 한 이유는 이후에 db 말고도 개발소스 파일 등도 압축해서 백업하기 위해서입니다.\r스케쥴링을 위한 crontab 설정 link이제 마지막으로 완성된 스크립트를 일정한 시간, 여기서는 매일 새벽 6시에 실행되도록 설정합니다.\ncrontab -e\r# 매일 새벽 6시에 백업이 진행되는 코드입니다.\r00 06 * * * /bin/db_backup.sh \u003e /dev/null 2\u003e\u00261\rcrontab에 \u003e /dev/null 2\u003e\u00261를 추가하지 않으면 /var/log/syslog 파일에 (CRON) info (No MTA installed, discarding output) 라는 오류 메시지가 계속 쌓입니다.\npostfix를 설치하면 해결된다는 이야기도 있는데 굳이 필요하지 않은 것을 설치하기 보다는 필요하지 않은 오류 메시지는 없애는 것이 나을 듯합니다.\r백업 결과 확인 link백업이 진행되고 나면 아래와 같이 db 백업 파일이 Object Storage에 저장된 것을 확인할 수 있습니다.\n스샷에서는 빠른 확인을 위해 새벽 6시가 아닌 5분 단위로 백업한 내역입니다.\n참고 URL link mysql DB 자동백업 방법\n"
            }
        );
    index.add(
            {
                id:  166 ,
                href: "\/docs\/database\/mysql-mariadb\/backup\/mysql-auto-backup-to-object-storage-centos\/",
                title: "MySQL DB를 Object Storage로 자동 백업하기 | CentOS",
                description: "Ncloud(네이버 클라우드) CentOS에서 MySQL DB를 Object Storage로 자동 백업하는 방법입니다",
                content: "개요 link네이버 클라우드 CentOS에서 설치형 mysql DB를 매일 일정한 시간에 Object Storage로 자동으로 백업 받는 방법에 대해 정리해보았습니다.\n순서는 로컬에 백업 파일 생성 후에 Object Storage로 저장하는 단계로 진행됩니다.\n백업 폴더 생성 link\rmkdir /data_backup\rmkdir /data_backup/db\rmysql DB 로컬 백업 스크립트 작성 link우선은 mysql DB를 로컬에 백업 받는 스크립트를 작성합니다.\nvi /bin/db_backup.sh\r#!/bin/bash\rDATE=$(date +%Y%m%d%H%M%S)\rBACKUP_DIR=/data_backup/db/\r# 전체 DB를 백업할 경우\rmysqldump -u root -p디비패스워드 --all-databases \u003e $BACKUP_DIR\"backup_\"$DATE.sql\r# 특정 DB를 백업할 경우\r# mysqldump -u root -p디비패스워드 --databases DB명 \u003e $BACKUP_DIR\"backup_\"$DATE.sql\rfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\r# 백업 파일을 202001224505 와 같은 형식으로 저장하고, 생성된지 7일이 지난 백업 파일을 삭제하는 코드입니다.\r# 백업 스크립트에 실행 권한을 부여합니다.\rchmod 755 /bin/db_backup.sh\rpip 설치 linkaws cli를 설치하려면 pip가 먼저 설치되어 있어야 합니다.\n혹시 이미 pip가 설치되어 있다면 아래에 있는 AWS CLI설치로 바로 이동하시면 되겠습니다.\nyum -y install python-pip\rCentOS 6.x 버전은 기술지원 종료로 인해 위 방법대로 설치가 되지 않습니다. 아래 문서의 방법대로 설치하면 됩니다.\n⁃ CentOS6에서 pip - Python 설치하기\rAWS CLI 설치 link네이버 클라우드의 설명에 따르면 aws cli 1.16이후 버전은 일부 기능을 사용할 수 없어서 1.15버전을 사용한다고 합니다.\npip install awscli==1.15.85\rAPI 인증키 생성 link네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\nAWS CLI 환경 설정 link이제 AWS CLI로 접속하기 위해 환경설정을 해야 합니다.\n위 단계에서 확인한 Access Key ID와 Secret Key를 아래 화면에서 입력하고 나머지 2가지 항목을 입력하지 않으셔도 됩니다.\naws configure\rAWS Access Key ID [None]: 3frEtFjfkdsj89243nkfv89s\rAWS Secret Access Key [None]: 0kr23-0vsijr2390fw:L?K23-0vcdsjr2390fchnr123[]vl/fwsh\rDefault region name [None]: [Enter]\rDefault output format [None]: [Enter]\rObject Storage Bucket 생성 linkObject Storage에 data-back-up Bucket을 생성하고 그 아래에 db 폴더를 생성합니다.\nObject Storage 접속 테스트 link이제 Object Storage로 접속해보겠습니다. 얼핏 명령어만 보면 AWS에 접속하는 것처럼 보입니다. 그래서 네이버 클라우드로 접속하기 위한 –endpoint-url= 로 시작하는 옵션이 반드시 필요합니다.\n# s3 ls 명령으로 Object Storage에 존재하는 버킷 리스트를 조회합니다.\raws --endpoint-url=https://kr.object.ncloudstorage.com s3 ls\r2021-01-21 15:34:07 data-back-up\rmysql DB 백업 스크립트 수정 link이제 위 단계에서 만들었던 DB 로컬 백업 스크립트에 DB백업 파일을 Object Storage로 백업-동기화 하는 명령을 추가하겠습니다.\nvi /bin/db_backup.sh\r#!/bin/bash\rDATE=$(date +%Y%m%d%H%M%S)\rBACKUP_DIR=/data_backup/db/\r# 전체 DB를 백업할 경우\rmysqldump -u root -p디비패스워드 --all-databases \u003e $BACKUP_DIR\"backup_\"$DATE.sql\r# 특정 DB를 백업할 경우\r# mysqldump -u root -p디비패스워드 --databases DB명 \u003e $BACKUP_DIR\"backup_\"$DATE.sql\rfind $BACKUP_DIR -ctime +7 -exec rm -f {} \\;\r# 로컬에 백업된 데이터를 Object Storage에 백업-동기화하는 명령어입니다.\raws --endpoint-url=https://kr.object.ncloudstorage.com s3 sync /data_backup/ s3://data-back-up/\r여기서 db 폴더만 백업-동기화를 하는 것이 아닌 상위 폴더인 /data_backup/ 폴더부터 백업-동기화를 한 이유는 이후에 db 말고도 개발소스 파일 등도 압축해서 백업하기 위해서입니다.\r스케쥴링을 위한 crontab 설정 link이제 마지막으로 완성된 스크립트를 일정한 시간, 여기서는 매일 새벽 6시에 실행되도록 설정합니다.\ncrontab -e\r# 매일 새벽 6시에 백업이 진행되는 코드입니다.\r00 06 * * * /bin/db_backup.sh\r백업 결과 확인 link백업이 진행되고 나면 아래와 같이 db 백업 파일이 Object Storage에 저장된 것을 확인할 수 있습니다.\n스샷에서는 빠른 확인을 위해 새벽 6시가 아닌 5분 단위로 백업한 내역입니다.\n참고 URL link mysql DB 자동백업 방법\n"
            }
        );
    index.add(
            {
                id:  167 ,
                href: "\/docs\/database\/mysql-mariadb\/replication\/basic-guide\/",
                title: "MYSQL(MARIADB) Replication 생성하기",
                description: "Ncloud(네이버 클라우드)에서 MYSQL(MARIADB) Replication 생성하는 방법입니다",
                content: "선행조건 link master, slave 장비의 mysql설치가 사전에 완료된 조건 mysql 버전 5.7이상 조건에서 작성됨 mysql 리플리케이션작업을 진행시 masterdb의 데이터베이스는 쓰기작업이 없는 서비스 미진행 상태이어야함. MASTER 장비 구성 linkmy.cnf파일 내용 추가\n[mysqld]\rlog-bin=mysql-bin\rbinlog_format = mixed\r# 해당 ID값은 마스터장비만 1을 설정할수있음\rserver-id = 1 # 마스터 장비의 bin로그 특정일자(예시는10일) 이후 삭제\r# (해당 내역이없을 경우 지속적으로 기록되어 디스크 사용)\rexpire_logs_days = 10 mysql접속 후 리플리케이션을 진행할 계정 생성\nGRANT REPLICATION SLAVE ON *.* TO '리플리케이션계정명'@'%' IDENTIFIED BY '패스워드';\rFLUSH PRIVILEGES;\rSLAVE 장비 구성 linkmy.cnf파일 내용 추가\n[mysqld]\rserver-id=2 #해당ID값은 1을 제외한 숫자지정\rslave-skip-errors = all 데이터베이스 사전 동기화작업 linkmaster장비의 데이터베이스가 생성되어 있고 데이터가 있을 경우 link master장비 데이터베이스 백업 진행 # 데이터베이스가 추가로 있다면 남은 데이터베이스도 백업\rmysqldump -u root -p --databases 데이터베이스명 \u003e 백업파일.sql slave장비 데이터베이스 복구 진행 create database 데이터베이스명; #mysql 접속 후 생성\rmysql -u root -p 데이터베이스명 \u003c 백업파일.sql master 장비의 데이터베이스가 없을 경우 link 별도 작업 없으며, 데이터베이스만 생성되어 데이터가 없을경우도 slave장비에 동일한 데이터베이스 생성으로 마무리 리플리케이션 작업 link master 장비 mysql 접속 후 현재 로그파일번호와 포지션 넘버 확인\nshow master status;\rfile| Position #내역을 확인 후 별도 기입.\rslave 장비 mysql 접속 후 아래 명령어 실행 하여 리플리케이션 master정보 기입\nCHANGE MASTER TO MASTER_HOST='마스터IP',MASTER_USER='생성한리플리케이션계정명',MASTER_PASSWORD='패스워드',MASTER_LOG_FILE='위에서확인된 file이름',MASTER_LOG_POS=위에서 확인된 포지션번호;\rslave 리플리케이션 시작및 확인\nstart slave;\rshow slave status\\G; #실행 후 에러가 없다면 정상.\r문서 업데이트 내역 link\r날짜 내용 2021-04-13 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  168 ,
                href: "\/docs\/database\/mysql-mariadb\/replication\/mysql-gtid-replication\/",
                title: "MySQL GTID Replication 생성 상세 가이드",
                description: "Ncloud(네이버 클라우드)에서 MySQL GTID를 이용해 replication 생성하는 방법에 대한 상세 가이드입니다",
                content: "GTID 란? linkGTID는 Global Transaction Identifier의 약자로 MySQL 복제에서 서버의 각 트랜잭션을 구분하는 고유한 식별자입니다. GTID는 모든 트랜잭션과 1:1 관계이며, GTID를 활용하면 복제본으로 장애 조치, 계층적 복제, 특정 시점으로 백업 복구하는 등의 작업을 더 쉽게 구현할 수 있으며, 오류 발생 빈도도 줄일 수 있습니다.\nGTID 구성 linkGTID는 source_id:transaction_id의 형태로 저장됩니다.\n예시: 2070b9863-4c88-72ef-9fa053db4612:1-12 source_id link여기서 source_id는 서버의 uuid이며 다음의 방법으로 확인할 수 있습니다.\nmysql\u003e SELECT @@server_uuid;\r테스트 환경 link\r⁃ CentOS 7.8\n⁃ MySQL 5.7\n⁃ Master Server IP: 10.0.0.6\n⁃ Slave Server IP: 10.0.0.7\n⁃ VPC 대역: 10.0.0.0/16\n⁃ Subnet 대역: 10.0.0.0/24\n⁃ ACG: test3-vpc-default-acg\r파라미터 설정 linkMaster 서버와 Slave 서버에 각각 파라미터를 설정합니다.\n# Master, Slave vi /etc/my.cnf\rMaster 서버 link\r# Master [mysqld]\rserver-id=1\rlog-bin=binlog\rgtid-mode=ON\renforce-gtid-consistency=ON\rlog_slave_updates=ON\rSlave 서버 link\r# Slave\r[mysqld]\rserver-id=2\rlog-bin=binlog\rgtid-mode=ON\renforce-gtid-consistency=ON\rlog_slave_updates=ON\rgtid_mode 상태 확인 link위 설정 변경 후 mysql DB를 재시작하고 Master와 Slave모두 gtid_mode가 ON상태인지 확인합니다.\n# Master, Slave systemctl restart mysqld\r/* Master, Slave */\rmysql\u003e show variables like '%gtid_mode%';\rMaster 서버 link\rSlave 서버 link\rReplication 전용 유저 생성 linkMaster 서버에서 Replication 전용 유저를 생성합니다.\n/* Master */\rmysql\u003e create user '3rd'@'%' identified by 'Test123$';\rmysql\u003e grant replication slave,replication client on *.* to '3rd'@'%';\rmysql\u003e flush privileges;\rmysql\u003e SELECT user,host,authentication_string FROM mysql.user;\r테스트용 DB 생성 link테스트에 사용할 database를 생성합니다.\n/* Master */\rmysql\u003e CREATE DATABASE testdb default CHARACTER SET UTF8;\rmysql\u003e show databases;\r백업 파일 생성 linkMaster 서버에서 백업 파일을 생성합니다.\n백업 디렉터리 생성 link\r# Master\rmkdir /root/db_backup\rmysqldump 명령으로 백업 파일 생성 link\r# Master mysqldump -u root -p -v --databases testdb \\\r--quick --single-transaction --routines --set-gtid-purged=ON \\\r--triggers --extended-insert --master-data=2 \u003e /root/db_backup/testdb.sql\r백업 파일 복사 link백업 파일을 Slave 서버로 복사하기 위해 Master 와 Slave 서버 모두 rsync를 설치합니다.\n(백업 파일 복사는 rsync를 사용하지 않고 다른 방법을 사용해도 됩니다.)\nyum -y install rsync\rMaster 서버 link\rSlave 서버 link\rACG (방화벽) 설정 link이제 Master, Slave 두 서버간에 동기화, 복제가 가능하도록 ACG (방화벽)를 설정합니다.\n두 서버를 설치할 때 사용하도록 설정한 ACG는 test3-vpc-default-acg이기에 해당 ACG를 선택하고, ACG 규칙 설정에서 접근소스에는 Subnet의 IP 대역인 10.0.0.0/24, 허용포트는 22, 3306를 입력하고 추가합니다.\n접근소스: 10.0.0.0/24 허용포트 22: rsync 사용을 위한 포트 허용포트 3306: Replication을 위한 포트 {% include tip.html title=“접근 소스” content=“여기서는 테스트를 위해 접근소스에 Subnet IP 전체 대역을 지정했지만, 실제 서비스 환경에서는 해당 Subnet에 DB서버 외에 다른 서버들이 존재하는 경우도 있을 수 있으므로 각 DB서버 IP만 지정하는 것이 보안 측면에서는 더욱 안전할 수 있습니다.” %}\n백업 파일 전송 linkMaster -\u003e Slave로 DB 백업 파일을 전송합니다.\n전송 과정에서 정말 전송할 것인지 확인하는 단계와 Slave 서버의 root 패스워드를 확인하는 단계가 있습니다.\n# rsync -avzr --progress testdb.sql root@슬레이브서버IP:~/\rcd db_backup/\rrsync -avzr --progress testdb.sql root@10.0.0.7:~/\rSlave 서버에서 DB 복원 linkrsync로 전송 받은 DB 백업 파일을 실행해서 DB를 복원합니다.\n/* Slave */\rmysql\u003e source testdb.sql;\rReplication 설정 linkSlave 서버에서 Replication을 설정합니다.\n/* Slave mysql\u003e CHANGE MASTER TO MASTER_HOST='Master 서버 IP',\rMASTER_USER='Replication 계정',MASTER_PASSWORD='Replication 계정 비번', MASTER_AUTO_POSITION=1;\r*/\rmysql\u003e CHANGE MASTER TO MASTER_HOST='101.0.0.6',\rMASTER_USER='3rd',MASTER_PASSWORD='Test123$', MASTER_AUTO_POSITION=1;\rmysql\u003e start slave;\rReplication 대기 상태 확인 linkSlave 서버에서 Replication 상태가 어떤지 확인합니다.\n아래 명령어를 실행해보면 Master에서의 이벤트 전송을 대기 중이라는 메시지와 Master 서버의 정보를 확인할 수 있습니다.\n/* Slave */\rmysql\u003e show slave status \\G\rReplication 테스트 linkMaster 서버에서 테스트용 테이블을 생성하고, 데이터를 입력한 후 Slave 서버에도 복제가 되었는지 확인합니다.\nMaster 서버에 테스트용 데이터 입력 link\r/* Master */\rmysql\u003e use testdb;\rmysql\u003e create table 3rd (\rno int(10) auto_increment , name varchar(10), primary key(no));\rmysql\u003e insert into 3rd values(1,'3rd');\rmysql\u003e commit;\rmysql\u003e select * from 3rd;\rSlave 서버에서 복제 확인 link\r/* Slave */\rmysql\u003e use testdb;\rmysql\u003e select * from 3rd;\r추가 테스트 link추가로 데이터를 다시 입력해보면 정상적으로 복제가 되는 것을 확인할 수 있습니다.\nMaster 서버 link\rSlave 서버 link\r오류 상황 linkMaster 서버에서 데이터를 입력해도 Slave 서버에 제대로 복제되지 않는 등 Replication 기능에 문제가 생겼을 때에는 위쪽에서도 사용했었던 다음 명령어로 Replication 상태를 확인해봅니다.\n/* Slave */\rmysql\u003e show slave status \\G\r혹시 Slave_IO_State: Connecting to master 등의 Master 서버에 연결하지 못한다는 메시지가 보이는 경우 ACG (방화벽) 설정에 문제가 있는 것이니 위쪽에서 설정했던 **ACG (방화벽) 설정 **을 다시 한번 확인해보시기 바랍니다.\nreport\rSlave_IO_State: Connecting to master\nreport\rSlave_IO_Running: Connecting\n참고 URL link GTID를 이용한 Mysql 복제 가이드\nhttps://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html 문서 업데이트 내역 link\r날짜 내용 2022-04-08 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  169 ,
                href: "\/docs\/database\/mysql-mariadb\/replication\/mysql-multi-source-replication\/",
                title: "MySQL Multi Source Replication 구성 가이드",
                description: "Ncloud(네이버 클라우드)에서 MySQL Multi Source Replication 구성하는 방법에 대한 상세 가이드입니다",
                content: "개요 linkn대의 마스터 DB와 1대의 슬레이브 DB를 연결하여 마스터 DB들의 데이터를 슬레이브 DB 한곳에 모아 조회할 수 있는 MySQL Multi-Source-Replication(MSR)을 구성하는 방법을 정리해보겠습니다.\n테스트 준비 link 마스터 서버 2대, 슬레이브 서버 1대 준비 각 서버에 MySQL 5.7 이상 설치 MySQL 리플리케이션작업 진행 시 마스터 서버의 데이터베이스에 쓰기 작업 금지 ACG 설정 link서버 준비가 끝났으면 우선 마스터 서버 슬레이브 서버로 디비 백업 파일 복사과 복제 구성에 필요한 22, 3306 포트를 오픈해야 합니다.\n오픈 할 때 규칙은 마스터 서버와 슬레이브 서버의 공통 ACG에 사설 IP 대역 전체를 지정할 수도 있고, 슬레이브 서버 전용 ACG에 마스터 서버 IP만 등록하는 방법도 있습니다.\nSlave 장비에 백업 디렉토리 생성 link먼저 Slave 장비에 Master 장비들로 부터 DB 복원용 덤프 파일을 전송 받을 백업 디렉토리를 생성하는 것 부터 시작하겠습니다.\nmkdir /data\rcd /data\rMaster1 장비 구성 linkmaster1 설정 추가 link /etc/my.cnf에 Master1 설정을 추가합니다. vi /etc/my.cnf\rserver-id = 1\rlog-bin = mysql-bin\rbinlog_format = mixed\rcharacter-set-server = utf8\r#MySQL을 재시작해 변경사항 적용.\rsystemctl restart mysqld\r리플리케이션 계정 생성 linkMySQL 접속 후 리플리케이션을 진행할 계정 생성\n#master1 계정 생성.\rmysql\u003e create user '리플리케이션 계정명'@'%' identified by '패스워드';\rmysql\u003e grant replication slave,replication client on *.* to '리플리케이션 계정명'@'%';\rmysql\u003e flush privileges;\r테스트 DB 생성 link다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\nmysql\u003e CREATE DATABASE testdb1 default CHARACTER SET UTF8;\rMaster1 정보확인 link이제 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\nmysql\u003e show variables like 'server_id';\rmysql\u003e show master status;\r[show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다.\rDB 백업 파일 슬레이브 장비로 전송 linktestdb1 DB의 백업파일을 생성하고, 슬레이브 서버로 전송합니다.\nmkdir /data\rcd /data\rmysqldump -u root -p --databases testdb1 \u003e /data/test1.sql #슬레이브 서버에 전송.\rscp test1.sql root@10.0.0.8:/data\rMaster2 장비 구성 linkMaster2 설정 추가 link /etc/my.cnf에 Master2 설정을 추가합니다. vi /etc/my.cnf\rserver-id = 2\rlog-bin = mysql-bin\rbinlog_format = mixed\rcharacter-set-server = utf8\r#DB를 재시작하여 변경사항 적용.\rsystemctl restart mysqld\r리플리케이션 계정 생성 linkMySQL 접속 후 리플리케이션을 진행할 계정 생성합니다.\n#master2 계정 생성.\rmysql\u003e create user '리플리케이션 계정명'@'%' identified by '패스워드';\rmysql\u003e grant replication slave,replication client on *.* to '리플리케이션 계정명'@'%';\rmysql\u003e flush privileges;\r테스트 DB 생성 link다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\nmysql\u003e CREATE DATABASE testdb2 default CHARACTER SET UTF8;\rMaster2 정보확인 link마찬가지로 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\nmysql\u003e show variables like 'server_id';\rmysql\u003e show master status;\r[show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다.\rDB 백업 파일 슬레이브 장비로 전송 linktestdb2 DB의 백업파일 생성하고, 슬레이브 서버로 전송합니다.\nmkdir /data\rcd /data\rmysqldump -u root -p --databases testdb2 \u003e /data/test2.sql\rscp test2.sql root@10.0.0.8:/data\rSlave 장비 구성 linkSlave 설정 추가 link /etc/my.cnf에 Slave 설정을 추가합니다.\nMySQL 8.0 버전 부터는 replicate-do-db 설정에 채널 정보도 추가할 수 있게 업데이트 되었습니다. MySQL 5.7\rMySQL 8.0\rvi /etc/my.cnf\r### MySQL5.7 기준 ###\rserver-id = 3 #리플리케이션 대상 디비 설정.\rreplicate-do-db = testdb1\rreplicate-do-db = testdb2\r#리플리케이션 제외 디비 설정.\rreplicate-ignore-db = information_schema\rreplicate-ignore-db = mysql\rreplicate-ignore-db = performance_schema\rreplicate-ignore-db = sys\rmaster_info_repository = 'TABLE'\rrelay_log_info_repository = 'TABLE'\rslave-skip-errors = all\r#DB를 재시작하여 변경사항 적용.\rsystemctl restart mysqld\rvi /etc/my.cnf\r### MySQL 8 기준 ###\rserver-id = 3 # 리플리케이션 대상 디비 설정 (replicate-do-db = 채널명:DB명)\rreplicate-do-db = ch_testdb1:testdb1\rreplicate-do-db = ch_testdb1:testdb2\r#리플리케이션 제외 디비 설정.\rreplicate-ignore-db = information_schema\rreplicate-ignore-db = mysql\rreplicate-ignore-db = performance_schema\rreplicate-ignore-db = sys\rslave-skip-errors = all\r#DB를 재시작하여 변경사항 적용.\rsystemctl restart mysqld\rDB 복구 진행 link먼저 복구할 DB를 미리 생성하고 Master1, Master2 장비에서 전송 받은 백업 파일을 사용해 DB를 복구합니다.\n#복구할 DB 생성.\rmysql\u003e create database testdb1;\rmysql\u003e create database testdb2;\rmysql\u003e quit\r#DB 복구\rmysql -u root -p testdb1 \u003c /data/test1.sql\rmysql -u root -p testdb2 \u003c /data/test2.sql\r백업 파일을 전송 받은 디렉토리로 이동해 백업 파일이 정상적으로 전송되었는지 확인합니다. 리플리케이션 채널 설정 link리플리케이션 채널을 설정하는 쿼리문은 다음과 같습니다.\n채널 설정 구문은 MySQL 버전별로 다르고, 특히 8.0.23 버전부터는 완전히 달라지므로 버전에 맞게 사용하시면 됩니다.\nMySQL 5.7\rMySQL 8.0 ~ 8.0.22\rMySQL 8.0.23~\r# MySQL 5.7\rmysql\u003e CHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\r# MySQL 8.0 ~ 8.0.22\rmysql\u003e CHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', GET_MASTER_PUBLIC_KEY=1, MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\r# MySQL 8.0.23 이후 버전\rmysql\u003e CHANGE REPLICATION SOURCE TO SOURCE_HOST='마스터IP', SOURCE_PORT=포트번호, SOURCE_USER='생성한 리플리케이션 계정명', SOURCE_PASSWORD='패스워드', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='위에서 확인된 File명', SOURCE_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL 'ch_testdb1';\r여기에 필요한 정보 중에서 [MASTER_LOG_FILE(SOURCE_LOG_FILE)]과 [MASTER_LOG_POS(SOURCE_LOG_POS)]은 위쪽에서 확인한 Master DB들의 정보에 나타났던 것으로 정리하면 다음과 같습니다.\nDB\rFile\rPosition\rMaster1mysql-bin.0000011321\rMaster2mysql-bin.000002970\rMaster 서버 정보 입력 linkSlave 서버에 Master 서버 정보를 하나씩 입력합니다.\nMySQL 5.7\rMySQL 8.0 ~ 8.0.22\rMySQL 8.0.23~\r#Master1\rmysql\u003e CHANGE MASTER TO MASTER_HOST='10.0.0.6', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=1321 FOR CHANNEL 'ch_testdb1';\r#Master2\rmysql\u003e CHANGE MASTER TO MASTER_HOST='10.0.0.7', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=970 FOR CHANNEL 'ch_testdb2';\rmysql\u003e FLUSH PRIVILEGES;\r#Master1\rmysql\u003e CHANGE MASTER TO MASTER_HOST='10.0.0.6', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', GET_MASTER_PUBLIC_KEY=1, MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=1321 FOR CHANNEL 'ch_testdb1';\r#Master2\rmysql\u003e CHANGE MASTER TO MASTER_HOST='10.0.0.7', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', GET_MASTER_PUBLIC_KEY=1, MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=970 FOR CHANNEL 'ch_testdb2';\rmysql\u003e FLUSH PRIVILEGES;\r#Master1\rmysql\u003e CHANGE REPLICATION SOURCE TO SOURCE_HOST='10.0.0.6', SOURCE_PORT=3306, SOURCE_USER='testuser', SOURCE_PASSWORD='Test!@123', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='mysql-bin.000001', SOURCE_LOG_POS=1321 FOR CHANNEL 'ch_testdb1';\r#Master2\rmysql\u003e CHANGE REPLICATION SOURCE TO SOURCE_HOST='10.0.0.7', SOURCE_PORT=3306, SOURCE_USER='testuser', SOURCE_PASSWORD='Test!@123', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='mysql-bin.000001', SOURCE_LOG_POS=970 FOR CHANNEL 'ch_testdb2';\rmysql\u003e FLUSH PRIVILEGES;\r리플리케이션 채널 시작 link리플리케이션 시작 후 에러가 없는지 확인합니다.\nMySQL 5.7\rMySQL 8.0\r#MySQL 5.7 기준\rmysql\u003e start slave for channel 'ch_testdb1'; mysql\u003e start slave for channel 'ch_testdb2';\rmysql\u003e show slave status for channel 'ch_testdb1'\\G mysql\u003e show slave status for channel 'ch_testdb2'\\G\r#MySQL 8 기준\rmysql\u003e start replica for channel 'ch_testdb1'; mysql\u003e start replica for channel 'ch_testdb2';\rmysql\u003e show replica status for channel 'ch_testdb1'\\G mysql\u003e show replica status for channel 'ch_testdb2'\\G\rMaster1\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다. Master2\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다. 리플리케이션 테스트 link리플리케이션 설정을 모두 마친 후에 Master 서버들에서 DB 작업을 진행하고, Slave 서버에 해당 내용이 복제되는지 확인해보겠습니다.\nMaster1 서버 작업\nMaster1 서버에 테스트를 위한 [sampletable] Table을 생성합니다. Slave 서버 확인\nSlave 서버에서 testdb1 DB에 sampletable Table이 복제되었는지 확인합니다. Master2 서버 작업\nMaster2 서버에 테스트를 위한 [sampletable] Table을 생성합니다. Slave 서버 확인\nSlave 서버에서 testdb2 DB에 sampletable Table이 복제되었는지 확인합니다. 버전별 명령어 비교 link\rMySQL 5.7\rMySQL 8.0 ~ 8.0.22\rMySQL 8.0.23~\rMySQL 5.7\r리플리케이션 명령어\r채널 설정\rCHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\r채널 시작START SLAVE FOR CHANNEL \"채널이름\";\r채널 중지STOP SLAVE FOR CHANNEL \"채널이름\";\r채널 상태 확인SHOW SLAVE STATUS FOR CHANNEL \"채널이름\";\r채널 정보 삭제RESET SLAVE ALL FOR CHANNEL \"채널이름\";\rMySQL 5.7\r리플리케이션 명령어\r채널 설정\rCHANGE MASTER TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', GET_Master_PUBLIC_KEY=1, MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL '채널 이름';\r채널 시작START SLAVE FOR CHANNEL \"채널이름\";\r채널 중지STOP SLAVE FOR CHANNEL \"채널이름\";\r채널 상태 확인SHOW SLAVE STATUS FOR CHANNEL \"채널이름\";\r채널 정보 삭제RESET SLAVE ALL FOR CHANNEL \"채널이름\";\rMySQL 8.0\r리플리케이션 명령어\r채널 설정\rCHANGE REPLICATION SOURCE TO SOURCE_HOST='마스터IP', SOURCE_PORT=포트번호, SOURCE_USER='생성한 리플리케이션 계정명', SOURCE_PASSWORD='패스워드', GET_SOURCE_PUBLIC_KEY=1, SOURCE_LOG_FILE='위에서 확인된 File명', SOURCE_LOG_POS=위에서 확인된 Position 번호 FOR CHANNEL 'ch_testdb1';\r채널 시작START REPLICA FOR CHANNEL \"채널이름\";\r채널 중지STOP REPLICA FOR CHANNEL \"채널이름\";\r채널 상태 확인SHOW REPLICA STATUS FOR CHANNEL \"채널이름\";\r채널 정보 삭제RESET REPLICA ALL FOR CHANNEL \"채널이름\";\r참고 URL link MySQL 5.7 Multi-Source Replication 가이드\nhttps://dev.mysql.com/doc/refman/5.7/en/replication-multi-source.html\nMySQL 8.0 Multi-Source Replication 가이드\nhttps://dev.mysql.com/doc/refman/8.0/en/replication-multi-source.html\n문서 업데이트 내역 link\r날짜 내용 2023-04-05 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  170 ,
                href: "\/docs\/database\/mysql-mariadb\/replication\/mariadb-multi-source-replication\/",
                title: "MariaDB Multi Source Replication 구성 가이드",
                description: "Ncloud(네이버 클라우드)에서 MariaDB Multi Source Replication 구성하는 방법에 대한 상세 가이드입니다",
                content: "개요 linkn대의 마스터 DB와 1대의 슬레이브 DB를 연결하여 마스터 DB들의 데이터를 슬레이브 DB 한곳에 모아 조회할 수 있는 Multi-Source-Replication(MSR)을 MariaDB에서 구성하는 방법을 정리해보겠습니다.\n테스트 준비 link 마스터 서버 2대, 슬레이브 서버 1대 준비 각 서버에 MariaDB 10.3 이상 설치 MariaDB 리플리케이션작업 진행 시 마스터 서버의 데이터베이스에 쓰기 작업 금지 ACG 설정 link서버 준비가 끝났으면 우선 마스터 서버 슬레이브 서버로 디비 백업 파일 복사과 복제 구성에 필요한 22, 3306 포트를 오픈해야 합니다.\n오픈 할 때 규칙은 마스터 서버와 슬레이브 서버의 공통 ACG에 사설 IP 대역 전체를 지정할 수도 있고, 슬레이브 서버 전용 ACG에 마스터 서버 IP만 등록하는 방법도 있습니다.\nSlave 장비에 백업 디렉토리 생성 link먼저 Slave 장비에 Master 장비들로 부터 DB 복원용 덤프 파일을 전송 받을 백업 디렉토리를 생성하는 것 부터 시작하겠습니다.\nmkdir /data\rcd /data\rMaster1 장비 구성 linkMaster1 설정 추가 link /etc/my.cnf.d/mariadb-server.cnf에 Master1 설정을 추가합니다. MariaDB 버전에 따라서는 /etc/my.cnf.d/server.cnf 인 경우도 있습니다. MySQL 호환\rMariaDB 전용\rvi /etc/my.cnf.d/mariadb-server.cnf\rserver-id = 1\rlog-bin = mariadb-bin\rbinlog_format = mixed\rcharacter-set-server = utf8\r#MariaDB를 재시작해 변경사항 적용.\rsystemctl restart mariadb\rvi /etc/my.cnf.d/mariadb-server.cnf\rlog-bin\rserver_id = 1\rlog-basename = mariadb\rbinlog-format = mixed\rcharacter-set-server = utf8\r#MariaDB을 재시작해 변경사항 적용.\rsystemctl restart mariadb\r리플리케이션 계정 생성 linkMariaDB 접속 후 리플리케이션을 진행할 계정 생성\n#master1 계정 생성.\rMariaDB [(none)]\u003e create user '리플리케이션 계정명'@'%' identified by '패스워드';\rMariaDB [(none)]\u003e grant replication slave on *.* to '리플리케이션 계정명'@'%';\rMariaDB [(none)]\u003e flush privileges;\r테스트 DB 생성 link다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\nMariaDB [(none)]\u003e CREATE DATABASE testdb1 default CHARACTER SET UTF8;\rMaster1 정보확인 link이제 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\nMariaDB [(none)]\u003e show variables like 'server_id';\rMariaDB [(none)]\u003e show master status;\r{% include callout-v2.html type=“warning” level=“3” content=\" [show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다. \" %}\nDB 백업 파일 슬레이브 장비로 전송 linktestdb1 DB의 백업파일을 생성하고, 슬레이브 서버로 전송합니다.\nmkdir /data\rcd /data\rmysqldump -u root -p --databases testdb1 \u003e /data/test1.sql #슬레이브 서버에 전송.\rscp test1.sql root@10.0.0.8:/data\rMaster2 장비 구성 linkMaster2 설정 추가 link /etc/my.cnf.d/mariadb-server.cnf에 Master2 설정을 추가합니다. MariaDB 버전에 따라서는 /etc/my.cnf.d/server.cnf 인 경우도 있습니다. MySQL 호환\rMariaDB 전용\rvi /etc/my.cnf.d/mariadb-server.cnf\rserver-id = 2\rlog-bin = mariadb-bin\rbinlog_format = mixed\rcharacter-set-server = utf8\r#MariaDB을 재시작해 변경사항 적용.\rsystemctl restart mariadb\rvi /etc/my.cnf.d/mariadb-server.cnf\rlog-bin\rserver_id = 2\rlog-basename = mariadb\rbinlog-format = mixed\rcharacter-set-server = utf8\r#MariaDB을 재시작해 변경사항 적용.\rsystemctl restart mariadb\r리플리케이션 계정 생성 linkMariaDB 접속 후 리플리케이션을 진행할 계정 생성합니다.\n#master2 계정 생성.\rMariaDB [(none)]\u003e create user '리플리케이션 계정명'@'%' identified by '패스워드';\rMariaDB [(none)]\u003e grant replication slave on *.* to '리플리케이션 계정명'@'%';\rMariaDB [(none)]\u003e flush privileges;\r테스트 DB 생성 link다음으로 테스트에 사용할 DB를 생성하겠습니다. 이미 생성되어 있는 다른 DB를 사용할 경우에는 별도로 테스트용 DB를 생성할 필요는 없습니다.\nMariaDB [(none)]\u003e CREATE DATABASE testdb2 default CHARACTER SET UTF8;\rMaster2 정보확인 link마찬가지로 리플리케이션 설정에 필요한 Master 정보를 확인합니다.\nMariaDB [(none)]\u003e show variables like 'server_id';\rMariaDB [(none)]\u003e show master status;\r[show master status] 명령으로 확인한 [File], [Position] 정보는 아래쪽에서 Slave DB를 설정할 때 입력해야 하므로 별도로 기록해두어야 합니다.\rDB 백업 파일 슬레이브 장비로 전송 linktestdb2 DB의 백업파일 생성하고, 슬레이브 서버로 전송합니다.\nmkdir /data\rcd /data\rmysqldump -u root -p --databases testdb2 \u003e /data/test2.sql\rscp test2.sql root@10.0.0.8:/data\rSlave 장비 구성 linkSlave 설정 추가 link /etc/my.cnf.d/mariadb-server.cnf에 Slave 설정을 추가합니다. MariaDB 버전에 따라서는 /etc/my.cnf.d/server.cnf 인 경우도 있습니다. vi /etc/my.cnf.d/mariadb-server.cnf\rserver-id = 3 #리플리케이션 대상 디비 설정.\rreplicate-do-db = testdb1\rreplicate-do-db = testdb2\r#리플리케이션 제외 디비 설정.\rreplicate-ignore-db = information_schema\rreplicate-ignore-db = mysql\rreplicate-ignore-db = performance_schema\rreplicate-ignore-db = sys\rslave-skip-errors = all\r#DB를 재시작하여 변경사항 적용.\rsystemctl restart mariadb\rDB 복구 진행 link먼저 복구할 DB를 미리 생성하고 Master1, Master2 장비에서 전송 받은 백업 파일을 사용해 DB를 복구합니다.\n#복구할 DB 생성.\rMariaDB [(none)]\u003e create database testdb1;\rMariaDB [(none)]\u003e create database testdb2;\rMariaDB [(none)]\u003e quit\r#DB 복구\rmysql -u root -p testdb1 \u003c /data/test1.sql\rmysql -u root -p testdb2 \u003c /data/test2.sql\r백업 파일을 전송 받은 디렉토리로 이동해 백업 파일이 정상적으로 전송되었는지 확인합니다. 백업 파일을 사용해 DB를 복구합니다. 리플리케이션 채널 설정 link리플리케이션 채널을 설정하는 쿼리문은 다음과 같은데, MySQL과는 일부 다른 부분이 있으니 잘 확인하고 사용해야 합니다.\nMariaDB [(none)]\u003e CHANGE MASTER '커넥션 이름' TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호;\r여기에 필요한 정보 중에서 [MASTER_LOG_FILE]과 [MASTER_LOG_POS]은 위쪽에서 확인한 Master DB들의 정보에 나타났던 것으로 정리하면 다음과 같습니다.\nDB\rFile\rPosition\rMaster1mariadb-bin.000001939\rMaster2mariadb-bin.000002939\rMaster 서버 정보 입력 link다음의 예시처럼 Slave 서버에 Master 서버 정보를 하나씩 입력합니다.\n#Master1 예시\rMariaDB [(none)]\u003e CHANGE MASTER 'ch_testdb1' TO MASTER_HOST='10.0.0.6', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mariadb-bin.000001', MASTER_LOG_POS=939;\r#Master2 예시\rMariaDB [(none)]\u003e CHANGE MASTER 'ch_testdb2' TO MASTER_HOST='10.0.0.7', MASTER_USER='testuser', MASTER_PORT=3306, MASTER_PASSWORD='Test123$', MASTER_LOG_FILE='mariadb-bin.000002', MASTER_LOG_POS=939;\rMariaDB [(none)]\u003e FLUSH PRIVILEGES;\r리플리케이션 채널 시작 link리플리케이션 시작 후 에러가 없는지 확인합니다.\n# start slave '커넥션명';\rMariaDB [(none)]\u003e start slave 'ch_testdb1'; MariaDB [(none)]\u003e start slave 'ch_testdb2';\r# show slave '커넥션명' status\\G\rMariaDB [(none)]\u003e show slave 'ch_testdb1' status\\G MariaDB [(none)]\u003e show slave 'ch_testdb2' status\\G\rMaster1\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다. Master2\n상태 확인에서는 [Slave_IO_State], [Slave_IO_Running], [Slave_SQL_Running] 항목들이 아래와 같이 되어 있으면 정상입니다. 리플리케이션 테스트 link리플리케이션 설정을 모두 마친 후에 Master 서버들에서 DB 작업을 진행하고, Slave 서버에 해당 내용이 복제되는지 확인해보겠습니다.\nMaster1 서버 작업\nMaster1 서버에 테스트를 위한 [sampletable1] Table을 생성합니다. Slave 서버 확인\nSlave 서버에서 testdb1 DB에 sampletable1 Table이 복제되었는지 확인합니다. Master2 서버 작업\nMaster2 서버에 테스트를 위한 [sampletable2] Table을 생성합니다. Slave 서버 확인\nSlave 서버에서 testdb2 DB에 sampletable2 Table이 복제되었는지 확인합니다. 리플리케이션 명령어 모음 link\r리플리케이션 명령어\r채널 설정\rCHANGE MASTER '커넥션 이름' TO MASTER_HOST='마스터IP', MASTER_PORT=포트번호, MASTER_USER='생성한 리플리케이션 계정명', MASTER_PASSWORD='패스워드', MASTER_LOG_FILE='위에서 확인된 File명', MASTER_LOG_POS=위에서 확인된 Position 번호;\r채널 시작START SLAVE \"커넥션 이름\";\r채널 중지STOP SLAVE \"커넥션 이름\";\r채널 상태 확인SHOW SLAVE \"커넥션 이름\" STATUS\\G\r채널 정보 삭제RESET SLAVE \"커넥션 이름\";\r참고 URL link MariaDB Replication 기본 설정 가이드\nhttps://mariadb.com/kb/en/setting-up-replication/\nMariaDB Multi-Source Replication 가이드\nhttps://mariadb.com/kb/en/multi-source-replication/\n문서 업데이트 내역 link\r날짜 내용 2023-04-20 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  171 ,
                href: "\/docs\/database\/cloud-db-mysql\/cdb-create-basic-guide\/",
                title: "VPC환경에서 Cloud DB for MySQL 생성하기",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Cloud DB for MySQL 생성하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Cloud DB for MySQL 서비스는 MySQL 데이터베이스를 쉽고 간편하게 구축하고 관리할 수 있고 자동 Fail-Over, 자동백업, 네이버 서비스에서 검증된 최적화된 설정 등을 제공해주는 완전 관리형 클라우드 데이터베이스 서비스입니다.\n여기서는 VPC환경에서 Cloud DB for MySQL 서비스를 생성하는 과정을 정리해보겠습니다.\n특징 link 기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6,000GB까지 자동으로 용량이 증가합니다. 하나의 마스터 DB마다 최대 10대의 슬레이브 DB를 생성할 수 있습니다. Load Balancer 상품을 통해 슬레이브 DB 서버들을 읽기 전용 복제본으로 사용함으로써 데이터베이스의 읽기 부하를 분산 시킬 수 있습니다. 매일 1회 고객이 원하는 시간에 DB를 자동으로 백업하며, 백업한 데이터를 최대 30일까지 보관할 수 있습니다. VPC 환경에서는 멀티 존으로 구성해 높은 안정성을 보장받을 수 있습니다. Cloud DB for MySQL 서비스는 완전 관리형 상품으로 사용자는 DB서버의 운영체제에 접근할 수 없습니다. DB 접속 방법 3가지 link Private 도메인을 이용해 접속하는 방법 SSL VPN을 이용해 접속하는 방법 Public 도메인을 이용해 접속하는 방법 아래에서는 VPC환경에서 Private 도메인을 이용해 접속하는 방법을 설명하도록 하겠습니다.\n만약 네이버 클라우드 외부 환경에서 Cloud DB for MySQL로 접속하려면 Public 도메인을 사용해야 합니다. 하지만, DB 보안을 위해 특수한 상황인 아닌한 Private 도메인에서 생성하는 것을 권장합니다.\nVPC-Subnet 생성 link이미 생성된 VPC와 Subnet이 있다면 이 단계는 건너띄고 다음 단계로 이동하시면 됩니다.\nVPC 생성 linkVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\nSubnet 생성 linkSubnet은 Cloud DB for MySQL을 위한 Private Subnet과 DB 접속 테스트 Server용 Public Subnet을 각각 생성합니다.\nCloud DB for MySQL을 위한 Private Subnet link\r테스트용 Server를 위한 Public Subnet link\r테스트 Server 생성 linkDB 서버 접속을 테스트 하기 위한 Server를 생성합니다. 여기서는 Rocky Linux 8.8 서버를 생성했습니다.\nDB 서버 생성 link[Database] - [Cloud DB for MySQL]에서 [DB Server 생성] 버튼을 클릭합니다.\nDB 서버 엔진 버전 linkDB 엔진 버전은 MySQL 최신 버전 중 네이버에서 안정성이 검증된 버전인 8.0.x 버전과 5.7.x 버전을 제공합니다. (기본값 8.0.32)\nDB 서버 이름과 DB 서비스 이름 link DB Server 이름은 고객이 DB 서버를 구분하기 위한 명칭으로, 사용자가 입력한 이름 뒤에 001, 002와 같이 숫자를 붙여 서버를 구분하게 됩니다. 예를 들어 DB 서버 이름을 mydb라고 입력하면 생성되는 DB 서버 이름은 mydb-001, mydb-002와 같습니다. DB 서비스 이름은 역할별 DB 서버를 구분하기 위한 이름입니다. 일반적으로 하나의 액티브 마스터 DB, 스탠바이 마스터 DB, 다수의 슬레이브 DB로 구성되는 DB 서버군을 말하며, 동일한 데이터를 갖고 있는 DB 서버들을 하나의 DB 서비스라 말합니다. 예를 들어 “쇼핑 메인 DB”, “게임 유저 DB\"와 같은 식으로 DB 서비스의 역할을 구분하기 위해 사용합니다. Cloud DB를 위한 ACG는 자동 생성됩니다(예: cloud-mysql-*)\rDB 서버 설정 linkDB 이름과 계정. 비번, 접속 포트 등을 설정합니다.\nHOST(IP) 설정에는 전체 허용을 뜻하는 [%]를 입력하고, 대신에 접근 제한은 방화벽인 ACG에서 설정하겠습니다.\nACG 외에 추가로 접근 제한을 하고 싶은 경우에는 접근을 허용할 IP대역을 입력합니다.\n테스트용 서버의 Subnet 대역을 모두 허용하려면 [10.0.0.%]를 입력 만약 특정 서버 1대만 허용하려고 할 경우에는 앞에서 생성한 테스트 서버 IP처럼 [10.0.0.7]을 입력 report\r접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\nACG 설정 linkCloud DB for MySQL을 생성할 때 자동 생성된 ACG [cloud-mysql-*]을 선택하고 ACG 설정을 클릭합니다.\nInbound 설정에 테스트용 Server의 Subnet 대역인 [10.0.0.0/24]를 접근소스에 입력합니다.\n또는 특정 서버 1대만 허용하려고 할 경우에는 앞에서 생성한 테스트 서버 IP처럼 [10.0.0.7]을 입력합니다.\nMySQL Client 설치 linkDB 접속 테스트를 위해 생성한 Rocky Linux 8.8 서버에서 MySQL 8.0 Client를 설치합니다.\n# mysql 8.0\r# {version-number} 확인 : https://dev.mysql.com/downloads/repo/yum/\r# dnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-{version-number}.noarch.rpm\rdnf -y install https://dev.mysql.com/get/mysql80-community-release-el8-8.noarch.rpm\rdnf module reset mysql\rdnf module disable mysql\rdnf repolist all | grep mysql\rdnf -y install mysql-community-server\rmysqld --initialize-insecure --user=mysql\rsystemctl start mysqld\rmysql_secure_installation\rDB 서버 접속 linkCloud DB for MySQL에 접속하기 위한 주소인 [Private 도메인]을 확인 합니다.\n테스트용 Server에서 Cloud DB for MySQL로 접속하는 방법은 다음과 같습니다.\nmysql -u [user_id] -p -h [Private 도메인명]\rDB에 접속해보면 처음 Cloud DB for MySQL 생성할 때 입력한 테이터베이스 [testdb]를 확인할 수 있습니다.\nDB 서버 상세보기 link[DB 관리] - [DB 서버 상세보기] 메뉴에서는 [Process list], [Variables], [Status], [Database 관리], [DB Config 관리], [DB User 관리], [Backup 설정 관리], [DB Server Logs] 등을 확인할 수 있습니다.\nDatabase 관리 link[Database 관리] 메뉴에서는 Cloud DB 서버의 Database를 생성하거나 삭제할 수 있습니다. 추가, 삭제 작업은 한번에 10개까지 가능하고, 최대 1,000개까지 생성 및 조회할 수 있습니다.\n콘솔이 아닌 터미널 환경에서 직접 Database를 생성하려면 다음과 같은 Stored Procedure를 사용해야 합니다. mysql\u003e CALL sys.ncp_create_db('생성할 DB명[필수]','Character Set[선택]','Collation[선택]');\r--예제\r--character set, collation 은 mysql 서버 default 설정으로 지정\rmysql\u003e CALL sys.ncp_create_db('testdb','','');\rDB User 관리 linkDB 서버를 이용하다보면 여러 계정이 필요하게 됩니다. 이때 계정을 추가하기 위해 [DB 서버 상세보기] - [DB User 관리] 메뉴를 클릭합니다.\nUSER_ID, HOST, DB 권한, 암호를 입력하고 DB User 추가 버튼을 클릭합니다.\n사용자가 변경한 DB 계정은 DB 서비스 전체에 적용됩니다. USER_ID + HOST(IP) 단위로 계정 추가 및 권한 관리를 합니다. DB 권한에서 DDL 권한은 CRUD 권한을 포함합니다. 콘솔에서 허용하지 않는 문자로 DB User를 생성한 경우는 콘솔에서 수정, 삭제가 불가능합니다.\nDB 서버에 직접 접속 후 변경해 주세요. 최대 1000개까지 계정을 추가 및 조회 할 수 있습니다. DB 계정 가져오기 linkDB Server에 생성된 계정 정보 가져오기를 수행하면 DB Server 에서 사용자가 직접 생성한 DB 계정 정보를 Console 에서 확인 및 삭제 할 수 있습니다.\n참고 URL link Cloud DB for MySQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-6\nCloud DB 서버 외부 접근 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-10\n문서 업데이트 내역 link\r날짜 내용 2021-08-02 문서 최초 생성 2023-09-01 Database 생성하는 방법 안내 추가, 전체 스크린샷 업데이트 "
            }
        );
    index.add(
            {
                id:  172 ,
                href: "\/docs\/database\/cloud-db-mysql\/cdb-access-public-domain-guide\/",
                title: "Cloud DB for MySQL 생성후 Public 도메인으로 접속하기",
                description: "Ncloud(네이버 클라우드) Cloud DB for MySQL 생성후 Public 도메인으로 접속하는 방법입니다",
                content: "개요 link네이버 클라우드의 Cloud DB for MySQL 서비스는 MySQL 데이터베이스를 쉽고 간편하게 구축하고 관리할 수 있고 자동 Fail-Over, 자동백업, 네이버 서비스에서 검증된 최적화된 설정 등을 제공해주는 완전 관리형 클라우드 데이터베이스 서비스입니다.\n여기서는 VPC환경에서 Cloud DB for MySQL 서비스를 생성하고, Public 도메인으로 접속하는 과정을 정리해보겠습니다.\n네이버 클라우드는 Classic환경에서는 DB 서버 이미지를 제공하지만, VPC 환경에서는 제공하지 않습니다. 그러므로 VPC 환경에서 DB서버를 사용하려면 OS에 사용자가 직접 DB를 설치해서 사용하는 방법과 Cloud DB를 사용하는 방법 중에서 선택해야 합니다.\r특징 link 기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6,000GB까지 자동으로 용량이 증가합니다. 하나의 마스터 DB마다 최대 10대의 슬레이브 DB를 생성할 수 있습니다. Load Balancer 상품을 통해 슬레이브 DB 서버들을 읽기 전용 복제본으로 사용함으로써 데이터베이스의 읽기 부하를 분산 시킬 수 있습니다. 매일 1회 고객이 원하는 시간에 DB를 자동으로 백업하며, 백업한 데이터를 최대 30일까지 보관할 수 있습니다. VPC 환경에서는 멀티 존으로 구성해 높은 안정성을 보장받을 수 있습니다. Cloud DB for MySQL 서비스는 완전 관리형 상품으로 사용자는 DB서버의 운영체제에 접근할 수 없습니다. DB 접속 방법 3가지 link Private 도메인을 이용해 접속하는 방법 SSL VPN을 이용해 접속하는 방법 Public 도메인을 이용해 접속하는 방법 아래에서는 VPC환경 기준으로 네이버 클라우드 외부 환경에서 Cloud DB for MySQL로 접속할 때 필요한 Public 도메인을 이용해 접속하는 방법을 정리하도록 하겠습니다.\nVPC-Subnet 생성 linkVPC 생성 linkVPC환경에서 작업할 것이므로 우선 VPC를 생성합니다.\nSubnet 생성 linkSubnet은 Public Subnet을 생성합니다.\nDB 서버 생성 link[Database] - [Cloud DB for MySQL]에서 [DB Server 생성] 버튼을 클릭합니다.\nDB 서버 엔진 버전 linkDB 엔진 버전은 MySQL 최신 버전 중 네이버에서 안정성이 검증된 버전인 5.7버전과 8.0버전을 제공합니다. (기본값 5.7.32)\nDB 서버 이름과 DB 서비스 이름 link DB Server 이름은 고객이 DB 서버를 구분하기 위한 명칭으로, 사용자가 입력한 이름 뒤에 001, 002와 같이 숫자를 붙여 서버를 구분하게 됩니다. 예를 들어 DB 서버 이름을 mydb라고 입력하면 생성되는 DB 서버 이름은 mydb-001, mydb-002와 같습니다. DB 서비스 이름은 역할별 DB 서버를 구분하기 위한 이름입니다. 일반적으로 하나의 액티브 마스터 DB, 스탠바이 마스터 DB, 다수의 슬레이브 DB로 구성되는 DB 서버군을 말하며, 동일한 데이터를 갖고 있는 DB 서버들을 하나의 DB 서비스라 말합니다. 예를 들어 “쇼핑 메인 DB”, “게임 유저 DB\"와 같은 식으로 DB 서비스의 역할을 구분하기 위해 사용합니다. Cloud DB를 위한 ACG는 자동 생성됩니다(예: cloud-mysql-*)\rDB 서버 설정 linkDB 이름과 계정. 비번, 접속 포트 등을 설정합니다.\nHOST(IP) 설정에는 DB에 접근을 허용할 IP대역을 입력합니다. 여기서는 Public 도메인을 이용하게 되므로 우선 모든 대역을 허용하기 위해 [%]를 입력합니다. 대신 접속 IP 제한의 경우 ACG에서 설정하게 됩니다.\nreport\r접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\nACG 설정 linkCloud DB for MySQL을 생성할 때 자동 생성된 ACG [cloud-mysql-*]을 선택하고 ACG 설정을 클릭합니다.\nInbound 설정에 접속을 허용할 IP를 입력합니다. 여기서는 테스트를 위해 [myIp] 버튼을 클릭해 현재 로컬PC IP를 입력합니다.\nPublic 도메인 할당 linkDB 서버를 생성한 직후에는 아래 스샷과 같이 Public 도메인이 미할당 상태입니다.\n[DB 관리] - [Public 도메인 관리] 메뉴를 클릭해 Public 도메인을 신청합니다.\nPublic 도메인을 신청하면 네이버 클라우드 플랫폼 외부에서 DB 서버로 접근할 수 있습니다.\n이때 외부에서 통신하는 데이터는 네트워크 사용량으로 과금이 됩니다.\nPublic 도메인 신청을 하고 나면 할당된 Public 도메인을 확인할 수 있습니다.\nDB User 관리 link네이버 클라우드 외부에서 DB에 접속하려고 할때는 보안을 위해 별도의 계정을 추가해서 사용하는 것을 추천합니다.\n계정을 추가하기 위해 [DB 관리] - [DB User 관리] 메뉴를 클릭합니다.\nUSER_ID, HOST, DB 권한, 암호를 입력하고 DB User 추가 버튼을 클릭합니다.\n사용자가 변경한 DB 계정은 DB 서비스 전체에 적용됩니다. USER_ID + HOST(IP) 단위로 계정 추가 및 권한 관리를 합니다. DB 권한에서 DDL 권한은 CRUD 권한을 포함합니다. 최대 1,000개까지 계정을 추가 및 조회 할 수 있습니다. 외부접속 테스트 link네이버 클라우드 외부 접속을 테스트 하기 위해 로컬PC에 MySQL Workbench를 설치해서 접속해보겠습니다. MySQL Workbench는 아래 경로에서 다운 받을 수 있습니다.\nhttps://www.mysql.com/products/workbench/ 앞에서 확인한 Public 도메인을 입력하고 Port와 Username도 함께 입력한 후에 [Test Connection]을 클릭해 문제없이 연결되는지 확인합니다.\nDB 서버 접속 후에 Database를 확인해보면 처음 Cloud DB for MySQL을 생성할 때 설정한 test Database가 존재하는 것을 확인할 수 있습니다.\n기타 linkDB 서버 상세보기 linkDB 서버 상세보기 메뉴에서는 [Process list], [Variables], [Status], [Database 관리], [DB Config 관리], [DB User 관리], [Backup 설정 관리], [DB Server Logs] 등을 확인할 수 있습니다.\n참고 URL link Cloud DB for MySQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-6\nCloud DB 서버 외부 접근 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-10\n문서 업데이트 내역 link\r날짜 내용 2021-12-13 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  173 ,
                href: "\/docs\/database\/cloud-db-mysql\/db-engine-upgrade-guide\/",
                title: "Ncloud Cloud DB for MySQL - DB Engine 업그레이드 가이드",
                description: "Ncloud(네이버 클라우드) Cloud DB for MySQL의 DB Engine을 업그레이드하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Cloud DB for MySQL에서는 DB Engine을 업그레이드할 수 있는데, Minor 버전 업그레이드(예: 5.7.32 -\u003e 5.7.40)와 Major 버전 업그레이드(예: 5.7.x -\u003e 8.0.x)가 있습니다. 각각에 대해 업그레이드 하는 방법에 대해 아래쪽에서 살펴보겠습니다.\n업그레이드 진행 방식 link\r⁃ 리스트에 있는 전체 서버의 버전이 변경되고, 버전 업그레이드 중인 서버는 접근이 차단 됩니다.\n⁃ Master DB 는 Standby Master DB 로 전환하여 서비스 접근 차단은 최소한으로 유지합니다.\n(Master DB Failover 기능으로 변경되는 시간과 동일합니다.)\n⁃ 업그레이드 작업은 1대씩 순차적으로 진행되고, Server 1대에 5분 내외로 작업 시간이 소요 됩니다.\n(작업 순서 : Recovery Slave Master)\n⁃ Stand Alone Server 는 업그레이드 되는 동안 DB 접속이 되지 않습니다.\n⁃ Major 버전 업그레이드로 인해 DB config 의 default 값이 변경될 수 있습니다.\n⁃ Stand Alone Server 는 Major 버전 업그레이드 기능을 지원하지 않습니다.\nMinor 버전 업그레이드 link아래와 같이 Cloud DB for MySQL 서버를 5.7.32 버전으로 준비했습니다.\nDB서버를 선택하고 [DB 관리] - [MySQL Engine Upgrade] 메뉴를 클릭합니다.\n[DB 엔진 버전]에서 업그레이드 가능한 버전을 선택할 수 있는데, 여기서는 [5.7.40]을 선택하겠습니다.\n업그레이드 중에는 [Status]가 [업그레이드]로 표시됩니다.\n업그레이드가 끝나면 아래와 같이 [DB 엔진 버전]이 [5.7.40]으로 변경되었고, [Master]와 [Standby Master] 서버가 서로 바뀐 것을 확인할 수 있습니다.\nMajor 버전 업그레이드 link[Major 버전 업그레이드] 항목을 체크하고 [DB 엔진 버전]에서 업그레이드 가능한 버전에서 [8.0.32]를 선택하겠습니다.\n주의사항 link\r⁃ Major 버전 업그레이드로 인한 애플리케이션 호환성 검토를 먼저 진행한 후에 업그레이드 하시는 것을 권장합니다.\n⁃ Major 버전 업그레이드는 **고가용성 구성인 경우만 작업이 가능**합니다.\n⁃ Major 버전 업그레이드 시 **이전 버전으로 rollback이 불가능**합니다.\n⁃ Major 버전 업그레이드 시 DB config 의 default 값이 변경될 수 있습니다.\n⁃ Major 버전 업그레이드 시 Major 버전 **업그레이드 전으로 시점 복구가 불가능**합니다.\n⁃ Major 버전 업그레이드 시 Major 버전 업그레이드 전의 백업본은 신규 서비스 생성만 가능합니다.\r[Major 버전 업그레이드]는 호환성 체크 등 업그레드 작업에 문제가 없을지 미리 점검을 진행하게 됩니다.\nreport\r업그레이드 점검에서 오류가 발견될 경우 업그레이드가 불가능합니다.\n업그레이드 점검이 문제없이 완료되었으면 [예] 버튼을 클릭해서 업그레이드를 진행합니다.\n업그레이드가 완료되면 아래와 같이 [DB 엔진 버전]이 위에서 선택했던 [8.0.32]로 변경된 것을 확인할 수 있습니다.\n참고 URL link Ncloud MySQL Engine Upgrade 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-2#mysql-engine-upgrade\nNcloud Cloud DB for MySQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbformysql-overview\n문서 업데이트 내역 link\r날짜 내용 2023-12-06 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  174 ,
                href: "\/docs\/database\/cloud-db-mysql\/db-restore-error-1227-troubleshotting\/",
                title: "MySQL 복구 시 ERROR 1227 (42000) 문제 원인과 해결방법",
                description: "Ncloud(네이버 클라우드) Cloud DB for MySQL 복구 시 ERROR 1227 (42000) 문제 원인과 해결방법입니다",
                content: "개요 link네이버 클라우드(Ncloud) Cloud DB for MySQL을 사용하면서 백업 데이터를 복구 하려고 할 때 ERROR 1227 (42000) 오류가 발생하는 경우가 있습니다. 오류 메시지로만 보면 계정 권한에 문제가 있는 것처럼 보이는데 정확하게 문제 원인이 무엇인지, 그리고 해결방법은 어떤 것이 있는지 정리해보겠습니다.\n오류 메시지 link전체 오류 메시지는 아래와 같습니다.\n이 오류 메시지의 원인은 크게 2가지로 구분할 수 있는데, 상황에 따라 각각의 원인 1가지에 해당하는 경우도 있고, 2가지 원인이 모두 해당되는 경우도 있습니다.\nreport\rERROR 1227 (42000) at line 77: Access denied; you need (at least one of) the SUPER privilege(s) for this operation\n원인 1 link첫번째 원인은 GTID(global transaction identifier)와 관련되어 있습니다.\n네이버 클라우드(Ncloud) Cloud DB for MySQL 상품은 GTID(Global Transaction IDentifier)를 사용하는데, 보통의 mysql db 복구(Restore)는 GTID를 사용하지 않는 방법이기 때문에 백업(Backup) 단계에서 [–set-gtid-purged=OFF] 옵션을 추가해야 하는데 이 옵션을 사용하지 않았기 때문입니다.\nGTID 란? linkGTID는 Global Transaction Identifier의 약자로 MySQL 복제에서 서버의 각 트랜잭션을 구분하는 고유한 식별자입니다. GTID는 모든 트랜잭션과 1:1 관계이며, GTID를 활용하면 복제본으로 장애 조치, 계층적 복제, 특정 시점으로 백업 복구하는 등의 작업을 더 쉽게 구현할 수 있으며, 오류 발생 빈도도 줄일 수 있습니다.\n오류 상황 재현 link아래와 같이 서버에서 mysqldump 명령으로 Cloud DB for MySQL DB를 백업 받는 상황을 가정해보겠습니다. 여기서는 [–set-gtid-purged=OFF] 옵션을 사용하지 않았습니다.\n[–set-gtid-purged=OFF] 옵션을 사용하지 않고, 백업을 받으면 백업은 정상 진행되지만, 아래와 같이 [–set-gtid-purged=OFF] 해야 한다는 Warning 메시지가 표시됩니다.\nmysqldump -u user -p -h db-......vpc-cdb.ntruss.com -S /var/lib/mysql/mysql.sock --single-transaction --routines --triggers --events --databases test \u003e dumpfile1.sql\r위에서 생성한 [–set-gtid-purged=OFF] 옵션을 사용하지 않은 백업 파일(dumpfile1.sql)을 이용해서 복구(Restore)시에 아래와 같이 ERROR 1227 (42000) 오류가 발생하면서 복구가 되지 않습니다.\nmysql -h db-......vpc-cdb.ntruss.com -u user -p \u003c ./dumpfile1.sql\r해결 방법 1 link이번에는 Warning 메시지에 나온 것처럼 [–set-gtid-purged=OFF] 옵션을 사용해서 백업을 받아 보겠습니다.\nmysqldump --set-gtid-purged=OFF -u user -p -h db-......vpc-cdb.ntruss.com -S /var/lib/mysql/mysql.sock --single-transaction --routines --triggers --events --databases test \u003e dumpfile2.sql\r[–set-gtid-purged=OFF] 옵션을 사용해서 생성한 백업 파일(dumpfile2.sql)을 이용해서 복구를 하면 아래와 같이 문제없이 복구가 잘됩니다.\n그런데 이렇게 옵션을 적용해도 동일한 오류가 발생하는 경우가 있는데 이에 대해서는 아래쪽 원인 2에서 확인해보겠습니다.\nmysql -h db-......vpc-cdb.ntruss.com -u user -p \u003c ./dumpfile2.sql\r해결 방법 2 link그런데 서비스를 하다 보면 DB 사이즈가 너무 커서 다시 백업을 진행하기 어렵다던가 하는 경우가 있습니다. 이럴 때는 백업 파일에 있는 GTID 관련 내용을 삭제하고 복구하시면 문제가 해결됩니다.\n백업 파일 상단과 하단에 각각 아래와 같은 코드가 포함되어 있는데 이 내용을 삭제하거나 주석처리한 후에 복구를 시도하면 문제 없이 복구가 완료됩니다.\n# 백업 파일 상단에 위치\rSET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION.SQL_LOG_BIN;\rSET @@SESSION.SQL_LOG_BIN= 0;\r# 백업 파일 하단에 위치\rSET @@GLOBAL.GTID_PURGED='207****-4***-7**-9*****c:1-12,\r2****-4**-9**-b**-d*****:1-19';\r원인 2 link위에서 설명한 [–set-gtid-purged=OFF]을 적용한 백업 파일을 이용해서 복구를 진행해도 동일한 오류가 발생하는 경우가 있는데 원인은 Trigger, Stored Routines (Procedures and Functions), View, Event 생성과 관련된 [DEFINER] 권한 때문입니다.\ninfo\rDEFINER 권한문제: 즉, Trigger, Stored Routines (Procedures and Functions), View, Event를 생성한 계정과 DB 복구를 시도하는 계정이 다른 경우에 발생하는 문제입니다.\n[원인 1]에서는 복구를 시도할 때 [user] 계정을 사용했었는데 이 [user]계정으로 Trigger, Stored Routines (Procedures and Functions), View, Event 등을 생성한 상황에서 다른 계정 [new_user]를 이용해서 복구를 시도하는 상황을 가정보겠습니다. [new_user] 계정으로 복구를 시도하면 [–set-gtid-purged=OFF]을 적용한 백업 파일(dumpfile2.sql)을 이용했음에도 동일한 ERROR 1227 (42000) 오류가 발생하는 것을 확인할 수 있습니다.\n아래와 같이 MySQL은 보안 강화를 위해 Trigger, Stored Routines (Procedures and Functions), View, Event를 처음 생성한 계정을 [DEFINER]로 명시해 둠으로써 다른 계정으로 접근하지 못하도록 하는 것이 기본 설정이 되어 있습니다.\n그러므로 DB 복구를 시도할 때는 [DEFINER] 관련 내용을 삭제하거나 동일한 계정 또는 SUPER privilege를 가진 계정으로 복구해야 합니다.\n해결 방법 1 link첫번째 해결 방법은 백업 파일에서 [DEFINER] 관련 내용을 모두 찾아서 삭제하는 방법이 있습니다. 여기서는 대표적으로 FUNCTION, PROCEDURE, VIEW에 해당하는 예시를 살펴보겠습니다.\nFUNCTION linkDB에서 FUNCTION을 사용했다면 아래와 같이 FUNCTION 생성 코드에 [CREATE DEFINER=`user`@`%` FUNCTION]처럼 계정이 표시되는데, 여기서 [DEFINER=`user`@`%`] 이 부분을 삭제하시면 됩니다.\nPROCEDURE linkDB에서 PROCEDURE를 사용했다면 아래와 같이 PROCEDURE 생성 코드에 [CREATE DEFINER=`user`@`%` PROCEDURE]처럼 계정이 표시되는데, 여기서 [DEFINER=`user`@`%`] 이 부분을 삭제하시면 됩니다.\nVIEW linkDB에서 VIEW를 사용했다면 아래와 같이 VIEW 생성 코드에 [/*!50013 DEFINER=`user`@`%` SQL SECURITY DEFINER */]처럼 계정이 표시되는데, 여기서는 이 라인을 모두 삭제하시면 됩니다.\n해결 방법 2 link두번째 해결 방법은 백업 파일 [DEFINER=]에 표시되어 있는 계정과 동일한 계정으로 복구를 진행하면 됩니다.\n참고 URL link Cloud DB for MySQL 백업, 복구 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-4\nGTID를 이용한 Mysql 복제 가이드\nhttps://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html\nGTID를 이용한 MariaDB 복제 가이드\nhttp://mariadb.com/kb/en/gtid/\nMySQL Stored Object Access Control : DEFINER 안내\nhttps://dev.mysql.com/doc/refman/5.7/en/stored-objects-security.html\n문서 업데이트 내역 link\r날짜 내용 2021-12-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  175 ,
                href: "\/docs\/database\/cloud-db-mysql\/load-balance\/classic-lb\/",
                title: "Cloud DB for MySQL 읽기 부하 로드밸런서로 분산시키는 방법 | Classic",
                description: "Ncloud(네이버 클라우드) Classic 환경에서 Cloud DB for MySQL 서버의 읽기 부하를 로드밸런서로 분산시키는 방법입니다",
                content: "개요 linkMySQL DB서버의 부하를 줄이기 위해 보통 읽기 전용 DB서버를 생성하게 되는데, 읽기 전용 서버를 여러대 생성해서 로드밸런서(Load Balancer)로 연결하면 읽기 부하를 분산 시키고 좀 더 안정적인 서비스가 가능해집니다.\n여기서는 Ncloud (네이버 클라우드) Classic 환경에서 관리형 DB인 Cloud DB for MySQL의 읽기 전용 Slave DB를 로드밸런서에 연결하고 제대로 부하가 분산되는지 확인해보겠습니다.\n사전 준비 linkDB 접속과 부하 분산을 테스트할 서버가 필요합니다. 여기서는 CentOS 7.8 서버를 준비했습니다.\nDB 서버 생성 link우선 [Cloud DB for MySQL] - [DB Server]에서 DB를 생성합니다.\n서버 설정 link서버 설정에서 중요한 부분은 [고가용성 지원] 항목입니다. Slave DB를 추가하기 위해서는 [고가용성 지원] 항목을 체크해야 합니다. 혹시 고가용성 지원 없이 서버를 생성했을 경우 이후에 [고가용성 지원]을 설정하면 문제 없이 Slave DB를 추가할 수 있습니다.\nDB 설정 link그 외 필요한 DB 설정을 입력합니다. 여기서 Backup 설정은 고가용성을 선택했을 경우 자동으로 사용하도록 설정됩니다.\nSlave DB 추가 linkDB 서버 생성이 완료되면 아래와 같이 [Master], [Standy Master] 2대의 서버가 생성된 것을 확인할 수 있습니다.\nMaster 서버를 선택하고 [DB 관리] 메뉴에서 [Slave 추가]를 선택합니다.\nSlave DB 정보 linkSlave DB 서버 추가 팝업에서는 특별히 수정할 부분 없이 [예] 버튼을 클릭하면 추가 됩니다.\nSlave DB Server는 Master DB Server와 동일한 스펙 (DB Server 타입, 스토리지 타입, 스토리지 용량)및 DB Config 설정으로 생성됩니다. Slave DB Server 역시 Master DB Server와 동일한 요금이 청구되며, 사용한 시간으로 과금됩니다.\r생성 완료 linkSlave DB를 1대 생성했으면 동일한 방법으로 하나 더 생성합니다. 여기서는 [test-003], [test-004]라는 이름으로 생성되었습니다.\nACG 설정 link다음으로 방화벽 ACG를 미리 설정해야 하는데, Master DB를 선택하고 아래쪽에 있는 [ACG] 항목을 클릭합니다.\nACG 리스트에서 Cloud DB를 생성할때 자동으로 생성된 [cloud-db-OOOO]라는 이름의 ACG를 선택하고 [ACG 설정] 버튼을 클릭합니다.\n규칙 설정 linkACG에 설정이 필요한 규칙은 2가지입니다.\n부하 분산을 위한 Load Balancer -\u003e Cloud DB for MySQL로 접근을 허용하는 규칙 테스트를 위한 Server -\u003e Cloud DB for MySQL로 접근을 허용하는 규칙 Load Balancer -\u003e Cloud DB for MySQL로 접근을 허용하는 규칙은 Load Balancer 전용 ACG [ncloud-load-balancer]를 [접근 소스] 항목에 추가합니다.\nServer -\u003e Cloud DB for MySQL로 접근을 허용하는 규칙은 [접근 소스] 항목에 [Server IP] 또는 [Server에 설정된 ACG]를 입력하면 됩니다.\nLoad Balancer 생성 link마지막으로 로드밸런서를 생성해야 하는데, 로드밸런서를 생성할 때 Slave DB와 연결하려면 네트워크 항목을 [Private IP]로 설정해야 합니다.\n그리고 프로토콜은 TCP, 포트는 3306으로 설정하겠습니다.\n서버 추가 link[서버 추가] 화면에는 적용할 서버 리스트에 위에서 생성했던 Slave DB 서버가 나타나는데, 모두 선택하고 오른쪽으로 이동 시킵니다.\n설정에 이상이 없으면 로드밸런서가 생성되고, 적용 서버의 연결 상태가 모두 [성공]으로 나타납니다.\n테스트 서버 설정 link읽기 부하가 제대로 분산되는지 테스트 하기 위해 준비된 서버에 [MySQL Client]를 설치합니다.\ninfo\rCentOS 7부터는 yum으로 설치하는 MySQL의 기본 데이터베이스가 MariaDB로 변경되었습니다.\nyum -y install mysql\r부하 분산 테스트 link설치된 MySQL Client를 이용해서 Load Balancer IP로 접속한 후에 접속한 DB 서버의 호스트명을 확인하는 쿼리를 실행합니다.\n여러 차례 반복해보면 아래와 같이 위에서 추가했던 Slave DB [test-003], [test-004]에 각각 접속되는 것을 확인할 수 있습니다.\nmysql -h {Load Balancer IP} -u {계정} -p\rMySQL [(none)]\u003e SELECT @@hostname;\r[test-003]에 접속된 상태 link\r[test-004]에 접속된 상태 link\rDB 삭제 link테스트를 끝낸 DB를 삭제하려고 할 때 [Slave나 Recovery DB 서버가 있는 경우 Master DB를 삭제할 수 없습니다.]라는 메시지가 나타나는 것을 확인할 수 있습니다.\n그래서 DB를 삭제할 때는 [Slave DB]부터 삭제해야 하고, [Slave DB]를 삭제할 때에도 동시에 삭제할 수 없고 1대씩 차례로 삭제해야 합니다.\n참고 URL link Ncloud Cloud DB for MySQL 읽기 부하 분산 설정 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-2#읽기-부하-분산-설정\nVPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 로드밸런서로 분산시키는 방법\n"
            }
        );
    index.add(
            {
                id:  176 ,
                href: "\/docs\/database\/cloud-db-mysql\/load-balance\/vpc-network-lb\/",
                title: "Cloud DB for MySQL 읽기 부하를 네트워크 로드밸런서로 분산시키는 방법 | VPC",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 Cloud DB for MySQL 서버의 읽기 부하를 네트워크 로드밸런서(Network Load Balancer)로 분산시키는 방법입니다",
                content: "개요 linkMySQL DB서버의 부하를 줄이기 위해 보통 읽기 전용 DB서버를 생성하게 되는데, 읽기 전용 서버를 여러대 생성해서 로드밸런서(Load Balancer)로 연결하면 읽기 부하를 분산 시키고 좀 더 안정적인 서비스가 가능해집니다.\n여기서는 Ncloud (네이버 클라우드) VPC 환경에서 관리형 DB인 Cloud DB for MySQL의 읽기 전용 Slave DB를 네트워크 로드밸런서(Network Load Balancer)에 연결하고 제대로 부하가 분산되는지 확인해보겠습니다.\n사전 준비 linkDB 접속과 부하 분산을 테스트할 서버가 필요합니다. 여기서는 CentOS 7.8 서버를 준비했습니다.\nDB 서버 생성 link우선 [Cloud DB for MySQL] - [DB Server]에서 DB를 생성합니다.\n서버 설정 linkDB엔진 버전과 VPC, 그리고 Subnet을 선택합니다.\n[고가용성 지원]을 선택하면 [Standby DB]도 추가로 생성되고, [Multi Zone]을 선택하면 Master와 Standby Master DB를 각각 [서로 다른 Zone에 생성]해서 안정성을 높일 수 있습니다.\nDB 서버 타입, 스토리지 타입, 스토리지 용량, DB 서버 이름, DB 서비스 이름 등을 입력합니다.\nPrivate Sub 도메인을 선택하고 입력하면 [*.{Private Sub Domain}.vpc-cdb.ntruss.com] 같은 형식으로 도메인이 생성됩니다.\nDB 설정 linkUSER ID, DB 접근 HOST(IP), USER 암호, 접속 포트, DB명 등을 입력합니다.\n고가용성을 선택한 경우 [Backup]은 기본으로 무조건 사용하게 됩니다.\nreport\r접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\nSlave DB Server 추가 linkDB가 생성되었으면 [Master] DB를 선택하고, [DB 관리]에서 [Slave 추가] 메뉴를 선택합니다.\nSlave DB Server를 추가할 때 설정할 수 있는 것은 Subnet 입니다. 부하 분산을 위해서는 2대 이상을 추가해야 하는데, 여기서는 테스트를 위해 2대를 추가하겠습니다.\n우선 첫번째 Slave DB Server는 KR-2 존에 추가했습니다.\n다음으로 두번째 Slave DB Server는 KR-1 존에 추가해보겠습니다.\n이렇게 Slave DB Server 2대를 추가해서 [Master], [Standy Master] 포함 총 4대의 서버가 생성되었습니다.\n[Master] DB 서버와 첫번째 [Slave] DB 서버는 KR-2 존에, [Standy Master] DB 서버와 두번째 [Slave] DB 서버는 KR-1 존에 생성해서 안정성을 높이는 구조를 선택했습니다.\rTarget Group 설정 link다음으로 Load Balancer와 Cloud DB for Mysql을 연결할 Target Group을 설정해보겠습니다.\nTarget Group 생성 link여기서 중요한 항목은 프로토콜입니다. [Network Load Balancer]에 사용할 Target Group이므로 [TCP]를 선택합니다.\n포트는 Cloud DB for Mysql 생성 시에 사용했던 포트를 입력해야 하는데 여기서는 3306을 사용하겠습니다.\nHealth Check 설정 linkHealth Check 설정에서는 TCP 프로토콜을 선택합니다. 포트는 마찬가지로 3306을 입력합니다.\nTarget 추가 linkTarget 추가 화면에 가면 앞에서 생성했던 Slave DB Server 2대를 확인할 수 있는데, 선택 후에 오른쪽으로 이동시킵니다.\nLoad Balancer 생성 link여기서는 [네트워크 프록시 로드밸런서 (Network Load Balancer)]를 선택합니다.\n애플리케이션 로드밸런서-Application Load Balancer는 Cloud DB for MySQL의 부하분산에 사용할 수 없습니다.\r로드밸런서 생성 link현재 네트워크 로드밸런서는 멀티존으로 구성할 수 없습니다. 그래서 서브넷 선택에서도 1개만 선택할 수 있습니다.\n리스너 설정 link리스너 프로토콜은 TCP, 포트는 3306으로 설정합니다.\nTarget Group 선택 link위에서 생성했던 Target Group을 선택합니다.\nACG 설정 link네트워크 로드밸런서와 연동을 할 때는 로드밸런서의 Subnet 대역 뿐만 아니라 [네트워크 로드밸런서]에 접근하는 장비의 공인 IP를 [Cloud DB for MySQL]의 ACG에 추가해야 합니다.\n⁃ 네트워크 로드밸런서는 보다 고속으로 분산처리를 하기 위해 DSR(Direct Server Return)로 동작합니다. ⁃ 그래서 로드밸런서에 접속하는 서버 IP를 Target Group에 묶인 장비(여기서는 DB 서버)에 그대로 전달하게 됩니다. ⁃ 그러므로 ACG에는 로드밸런서의 Subnet 대역이 아닌 접속하는 서버의 공인 IP를 허용해 주어야 합니다.\rTest 서버 공인 IP 확인 link테스트를 위해 미리 준비해 둔 CentOS를 설치한 서버입니다. ACG 설정에 추가할 공인 IP를 확인합니다.\nLoad Balancer 서브넷 확인 linkACG에 추가할 멀티존으로 구성된 로드밸런서의 서브넷을 확인합니다.\n그리고, 테스트 시에 접속할 로드밸런서의 접속 정보를 메모해 둡니다.\nACG 확인 link[Cloud DB for MySQL]의 [Master] DB를 선택하고 [ACG] 항목 옆의 버튼을 클릭합니다.\n[ACG] 리스트에서 해당 ACG를 선택하고 [ACG 설정] 버튼을 클릭합니다.\nACG 규칙 추가 link필요한 ACG 규칙을 추가합니다. 여기서는 테스트에 필요한 다음 항목들을 추가했습니다.\nTest CentOS Server -\u003e Cloud DB for MySQL 접근 규칙 Load Balancer -\u003e Cloud DB for MySQL 접근 규칙 테스트 서버 설정 linkDB 부하 분산 테스트에 사용할 서버에 MySQL Client를 설치합니다.\ninfo\rCentOS 7부터는 yum으로 설치하는 MySQL의 기본 데이터베이스가 MariaDB로 변경되었습니다.\nyum -y install mysql\r부하 분산 테스트 link설치된 MySQL Client를 이용해서 Load Balancer 도메인으로 접속한 후에 접속한 DB 서버의 호스트명을 확인하는 쿼리를 실행합니다.\n여러 차례 반복해보면 아래와 같이 위에서 추가했던 Slave DB [test-003-OOO], [test-004-OOO]에 각각 접속되는 것을 확인할 수 있습니다.\nmysql -h {Load Balancer 접속 도메인} -u {계정} -p\rMySQL [(none)]\u003e SELECT @@hostname;\r[test-003-OOO]에 접속된 상태 link\r[test-004-OOO]에 접속된 상태 link\rDB 삭제 link테스트를 끝낸 DB를 삭제하려고 할 때 [Slave나 Recovery DB 서버가 있는 경우 Master DB를 삭제할 수 없습니다.]라는 메시지가 나타나는 것을 확인할 수 있습니다.\n그래서 DB를 삭제할 때는 [Slave DB]부터 삭제해야 하고, [Slave DB]를 삭제할 때에도 동시에 삭제할 수 없고 1대씩 차례로 삭제해야 합니다.\n참고 URL link Ncloud Cloud DB for MySQL 읽기 부하 분산 설정 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-2#읽기-부하-분산-설정\nClassic 환경 Cloud DB for MySQL 읽기 부하를로드밸런서로 분산시키는 방법\n"
            }
        );
    index.add(
            {
                id:  177 ,
                href: "\/docs\/database\/cloud-db-mysql\/load-balance\/vpc-network-proxy-lb\/",
                title: "Cloud DB for MySQL 읽기 부하를 네트워크 프록시 로드밸런서로 분산시키는 방법 | VPC",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 Cloud DB for MySQL 서버의 읽기 부하를 네트워크 프록시 로드밸런서(Network Load Balancer)로 분산시키는 방법입니다",
                content: "개요 linkMySQL DB서버의 부하를 줄이기 위해 보통 읽기 전용 DB서버를 생성하게 되는데, 읽기 전용 서버를 여러대 생성해서 로드밸런서(Load Balancer)로 연결하면 읽기 부하를 분산 시키고 좀 더 안정적인 서비스가 가능해집니다.\n여기서는 Ncloud (네이버 클라우드) VPC 환경에서 관리형 DB인 Cloud DB for MySQL의 읽기 전용 Slave DB를 네트워크 프록시 로드밸런서(Network Proxy Load Balancer)에 연결하고 제대로 부하가 분산되는지 확인해보겠습니다.\n사전 준비 linkDB 접속과 부하 분산을 테스트할 서버가 필요합니다. 여기서는 CentOS 7.8 서버를 준비했습니다.\nDB 서버 생성 link우선 [Cloud DB for MySQL] - [DB Server]에서 DB를 생성합니다.\n서버 설정 linkDB엔진 버전과 VPC, 그리고 Subnet을 선택합니다.\n[고가용성 지원]을 선택하면 [Standby DB]도 추가로 생성되고, [Multi Zone]을 선택하면 Master와 Standby Master DB를 각각 [서로 다른 Zone에 생성]해서 안정성을 높일 수 있습니다.\nDB 서버 타입, 스토리지 타입, 스토리지 용량, DB 서버 이름, DB 서비스 이름 등을 입력합니다.\nPrivate Sub 도메인을 선택하고 입력하면 [*.{Private Sub Domain}.vpc-cdb.ntruss.com] 같은 형식으로 도메인이 생성됩니다.\nDB 설정 linkUSER ID, DB 접근 HOST(IP), USER 암호, 접속 포트, DB명 등을 입력합니다.\n고가용성을 선택한 경우 [Backup]은 기본으로 무조건 사용하게 됩니다.\nreport\r접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\nSlave DB Server 추가 linkDB가 생성되었으면 [Master] DB를 선택하고, [DB 관리]에서 [Slave 추가] 메뉴를 선택합니다.\nSlave DB Server를 추가할 때 설정할 수 있는 것은 Subnet 입니다. 부하 분산을 위해서는 2대 이상을 추가해야 하는데, 여기서는 테스트를 위해 2대를 추가하겠습니다.\n우선 첫번째 Slave DB Server는 KR-2 존에 추가했습니다.\n다음으로 두번째 Slave DB Server는 KR-1 존에 추가해보겠습니다.\n이렇게 Slave DB Server 2대를 추가해서 [Master], [Standy Master] 포함 총 4대의 서버가 생성되었습니다.\n[Master] DB 서버와 첫번째 [Slave] DB 서버는 KR-2 존에, [Standy Master] DB 서버와 두번째 [Slave] DB 서버는 KR-1 존에 생성해서 안정성을 높이는 구조를 선택했습니다.\rTarget Group 설정 link다음으로 Load Balancer와 Cloud DB for Mysql을 연결할 Target Group을 설정해보겠습니다.\nTarget Group 생성 link여기서 중요한 항목은 프로토콜입니다. [Network Proxy Load Balancer]에 사용할 Target Group이므로 [PROXY_TCP]를 선택합니다.\n포트는 Cloud DB for Mysql 생성 시에 사용했던 포트를 입력해야 하는데 여기서는 3306을 사용하겠습니다.\nHealth Check 설정 linkHealth Check 설정에서는 TCP 프로토콜을 선택합니다. 포트는 마찬가지로 3306을 입력합니다.\nTarget 추가 linkTarget 추가 화면에 가면 앞에서 생성했던 Slave DB Server 2대를 확인할 수 있는데, 선택 후에 오른쪽으로 이동시킵니다.\nLoad Balancer 생성 link여기서는 [네트워크 프록시 로드밸런서 (Network Proxy Load Balancer)]를 선택합니다.\n애플리케이션 로드밸런서-Application Load Balancer는 Cloud DB for MySQL의 부하분산에 사용할 수 없습니다.\r로드밸런서 생성 link안정성을 높이려면 로드밸런서도 멀티존으로 구성할 수 있습니다. KR-1, KR-2 두 곳의 서브넷을 모두 선택하겠습니다.\n리스너 설정 link리스너 프로토콜은 TCP, 포트는 3306으로 설정합니다.\nTarget Group 선택 link위에서 생성했던 Target Group을 선택합니다.\nACG 설정 link[Cloud DB for MySQL]에 접근하는 로드밸런서들의 Subnet 대역을 ACG에 추가해야 합니다.\nLoad Balancer 서브넷 확인 linkACG에 추가할 멀티존으로 구성된 로드밸런서의 서브넷 2가지를 확인합니다.\n그리고, 테스트 시에 접속할 로드밸런서의 접속 정보를 메모해 둡니다.\nACG 확인 link[Cloud DB for MySQL]의 [Master] DB를 선택하고 [ACG] 항목 옆의 버튼을 클릭합니다.\n[ACG] 리스트에서 해당 ACG를 선택하고 [ACG 설정] 버튼을 클릭합니다.\nACG 규칙 추가 link필요한 ACG 규칙을 추가합니다.\nLoad Balancer (KR-1) -\u003e Cloud DB for MySQL 접근 규칙 Load Balancer (KR-2) -\u003e Cloud DB for MySQL 접근 규칙 테스트 서버 설정 linkDB 부하 분산 테스트에 사용할 서버에 MySQL Client를 설치합니다.\ninfo\rCentOS 7부터는 yum으로 설치하는 MySQL의 기본 데이터베이스가 MariaDB로 변경되었습니다.\nyum -y install mysql\r부하 분산 테스트 link설치된 MySQL Client를 이용해서 Load Balancer 도메인으로 접속한 후에 접속한 DB 서버의 호스트명을 확인하는 쿼리를 실행합니다.\n여러 차례 반복해보면 아래와 같이 위에서 추가했던 Slave DB [test-003-OOO], [test-004-OOO]에 각각 접속되는 것을 확인할 수 있습니다.\nmysql -h {Load Balancer 접속 도메인} -u {계정} -p\rMySQL [(none)]\u003e SELECT @@hostname;\r[test-003-OOO]에 접속된 상태 link\r[test-004-OOO]에 접속된 상태 link\rDB 삭제 link테스트를 끝낸 DB를 삭제하려고 할 때 [Slave나 Recovery DB 서버가 있는 경우 Master DB를 삭제할 수 없습니다.]라는 메시지가 나타나는 것을 확인할 수 있습니다.\n그래서 DB를 삭제할 때는 [Slave DB]부터 삭제해야 하고, [Slave DB]를 삭제할 때에도 동시에 삭제할 수 없고 1대씩 차례로 삭제해야 합니다.\n참고 URL link Ncloud Cloud DB for MySQL 읽기 부하 분산 설정 가이드\nhttps://guide.ncloud-docs.com/docs/database-database-5-2#읽기-부하-분산-설정\nVPC 환경 Cloud DB for MySQL 읽기 부하를 네트워크 프록시 로드밸런서로 분산시키는 방법\n"
            }
        );
    index.add(
            {
                id:  178 ,
                href: "\/docs\/database\/cloud-db-mysql\/db-migration\/from-mysql57-to-mysql57-guide\/",
                title: "Ncloud 데이터베이스 마이그레이션 서비스 | From MySQL 5.7 To MySQL 5.7",
                description: "Ncloud(네이버 클라우드) Database Migration 서비스를 이용해 MySQL 5.7에서 클라우드 환경 Cloud DB for MySQL 5.7로 마이그레이션하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 MySQL 5.7을 Private 환경의 [Cloud DB for MySQL 5.7]로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n서비스에서 제공하는 기능 link 마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화 Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능 연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행 마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능 지원 데이터베이스 linkDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\nMajor 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다. Source DB는 MariaDB도 가능합니다. Target DB는 MySQL만 가능합니다. 상세 설정 지원 여부 linkSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n지원 항목 link 데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원 Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원 미지원 항목 link TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원 사용자 계정 정보, MySQL Config 항목, Event 마이그레이션 미지원 마이그레이션 진행 구조 link마이그레이션은 Target DB -\u003e Source DB로 접근하여 DB 데이터를 가져오는 방식으로 진행됩니다.\n또한 작업 진행 단계는 다음과 같습니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 완료 상태 마이그레이션 작업 완료 서비스 점검 link마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 상태 서비스 점검 시작 마이그레이션 작업 완료 서비스 점검 종료 테스트 환경 linkSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\nSource DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다. Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다. Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다. Target DB는 NAT Gateway를 통해서 Source DB에 접근한다. DB 버전 정보 link Source DB: CentOS 7.8, MySQL 5.7.43 Target DB: Cloud DB for MySQL 5.7.40 Source DB\rTarget DB\rSource DB 정보 확인 link테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\nMySQL 버전\rDatabase\r계정\rTable\rProcedure\r테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MySQL 5.7.43입니다.\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\nSource DB 사전 설정 link마이그레이션 전용 DB User 생성 link마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` \u0026 + \\ \" ’ / 스페이스 는 패스워드로 사용할 수 없습니다. 기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다. CREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password' BY '[패스워드]';\rGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\rGRANT SELECT ON mysql.* TO 'migration_test'@'%';\rGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\rFLUSH PRIVILEGES;\r위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다. Character Set 점검 linkTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\nCharacter Set 점검 쿼리 SELECT character_set_name\rFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\rWHERE CCSA.collation_name = T.table_collation AND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\rSELECT DEFAULT_CHARACTER_SET_NAME\rFROM information_schema.SCHEMATA T\rWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\rCharacter Set 변경 쿼리 예시 ALTER DATABASE [데이터베이스명] CHARACTER SET utf8;\rALTER DATABASE [데이터베이스명] CHARACTER SET utf8 COLLATE utf8_general_ci;\rALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci;\r바이너리 로그 설정 linkSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n현재 설정 확인 link아래 쿼리를 사용해 현재 설정 값을 확인합니다.\nshow variables like 'server_id';\rshow variables like 'log_bin';\r현재 테스트용 Source DB는 두 값이 모두 설정되어 있지 않은 상태입니다. 설정 변경 linkMySQL의 환경 설정 파일 [my.cnf]를 열어서 아래 값을 추가하고, MySQL 데몬을 재시작합니다.\n~# vim /etc/my.cnf\rserver_id = 1\rlog_bin = binlog\r~# systemctl restart mysqld\r변경 설정 확인 link설정 변경 후에 확인해보면 아래와 같이 [server_id] 값이 설정되어 있고, [log_bin]이 ON 상태로 변경된 것을 알 수 있습니다.\nTarget DB 사전 설정 link위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\nDEFINER 계정 확인 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\nSELECT DEFINER FROM information_schema.ROUTINES\rWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\rSELECT DEFINER FROM information_schema.VIEWS\rWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\r위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다. 위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.\rDEFINER 계정 추가 link[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\nDB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다. 접근 권한 설정 link[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB -\u003e Source DB로 접근하게 됩니다.\nNAT Gateway 생성 link현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n[NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다. VPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n⁃ VPC 환경에서 NAT Gateway 생성하는 방법\rRoute Table 설정 link다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\nRoute Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다. 방화벽(ACG) 설정 linkTarget DB -\u003e Source DB로 접근하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을, [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\nTarget DB ACG 설정 link우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n[ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다. [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다. Source DB 방화벽 설정 link이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\nOn Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\nNcloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n마이그레이션 서비스 위치 link이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n마이그레이션 설정 link[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\nEndpoint 설정 link우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\nEndpoint URL: Source DB의 IP 또는 도메인을 입력합니다. DB PORT: Source DB의 Port를 입력합니다. DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다. DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다. 마이그레이션 작업 생성 link[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\nTest Connection link[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB -\u003e Source DB로 접근을 테스트 해봅니다.\n마이그레이션 작업 시작 link[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n마이그레이션 작업 진행 상태 link마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n진행 상태 확인 메일 link진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\nExport Completed\rImport Completed\rMigration Completed\r이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다.\r마이그레이션 완료 link마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 복제 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n[완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다. 최종 완료 link최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\nTarget DB 데이터 확인 link마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고, [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n오류 상황 link지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n방화벽 설정 오류 link[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정 내용을 다시 확인해주세요.\nSource DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG를 점검해 주세요.\rEndpoint DB User 설정 오류 link[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정 내용을 다시 확인해주세요.\nSource DB 에 접속이 되지 않습니다.\nDB ACL 을 점검해 주세요.\rDEFINER 계정 생성 오류 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정 내용을 다시 확인해주세요.\nSource DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.\nDefiner 에 사용된 계정은 먼저 생성후 진행해 주세요.\n필요 Definer 계정 : abcd2@%\r바이너리 로그 설정 오류 linkSource DB의 바이너리 로그 설정 중에서, [server_id], [log_bin] 관련 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 바이너리 로그 설정 내용을 다시 확인해주세요.\n마이그레이션을 위해서는 Source DB Config 설정이 필요합니다.\n추가 필요 설정 : log_bin\r참고 URL link Database Migration Service 개요\nhttps://guide.ncloud-docs.com/docs/ko/dms-overview\nSource DB 및 Target DB 접속 설정\nhttps://guide.ncloud-docs.com/docs/dms-connect\n문서 업데이트 내역 link\r날짜 내용 2023-10-23 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  179 ,
                href: "\/docs\/database\/cloud-db-mysql\/db-migration\/from-mysql57-to-mysql80-guide\/",
                title: "Ncloud 데이터베이스 마이그레이션 서비스 | From MySQL 5.7 To MySQL 8.0",
                description: "Ncloud(네이버 클라우드) Database Migration 서비스를 이용해 MySQL 5.7에서 클라우드 환경 Cloud DB for MySQL 8.0으로 마이그레이션하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 MySQL 5.7을 Private 환경의 [Cloud DB for MySQL 8.0]으로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n서비스에서 제공하는 기능 link 마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화 Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능 연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행 마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능 지원 데이터베이스 linkDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\nMajor 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다. Source DB는 MariaDB도 가능합니다. Target DB는 MySQL만 가능합니다. 상세 설정 지원 여부 linkSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n지원 항목 link 데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원 Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원 미지원 항목 link TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원 사용자 계정 정보, MySQL Config 항목, Event 마이그레이션 미지원 마이그레이션 진행 구조 link마이그레이션은 Target DB -\u003e Source DB로 접근하여 DB 데이터를 가져오는 방식으로 진행됩니다.\n또한 작업 진행 단계는 다음과 같습니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 완료 상태 마이그레이션 작업 완료 서비스 점검 link마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 상태 서비스 점검 시작 마이그레이션 작업 완료 서비스 점검 종료 테스트 환경 linkSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\nSource DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다. Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다. Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다. Target DB는 NAT Gateway를 통해서 Source DB에 접근한다. DB 버전 정보 link Source DB: CentOS 7.8, MySQL 5.7.43 Target DB: Cloud DB for MySQL 8.0.32 Source DB\rTarget DB\rSource DB 정보 확인 link테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\nMySQL 버전\rDatabase\r계정\rTable\rProcedure\r테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MySQL 5.7.43입니다.\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\nSource DB 사전 설정 link마이그레이션 전용 DB User 생성 link마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` \u0026 + \\ \" ’ / 스페이스 는 패스워드로 사용할 수 없습니다. 기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다. CREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password' BY '[패스워드]';\rGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\rGRANT SELECT ON mysql.* TO 'migration_test'@'%';\rGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\rFLUSH PRIVILEGES;\r위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다. Character Set 점검 linkTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\nCharacter Set 점검 쿼리 SELECT character_set_name\rFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\rWHERE CCSA.collation_name = T.table_collation AND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\rSELECT DEFAULT_CHARACTER_SET_NAME\rFROM information_schema.SCHEMATA T\rWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\rCharacter Set 변경 쿼리 예시 ALTER DATABASE [데이터베이스명] CHARACTER SET utf8;\rALTER DATABASE [데이터베이스명] CHARACTER SET utf8 COLLATE utf8_general_ci;\rALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci;\rsql_mode 설정 점검 linkMySQL 5.7 버전에서 Default 값으로 지원하는 sql_mode=‘NO_AUTO_CREATE_USER’ 설정은 MySQL 8.0 버전부터는 지원하지 않기 때문에, Source DB에서 사용된 곳이 있으면 찾아서 해당 옵션을 제거해야 합니다.\nsql_mode 설정 점검 쿼리 linkProcedure, Function 등의 ROUTINE과 TRIGGER에서 사용되므로 아래 쿼리로 [NO_AUTO_CREATE_USER] 옵션이 사용된 곳이 있는지 점검합니다.\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\rFROM information_schema.routines\rWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\rSELECT TRIGGER_SCHEMA, TRIGGER_NAME, sql_mode\rFROM information_schema.triggers\rWHERE TRIGGER_SCHEMA NOT IN ('sys','mysql');\r테스트용 Source DB에서 점검 쿼리를 실행해보면 아래와 같이 [testdb2]의 [new_procedure2]에 [NO_AUTO_CREATE_USER] 옵션이 적용되어 있는 것을 확인할 수 있습니다. sql_mode 호환성 이슈 조치 방법 linkProcedure, Function, Trigger의 Dump 파일을 생성하고 [NO_AUTO_CREATE_USER] 옵션을 제거한 후 다시 적용하면 됩니다.\nProcedure, Function, Trigger 에 대해서만 drop 및 create 구문이 생성된 sql 파일 생성 mysqldump -u {사용자명} -p --set-gtid-purged=OFF --routines --triggers --no-create-info --no-data --no-create-db --add-drop-trigger --databases {사용자 DB} \u003e backup.sql\rbackup.sql 파일내 NO_AUTO_CREATE_USER 구문 모두 제거\n해당 옵션을 일일이 찾아서 제거하기 힘드니 vim 에디터에서 [NO_AUTO_CREATE_USER] 문자를 찾아서 제거하는 명령을 실행합니다.\n경우에 따라서는 Dump 파일에 [NO_AUTO_CREATE_USER] 옵션이 포함되지 않는 경우도 있습니다. 이때는 걱정말고 Dump 파일을 그냥 그대로 적용하면 됩니다. vim 명령: %s /NO_AUTO_CREATE_USER,//g\r원본 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION' 수정 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION'\r적용하기\n수정된 Dump 파일을 Source DB에 적용합니다. mysql -u {사용자명} -p {사용자 DB} \u003c backup.sql\rsql_mode 설정 변경 확인 link설정이 제대로 변경되었는지 점검 쿼리로 다시 확인해보겠습니다.\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\rFROM information_schema.routines\rWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\r아래 스샷처럼 [NO_AUTO_CREATE_USER] 옵션이 사라진 것을 확인할 수 있습니다. 바이너리 로그 설정 linkSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n현재 설정 확인 link아래 쿼리를 사용해 현재 설정 값을 확인합니다.\nshow variables like 'server_id';\rshow variables like 'log_bin';\r현재 테스트용 Source DB는 두 값이 모두 설정되어 있지 않은 상태입니다. 설정 변경 linkMySQL의 환경 설정 파일 [my.cnf]를 열어서 아래 값을 추가하고, MySQL 데몬을 재시작합니다.\nvim /etc/my.cnf\rserver_id = 1\rlog_bin = binlog\rsystemctl restart mysqld\r변경 설정 확인 link설정 변경 후에 확인해보면 아래와 같이 [server_id] 값이 설정되어 있고, [log_bin]이 ON 상태로 변경된 것을 알 수 있습니다.\nTarget DB 사전 설정 link위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\nDEFINER 계정 확인 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\nSELECT DEFINER FROM information_schema.ROUTINES\rWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\rSELECT DEFINER FROM information_schema.VIEWS\rWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\r위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다. 위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.\rDEFINER 계정 추가 link[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\nDB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다. 접근 권한 설정 link[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB -\u003e Source DB로 접근하게 됩니다.\nNAT Gateway 생성 link현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n[NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다. VPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n⁃ VPC 환경에서 NAT Gateway 생성하는 방법\rRoute Table 설정 link다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\nRoute Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다. 방화벽(ACG) 설정 linkTarget DB -\u003e Source DB로 접근하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을, [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\nTarget DB ACG 설정 link우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n[ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다. [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다. Source DB 방화벽 설정 link이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\nOn Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\nNcloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n마이그레이션 서비스 위치 link이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n마이그레이션 설정 link[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\nEndpoint 설정 link우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\nEndpoint URL: Source DB의 IP 또는 도메인을 입력합니다. DB PORT: Source DB의 Port를 입력합니다. DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다. DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다. 마이그레이션 작업 생성 link[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\nTest Connection link[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB -\u003e Source DB로 접근을 테스트 해봅니다.\n마이그레이션 작업 시작 link[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n마이그레이션 작업 진행 상태 link마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n진행 상태 확인 메일 link진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\nExport Completed\rImport Completed\rMigration Completed\r이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다.\r마이그레이션 완료 link마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n[완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다. 최종 완료 link최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\nTarget DB 데이터 확인 link마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고, [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n오류 상황 link지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n방화벽 설정 오류 link[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정 내용을 다시 확인해주세요.\nSource DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG를 점검해 주세요.\rEndpoint DB User 설정 오류 link[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정 내용을 다시 확인해주세요.\nSource DB 에 접속이 되지 않습니다.\nDB ACL 을 점검해 주세요.\rDEFINER 계정 생성 오류 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정 내용을 다시 확인해주세요.\nSource DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.\nDefiner 에 사용된 계정은 먼저 생성후 진행해 주세요.\n필요 Definer 계정 : abcd2@%\r바이너리 로그 설정 오류 linkSource DB의 바이너리 로그 설정 중에서, [server_id], [log_bin] 관련 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 바이너리 로그 설정 내용을 다시 확인해주세요.\n마이그레이션을 위해서는 Source DB Config 설정이 필요합니다.\n추가 필요 설정 : log_bin\rsql_mode 설정 오류 link[Source DB] 사전 설정에서 sql_mode 관련된 설정을 수정하지 않았을 경우 아래와 같이 마이그레이션 진행 중에 [Importing] 단계에서 실패가 발생하고 [에러 보기] 버튼을 클릭하면 아래와 같은 메시지가 나타납니다. sql_mode 설정 내용을 다시 확인해주세요.\nERROR 1234 (42000) at line 98: Variable ‘sql_mode’ can’t be set to the value of ‘NO_AUTO_CREATE_USER\r마이그레이션 재실행 link위와 같이 [sql_mode] 관련 오류로 마이그레이션 작업이 실패했을 경우에는 [재시작] 버튼으로 재시작을 할 경우에는 동일한 오류가 계속 발생하게 됩니다.\n이때는 [sql_mode] 설정을 수정한 후에 마이그레이션 작업을 삭제하고, [Target DB]에 생성된 [Database]을 모두 삭제 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n[sql_mode] 설정을 수정한 후에 [삭제] 버튼을 클릭해서 마이그레이션 작업을 삭제합니다. [Target DB]의 [DB 관리] - [DB Server 상세보기] 메뉴를 클릭해서 [Database 관리] 기능으로 이동합니다. [Database 관리]에서 [Source DB]에서 Import한 [Database]을 모두 삭제하고, [저장] 버튼을 클릭합니다.\n그런 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다. 참고 URL link Database Migration Service 개요\nhttps://guide.ncloud-docs.com/docs/ko/dms-overview\nSource DB 및 Target DB 접속 설정\nhttps://guide.ncloud-docs.com/docs/dms-connect\n문서 업데이트 내역 link\r날짜 내용 2023-10-24 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  180 ,
                href: "\/docs\/database\/cloud-db-mysql\/db-migration\/from-mysql80-to-mysql80-guide\/",
                title: "Ncloud 데이터베이스 마이그레이션 서비스 | From MySQL 8.0 To MySQL 8.0",
                description: "Ncloud(네이버 클라우드) Database Migration 서비스를 이용해 MySQL 8.0에서 클라우드 환경 Cloud DB for MySQL 8.0으로 마이그레이션하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 MySQL 8.0을 Private 환경의 [Cloud DB for MySQL 8.0]으로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n서비스에서 제공하는 기능 link 마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화 Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능 연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행 마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능 지원 데이터베이스 linkDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\nMajor 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다. Source DB는 MariaDB도 가능합니다. Target DB는 MySQL만 가능합니다. 상세 설정 지원 여부 linkSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n지원 항목 link 데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원 Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원 미지원 항목 link TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원 사용자 계정 정보, MySQL Config 항목, Event 마이그레이션 미지원 마이그레이션 진행 구조 link마이그레이션은 Target DB -\u003e Source DB로 접근하여 DB 데이터를 가져오는 방식으로 진행됩니다.\n또한 작업 진행 단계는 다음과 같습니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 완료 상태 마이그레이션 작업 완료 서비스 점검 link마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 상태 서비스 점검 시작 마이그레이션 작업 완료 서비스 점검 종료 테스트 환경 linkSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\nSource DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다. Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다. Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다. Target DB는 NAT Gateway를 통해서 Source DB에 접근한다. DB 버전 정보 link Source DB: CentOS 7.8, MySQL 8.0.35 Target DB: Cloud DB for MySQL 8.0.32 Source DB\rTarget DB\rSource DB 정보 확인 link테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\nMySQL 버전\rDatabase\r계정\rTable\rProcedure\r테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MySQL 8.0.35입니다.\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\nSource DB 사전 설정 link마이그레이션 전용 DB User 생성 link마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` \u0026 + \\ \" ’ / 스페이스 는 패스워드로 사용할 수 없습니다. 반드시 mysql_native_password 형식으로 생성된 패스워드를 사용해야 합니다. 기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다. MySQL 8.0.20 이상은 8.0.19 이하 버전과 다르게 ROUTINE Dump를 위한 SHOW_ROUTINE 권한이 필수이니 버전에 맞게 쿼리를 사용해야 합니다. 8.0.20 이상\r8.0.19 이하\r⁃ 위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다.\nCREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password' BY '[패스워드]';\rGRANT SHOW_ROUTINE, RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\rGRANT SELECT ON mysql.* TO 'migration_test'@'%';\rGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\rFLUSH PRIVILEGES;\r⁃ 위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다.\nCREATE USER 'migration_test'@'%' IDENTIFIED WITH 'mysql_native_password' BY '[패스워드]';\rGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\rGRANT SELECT ON mysql.* TO 'migration_test'@'%';\rGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\rFLUSH PRIVILEGES;\rCharacter Set 점검 linkTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\nCharacter Set 점검 쿼리 SELECT character_set_name\rFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\rWHERE CCSA.collation_name = T.table_collation AND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\rSELECT DEFAULT_CHARACTER_SET_NAME\rFROM information_schema.SCHEMATA T\rWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\rCharacter Set 변경 쿼리 예시 ALTER DATABASE [데이터베이스명] CHARACTER SET utf8mb4;\rALTER DATABASE [데이터베이스명] CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\rALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\r바이너리 로그 설정 linkSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n현재 설정 확인 link아래 쿼리를 사용해 현재 설정 값을 확인합니다.\nshow variables like 'server_id';\rshow variables like 'log_bin';\rMySQL 8.0 부터는 기본적으로 설정이 되어 있으므로, 보통의 경우 특별한 조치 없이 그대로 진행하면 됩니다. Target DB 사전 설정 link위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\nDEFINER 계정 확인 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\nSELECT DEFINER FROM information_schema.ROUTINES\rWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\rSELECT DEFINER FROM information_schema.VIEWS\rWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\r위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다. 위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.\rDEFINER 계정 추가 link[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\nDB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다. 접근 권한 설정 link[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB -\u003e Source DB로 접근하게 됩니다.\nNAT Gateway 생성 link현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n[NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다. VPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n⁃ VPC 환경에서 NAT Gateway 생성하는 방법\rRoute Table 설정 link다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\nRoute Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다. 방화벽(ACG) 설정 linkTarget DB -\u003e Source DB로 접근하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을, [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\nTarget DB ACG 설정 link우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n[ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다. [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다. Source DB 방화벽 설정 link이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\nOn Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\nNcloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n마이그레이션 서비스 위치 link이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n마이그레이션 설정 link[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\nEndpoint 설정 link우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\nEndpoint URL: Source DB의 IP 또는 도메인을 입력합니다. DB PORT: Source DB의 Port를 입력합니다. DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다. DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다. 마이그레이션 작업 생성 link[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\nTest Connection link[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB -\u003e Source DB로 접근**을 테스트 해봅니다.\n마이그레이션 작업 시작 link[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n마이그레이션 작업 진행 상태 link마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n진행 상태 확인 메일 link진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\nExport Completed\rImport Completed\rMigration Completed\r이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다.\r마이그레이션 완료 link마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n[완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다. 최종 완료 link최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\nTarget DB 데이터 확인 link마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고, [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n오류 상황 link지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n방화벽 설정 오류 link[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정 내용을 다시 확인해주세요.\nSource DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG를 점검해 주세요.\rEndpoint DB User 설정 오류 link[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정 내용을 다시 확인해주세요.\nSource DB 에 접속이 되지 않습니다.\nDB ACL 을 점검해 주세요.\rDEFINER 계정 생성 오류 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정 내용을 다시 확인해주세요.\nSource DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.\nDefiner 에 사용된 계정은 먼저 생성후 진행해 주세요.\n필요 Definer 계정 : abcd2@%\r마이그레이션 재실행 link그 외의 오류로 마이그레이션 작업이 실패했을 경우 아래와 같이 [재시작], [삭제] 버튼이 활성화 되는데, [재시작] 버튼으로 재시작을 할 경우에는 동일한 오류가 계속 발생하는 경우가 있습니다.\n이때는 마이그레이션 작업을 삭제하고, [Target DB]에 생성된 [Database]을 모두 삭제 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n[삭제] 버튼을 클릭해서 마이그레이션 작업을 삭제합니다. [Target DB]의 [DB 관리] - [DB Server 상세보기] 메뉴를 클릭해서 [Database 관리] 기능으로 이동합니다. [Database 관리]에서 [Source DB]에서 Import한 [Database]을 모두 삭제하고, [저장] 버튼을 클릭합니다.\n그런 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다. 참고 URL link Database Migration Service 개요\nhttps://guide.ncloud-docs.com/docs/ko/dms-overview\nSource DB 및 Target DB 접속 설정\nhttps://guide.ncloud-docs.com/docs/dms-connect\n문서 업데이트 내역 link\r날짜 내용 2023-10-26 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  181 ,
                href: "\/docs\/database\/cloud-db-mysql\/db-migration\/from-mariadb-to-mysql80-guide\/",
                title: "Ncloud 데이터베이스 마이그레이션 서비스 | From MariaDB To MySQL 8.0",
                description: "Ncloud(네이버 클라우드) Database Migration 서비스를 이용해 MariaDB에서 클라우드 환경 Cloud DB for MySQL 8.0으로 마이그레이션하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)의 Database Migration Service는 다양한 환경의 데이터베이스를 클라우드 환경으로 손쉽게 마이그레이션하도록 도와주는 서비스로 여기서는 Public 환경의 [MariaDB]를 Private 환경의 [Cloud DB for MySQL 8.0]으로 마이그레이션하는 방법에 대해 정리해보겠습니다.\n서비스에서 제공하는 기능 link 마이그레이션의 단계별 작업 자동화: Migration 작업을 생성하여 마이그레이션에 필요한 단계별 작업 자동화 Endpoint 관리 기능: 손쉽게 Source DB Endpoint 생성 및 관리 가능 연결 테스트 기능: 마이그레이션 실행 전 Source DB와 Target DB 간 연결 테스트 진행 마이그레이션 작업 내역 모니터링: 마이그레이션 작업 상태와 내역 조회 가능 지원 데이터베이스 linkDatabase Migration Service는 MySQL 데이터베이스 간 마이그레이션을 지원합니다.\nMajor 버전이 동일한 데이터베이스 간의 마이그레이션이 권장됩니다. Source DB는 MariaDB도 가능합니다. Target DB는 MySQL만 가능합니다. ⁃ MariaDB도 마이그레이션이 가능하지만 MySQL 8.0과의 호환성 문제로 마이그레이션이 실패할 수도 있습니다. ⁃ 마이그레이션이 실패했을 경우에는 MariaDB -\u003e MySQL 5.7 -\u003e MySQL 8.0 이렇게 2단계로 마이그레이션 하는 방법을 시도해보시기 바랍니다.\r상세 설정 지원 여부 linkSource DB의 상세 설정에 따른 지원 여부는 다음과 같습니다.\n지원 항목 link 데이터베이스, TABLE의 캐릭터셋(CharacterSet): euckr, utf8(utf8mb3), utf8mb4 지원 Table, View, Stored Procedure, Function, Trigger 마이그레이션 지원 미지원 항목 link TABLE ENGINE: MyISAM, BLACKHOLE, FEDERATED, ARCHIVE 미지원 사용자 계정 정보, MariaDB Config 항목, Event 마이그레이션 미지원 마이그레이션 진행 구조 link마이그레이션은 Target DB **Source DB로 접근하여 DB 데이터를 가져오는 방식**으로 진행됩니다.\n또한 작업 진행 단계는 다음과 같습니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 완료 상태 마이그레이션 작업 완료 서비스 점검 link마이그레이션 작업을 진행할 때 서비스 점검을 언제할 것인가가 중요한 고려사항이 됩니다. 물론 가장 안전한 방법은 마이그레이션 작업 전에 서비스 점검을 시작하는 것이지만, DB의 용량이 클 경우는 [Export], [Import] 각각 몇 시간씩 소요될 수 있는데, 오랜 시간 서비스 점검을 하려면 부담이 될 수 밖에 없습니다.\n그러므로 오랜 시간 동안 서비스 점검을 하기 어려울 경우 다음과 같이 진행하면 되겠습니다.\n마이그레이션에서 [Export], [Import] 작업이 끝나면 두 DB간의 Replication 상태가 유지되는데 이때는 [Source DB]에 새로운 데이터가 추가되면 자동으로 [Target DB]로 복제가 됩니다. 그러므로 두 DB 간의 Replication이 완료 상태에서 서비스 점검을 시작하고 최종 마이그레이션 작업이 완료된 후에 서비스 점검을 종료하면 됩니다.\n[Source DB]에서 [Export] [Target DB]로 [Import] 두 DB 간의 Replication 상태 서비스 점검 시작 마이그레이션 작업 완료 서비스 점검 종료 테스트 환경 linkSource DB는 Ncloud(네이버 클라우드) 외부에 위치한 경우가 많을 것으로 예상되므로 다음과 같은 사항들을 가정하고 테스트 환경을 준비해보겠습니다.\nSource DB와 Target DB가 사설 네트워크로 접근이 불가능한 서로 다른 네트워크 환경에 존재한다. Source DB는 외부에서 공인 IP로 접근 가능한 Public 네트워크 환경에 존재한다. Target DB는 외부에서 접근이 불가능한 Private 네트워크 환경에 존재한다. Target DB는 NAT Gateway를 통해서 Source DB에 접근한다. DB 버전 정보 link Source DB: CentOS 7.8, MariaDB 10.4.31 Target DB: Cloud DB for MySQL 8.0.32 {% tabs db-verstion %}\n{% tab db-verstion Source DB %}\n⁃ Source DB\n{% endtab %}\n{% tab db-verstion Target DB %}\n⁃ Target DB\n{% endtab %}\n{% endtabs %}\nSource DB 정보 확인 link테스트에 사용할 Source DB의 버전, Database, DB User 등의 정보를 확인해보겠습니다.\n{% tabs sourcedb-setting %}\n{% tab sourcedb-setting MariaDB 버전 %}\n⁃ MariaDB 버전\n테스트에 사용할 DB는 아래에서 확인할 수 있듯이 MariaDB 5.7.43입니다.\n{% endtab %}\n{% tab sourcedb-setting Database %}\n⁃ Database\n테스트를 위해 testdb1, testdb2 이렇게 2개의 DB를 생성했습니다.\n{% endtab %}\n{% tab sourcedb-setting 계정 %}\n⁃ 계정\n테스트를 위한 abcd1, abcd2 이렇게 2개의 DB User를 생성했습니다.\n{% endtab %}\n{% tab sourcedb-setting Table %}\n⁃ Table\n테스트용 Database에 sampletable1, sampletable2 이렇게 각각 테이블을 1개씩 생성했습니다.\n{% endtab %}\n{% tab sourcedb-setting Procedure %}\n⁃ Procedure\n테스트용 Database testdb2에 new_procedure2라는 이름의 Procedure를 생성했습니다.\n{% endtab %}\n{% endtabs %}\nSource DB 사전 설정 link마이그레이션 전용 DB User 생성 link마이그레이션을 위한 전용 유저 즉, Target DB에서 Source DB로 접속할 때 사용할 DB User를 아래와 같이 생성합니다.\n패스워드는 최소 8자 이상, 최대 21 자까지만 입력이 가능합니다.\n영문 / 특수문자 / 숫자가 포함되어야 합니다.\n` \u0026 + \\ \" ’ / 스페이스 는 패스워드로 사용할 수 없습니다. 기본 시스템DB를 제외한 사용자가 추가로 생성한 모든 데이터베이스에 대해 권한을 부여합니다. CREATE USER 'migration_test'@'%' IDENTIFIED BY '[패스워드]';\rGRANT RELOAD, PROCESS, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'migration_test'@'%';\rGRANT SELECT ON mysql.* TO 'migration_test'@'%';\rGRANT SELECT, SHOW VIEW, LOCK TABLES, TRIGGER ON [사용자 생성 DB].* TO 'migration_test'@'%';\rFLUSH PRIVILEGES;\r위쪽에서 Source DB에 테스용으로 [testdb1], [testdb2] 이렇게 2개를 데이터베이스가 존재하므로 두 개의 데이터베이스 각각에 대해 권한을 부여했습니다. Character Set 점검 linkTarget DB로 생성되는 Cloud DB for MySQL은 [utf8, utf8mb4, euckr] Character Set만 지원합니다.\nSource DB에 이 외의 설정으로 되어 있다면 Character Set을 변경 후 마이그레이션을 진행해야 합니다.\nCharacter Set 점검 쿼리 SELECT character_set_name\rFROM information_schema.TABLES T, information_schema.COLLATION_CHARACTER_SET_APPLICABILITY CCSA\rWHERE CCSA.collation_name = T.table_collation AND TABLE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND CCSA.character_set_name NOT IN ( 'utf8', 'utf8mb4', 'euckr' );\rSELECT DEFAULT_CHARACTER_SET_NAME\rFROM information_schema.SCHEMATA T\rWHERE SCHEMA_NAME NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND DEFAULT_CHARACTER_SET_NAME NOT IN ( 'utf8', 'utf8mb4', 'euckr');\rCharacter Set 변경 쿼리 예시 ALTER DATABASE [데이터베이스명] CHARACTER SET utf8;\rALTER DATABASE [데이터베이스명] CHARACTER SET utf8 COLLATE utf8_general_ci;\rALTER TABLE [테이블명] CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci;\rsql_mode 설정 점검 linkMariaDB에서 지원하는 sql_mode=‘NO_AUTO_CREATE_USER’ 설정은 MySQL 8.0 버전에서는 지원하지 않기 때문에, Source DB에서 사용된 곳이 있으면 찾아서 해당 옵션을 제거해야 합니다.\nsql_mode 설정 점검 쿼리 linkProcedure, Function 등의 ROUTINE과 TRIGGER에서 사용되므로 아래 쿼리로 [NO_AUTO_CREATE_USER] 옵션이 사용된 곳이 있는지 점검합니다.\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\rFROM information_schema.routines\rWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\rSELECT TRIGGER_SCHEMA, TRIGGER_NAME, sql_mode\rFROM information_schema.triggers\rWHERE TRIGGER_SCHEMA NOT IN ('sys','mysql');\r테스트용 Source DB에서 점검 쿼리를 실행해보면 아래와 같이 [testdb2]의 [new_procedure2]에 [NO_AUTO_CREATE_USER] 옵션이 적용되어 있는 것을 확인할 수 있습니다. sql_mode 호환성 이슈 조치 방법 linkProcedure, Function, Trigger의 Dump 파일을 생성하고 [NO_AUTO_CREATE_USER] 옵션을 제거한 후 다시 적용하면 됩니다.\nProcedure, Function, Trigger 에 대해서만 drop 및 create 구문이 생성된 sql 파일 생성 ~# mariadb-dump -u {사용자명} -p --routines --triggers --no-create-info --no-data --no-create-db --add-drop-trigger --databases {사용자 DB} \u003e backup.sql\rbackup.sql 파일내 NO_AUTO_CREATE_USER 구문 모두 제거\n해당 옵션을 일일이 찾아서 제거하기 힘드니 vim 에디터에서 [NO_AUTO_CREATE_USER] 문자를 찾아서 제거하는 명령을 실행합니다.\n경우에 따라서는 Dump 파일에 [NO_AUTO_CREATE_USER] 옵션이 포함되지 않는 경우도 있습니다. 이때는 걱정말고 Dump 파일을 그냥 그대로 적용하면 됩니다. vim 명령: %s /NO_AUTO_CREATE_USER,//g\r원본 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION' 수정 예시: SET sql_mode = 'STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION'\r적용하기\n수정된 Dump 파일을 Source DB에 적용합니다. ~# mariadb -u {사용자명} -p {사용자 DB} \u003c backup.sql\rsql_mode 설정 변경 확인 link설정이 제대로 변경되었는지 점검 쿼리로 다시 확인해보겠습니다.\nSELECT ROUTINE_SCHEMA, ROUTINE_NAME, SQL_MODE\rFROM information_schema.routines\rWHERE ROUTINE_SCHEMA NOT IN ('sys','mysql');\r아래 스샷처럼 [NO_AUTO_CREATE_USER] 옵션이 사라진 것을 확인할 수 있습니다. 바이너리 로그 설정 linkSource DB의 바이너리 로그 설정 중에서, [server_id] 값이 설정되어 있는지와 [log_bin]이 ON 상태로 설정되어 있지 확인 후 설정되어 있지 않다면 설정 후에 진행해야 합니다.\n현재 설정 확인 link아래 쿼리를 사용해 현재 설정 값을 확인합니다.\nshow variables like 'server_id';\rshow variables like 'log_bin';\r현재 테스트용 Source DB는 [server_id]는 설정되어 있고, [log_bin]은 설정되어 있지 않은 상태입니다. 설정 변경 linkMariaDB의 환경 설정 파일 [server.cnf]를 열어서 아래 값을 추가하고, MariaDB 데몬을 재시작합니다.\n~# vim /etc/my.cnf.d/server.cnf\rlog-bin\rlog-basename = mariadb\rbinlog-format = mixed\rcharacter-set-server = utf8\r~# systemctl restart mariadb\r변경 설정 확인 link설정 변경 후에 확인해보면 아래와 같이 [server_id] 값이 설정되어 있고, [log_bin]이 ON 상태로 변경된 것을 알 수 있습니다.\nTarget DB 사전 설정 link위에서 [Source DB]의 사전 설정이 끝났으므로 이제 [Target DB]의 사전 설정이 필요한 항목을 확인해보겠습니다.\nDEFINER 계정 확인 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재한다면 이 때 사용된 DB User 즉, [DEFINER] 계정을 [Target DB]에도 미리 추가 생성해 두어야 마이그레이션을 진행할 수 있습니다.\n아래 쿼리는 [Procedure], [Function], [VIEW] 등을 생성할 때 사용된 [DEFINER] 계정을 확인하는 쿼리입니다.\nSELECT DEFINER FROM information_schema.ROUTINES\rWHERE ROUTINE_SCHEMA NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER';\rSELECT DEFINER FROM information_schema.VIEWS\rWHERE table_schema NOT IN ( 'information_schema', 'mysql', 'performance_schema', 'sys' ) AND SECURITY_TYPE = 'DEFINER' ;\r위에서 [Source DB]에 테스트 환경을 설정하면서 [Procedure]를 하나 생성했었는데 그때 사용된 [DEFINER] 계정을 확인할 수 있었습니다. 여기서 확인된 DB User를 [Target DB]에 미리 추가 생성해 두어야 합니다. {% include callout-v2.html type=“warning” level=“3” content=“위 단계에서 DEFINER User가 없는 것으로 확인될 경우 DEFINER User 추가 없이 다음 단계로 진행하셔도 됩니다.” %}\nDEFINER 계정 추가 link[Target DB]를 선택하고 [DB 관리] - [DB User 관리] 메뉴를 선택합니다.\nDB User 관리 화면에서 위에서 확인했던 [DEFINER] 계정을 DDL 권한으로 설정해서 추가하고 저장합니다. 접근 권한 설정 link[Source DB], [Target DB] 양쪽의 사전 설정을 모두 완료했으면, 다음으로는 양쪽 DB간의 접근 권한을 설정해야 합니다.\n앞에서도 설명했지만 마이그레이션은 Target DB **Source DB로 접근**하게 됩니다.\nNAT Gateway 생성 link현재 [Target DB]는 [Private] 네트워크 환경에 위치해 있으므로 [Source DB]로 접근하기 위해서는 [NAT Gateway]를 생성해서 외부 통신이 가능하도록 해야 합니다.\n여기서는 [NAT Gateway]가 생성되어 있다고 가정하고, 어떻게 설정하는지 확인해보겠습니다.\n[NAT Gateway] 상세 정보 중에서 [공인 IP]는 따로 기록해 두었다가, 아래쪽에서 [방화벽(ACG) 설정]에서 사용하게 됩니다. VPC 환경에서 [NAT Gateway]를 생성하는 상세한 방법은 아래 문서를 참고하시면 됩니다.\n{% include callout-v2.html type=“info” level=“2” content=\" ⁃ VPC 환경에서 NAT Gateway 생성하는 방법 \" %}\nRoute Table 설정 link다음으로 [VPC] - [Route Table]에서 [Target DB]의 Subnet에 연관된 [Route Table]을 선택하고, [Routes 설정] 버튼을 클릭합니다.\nRoute Table 설정 화면에서 [Destination]에는 [Source DB]의 공인 IP를 입력하고, [Target Type]은 [NATGW], [Target Name]은 위에서 생성했던 NAT Gateway를 선택하고 [생성] 버튼을 클릭합니다. 방화벽(ACG) 설정 linkTarget DB **Source DB로 접근**하여 DB 데이터를 가져오기 위해 [Target DB] 방화벽에서는 [Outbound] 규칙을, [Source DB] 방화벽에서는 [Inbound] 규칙을 설정해야 합니다.\nTarget DB ACG 설정 link우선 [Target DB]의 [Outbound] 규칙을 설정해보겠습니다. [Target DB]를 선택하면 나타나는 DB 상세 정보 화면에서 [ACG]를 클릭합니다.\n[ACG] 화면에서 해당 ACG를 선택하고 [ACG 설정] 메뉴를 클릭합니다. [ACG 규칙 설정] 팝업에서 [Outbound] 탭을 선택하고, [목적지]에는 [Source DB]의 IP 주소, [허용 포트]에는 [Source DB]의 포트 번호를 입력한 후 [추가]-[적용] 버튼을 클릭합니다. Source DB 방화벽 설정 link이제 [Source DB] 방화벽에 위에서 확인했던 [NAT Gateway]의 [공인 IP]를 추가해서 [Taget DB]가 접근할 수 있도록 설정하겠습니다.\nOn Premise 등 Ncloud 외부 서버의 경우 자체 방화벽에 직접 추가하시면 됩니다.\nNcloud 내부 서버의 경우 해당 서버의 ACG의 [Inbound] 설정에 아래처럼 추가하면 됩니다.\n마이그레이션 서비스 위치 link이제 모든 준비를 마쳤으면 본격적으로 마이그레이션 작업을 진행해보겠습니다.\n[Database Migration] 서비스는 [Services] - [Database] - [Database Migration]에 있습니다.\n마이그레이션 설정 link[Source DB]와 [Target DB]에서 사전 준비가 끝났으면 이제 [Database Migration Service] 설정을 시작합니다.\nEndpoint 설정 link우선 [Database Migration Service] - [Endpoint Management] 메뉴에서 [Endpoint 생성] 버튼을 클릭합니다.\n여기서 [Endpoint]는 [Source DB]를 지칭하는 것으로 [Source DB]의 정보를 입력한다고 생각하시면 됩니다.\n다음으로 Endpoint 생성화면에서 [Source DB] 관련 정보를 입력하고 [생성] 버튼을 클릭합니다.\nEndpoint URL: Source DB의 IP 또는 도메인을 입력합니다. DB PORT: Source DB의 Port를 입력합니다. DB User: 위에서 Source DB에 생성했던 마이그레이션 전용 DB User를 입력합니다. DB Password: 마이그레이션 전용 DB User의 패스워드를 입력합니다. 마이그레이션 작업 생성 link[Database Migration Service] - [Migration Management] 메뉴에서 [Migration 작업생성] 버튼을 클릭합니다.\nTest Connection link[Source DB] 항목과 [Target DB] 항목을 선택한 후에 [Test Connection] 버튼을 클릭해 Target DB **Source DB로 접근**을 테스트 해봅니다.\n마이그레이션 작업 시작 link[Test Connection]에서 이상이 없을 경우 아래와 같이 옮겨오게 될 [Source DB]의 정보를 확인할 수 있습니다. 문제가 없으면 [Migration 작업시작] 버튼을 클릭해서 마이그레이션 작업을 시작합니다.\n마이그레이션 작업 진행 상태 link마이그레이션 작업은 [Exporting], [Importing], [Replication] 이렇게 3가지 단계로 진행되는데, 각각의 진행 상태를 확인할 수 있습니다.\n진행 상태 확인 메일 link진행 상태는 콘솔에서도 확인할 수 있지만, 작업이 오래 걸리는 경우도 대비해서 각 단계가 완료될 때마다 안내 메일이 발송됩니다.\n{% tabs migration-status %}\n{% tab migration-status Export Completed %}\n⁃ Export Completed\n{% endtab %}\n{% tab migration-status Import Completed %}\n⁃ Import Completed\n{% endtab %}\n{% tab migration-status Migration Completed %}\n⁃ Migration Completed\n{% endtab %}\n{% endtabs %}\n{% include callout-v2.html type=“warning” level=“2” content=\" 이 단계까지 완료되면 현재 상태는 Source DB와 Target DB간의 Replication이 완료된 상태이므로 이때 서비스 점검을 시작하고 아래쪽의 마이그레이션 완료 버튼을 클릭해서 최종 완료를 확인한 후에 서비스 점검을 종료하면 되겠습니다. \" %}\n마이그레이션 완료 link마이그레이션 작업이 완료되면 아래와 같이 콘솔화면에서 [완료] 버튼이 활성화 됩니다. 즉, 현재는 [Replication] 작업이 완료된 상태로 [Source DB]와 [Target DB]가 동기화 되어 있고, [Target DB]는 [쓰기 불가] 상태입니다.\n그러므로 [완료] 버튼 클릭해야 모든 작업이 완료되고, [Target DB]가 [쓰기 가능] 상태로 변경됩니다.\n[완료] 버튼 클릭하면 아래와 같이 안내 메시지가 출력되고 [확인] 버튼을 클릭하면 완료됩니다. 최종 완료 link최종 완료가 되면 아래와 같이 [Migration Status] 상태가 완료상태로 변경되고 [Migration 종료 일시]로 기록됩니다.\nTarget DB 데이터 확인 link마이그레이션이 모두 완료되었으므로 [Source DB]의 데이터가 [Target DB]로 모두 이상 없이 마이그레이션 되었는지 [Target DB]에 접속해서 직접 확인해보겠습니다.\n확인해보는 방법은 [Target DB]와 동일한 [Subnet]에 테스터 서버를 생성하고, [Target DB]에 접속해서 [Database], [Table], [Procedure] 등이 정상적으로 존재하는지 살펴보는 것인데, 아래 스샷처럼 모두 이상이 없는 것을 확인할 수 있습니다.\n오류 상황 link지금부터는 마이그레이션 진행 중에 나타날 수 있는 오류 메시지 관련해서 정리해보고, 해결 방법을 알아보겠습니다.\n방화벽 설정 오류 link[Source DB]의 방화벽 Inbound 설정과 [Target DB]의 ACG Outbound 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 접근 권한 설정 내용을 다시 확인해주세요. {% include callout-v2.html type=“warning” level=“2” content=“Source DB 와 Target DB 서버 통신이 되지 않습니다. Source DB Inbound 와 Target DB Outbound ACG 를 점검해 주세요.”%}\nEndpoint DB User 설정 오류 link[Endpoint 설정]에서 [DB User] 또는 [DB Password] 설정이 올바르지 않을 경우 나타나는 메시지 입니다. Endpoint 설정 내용을 다시 확인해주세요. {% include callout-v2.html type=“warning” level=“2” content=“Source DB 에 접속이 되지 않습니다.\nDB ACL 을 점검해 주세요.”%}\nDEFINER 계정 생성 오류 link[Source DB]에 [Procedure], [Function], [VIEW] 등이 존재하고, 이때 사용된 DB User 즉, [DEFINER] 계정이 [Target DB]에 존재하지 않았을 경우 나타나는 메시지 입니다. DEFINER 설정 내용을 다시 확인해주세요. {% include callout-v2.html type=“warning” level=“2” content=“Source DB에 생성된 Definer 계정이 Target DB 에 존재하지 않습니다.\nDefiner 에 사용된 계정은 먼저 생성후 진행해 주세요.\n필요 Definer 계정 : abcd2@%”%}\n바이너리 로그 설정 오류 linkSource DB의 바이너리 로그 설정 중에서, [server_id], [log_bin] 관련 설정이 올바르지 않을 경우 나타나는 메시지 입니다. 바이너리 로그 설정 내용을 다시 확인해주세요. {% include callout-v2.html type=“warning” level=“2” content=“마이그레이션을 위해서는 Source DB Config 설정이 필요합니다.\n추가 필요 설정 : log_bin”%}\nsql_mode 설정 오류 link[Source DB] 사전 설정에서 sql_mode 관련된 설정을 수정하지 않았을 경우 아래와 같이 마이그레이션 진행 중에 [Importing] 단계에서 실패가 발생하고 [에러 보기] 버튼을 클릭하면 아래와 같은 메시지가 나타납니다. sql_mode 설정 내용을 다시 확인해주세요.\n{% include callout-v2.html type=“warning” level=“2” content=“ERROR 1234 (42000) at line 98: Variable ‘sql_mode’ can’t be set to the value of ‘NO_AUTO_CREATE_USER’”%}\n마이그레이션 재실행 link위와 같이 [sql_mode] 관련 오류로 마이그레이션 작업이 실패했을 경우에는 [재시작] 버튼으로 재시작을 할 경우에는 동일한 오류가 계속 발생하게 됩니다.\n이때는 [sql_mode] 설정을 수정한 후에 마이그레이션 작업을 삭제하고, [Target DB]에 생성된 [Database]을 모두 삭제 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다.\n[sql_mode] 설정을 수정한 후에 [삭제] 버튼을 클릭해서 마이그레이션 작업을 삭제합니다. [Target DB]의 [DB 관리] - [DB Server 상세보기] 메뉴를 클릭해서 [Database 관리] 기능으로 이동합니다. [Database 관리]에서 [Source DB]에서 Import한 [Database]을 모두 삭제하고, [저장] 버튼을 클릭합니다.\n그런 후에 마이그레이션 작업을 다시 생성해야 정상 작동합니다. 참고 URL link Database Migration Service 개요\nhttps://guide.ncloud-docs.com/docs/ko/dms-overview\nSource DB 및 Target DB 접속 설정\nhttps://guide.ncloud-docs.com/docs/dms-connect\n문서 업데이트 내역 link\r날짜 내용 2023-11-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  182 ,
                href: "\/docs\/database\/cloud-db-mssql\/cdb-create-basic-guide\/",
                title: "VPC환경에서 Cloud DB for MSSQL 생성하기",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Cloud DB for MSSQL 생성하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드) Cloud DB for MSSQL의 메뉴와 주요 기능에 대한 간략한 소개를 정리해보겠습니다.\n테스트 환경 link VPC와 Private Subnet Cloud DB for MSSQL 15.0.4.198.2 Standard Edition (MSSQL 2019) Cloud DB for MSSQL 서비스 위치 link[Cloud DB for MSSQL]은 [콘솔] - [Services] - [Database]에서 찾을 수 있습니다.\n그리고 Cloud DB for MSSQL에는 다음과 같은 메뉴들이 있는데, 자세한 내용은 아래쪽에서 메뉴별로 하나씩 소개해보겠습니다.\nDB Server Monitoring Backup Event Config Group DB Server 메뉴 linkDB Server 메뉴에서는 MSSQL Server를 생성, 삭제하거나 운영 중인 MSSQL Server 목록을 확인할 수 있습니다. 또한 운영 중인 MSSQL Server의 스펙을 변경하거나 관리자(User) 계정 등을 관리할 수 있습니다.\n재시작 link서버를 재시작합니다. 정지 기능은 제공하지 않습니다.\nDB Server 삭제 linkDB Server를 삭제합니다. 동시에 Mirror 도 같이 삭제 되며, 삭제하는 DB Server의 모든 데이터는 삭제됩니다.\n이때, 백업된 데이터도 같이 삭제되고 삭제 이후에는 복구 할 수 없으니 만약의 경우를 대비하여 백업 데이터를 별도로 보관하는 것도 좋은 방법입니다.\nMonitoring linkDB Dashboard, Performance, DB Logs, Audit Logs 등의 메뉴를 제공하여 각 종 로그와 성능 지표를 확인할 수 있도록 Monitoring 서비스 항목으로 이동합니다.\nDB 관리 link DB Server 상세보기 DB Config 관리: DB Config Croup 변경이 가능합니다. Database 관리: Databases를 생성 및 삭제할 수 있습니다. Db User 관리: 관리자용 DB 계정의 비밀번호를 변경할 수 있습니다. Backup 설정관리: Backup 파일의 보관 기간 및 Backup 시간을 관리합니다. DB 스펙변경: DB Server의 스펙을 변경합니다. Audit 설정 관리: Audit 설정을 활성화 하면 DB 서버의 로그인 기록 및 데이터베이스 내 오브젝트 생성, 변경, 삭제 기록(DDL)을 남길 수 있습니다. Log 다운로드: Error Log, Default Trace File, Agent Log, Audit Log 파일을 다운로드 할 수 있습니다. DB 스펙 변경은 동일한 DB 서비스 이름으로 서비스 되는 모든 서버(Principle, Mirror, Slave 등)가 똑같이 변경되며 DB Server가 재시작 됩니다. 또한, 재시작 동안에는 DB Server 접속할 수 없습니다.\rSlave 추가 : 선택한 DB Service의 Slave DB Server를 추가합니다. 읽기가능 시간 조정 : 매일 정해진 시간에 읽기 가능하도록 설정하여 batch 등에 사용할 수 있습니다. (Slave DB 생성 후 적용가능) 고가용성 설정 변경 : DB Server를 Stand Alone 또는 고가용성 구성으로 변경하며, 이때 서버 스펙, DB 설정 정보는 동일하게 설정됩니다. Public 도메인 관리 : 외부에서 접근할 수 있는 Public 도메인을 신청할 수 있습니다. MSSQL Engine Upgrade : DB Server Engine 버전을 업그레이드 합니다. MSSQL Engine Upgrade는 리스트에 있는 전체 서버의 버전이 변경되고, 버전 업그레이드 중에는 DB서버 접근이 차단됩니다.\rMonitoring 메뉴 linkMSSQL Server 성능 및 이력에 대한 모니터링 정보를 확인할 수 있습니다. Monitoring은 별도의 추가 비용 없이 사용이 가능합니다.\nDB Dashboard linkMonitoring에서 제공하고 있는 대시보드는 여러 개의 그래픽 차트로 구성되어 있으며, 사용자는 서버별로 확인하고 싶은 대시보드에서 원하는 정보만 디스플레이하여 직관적으로 확인할 수 있습니다. 대시보드에서 보여주는 정보는 매분 수집하여 표시하되 평균값을 보여줍니다.\nPerformance link운영 중인 MSSQL Server의 성능 관련 모니터링 정보를 보여줍니다.\nDB Logs link운영 중인 MSSQL Server에서 발생한 모든 로그의 발생 시간 및 내용을 기록하여 보여줍니다.\nBackup 메뉴 linkBackup에서는 Cloud DB for MSSQL을 사용 중인 사용자의 캐시 데이터를 안전하게 보관하기 위해 서버별로 설정해놓은 백업 정보를 확인할 수 있습니다. 또한 장애가 발생하여 캐시 데이터가 손실된 경우 보관 중이던 백업 파일로 복원을 진행할 수도 있으며, 고가용성 설정을 사용하는 서버 뿐만 아니라 Stand Alone Server도 백업 및 복원 기능을 사용할 수 있습니다.\n기본 수행 규칙 link백업과 복원을 사용하기 위해서 우선 Cloud DB for MSSQL에서 제공하고 있는 백업에 대한 기본 수행 규칙을 이해하는 것이 좋습니다.\n백업 수행 방식\n풀백업: 하루 한 번씩 매일 수행 자동 설정과 사용자 정의 설정 가운데 선택 자동 설정: MSSQL Server 생성 시 임의의 시간이 지정되며, 이후 처음 백업된 시간과 유사한 시간에 백업 수행 사용자 정의 설정: 사용자가 선택한 시간 +15분 내 백업 수행 시작 로그백업: 15분 간격으로 자동 수행. 시간 설정 불가 백업 파일\n보관 기간: 사용자 설정에 따라 최대 30일까지 보관 가능 저장 위치: 별도의 데이터 스토리지(백업 파일 크기에 따라 스토리지 계약 진행) DB 서비스 이름: 사용자가 지정한 DB Service 이름 Backup 보관일: 백업 파일을 데이터 스토리지에 저장하여 보관하는 최대 일수 FullBackup 시작 시간: 매일 1회 풀백업을 수행하는 시간 보관중인 Backup 데이터 크기: 완료된 백업 파일의 총 크기 (풀백업과 로그백업 파일의 합) FullBackup 데이터 크기: 풀백업 파일의 크기 Log Backup 데이터 크기: 풀백업 이후에 생성된 로그백업의 크기 Log Backup 수: 풀백업 이후에 생성된 로그백업의 개수 상세정보 보기: 서버별 생성된 백업 파일 목록의 상세 정보 및 복원 Backup 리스트 확인 link[Backup] - [상세정보 보기] - [상세내역]에서 백업 수행을 완료하여 서버별로 생성된 백업 파일 목록을 확인하고 복원할 수 있습니다.\nDB 이름: 백업된 DB 이름 FullBackup 시작시간: 백업이 시작된 시간 FullBackup 종료시간: 백업이 완료된 시간 FullBackup 크기: 백업 파일의 사이즈 연관된 Log Backup 크기: 풀백업 이후 생성된 로그백업의 사이즈 복원 link[Backup] - [상세정보 보기] - [상세내역] - [복원하기] 기능으로 보관되어 있는 백업 파일 목록 가운데 원하는 백업 파일을 선택하여 MSSQL Server를 복원할 수 있습니다.\nBackup 파일 보관 기간 내의 원하는 시간으로 DB 복원이 가능합니다. 복원 요청 시 신규 DB Server가 생성되며, 선택한 시간으로 DB 데이터가 복원됩니다. 그리고, 생성된 DB Server는 Stand Alone 모드로 복원됩니다.\nEvent 메뉴 linkCloud DB for MSSQL 서버에서 발생한 이벤트 이력을 확인할 수 있습니다. 알람 항목과 임계치를 지정하여 이벤트를 생성하면 해당 이벤트가 발생할 때 메일과 SMS로 통보받을 수 있습니다.\n이벤트 알림 설정은 [Event Rule 설정(Cloud Insight)]을 클릭하여 Cloud Insight 서비스로 이동하여 설정 가능합니다.\nCloud Insight 설정 방법은 아래 링크를 참조합니다.\n⁃ 모니터링 서비스 Cloud Insight 설정 가이드 ⁃ 모니터링 서비스 Cloud Insight Rule Template 설정 가이드\rConfig Group 메뉴 linkConfig Group에서는 생성한 MSSQL Server를 그룹핑하여 그룹에 속한 서버들에 동일한 설정값을 지정하여 효율적으로 관리할 수 있고 생성, 변경, 삭제할 수 있습니다. 생성된 Config Group은 여러 MSSQL Service에 적용이 가능하며 MSSQL 설치 기본값이 포함된 Config Group이 기본 제공됩니다.\nConfig Group 생성 link\rConfig 변경 link기본 Config Group는 임의로 변경할 수 없으며, 추가로 생성한 Config Group만 변경이 가능합니다.\n삭제 link기본 Config Group은 삭제가 불가능 합니다. 추가로 생성한 Config Group만 삭제가 가능합니다.\n참고 URL link Ncloud Cloud DB for MSSQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbformssql-start-vpc\nNcloud Cloud DB for MSSQL 기능 상세 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbformssql-dbserver-vpc\n문서 업데이트 내역 link\r날짜 내용 2023-05-26 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  183 ,
                href: "\/docs\/database\/cloud-db-mssql\/cdb-access-public-domain-guide\/",
                title: "Cloud DB for MSSQL 생성후 Public 도메인으로 접속하기",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Cloud DB for MSSQL 생성후 Public 도메인으로 접속하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) VPC 환경에서 관리형 MSSQL DB 서버인 Cloud DB for MSSQL 생성 Public 도메인으로 접속하는 방법에 대하여 정리해보겠습니다.\n테스트 환경 link VPC와 Public Subnet Cloud DB for MSSQL 15.0.4.198.2 Standard Edition (MSSQL 2019) Cloud DB for MSSQL 서비스 위치 link[콘솔] - [Services] - [Database]에서 [Cloud DB for MSSQL]을 찾을 수 있습니다.\nCloud DB for MSSQL 서버 생성 link[Cloud DB for MSSQL] - [DB Server]에서 [DB server 생성] 버튼을 클릭합니다.\n서버 설정 link생성할 서버의 스펙 선택 및 세부정보를 입력합니다.\nCloud DB for MSSQL은 고가용성(HA) 기능 즉, 서버 이중화를 기본으로 지원합니다. 운영 중인 Principal Server에서 장애가 발생하여 정상적인 서비스가 불가능한 경우 Mirror Server로 자동 Failover 합니다. DNS 방식으로 이중화를 구성하므로 별도의 애플리케이션 변경이 필요 없습니다.\rreport\rSubnet 선택 주의사항: 서버를 생성 후에는 Subnet 변경이 불가합니다. 회사 PC 등 외부에서 접근이 필요하실 경우는 ACG에서 IP 제한을 적용한 후 Public Subnet으로 설정하고, 내부 서버를 통해 접근하거나 SSL VPN을 이용해 접속할 경우는 Private Subnet으로 설정하면 됩니다.\n여기서는 외부에서 접근하는 방식을 테스트할 예정이므로 Public Subnet을 선택합니다.\rCloud DB for MSSQL의 스토리지 용량은 최소 100GB부터 10GB씩 자동 증가되며 최대 2TB까지 사용 가능합니다.\rDB 설정 link다음으로 계정 정보와 DB 접속 포트 등을 입력하고, Backup 관련 설정을 선택합니다.\nBackup 파일 보관 기간은 최소 1일 부터 최대 30일까지 선택 가능하며 FullBackup만 지원하고 있습니다. Backup 시간은 자동 또는 수동모드로 변경하여 시간 지정이 가능합니다.\rCloud DB for MSSQL 서버는 고가용성을 선택할 경우 서버 생성까지 대략 1시간 정도가 소요되니 여유를 갖고 기다리시면 됩니다.\rDB 생성 완료 link생성될 서버의 최종 정보를 확인하고 서버를 생성하면 아래와 같이 기본 옵션으로 선택했던 고가용성에 해당하는 Principal, Mirror 이렇게 2대의 서버가 생성된 것을 확인할 수 있습니다. 또한 Subnet도 [Public Subnet]으로 설정된 것을 확인할 수 있습니다.\nACG 설정 link이제 외부에서 Cloud DB for MSSQL로 접속할 수 있도록 ACG를 설정해야 합니다.\n생성된 MSSQL DB 서버의 상세 정보를 살펴보면 DB 생성 과정에서 ACG가 자동으로 생성, 적용되어 있는 것을 아래와 같이 확인할 수 있습니다.\nACG 옆에 있는 아이콘을 클릭해서 ACG 화면으로 이동합니다. 위에서 확인했던 Cloud DB for MSSQL의 ACG [cloud-mssql-***]를 선택 후 ACG 설정을 클릭합니다. Inbound 규칙에서 접근 소스는 [myIp] 버튼을 클릭해서 현재 IP 즉, 사무실 IP 등을 등록하고 허용 포트 1433을 추가합니다. Public 도메인 할당 link다음으로, 사무실 등의 외부에서 Cloud DB에 접속하려면 Public 도메인을 추가로 할당해야 합니다. [DB 관리] - [Public 도메인 관리] 메뉴를 클릭해 Public 도메인을 신청합니다.\nPublic 도메인 신청 팝업을 확인하고 [예] 버튼을 클릭합니다. 신청 후 잠시 기다렸다 Cloud DB for MSSQL 서버의 상세 정보를 살펴보면 아래와 같이 [Public 도메인]이 할당된 것을 확인할 수 있습니다. DB 서버 접속 linkSQL Server Management Studio 설치 link사무실 PC에 MSSQL Client인 SSMS (SQL Server Management Studio)를 다운로드하고 설치합니다.\n⁃ SSMS (SQL Server Management Studio) 다운로드\r설치된 SSMS (SQL Server Management Studio)를 찾아서 실행합니다. DB Server Public 도메인 확인 link아래 화면처럼 DB 서버 상세 정보에서 확인한 Public 도메인 주소를 복사해서 다음 단계인 DB 로그인 창에 입력하면 됩니다.\nDB 로그인 link로그인 접속 화면에서 정보를 입력하고 접속합니다.\n서버 이름 : {MSSQL DB Server의 Public 도메인}, {접속 포트} (쉼표로 구분하여 입력) 인증 : [SQL Server 인증] 으로 변경합니다. 로그인 및 암호 : DB 서버 생성과정에서 입력한 유저 정보를 입력합니다. 정상적으로 접속된 것을 확인할 수 있습니다. 참고 URL link Ncloud Cloud DB for MSSQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbformssql-start-vpc\nNcloud Cloud DB for MSSQL 기능 상세 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbformssql-dbserver-vpc\n문서 업데이트 내역 link\r날짜 내용 2023-05-30 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  184 ,
                href: "\/docs\/database\/cloud-db-mssql\/db-config-manage-guide\/",
                title: "Cloud DB for MSSQL의 메뉴와 주요 기능에 대한 소개",
                description: "Ncloud(네이버 클라우드) VPC환경 Cloud DB for MSSQL의 메뉴와 주요 기능에 대한 간략한 소개입니다",
                content: "개요 linkNcloud (네이버 클라우드) Cloud DB for MSSQL의 메뉴와 주요 기능에 대한 간략한 소개를 정리해보겠습니다.\n테스트 환경 link VPC와 Private Subnet Cloud DB for MSSQL 15.0.4.198.2 Standard Edition (MSSQL 2019) Cloud DB for MSSQL 서비스 위치 link[Cloud DB for MSSQL]은 [콘솔] - [Services] - [Database]에서 찾을 수 있습니다.\n그리고 Cloud DB for MSSQL에는 다음과 같은 메뉴들이 있는데, 자세한 내용은 아래쪽에서 메뉴별로 하나씩 소개해보겠습니다.\nDB Server Monitoring Backup Event Config Group DB Server 메뉴 linkDB Server 메뉴에서는 MSSQL Server를 생성, 삭제하거나 운영 중인 MSSQL Server 목록을 확인할 수 있습니다. 또한 운영 중인 MSSQL Server의 스펙을 변경하거나 관리자(User) 계정 등을 관리할 수 있습니다.\n재시작 link서버를 재시작합니다. 정지 기능은 제공하지 않습니다.\nDB Server 삭제 linkDB Server를 삭제합니다. 동시에 Mirror 도 같이 삭제 되며, 삭제하는 DB Server의 모든 데이터는 삭제됩니다.\n이때, 백업된 데이터도 같이 삭제되고 삭제 이후에는 복구 할 수 없으니 만약의 경우를 대비하여 백업 데이터를 별도로 보관하는 것도 좋은 방법입니다.\nMonitoring linkDB Dashboard, Performance, DB Logs, Audit Logs 등의 메뉴를 제공하여 각 종 로그와 성능 지표를 확인할 수 있도록 Monitoring 서비스 항목으로 이동합니다.\nDB 관리 link DB Server 상세보기 DB Config 관리: DB Config Croup 변경이 가능합니다. Database 관리: Databases를 생성 및 삭제할 수 있습니다. Db User 관리: 관리자용 DB 계정의 비밀번호를 변경할 수 있습니다. Backup 설정관리: Backup 파일의 보관 기간 및 Backup 시간을 관리합니다. DB 스펙변경: DB Server의 스펙을 변경합니다. Audit 설정 관리: Audit 설정을 활성화 하면 DB 서버의 로그인 기록 및 데이터베이스 내 오브젝트 생성, 변경, 삭제 기록(DDL)을 남길 수 있습니다. Log 다운로드: Error Log, Default Trace File, Agent Log, Audit Log 파일을 다운로드 할 수 있습니다. DB 스펙 변경은 동일한 DB 서비스 이름으로 서비스 되는 모든 서버(Principle, Mirror, Slave 등)가 똑같이 변경되며 DB Server가 재시작 됩니다. 또한, 재시작 동안에는 DB Server 접속할 수 없습니다.\rSlave 추가 : 선택한 DB Service의 Slave DB Server를 추가합니다. 읽기가능 시간 조정 : 매일 정해진 시간에 읽기 가능하도록 설정하여 batch 등에 사용할 수 있습니다. (Slave DB 생성 후 적용가능) 고가용성 설정 변경 : DB Server를 Stand Alone 또는 고가용성 구성으로 변경하며, 이때 서버 스펙, DB 설정 정보는 동일하게 설정됩니다. Public 도메인 관리 : 외부에서 접근할 수 있는 Public 도메인을 신청할 수 있습니다. MSSQL Engine Upgrade : DB Server Engine 버전을 업그레이드 합니다. MSSQL Engine Upgrade는 리스트에 있는 전체 서버의 버전이 변경되고, 버전 업그레이드 중에는 DB서버 접근이 차단됩니다.\rMonitoring 메뉴 linkMSSQL Server 성능 및 이력에 대한 모니터링 정보를 확인할 수 있습니다. Monitoring은 별도의 추가 비용 없이 사용이 가능합니다.\nDB Dashboard linkMonitoring에서 제공하고 있는 대시보드는 여러 개의 그래픽 차트로 구성되어 있으며, 사용자는 서버별로 확인하고 싶은 대시보드에서 원하는 정보만 디스플레이하여 직관적으로 확인할 수 있습니다. 대시보드에서 보여주는 정보는 매분 수집하여 표시하되 평균값을 보여줍니다.\nPerformance link운영 중인 MSSQL Server의 성능 관련 모니터링 정보를 보여줍니다.\nDB Logs link운영 중인 MSSQL Server에서 발생한 모든 로그의 발생 시간 및 내용을 기록하여 보여줍니다.\nBackup 메뉴 linkBackup에서는 Cloud DB for MSSQL을 사용 중인 사용자의 캐시 데이터를 안전하게 보관하기 위해 서버별로 설정해놓은 백업 정보를 확인할 수 있습니다. 또한 장애가 발생하여 캐시 데이터가 손실된 경우 보관 중이던 백업 파일로 복원을 진행할 수도 있으며, 고가용성 설정을 사용하는 서버 뿐만 아니라 Stand Alone Server도 백업 및 복원 기능을 사용할 수 있습니다.\n기본 수행 규칙 link백업과 복원을 사용하기 위해서 우선 Cloud DB for MSSQL에서 제공하고 있는 백업에 대한 기본 수행 규칙을 이해하는 것이 좋습니다.\n백업 수행 방식\n풀백업: 하루 한 번씩 매일 수행 자동 설정과 사용자 정의 설정 가운데 선택 자동 설정: MSSQL Server 생성 시 임의의 시간이 지정되며, 이후 처음 백업된 시간과 유사한 시간에 백업 수행 사용자 정의 설정: 사용자가 선택한 시간 +15분 내 백업 수행 시작 로그백업: 15분 간격으로 자동 수행. 시간 설정 불가 백업 파일\n보관 기간: 사용자 설정에 따라 최대 30일까지 보관 가능 저장 위치: 별도의 데이터 스토리지(백업 파일 크기에 따라 스토리지 계약 진행) DB 서비스 이름: 사용자가 지정한 DB Service 이름 Backup 보관일: 백업 파일을 데이터 스토리지에 저장하여 보관하는 최대 일수 FullBackup 시작 시간: 매일 1회 풀백업을 수행하는 시간 보관중인 Backup 데이터 크기: 완료된 백업 파일의 총 크기 (풀백업과 로그백업 파일의 합) FullBackup 데이터 크기: 풀백업 파일의 크기 Log Backup 데이터 크기: 풀백업 이후에 생성된 로그백업의 크기 Log Backup 수: 풀백업 이후에 생성된 로그백업의 개수 상세정보 보기: 서버별 생성된 백업 파일 목록의 상세 정보 및 복원 Backup 리스트 확인 link[Backup] - [상세정보 보기] - [상세내역]에서 백업 수행을 완료하여 서버별로 생성된 백업 파일 목록을 확인하고 복원할 수 있습니다.\nDB 이름: 백업된 DB 이름 FullBackup 시작시간: 백업이 시작된 시간 FullBackup 종료시간: 백업이 완료된 시간 FullBackup 크기: 백업 파일의 사이즈 연관된 Log Backup 크기: 풀백업 이후 생성된 로그백업의 사이즈 복원 link[Backup] - [상세정보 보기] - [상세내역] - [복원하기] 기능으로 보관되어 있는 백업 파일 목록 가운데 원하는 백업 파일을 선택하여 MSSQL Server를 복원할 수 있습니다.\nBackup 파일 보관 기간 내의 원하는 시간으로 DB 복원이 가능합니다. 복원 요청 시 신규 DB Server가 생성되며, 선택한 시간으로 DB 데이터가 복원됩니다. 그리고, 생성된 DB Server는 Stand Alone 모드로 복원됩니다.\nEvent 메뉴 linkCloud DB for MSSQL 서버에서 발생한 이벤트 이력을 확인할 수 있습니다. 알람 항목과 임계치를 지정하여 이벤트를 생성하면 해당 이벤트가 발생할 때 메일과 SMS로 통보받을 수 있습니다.\n이벤트 알림 설정은 [Event Rule 설정(Cloud Insight)]을 클릭하여 Cloud Insight 서비스로 이동하여 설정 가능합니다.\nCloud Insight 설정 방법은 아래 링크를 참조합니다.\n⁃ 모니터링 서비스 Cloud Insight 설정 가이드 ⁃ 모니터링 서비스 Cloud Insight Rule Template 설정 가이드\rConfig Group 메뉴 linkConfig Group에서는 생성한 MSSQL Server를 그룹핑하여 그룹에 속한 서버들에 동일한 설정값을 지정하여 효율적으로 관리할 수 있고 생성, 변경, 삭제할 수 있습니다. 생성된 Config Group은 여러 MSSQL Service에 적용이 가능하며 MSSQL 설치 기본값이 포함된 Config Group이 기본 제공됩니다.\nConfig Group 생성 link\rConfig 변경 link기본 Config Group는 임의로 변경할 수 없으며, 추가로 생성한 Config Group만 변경이 가능합니다.\n삭제 link기본 Config Group은 삭제가 불가능 합니다. 추가로 생성한 Config Group만 삭제가 가능합니다.\n참고 URL link Ncloud Cloud DB for MSSQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbformssql-start-vpc\nNcloud Cloud DB for MSSQL 기능 상세 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbformssql-dbserver-vpc\n문서 업데이트 내역 link\r날짜 내용 2023-05-31 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  185 ,
                href: "\/docs\/database\/postgresql\/db-install-access-guide-rocky-linux\/",
                title: "설치형 PostgreSQL DB 설치, 접속 가이드 | Rocky Linux",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Rocky Linux 서버에 설치형 PostgreSQL DB를 설치하고, 접속하는 방법입니다",
                content: "개요 linkPostgreSQL은 설치 후에 DB에 접속할 때 MySQL등 다른 DB와 달리 [OS와 PostgreSQL 양쪽에 동일한 계정을 생성]하거나 [인증관련 환경설정 파일을 수정]해야 접속할 수 있는데 이 두가지 방법을 [Rocky Linux]에서 적용하는 과정을 정리해보겠습니다.\n테스트 환경 link Rocky Linux 8.8 PostgreSQL 13.12 설치 link기본 배포 버전으로 테스트할 수도 있지만, 여기서는 PostgreSQL 13 최신 버전을 설치해보겠습니다.\n리포지토리 버전 확인 link우선 Rocky Linux에서 지원하는 기본 버전들을 확인해보면 아래와 같이 PostgreSQL [9.6], [10], [12], [13], [15] 인 것을 확인할 수 있습니다.\ndnf module list postgresql\r기본 버전 비활성화 linkPostgreSQL 13 최신 버전을 사용하기 위해 기본 버전들은 모두 비활성화합니다. 비활성화 처리 후 리스트를 다시 조회해보면 [disabled]를 뜻하는 [X]로 변경된 것을 확인할 수 있습니다.\ndnf -qy module disable postgresql\rdnf module list postgresql\r리포지토리 설치 link[PostgreSQL 13] 설치 정보가 담겨 있는 리포지토리 RPM을 설치합니다.\ndnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm\rPostgreSQL 설치 link[PostgreSQL 13]을 설치합니다.\ndnf install -y postgresql13-server\r기본 DB 생성 link[initdb] 명령으로 기본 DB를 생성하고 올바르게 생성되었는지 로그를 확인해보겠습니다.\ncd /usr/pgsql-13/bin/\rpostgresql-13-setup initdb\rcat /var/lib/pgsql/13/initdb.log\rPostgreSQL 시작 link\rsystemctl enable postgresql-13\rsystemctl start postgresql-13\rsystemctl status postgresql-13\rDB 접속 link기본 마스터 계정인 [postgres]로 [PostgreSQL]에 접속합니다.\nsu postgres\rbash$ psql\r유저 생성 link테스트용 계정 [testuser]를 생성하고 [\\du] 명령으로 생성된 유저를 확인합니다.\npostgres=# create user testuser password 'test123$' superuser;\rpostgres=# \\du DB 생성 및 소유자 지정 link테스트용 DB를 생성하고 소유자를 지정한 후에 [\\l] 명령으로 생성된 DB를 확인합니다.\npostgres=# create database testdb owner testuser;\rpostgres=# \\l\rpostgres=# \\q\rbash$\r접속 시도 - 인증 오류 link위에서 생성한 계정으로 접속을 시도해보면, 아래와 같이 인증 오류가 발생합니다.\n다음 단계에서는 이 인증 오류를 해결하는 방법 2가지를 확인해보겠습니다.\npsql -U testuser -d testdb\rpsql: error: FATAl: Peer authentication failed for user \"testuser\"\r인증 오류 해결 link인증 문제를 해결하고 [PostgreSQL]에 접속하는 방법은 크게 2가지가 있는데 한가지씩 확인해보겠습니다.\n방법1 - 동일한 계정 생성 link우선, 처음에 DB 생성 후에 추가했던 [PostgreSQL] 유저 계정과 동일한 계정을 OS 사용자에도 추가하는 방법입니다.\n아래와 같이 DB 유저와 동일한 [testuser] 계정을 생성하겠습니다.\nadduser testuser\rpasswd testuser\rDB 접속\n새로 생성한 [testuser] 계정으로 전환한 후에 접속을 해보면 문제 없이 접속되는 것을 확인할 수 있습니다. su testuser\r~$ psql -U testuser -d testdb\r방법2 - 인증 설정 파일 수정 link다음으로 인증 관련 설정 파일인 [pg_hba.conf] 파일을 수정해서 접속하는 방법을 확인해보겠습니다.\n[pg_hba.conf] 파일을 열어보면 아래와 같이 DB 접근 설정 항목들이 있는데 [local]과 IPv4용 [host]의 METHOD 항목을 보시면 각각 [peer]과 [scram-sha-256]으로 설정되어 있는 것을 확인할 수 있습니다.\n여기서 [peer]는 운영 체제에서 클라이언트의 운영 체제 사용자 이름과 요청한 데이터베이스 사용자 이름이 일치하는지 확인하는 옵션입니다.\r이 항목을 [scram-sha-256] 또는 [md5]로 수정합니다.\nvim /var/lib/pgsql/13/data/pg_hba.conf\r수정 전 수정 후 DB 재시작 후 접속\n설정 파일을 수정했으면 [PostgreSQL]을 재시작하고 다시 접속해봅니다.\n이번에는 문제 없이 DB 유저 생성 시 입력했던 패스워드를 입력하고 접속 가능한 것을 확인할 수 있습니다. systemctl restart postgresql-13\rpsql -U testuser -d testdb\r기본 배포 버전 설치 link[PostgreSQL 13] 최신 버전이 아닌 기본 배포 버전을 설치하려면 아래와 같은 방법으로 설치를 하면 됩니다.\n나머지 인증 방법은 위에서 설명한 내용과 동일합니다.\ndnf install -y postgresql-server\rcd /usr/bin/\rpostgresql-setup --initdb\rsystemctl enable postgresql\rsystemctl start postgresql\rsystemctl status postgresql\rOS별 배포 버전 link2023년 9월 13일 기준 Red Hat family OS별로 설치되는 배포 버전은 다음과 같습니다.\nRHEL / Rocky Linux 9 : 15, 13 RHEL / Rocky Linux / OL 8\t: 15, 13, 12, 10 and 9.6 via modules RHEL / CentOS / SL / OL 7\t: 9.2 RHEL / CentOS / SL / OL 6\t: 8.4 Fedora 37\t: 14 Fedora 36\t: 14 pg_hba.conf 파일 Method 옵션 link[pg_hba.conf] 설정 파일의 Method 옵션 리스트는 아래와 같습니다.\ntrust: 무조건 접속을 허용합니다. 이 방법을 사용하면 PostgreSQL 데이터베이스 서버에 연결할 수 있는 모든 사람이 암호나 다른 인증 없이 원하는 PostgreSQL 사용자로 로그인할 수 있습니다.\nreject: 무조건 연결을 거부합니다. 이것은 그룹에서 특정 호스트 를 \" 필터링 “reject 하는 데 유용합니다. 예를 들어 한 라인은 특정 호스트의 연결을 차단할 수 있고 나중 라인은 특정 네트워크의 나머지 호스트가 연결할 수 있도록 합니다.\nscram-sha-256: SCRAM-SHA-256 인증을 수행해 사용자의 암호를 확인합니다.\nmd5: SCRAM-SHA-256 또는 MD5 인증을 수행해 사용자의 암호를 확인합니다.\npassword: 클라이언트가 인증을 위해 암호화되지 않은 암호를 제공하도록 요구합니다. 암호는 네트워크를 통해 일반 텍스트로 전송되기 때문에 신뢰할 수 없는 네트워크에서는 사용해서는 안 됩니다.\ngss: GSSAPI를 사용해 사용자를 인증합니다. 이것은 TCP/IP 연결에만 사용할 수 있습니다. GSSAPI 암호화와 함께 사용할 수 있습니다.\nsspi: SSPI를 사용해 사용자를 인증합니다. 이것은 Windows에서만 사용할 수 있습니다.\nident: 클라이언트의 ident 서버에 연결하여 클라이언트의 운영 체제 사용자 이름을 얻고 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. ID 인증은 TCP/IP 연결에서만 사용할 수 있습니다. 로컬 연결에 대해 지정된 경우 피어 인증이 대신 사용됩니다.\npeer: 운영 체제에서 클라이언트의 운영 체제 사용자 이름을 가져와서 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. 이것은 로컬 연결에만 사용할 수 있습니다.\nlda: LDAP 서버를 사용해 인증 합니다.\nradius: RADIUS 서버를 사용해 인증합니다.\ncert: SSL 클라이언트 인증서를 사용해 인증합니다.\npam: 운영 체제에서 제공하는 PAM(Pluggable Authentication Modules) 서비스를 사용해 인증합니다.\nbsd: 운영 체제에서 제공하는 BSD 인증 서비스를 사용해 인증합니다.\n참고 URL link PostgreSQL OS별 다운로드 안내\nhttps://www.postgresql.org/download/linux/\nPostgreSQL pg_hba.conf 파일 옵션 안내\nhttps://www.postgresql.org/docs/current/auth-pg-hba-conf.html\n문서 업데이트 내역 link\r날짜 내용 2023-09-13 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  186 ,
                href: "\/docs\/database\/postgresql\/db-install-access-guide-ubuntu\/",
                title: "설치형 PostgreSQL DB 설치, 접속 가이드 | Ubuntu",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Ubuntu 서버에 설치형 PostgreSQL DB를 설치하고, 접속하는 방법입니다",
                content: "개요 linkPostgreSQL은 설치 후에 DB에 접속할 때 MySQL등 다른 DB와 달리 [OS와 PostgreSQL 양쪽에 동일한 계정을 생성]하거나 [인증관련 환경설정 파일을 수정]해야 접속할 수 있는데 이 두가지 방법을 Ubuntu에서 적용하는 과정을 정리해보겠습니다.\n테스트 환경 link Ubuntu 20.04 PostgreSQL 13.8 설치 link기본 배포 버전으로 테스트할 수도 있지만, 여기서는 PostgreSQL 13을 설치해보겠습니다.\n리포지토리 설정 파일 생성 link[PostgreSQL 13] 설치 정보가 담겨 있는 리포지토리 설정 파일을 생성합니다.\nsh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\" \u003e /etc/apt/sources.list.d/pgdg.list'\rwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\rPostgreSQL 설치 link[PostgreSQL 13]을 설치합니다.\napt-get update\rapt-get -y install postgresql-13\rPostgreSQL 시작 link\rsystemctl enable postgresql\rsystemctl start postgresql\rsystemctl status postgresql\rDB 접속 link기본 마스터 계정인 [postgres]로 [PostgreSQL]에 접속합니다.\nsudo -i -u postgres\r~$ psql\r유저 생성 link테스트용 계정 [testuser]를 생성하고 [\\du] 명령으로 생성된 유저를 확인합니다.\npostgres=# create user testuser password 'test123$' superuser;\rpostgres=# \\du DB 생성 및 소유자 지정 link테스트용 DB를 생성하고 소유자를 지정한 후에 [\\l] 명령으로 생성된 DB를 확인합니다.\npostgres=# create database testdb owner testuser;\rpostgres=# \\l\rpostgres=# \\q\r~$ exit\r접속 시도 - 인증 오류 link위에서 생성한 계정으로 접속을 시도해보면, 아래와 같이 인증 오류가 발생합니다.\n다음 단계에서는 이 인증 오류를 해결하는 방법 2가지를 확인해보겠습니다.\npsql -U testuser -d testdb\rpsql: error: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: FATAL: Peer authentication failed for user \"testuser\"\r인증 오류 해결 link인증 문제를 해결하고 [PostgreSQL]에 접속하는 방법은 크게 2가지가 있는데 한가지씩 확인해보겠습니다.\n방법1 - 동일한 계정 생성 link우선, 처음에 DB 생성 후에 추가했던 [PostgreSQL] 유저 계정과 동일한 계정을 OS 사용자에도 추가하는 방법입니다.\n아래와 같이 DB 유저와 동일한 [testuser] 계정을 생성하겠습니다.\nadduser testuser\rDB 접속\n새로 생성한 [testuser] 계정으로 전환한 후에 접속을 해보면 문제 없이 접속되는 것을 확인할 수 있습니다. sudo -i -u testuser\r~$ psql -U testuser -d testdb\r방법2 - 인증 설정 파일 수정 link다음으로 인증 관련 설정 파일인 [pg_hba.conf] 파일을 수정해서 접속하는 방법을 확인해보겠습니다.\n[pg_hba.conf] 파일을 열어보면 아래와 같이 DB 접근 설정 항목들이 있는데 [local]과 IPv4용 [host]의 METHOD 항목을 보시면 각각 [peer]과 [md5]으로 설정되어 있는 것을 확인할 수 있습니다.\n여기서 [peer]는 운영 체제에서 클라이언트의 운영 체제 사용자 이름과 요청한 데이터베이스 사용자 이름이 일치하는지 확인하는 옵션입니다.\r이 항목을 [md5]로 수정합니다.\nvi /etc/postgresql/13/main/pg_hba.conf\r수정 전 수정 후 DB 재시작 후 접속\n설정 파일을 수정했으면 [PostgreSQL]을 재시작하고 다시 접속해봅니다.\n이번에는 문제 없이 패스워드를 입력하고 접속 가능한 것을 확인할 수 있습니다. systemctl restart postgresql\rpsql -U testuser -d testdb\r기본 배포 버전 설치 link[PostgreSQL 13] 버전이 아닌 기본 배포 버전을 설치하려면 아래와 같은 방법으로 설치를 하면 됩니다.\n2022년 10월 16일 기준 기본 배포 버전은 [12.8]입니다. 나머지 인증 방법은 위에서 설명한 내용과 동일합니다.\napt-get update\rapt-get -y install postgresql\rsystemctl enable postgresql\rsystemctl start postgresql\rsystemctl status postgresql\rpg_hba.conf 파일 Method 옵션 link[pg_hba.conf] 설정 파일의 Method 옵션 리스트는 아래와 같습니다.\ntrust: 무조건 접속을 허용합니다. 이 방법을 사용하면 PostgreSQL 데이터베이스 서버에 연결할 수 있는 모든 사람이 암호나 다른 인증 없이 원하는 PostgreSQL 사용자로 로그인할 수 있습니다.\nreject: 무조건 연결을 거부합니다. 이것은 그룹에서 특정 호스트 를 \" 필터링 “reject 하는 데 유용합니다. 예를 들어 한 라인은 특정 호스트의 연결을 차단할 수 있고 나중 라인은 특정 네트워크의 나머지 호스트가 연결할 수 있도록 합니다.\nscram-sha-256: SCRAM-SHA-256 인증을 수행해 사용자의 암호를 확인합니다.\nmd5: SCRAM-SHA-256 또는 MD5 인증을 수행해 사용자의 암호를 확인합니다.\npassword: 클라이언트가 인증을 위해 암호화되지 않은 암호를 제공하도록 요구합니다. 암호는 네트워크를 통해 일반 텍스트로 전송되기 때문에 신뢰할 수 없는 네트워크에서는 사용해서는 안 됩니다.\ngss: GSSAPI를 사용해 사용자를 인증합니다. 이것은 TCP/IP 연결에만 사용할 수 있습니다. GSSAPI 암호화와 함께 사용할 수 있습니다.\nsspi: SSPI를 사용해 사용자를 인증합니다. 이것은 Windows에서만 사용할 수 있습니다.\nident: 클라이언트의 ident 서버에 연결하여 클라이언트의 운영 체제 사용자 이름을 얻고 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. ID 인증은 TCP/IP 연결에서만 사용할 수 있습니다. 로컬 연결에 대해 지정된 경우 피어 인증이 대신 사용됩니다.\npeer: 운영 체제에서 클라이언트의 운영 체제 사용자 이름을 가져와서 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. 이것은 로컬 연결에만 사용할 수 있습니다.\nlda: LDAP 서버를 사용해 인증 합니다.\nradius: RADIUS 서버를 사용해 인증합니다.\ncert: SSL 클라이언트 인증서를 사용해 인증합니다.\npam: 운영 체제에서 제공하는 PAM(Pluggable Authentication Modules) 서비스를 사용해 인증합니다.\nbsd: 운영 체제에서 제공하는 BSD 인증 서비스를 사용해 인증합니다.\n참고 URL link PostgreSQL OS별 다운로드 안내\nhttps://www.postgresql.org/download/linux/\nPostgreSQL pg_hba.conf 파일 옵션 안내\nhttps://www.postgresql.org/docs/current/auth-pg-hba-conf.html\n문서 업데이트 내역 link\r날짜 내용 2022-10-07 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  187 ,
                href: "\/docs\/database\/postgresql\/db-install-access-guide-centos\/",
                title: "설치형 PostgreSQL DB 설치, 접속 가이드 | CentOS",
                description: "Ncloud(네이버 클라우드) VPC환경에서 CentOS 서버에 설치형 PostgreSQL DB를 설치하고, 접속하는 방법입니다",
                content: "개요 linkPostgreSQL은 설치 후에 DB에 접속할 때 MySQL등 다른 DB와 달리 [OS와 PostgreSQL 양쪽에 동일한 계정을 생성]하거나 [인증관련 환경설정 파일을 수정]해야 접속할 수 있는데 이 두가지 방법을 CentOS에서 적용하는 과정을 정리해보겠습니다.\n테스트 환경 link CentOS 7.8 PostgreSQL 13.8 설치 link기본 배포 버전으로 테스트할 수도 있지만, 여기서는 PostgreSQL 13을 설치해보겠습니다.\n리포지토리 설치 link[PostgreSQL 13] 설치 정보가 담겨 있는 리포지토리 RPM을 설치합니다.\nyum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm\rPostgreSQL 설치 link[PostgreSQL 13]을 설치합니다.\nyum install -y postgresql13-server\r기본 DB 생성 link[initdb] 명령으로 기본 DB를 생성하고 올바르게 생성되었는지 로그를 확인해보겠습니다.\ncd /usr/pgsql-13/bin/\rpostgresql-13-setup initdb\rcat /var/lib/pgsql/13/initdb.log\rPostgreSQL 시작 link\rsystemctl enable postgresql-13\rsystemctl start postgresql-13\rsystemctl status postgresql-13\rDB 접속 link기본 마스터 계정인 [postgres]로 [PostgreSQL]에 접속합니다.\nsu postgres\rbash$ psql\r유저 생성 link테스트용 계정 [testuser]를 생성하고 [\\du] 명령으로 생성된 유저를 확인합니다.\npostgres=# create user testuser password 'test123$' superuser;\rpostgres=# \\du DB 생성 및 소유자 지정 link테스트용 DB를 생성하고 소유자를 지정한 후에 [\\l] 명령으로 생성된 DB를 확인합니다.\npostgres=# create database testdb owner testuser;\rpostgres=# \\l\rpostgres=# \\q\rbash$\r접속 시도 - 인증 오류 link위에서 생성한 계정으로 접속을 시도해보면, 아래와 같이 인증 오류가 발생합니다.\n다음 단계에서는 이 인증 오류를 해결하는 방법 2가지를 확인해보겠습니다.\npsql -U testuser -d testdb\rpsql: error: FATAl: Peer authentication failed for user \"testuser\"\r인증 오류 해결 link인증 문제를 해결하고 [PostgreSQL]에 접속하는 방법은 크게 2가지가 있는데 한가지씩 확인해보겠습니다.\n방법1 - 동일한 계정 생성 link우선, 처음에 DB 생성 후에 추가했던 [PostgreSQL] 유저 계정과 동일한 계정을 OS 사용자에도 추가하는 방법입니다.\n아래와 같이 DB 유저와 동일한 [testuser] 계정을 생성하겠습니다.\nadduser testuser\rpasswd testuser\rDB 접속\n새로 생성한 [testuser] 계정으로 전환한 후에 접속을 해보면 문제 없이 접속되는 것을 확인할 수 있습니다. su testuser\r~$ psql -U testuser -d testdb\r방법2 - 인증 설정 파일 수정 link다음으로 인증 관련 설정 파일인 [pg_hba.conf] 파일을 수정해서 접속하는 방법을 확인해보겠습니다.\n[pg_hba.conf] 파일을 열어보면 아래와 같이 DB 접근 설정 항목들이 있는데 [local]과 IPv4용 [host]의 METHOD 항목을 보시면 각각 [peer]과 [scram-sha-256]으로 설정되어 있는 것을 확인할 수 있습니다.\n여기서 [peer]는 운영 체제에서 클라이언트의 운영 체제 사용자 이름과 요청한 데이터베이스 사용자 이름이 일치하는지 확인하는 옵션입니다.\r이 항목을 [scram-sha-256] 또는 [md5]로 수정합니다.\nvi /var/lib/pgsql/13/data/pg_hba.conf\r수정 전 수정 후 DB 재시작 후 접속\n설정 파일을 수정했으면 [PostgreSQL]을 재시작하고 다시 접속해봅니다.\n이번에는 문제 없이 패스워드를 입력하고 접속 가능한 것을 확인할 수 있습니다. systemctl restart postgresql-13\rpsql -U testuser -d testdb\r기본 배포 버전 설치 link[PostgreSQL 13] 버전이 아닌 기본 배포 버전을 설치하려면 아래와 같은 방법으로 설치를 하면 됩니다.\n나머지 인증 방법은 위에서 설명한 내용과 동일합니다.\nyum install postgresql-server\rcd /usr/bin/\rpostgresql-setup --initdb\rsystemctl enable postgresql\rsystemctl start postgresql\rsystemctl status postgresql\rOS별 배포 버전 link2022년 10월 05일 기준 Red Hat family OS별로 설치되는 배포 버전은 다음과 같습니다.\nRHEL / Rocky Linux 9 : 13 RHEL / Rocky Linux / OL 8\t: 13, 12, 10 and 9.6 via modules RHEL / CentOS / SL / OL 7\t: 9.2 RHEL / CentOS / SL / OL 6\t: 8.4 Fedora 36\t: 14 Fedora 35\t: 13 pg_hba.conf 파일 Method 옵션 link[pg_hba.conf] 설정 파일의 Method 옵션 리스트는 아래와 같습니다.\ntrust: 무조건 접속을 허용합니다. 이 방법을 사용하면 PostgreSQL 데이터베이스 서버에 연결할 수 있는 모든 사람이 암호나 다른 인증 없이 원하는 PostgreSQL 사용자로 로그인할 수 있습니다.\nreject: 무조건 연결을 거부합니다. 이것은 그룹에서 특정 호스트 를 \" 필터링 “reject 하는 데 유용합니다. 예를 들어 한 라인은 특정 호스트의 연결을 차단할 수 있고 나중 라인은 특정 네트워크의 나머지 호스트가 연결할 수 있도록 합니다.\nscram-sha-256: SCRAM-SHA-256 인증을 수행해 사용자의 암호를 확인합니다.\nmd5: SCRAM-SHA-256 또는 MD5 인증을 수행해 사용자의 암호를 확인합니다.\npassword: 클라이언트가 인증을 위해 암호화되지 않은 암호를 제공하도록 요구합니다. 암호는 네트워크를 통해 일반 텍스트로 전송되기 때문에 신뢰할 수 없는 네트워크에서는 사용해서는 안 됩니다.\ngss: GSSAPI를 사용해 사용자를 인증합니다. 이것은 TCP/IP 연결에만 사용할 수 있습니다. GSSAPI 암호화와 함께 사용할 수 있습니다.\nsspi: SSPI를 사용해 사용자를 인증합니다. 이것은 Windows에서만 사용할 수 있습니다.\nident: 클라이언트의 ident 서버에 연결하여 클라이언트의 운영 체제 사용자 이름을 얻고 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. ID 인증은 TCP/IP 연결에서만 사용할 수 있습니다. 로컬 연결에 대해 지정된 경우 피어 인증이 대신 사용됩니다.\npeer: 운영 체제에서 클라이언트의 운영 체제 사용자 이름을 가져와서 요청한 데이터베이스 사용자 이름과 일치하는지 확인합니다. 이것은 로컬 연결에만 사용할 수 있습니다.\nlda: LDAP 서버를 사용해 인증 합니다.\nradius: RADIUS 서버를 사용해 인증합니다.\ncert: SSL 클라이언트 인증서를 사용해 인증합니다.\npam: 운영 체제에서 제공하는 PAM(Pluggable Authentication Modules) 서비스를 사용해 인증합니다.\nbsd: 운영 체제에서 제공하는 BSD 인증 서비스를 사용해 인증합니다.\n참고 URL link PostgreSQL OS별 다운로드 안내\nhttps://www.postgresql.org/download/linux/\nPostgreSQL pg_hba.conf 파일 옵션 안내\nhttps://www.postgresql.org/docs/current/auth-pg-hba-conf.html\n문서 업데이트 내역 link\r날짜 내용 2022-10-06 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  188 ,
                href: "\/docs\/database\/cloud-db-postgresql\/cdb-create-basic-guide-ubuntu\/",
                title: " VPC환경에서 Cloud DB for PostgreSQL 생성하고 Ubuntu서버로 접속하기",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Cloud DB for PostgreSQL 생성하고 Ubuntu Server를 통해 Private 도메인으로 접속하는 방법입니다",
                content: "지원 클라우드 환경 linkNcloud Cloud DB for PostgreSQL이 지원하는 클라우드 환경은 다음과 같습니다.\n리전(존): 한국, 싱가포르 VPC만\t지원 언어: 한국어, 영어, 일본어, 중국어(간체) DB 엔진 버전: PostgreSQL 13.3 서버 사양과 요금 link(2022-03-30 기준)\n타입제공사양이용 요금\rvCPU메모리디스크시간당/대\rHigh CPU2개4GB50GB158원\r4개8GB323원\r8개16GB653원\r16개32GB1,313원\r32개64GB2,633원\rStandard2개8GB50GB250원\r4개16GB506원\r8개32GB1,019원\r16개64GB2,045원\r32개128GB4,099원\rHigh Memory2개16GB50GB302원\r4개32GB611원\r8개64GB1,227원\r16개128GB2,462원\r32개256GB4,927원\r서버 사양 변경 시 제약 사항 linkCloud DB for PostgreSQL 서버는 타입은 변경할 수 없지만 메모리 크기는 콘솔 PostgreSQL Server 메뉴에서 스펙 변경 기능을 사용하여 언제든지 변경할 수 있습니다. 그 외 제약 사항은 아래와 같습니다.\n같은 타입 내에서만 변경 가능 2대 이상의 서버로 구성된 경우(고가용성 사용 및 Read Replica 사용) 모두 동일한 사양으로 변경 변경 완료 후 서버가 다시 시작되며 이에 따라 서비스 영향 발생 가능성 존재 상세 특징 link DB 엔진 버전: PostgreSQL 13.3 스토리지: 기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6000GB까지 자동으로 용량이 증가 Multi Zone 구성 제공 자동 Fail-over 기본 지원 최대 5대까지 Read Replica 확장 최대 30일까지 자동 백업 및 보관 서버 접근 방법 linkCloud DB for PostgreSQL은 현재 다음의 3가지 방법으로 접근 가능한데 여기서는 별도의 Linux 서버를 생성해서 PostgreSQL과 Private 통신을 하는 방법으로 진행하겠습니다.\n⁃ Public Domain으로 접근 (2022-04-21 업데이트) ⁃ PostgreSQL DB와 Private 통신을 위한 별도의 서버를 생성해서 접근 ⁃ SSL VPN을 이용해서 접근\rDB 생성 link[Cloud DB for PostgreSQL] - [DB Server]에서 [DB Server 생성] 버튼을 클릭해 DB를 생성을 시작합니다.\n서버 설정 link DB 엔진: 현재 지원되는 DB 엔진 버전은 PostgreSQL 13.3 입니다. 고가용성 지원은 기본 선택 사항인데, 필요하지 않을 경우 체크를 해제하면 됩니다. VPC와 Subnet을 선택하고, 미리 생성된 VPC와 Subnet가 없으면 생성 버튼을 클릭합니다. DB Server 타입은 위쪽에서 확인했던 서버 사양 중에서 원하는 vCPU와 메모리를 선택하면 됩니다. 데이터 스토리지 타입과 암호화 적용 여부를 선택합니다. 데이터 스토리지는 기본 10GB로 설정되며 최대 6000GB까지 자동으로 증가합니다. DB Server 이름과 DB Service 이름을 입력합니다. DB Service 이름은 DB Server를 역할별로 구분한 그룹의 명칭입니다. DB 설정 link USER ID와 암호를 입력합니다. (ID와 암호는 잊어버리지 않도록 잘 보관해야 합니다.) 접근제어는 접근을 허용할 IP 대역을 입력합니다. DB 접속포트는 기본 포트가 5432 입니다. 기본 DB명을 입력하고, Backup 설정을 선택합니다. report\r접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n최종 확인 link지금까지 입력한 값이 이상이 없는지 최종 확인하고, 수정할 부분이 없으면 [생성] 버튼을 클릭합니다.\nDB 상세 정보 linkDB 생성이 완료되면 아래와 같이 DB의 상세 정보를 확인할 수 있습니다.\n이 중에서 Private 도메인과 ACG는 이후 설정에서 사용할 중요한 항목입니다.\nClient Server 생성 | Ubuntu link처음에 설명했 듯이 Cloud DB for PostgreSQL DB Server는 Private 환경에서만 접속 가능하므로 PostgreSQL Client를 설치할 Linux Server를 생성해야 하는데, 여기서는 Ubuntu 18.04을 설치했습니다.\nVPC 환경에서 Linux Server를 생성하는 방법은 다음 문서를 참고하시기 바랍니다.\n"
            }
        );
    index.add(
            {
                id:  189 ,
                href: "\/docs\/database\/cloud-db-postgresql\/cdb-create-basic-guide-centos\/",
                title: " VPC환경에서 Cloud DB for PostgreSQL 생성하고 CentOS서버로 접속하기",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Cloud DB for PostgreSQL 생성하고 CentOS Server를 통해 Private 도메인으로 접속하는 방법입니다",
                content: "지원 클라우드 환경 linkNcloud Cloud DB for PostgreSQL이 지원하는 클라우드 환경은 다음과 같습니다.\n리전(존): 한국, 싱가포르 VPC만\t지원 언어: 한국어, 영어, 일본어, 중국어(간체) DB 엔진 버전: PostgreSQL 13.3 서버 사양과 요금 link(2022-03-30 기준)\n타입제공사양이용 요금\rvCPU메모리디스크시간당/대\rHigh CPU2개4GB50GB158원\r4개8GB323원\r8개16GB653원\r16개32GB1,313원\r32개64GB2,633원\rStandard2개8GB50GB250원\r4개16GB506원\r8개32GB1,019원\r16개64GB2,045원\r32개128GB4,099원\rHigh Memory2개16GB50GB302원\r4개32GB611원\r8개64GB1,227원\r16개128GB2,462원\r32개256GB4,927원\r서버 사양 변경 시 제약 사항 linkCloud DB for PostgreSQL 서버는 타입은 변경할 수 없지만 메모리 크기는 콘솔 PostgreSQL Server 메뉴에서 스펙 변경 기능을 사용하여 언제든지 변경할 수 있습니다. 그 외 제약 사항은 아래와 같습니다.\n같은 타입 내에서만 변경 가능 2대 이상의 서버로 구성된 경우(고가용성 사용 및 Read Replica 사용) 모두 동일한 사양으로 변경 변경 완료 후 서버가 다시 시작되며 이에 따라 서비스 영향 발생 가능성 존재 상세 특징 link DB 엔진 버전: PostgreSQL 13.3 스토리지: 기본 10GB 데이터 스토리지를 제공하며, 10GB 단위로 6000GB까지 자동으로 용량이 증가 Multi Zone 구성 제공 자동 Fail-over 기본 지원 최대 5대까지 Read Replica 확장 최대 30일까지 자동 백업 및 보관 서버 접근 방법 linkCloud DB for PostgreSQL은 현재 다음의 3가지 방법으로 접근 가능한데 여기서는 별도의 Linux 서버를 생성해서 PostgreSQL과 Private 통신을 하는 방법으로 진행하겠습니다.\n⁃ Public Domain으로 접근 (2022-04-21 업데이트) ⁃ PostgreSQL DB와 Private 통신을 위한 별도의 서버를 생성해서 접근 ⁃ SSL VPN을 이용해서 접근\rDB 생성 link[Cloud DB for PostgreSQL] - [DB Server]에서 [DB Server 생성] 버튼을 클릭해 DB를 생성을 시작합니다.\n서버 설정 link DB 엔진: 현재 지원되는 DB 엔진 버전은 PostgreSQL 13.3 입니다. 고가용성 지원은 기본 선택 사항인데, 필요하지 않을 경우 체크를 해제하면 됩니다. VPC와 Subnet을 선택하고, 미리 생성된 VPC와 Subnet가 없으면 생성 버튼을 클릭합니다. DB Server 타입은 위쪽에서 확인했던 서버 사양 중에서 원하는 vCPU와 메모리를 선택하면 됩니다. 데이터 스토리지 타입과 암호화 적용 여부를 선택합니다. 데이터 스토리지는 기본 10GB로 설정되며 최대 6000GB까지 자동으로 증가합니다. DB Server 이름과 DB Service 이름을 입력합니다. DB Service 이름은 DB Server를 역할별로 구분한 그룹의 명칭입니다. DB 설정 link USER ID와 암호를 입력합니다. (ID와 암호는 잊어버리지 않도록 잘 보관해야 합니다.) 접근제어는 접근을 허용할 IP 대역을 입력합니다. DB 접속포트는 기본 포트가 5432 입니다. 기본 DB명을 입력하고, Backup 설정을 선택합니다. report\r접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n최종 확인 link지금까지 입력한 값이 이상이 없는지 최종 확인하고, 수정할 부분이 없으면 [생성] 버튼을 클릭합니다.\nDB 상세 정보 linkDB 생성이 완료되면 아래와 같이 DB의 상세 정보를 확인할 수 있습니다.\n이 중에서 Private 도메인과 ACG는 이후 설정에서 사용할 중요한 항목입니다.\nClient Server 생성 | CentOS link처음에 설명했 듯이 Cloud DB for PostgreSQL DB Server는 Private 환경에서만 접속 가능하므로 PostgreSQL Client를 설치할 Linux Server를 생성해야 하는데, 여기서는 CentOS 7.8을 설치했습니다.\nVPC 환경에서 Linux Server를 생성하는 방법은 다음 문서를 참고하시기 바랍니다.\n"
            }
        );
    index.add(
            {
                id:  190 ,
                href: "\/docs\/database\/cloud-db-postgresql\/cdb-access-public-domain-guide\/",
                title: "Cloud DB for PostgreSQL 생성 후 Public 도메인으로 접속하기",
                description: "Ncloud(네이버 클라우드) VPC환경에서 Cloud DB for PostgreSQL 생성 후 Public 도메인으로 접속하는 방법입니다",
                content: "지원 클라우드 환경 linkNcloud Cloud DB for PostgreSQL이 지원하는 클라우드 환경은 다음과 같습니다.\n리전(존): 한국, 싱가포르 VPC만\t지원 언어: 한국어, 영어, 일본어, 중국어(간체) DB 엔진 버전: PostgreSQL 13.3 DB 생성 link[Cloud DB for PostgreSQL] - [DB Server]에서 [DB Server 생성] 버튼을 클릭해 DB를 생성을 시작합니다.\n서버 설정 link DB 엔진: 현재 지원되는 DB 엔진 버전은 PostgreSQL 13.3 입니다. 고가용성 지원은 기본 선택 사항인데, 필요하지 않을 경우 체크를 해제하면 됩니다. VPC와 Subnet을 선택하고, 미리 생성된 VPC와 Subnet가 없으면 생성 버튼을 클릭합니다. Subnet은 반드시 Public Subnet으로 선택합니다. DB Server 타입은 위쪽에서 확인했던 서버 사양 중에서 원하는 vCPU와 메모리를 선택하면 됩니다. ⁃ Public 도메인은 Public Subnet에 생성된 DB 서버에서만 이용 신청이 가능합니다. ⁃ DB 서버 생성 이후에 Subnet 이전은 불가능합니다.\r데이터 스토리지 타입과 암호화 적용 여부를 선택합니다. 데이터 스토리지는 기본 10GB로 설정되며 최대 6000GB까지 자동으로 증가합니다. DB Server 이름과 DB Service 이름을 입력합니다. DB Service 이름은 DB Server를 역할별로 구분한 그룹의 명칭입니다. DB 설정 link USER ID와 암호를 입력합니다. (ID와 암호는 잊어버리지 않도록 잘 보관해야 합니다.) 접근제어는 접근을 허용할 IP 대역을 입력합니다. DB 접속포트는 기본 포트가 5432 입니다. 기본 DB명을 입력하고, Backup 설정을 선택합니다. report\r접속포트 설정: DB 접속포트는 한번 설정하면 이후에 변경할 수 없으니 신중하게 설정하셔야 합니다.\n최종 확인 link지금까지 입력한 값이 이상이 없는지 특히 Public Subnet으로 설정했는지 최종 확인하고, 수정할 부분이 없으면 [생성] 버튼을 클릭합니다.\nPublic 도메인 설정 linkDB 생성이 완료되면 아래와 같이 DB의 상세 정보를 확인할 수 있습니다.\n[DB 관리] - [Public 도메인 관리] 메뉴를 클릭합니다.\n[Public 도메인 신청] 팝업에서 [예] 버튼을 클릭합니다.\n이제 [Public 도메인]이 생성되었습니다. 생성된 Public 도메인과 ACG 이름이 중요하니 기억해 둡니다.\nACG 설정 link[Server] - [ACG]에서 Cloud DB for PostgreSQL 생성 시에 자동으로 생성된 ACG [cloud-postgresql-ooooo]를 선택하고, [ACG 설정] 버튼을 클릭합니다.\nACG 규칙 설정 linkACG 규칙 설정 창에서 [Inbound] 탭을 선택하고 [접근 소스]는 [myIp]를 클릭하고 허용 포트는 5432를 입력하고 [추가] 버튼을 클릭합니다.\npgAdmin 4 다운로드 linkPostgreSQL에 접속하기 위한 클라이언트 pgAdmin 4를 다운로드 합니다.\npgAdmin 다운로드 페이지 다운로드 할 버전은 pgAdmin 4 v6.7 (released March 14, 2022) 입니다.\npgAdmin 4 설치 linkpgAdmin 4 클라이언트가 설치되는 기본 경로는 다음과 같습니다.\nC:\\Users\\{Windows User Account}\\AppData\\Local\\Programs\\pgAdmin 4\\v6\rpgAdmin 4 실행 linkpgAdmin Master Password 입력 linkpgAdmin 4 접속/관리를 위한 Master Password를 입력합니다. DB와는 관계없고 단지 pgAdmin 클라이언트를 위한 패스워드입니다.\nMaster Password는 반드시 입력해야 합니다. 여기서 설정하지 않으면 internal server error: crypt key is missing 에러가 발생하면서 서버 관리를 할 수 없게 됩니다.\rpgAdmin Master Password 재설정 link이후에 혹시 Master Password를 잊어버렸을 경우에는 아래와 같이 [Reset Master Password] 기능을 이용해 재설정 할 수 있습니다.\n서버 추가 linkpgAdmin에서 [Add New Server] 버튼을 클릭해서 위에서 생성했던 DB서버를 연결합니다.\nName 입력 link등록할 DB의 이름을 편하게 입력합니다.\n연결 정보 입력 link Host name/address: Cloud DB for PostgreSQL 생성 후에 확인한 Public 도메인 (pg-oooo-vpc-pub-cdb-kr.ntruss.com)을 입력합니다. Username: Cloud DB for PostgreSQL 생성 시에 입력한 USER ID를 입력합니다. Password: Cloud DB for PostgreSQL 생성 시에 입력한 USER 암호를 입력합니다. pgAdmin 4 대시보드 link연결 정보에 이상이 없고 정상적으로 접속이 되면 아래와 같이 대시보드 화면을 확인할 수 있습니다.\nDB Service 상세 보기 linkDB Service 상세 보기에서는 Database 추가/삭제, Config 관리, User 추가/삭제, Backup 설정 등을 관리할 수 있습니다.\nCloud DB for PostgreSQL을 선택하고 [DB 관리] - [DB Service 상세보기] 메뉴를 클릭합니다.\nDatabase 관리 linkPostgreSQL DB의 Database를 추가/삭제 할 수 있습니다.\nDB User 관리 linkCloud DB for PostgreSQL의 DB User를 추가/삭제 할 수 있습니다.\n⁃ PostgreSQL은 1개의 DB에 1개 계정만 owner로 지정할 수 있습니다.\n⁃ 1개의 DB를 여러 계정으로 관리해야 하는 경우는 서브 계정을 만들고 owner 계정으로 서브 계정에 별도의 권한을 설정해야 합니다.\n⁃ 이때 계정 생성은 Ncloud 콘솔에서만 가능합니다. (아래 화면의 DB User 관리 기능)\n⁃ 그 외의 권한 설정은 pgAdmin4 웹페이지에서 설정해야 합니다.\r서브 계정 linksubid라는 서브 계정을 만들었다고 가정했을 때 아래 화면처럼 Superuser 등의 권한 설정을 할 수 있습니다.\nDB 접근 권한 설정 link서브 계정의 특정 DB에 대한 접근 권한을 설정하고자 할 경우는 아래와 같이 DB를 선택하고, 마우스 오른쪽 클릭을 한 후 [Properties] 메뉴를 선택합니다.\n[Properties] 설정 화면에서 [Security] 메뉴를 선택하면 계정별로 권한을 설정할 수 있습니다.\n오류 상황 linkpgAdmin 4를 사용할 때 아래와 같은 오류가 발생하는 경우가 있습니다.\n이는 pgAdmin 4 최신 버전인 6.8을 사용할 때 발생하는 것으로 위에서 안내했 듯이 6.7 버전을 사용하면 문제가 없습니다.\nreport\rFailed to retrieve data from server: Request failed with status code 500\n참고 URL link Ncloud Cloud DB for PostgreSQL 기본 가이드\nhttps://guide.ncloud-docs.com/docs/clouddbforpostgresql-overview\npgAdmin 홈페이지\nhttps://www.pgadmin.org/\nCloud DB for PostgreSQL Private 도메인 접속 - Ubuntu\n"
            }
        );
    index.add(
            {
                id:  191 ,
                href: "\/docs\/security\/ncloud-security-service-summary\/",
                title: "Ncloud Security 서비스 요약",
                description: "Ncloud(네이버 클라우드)에서 제공하는 Security 서비스 상품들을 간단한 설명과 함께 요약 정리했습니다",
                content: "개요 link네이버 클라우드에서 제공하는 Security 서비스 상품들을 간단한 설명과 함께 요약 정리한 내용입니다. 이 내용도 파트너 테크데이에서 공개된 자료입니다.\n서비스 요약 link 구분 상품 설명 침입탐지/대응 Basic Security 모든 고객에게 기본으로 제공되는 무료 보안 서비스 Security Monitoring IDS, Anti-DDos, Anti-Virus, IPS, WAF와 같은 다양한 보안 상품들을 이용하여 높은 수준의 보안 서비스를 제공 Site Safer 고객이 개발한 웹사이트가 해킹 또는 다른 보안 문제로 인해 악성코드를 배포하는지 검사 File Safer 고객의 서비스에서 제공하는 파일과 아웃링크 URL의 악성코드 감염 여부를 해시 기반으로 검사 App Safer 고객의 앱이 모바일에서 실행될 때, 루팅/탈옥, 악성 앱 설치, 앱 변조 등 보안 위협 여부를 실시간으로 탐지 Webshell Behavior Detector 고객의 웹 서비스를 공격하는 다양한 웹셀을 행위기반으로 실시간 탐지하는 서비스 접근제어 ACG 인스턴스 그룹 단위로 IP, Port 기반의 네트워크 패킷 필터링 기능을 제공 Secure Zone 개인정보와 같이 중요한 정보를 보다 더 안전하게 보호할 수 있도록 대외 인터넷 망과 분리된 별도의 존을 제공 인증/권한 관리 Sub Account 사용자 업무 역할별로 권한 관리를 할 수 있는 기능 제공 암호화 KMS 고객 데이터의 암/복호화에 이용되는 키를 안전하게 보호할 수 있는 서비스 Certificate Manager SSL 인증서의 손쉬운 등록 및 관리 서비스를 제공 로깅 및 모니터링 Resource Manager 네이버 클라우드 서비스 내에 생성한 모든 리소스를 한 눈에 볼 수 있는 통합관리 서비스 Cloud Activity Tracer 네이버 클라우드 서비스에서 발생한 계정 활동 로그를 자동으로 수집해주는 서비스 Cloud Advisor 네이버 클라우드 모범 사례에 따른 서비스 이용 권장 지침 안내 취약점 관리 System Security Checker 고객 서버의 운영체제 및 WAS 시스템에 대해서 보안상 취약점이 없는지 점검하고 결과 리포트를 제공해주는 서비스 Web Security Checker 고객의 웹서비스에 대해 총 20가지의 주요 웹 취약점을 자동으로 진단하고 결과 리포트를 제공해주는 서비스 App Security Checker 고객의 Andorid 모바일 앱에 대해 취약점을 자동으로 점검하고 결과 리포트를 제공해주는 서비스 Compliance Compliance Guide 고객이 보안 인증이나 규제에 대응하는데 필요한 사항을 알기 쉽게 정리한 가이드 참고 URL link Ncloud Security Service 상품 소개\nhttps://www.ncloud.com/product/security 문서 업데이트 내역 link\r날짜 내용 2021-04-26 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  192 ,
                href: "\/docs\/security\/ncloud-security-service-onpremise-compare\/",
                title: "Ncloud vs On-Premise Security 서비스 비교",
                description: "Ncloud(네이버 클라우드)와 On-Premise 두 환경의 보안서비스에 대한 비교 정리입니다",
                content: "개요 link기존의 IDC 등의 On-Premise 환경에서 사용하고 있는 보안 서비스를 네이버 클라우드 환경에서 어떻게 구현할 수 있는지에 대한 비교 가이드입니다.\nIDC에 있는 서버들을 네이버 클라우드로 마이그레이션 할 때 참고하시면 되겠습니다.\nOn-Premise → Naver Cloud link 구분 On-Premise Naver Cloud 설명 Network DDos → Security Monitoring Security Monitoring DDos 서비스를 통해 고객별 특화된 탐지 정책을 적용 방화벽 → ACG(Access Control Group) ACG Rule 변경 기능으로 서버 접속을 허용할 트래픽 규칙을 안전하고 편리하게 관리 IDS/IPS → Security Monitoring Security Monitoring IDS/IPS 서비스를 통해 고객별 특화된 탐지/차단 정책을 적용 전송구간 암호화 → IPSec/SSL VPN, Cloud Connect 고객의 네트워크와 네이버 클라우드에 있는 네트워크에 대한 안전한 연결을 제공 DB DB 접근 통제 → Naver Cloud MarketPlace MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용 DB 암호화 → Naver Cloud MarketPlace MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용 Server 서버접근통제 → SSL VPN, Naver Cloud MarketPlace SSL VPN을 이용해 서버 접근을 관리 MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용 서버보안(SecureOS) → Naver Cloud MarketPlace MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용 Anti Virus → Security Monitoring Security Monitoring DDos 악성코드 의심 이벤트 발생 시 탐지 보고서 및 분석 정보 전달 Application 웹 방화벽 → Security Monitoring Security Monitoring WAF서비스를 통해 고객별 특화된 탐지/차단 정책을 적용 Anti-Webshell → Naver Cloud MarketPlace MarketPlace에서 제공하는 3rd-Party 솔루션을 VM에 설치하여 사용 User Access 사용자 접근통제 → Sub Account Sub Account 서비스를 이요하여 콘솔 접근에 대한 사용자 접속을 관리 Audit - → Cloud Activity Tracer / Resource Manager 리소스(서버, 네트워크, DB등) 생성, 변경, 삭제에 대해 추적 기능을 제공 Key Management - → Key Management Service Key에 대한 접근 제어 기능을 이용하여 데이터 암호화 키를 안전하게 보호하고 관리 참고 URL link Ncloud Security Service 상품 소개\nhttps://www.ncloud.com/product/security 문서 업데이트 내역 link\r날짜 내용 2020-12-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  193 ,
                href: "\/docs\/security\/acg\/basic-guide\/",
                title: "Ncloud 방화벽 ACG 설정 기본 가이드",
                description: "Ncloud(네이버 클라우드)에서 제공하는 IP/Port 기반 필터링 방화벽 서비스 ACG(Access Control Group) 기본 가이드입니다",
                content: "개요 linkACG(Access Control Group)는 서버 간 네트워크 접근 제어 및 관리를 할 수 있는 IP/Port 기반 필터링 방화벽 서비스로 AWS에서는 비슷하게 Security Group이라는 것이 있습니다.\n제한 사항 linkVPC 환경 link VPC당 최대 500개까지 ACG 생성 가능 NIC당 3개의 ACG를 허용 Inbound / Outbound 각각 50개의 규칙 생성 가능 Classic 환경 link 계정당 최대 100개까지 ACG를 생성 가능 각 ACG에는 최대 100개까지의 규칙을 설정할 수 있음 서버는 최대 5개의 ACG에 중복 포함될 수 있음 서버가 생성될 시 선택한 ACG는 변경이 불가하며, 반납 전까지 해당 ACG 규칙을 적용 받게 됨 Classic 환경에서는 서버 자체에 할당되는 개념이었으나 VPC에는 NIC 즉, 네트워크 카드에 할당되는 개념이어서 VPC 환경에서는 NIC 당 최대 3개까지 ACG를 적용할 수 있습니다.\rACG 위치 linkNcloud 콘솔에서 ACG의 위치는 [Services] - [Compute] - [Server] - [ACG]에 있습니다.\nVPC 환경 link\rClassic 환경 link\r기본 규칙 linkDefault ACG link기본적으로 추가되는 ACG\n모든 들어오는 연결(inbound traffic)을 차단함 모든 나가는 연결(outbound traffic)을 허용함 Default ACG 내 속한 서버들끼리의 네트워크 양방향 통신(TCP, UDP, ICMP)이 허용됨 원격 접속 기본 포트 (Linux - 22, Windows - 3389)에 대한 TCP 허용됨 VPC 화면 linkInbound (기본 설정) link\r기본으로 생성된 ACG에는 위처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 허용되어 있는데 보안을 위해 이 항목을 삭제하고 아래와 같이 지정된 IP에서만 접속하도록 수정하는 것을 적극 권장합니다.\rInbound (권장 설정) link\rOutbound link\rClassic 화면 (기본 설정) link\r기본으로 생성된 ACG에는 위처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 허용되어 있는데 보안을 위해 이 항목을 삭제하고 아래와 같이 지정된 IP에서만 접속하도록 수정하는 것을 적극 권장합니다.\rClassic 화면 (권장 설정) link\rCustom ACG linkDefault ACG 이외에 사용자가 추가하는 ACG\n모든 inbound traffic을 차단함(규칙으로 명시되어 있지 않음) 모든 outbound traffic을 허용함(규칙으로 명시되어 있지 않음) 접근소스 설정 linkACG를 설정할 때 접근 소스 항목은 보통 IP주소를 입력하게 됩니다. 하지만 특수한 경우로 Load Balancer를 지정하거나 ACG 이름을 지정하는 경우도 있습니다. 이 중에서 다른 ACG를 접근 소스 항목으로 지정하는 경우는 해당 ACG가 적용된 서버들이 접근할 수 있도록 규칙을 설정하는 것인데, 아래 예시를 이용해 정리해보겠습니다.\nACG-1 link 적용서버 : SVR-1, SVR-2 ACG-2 link 적용서버 : SVR-3 ACG-2 적용 규칙 link 프로토콜 : TCP 접근소스 : ACG-1 허용포트 : 80 info\r위와 같은 경우 ACG-1이 적용된 SVR-1, SVR-2 서버에서 ACG-2가 적용된 SVR-3 서버로 80포트를 이용한 접근을 허용한다는 의미입니다.\nVPC 환경에서 ACG를 접근소스를 설정할 때는 동일한 VPC에 생성된 ACG만 접근소스로 설정할 수 있습니다.\r문서 업데이트 내역 link\r날짜 내용 2022-06-30 문서 최초 생성 2023-04-20 스크린샷 업데이트 "
            }
        );
    index.add(
            {
                id:  194 ,
                href: "\/docs\/security\/acg\/custom-acg-configure-sample\/",
                title: "Ncloud 방화벽 ACG 권장설정과 Custom ACG 설정 예시",
                description: "Ncloud(네이버 클라우드)에서 제공하는 IP/Port 기반 필터링 방화벽 서비스 ACG(Access Control Group) 권장설정과 Custom ACG 설정 예시를 몇가지 정리해보았습니다",
                content: "개요 linkNcloud (네이버 클라우드)의 IP/Port 기반 필터링 방화벽 서비스인 ACG(Access Control Group) 권장설정과 Custom ACG 설정할 때 참고할 만한 예시를 몇가지 정리해보겠습니다.\nInboud 기본 규칙 삭제 link\r서버 생성 시에 기본으로 생성되는 Default ACG에는 아래처럼 22, 3389 포트에 대해 0.0.0.0/0 즉, 전체 IP에 대해 접근이 허용되어 있는데 보안을 위해 이 항목을 삭제하고 지정된 IP에서만 접속하도록 수정하는 것을 적극 권장합니다.\rVPC 화면 link아래는 Default ACG가 생성되면서 설정된 전체 접근 허용 상태입니다. 여기서 X버튼을 클릭해서 [0.0.0.0/0] 대역의 설정 2가지를 모두 삭제합니다.\n위에서 기본 설정을 삭제하고 특정 IP만 접근 허용 상태입니다.\n일반적으로 [myip] 버튼을 클릭해서 현재 접속한 PC의 IP를 허용하게 됩니다.\nClassic 화면 link아래도 Default ACG가 생성되면서 설정된 전체 접근 허용 상태입니다. 여기서 X버튼을 클릭해서 [0.0.0.0/0] 대역의 설정 2가지를 모두 삭제합니다.\n위에서 기본 설정을 삭제하고 특정 IP만 접근 허용한 상태입니다.\n일반적으로 [myip] 버튼을 클릭해서 현재 접속한 PC의 IP를 허용하게 됩니다.\n용도별 ACG 구분 linkACG는 사용하는 서버들을 용도별로 구분해서 기본 ACG외에 별도의 Custom ACG를 아래의 예시처럼 그룹별로 생성해서 적용하는 것이 좋습니다.\nVPC 환경에서 ACG 생성 link[Server] - [ACG]에서 생성할 수 있으며 이름 규칙은 최소 3자, 최대 30자, 소문자만, 숫자와 하이픈(-) 사용 가능합니다.\n그리고, ACG를 적용할 VPC도 선택해야 합니다.\nClassic 환경에서 ACG 생성 link[Server] - [ACG]에서 생성할 수 있으며 이름 규칙은 최소 6자, 최대 30자, 소문자만, 숫자와 하이픈(-) 사용 가능합니다.\n용도별 Custom ACG 생성 예시 link아래의 Custom ACG 명칭은 임의로 작성한 것이며, 어떤 규칙으로 이름을 정할 것인가는 각자 자체 기준에 따라 편하신대로 정하시면 됩니다.\nDB-ACG APP-ACG WAS-ACG WEB-ACG BILL-ACG Jenkins-ACG Login-Server-ACG Lobby-Server-ACG Chat-Server-ACG PVP-Server-ACG Live-Streaming-ACG VOD-Server-ACG API-Server-ACG Bill-DB-ACG Bill-APP-ACG Admin-Tool-ACG Live-Service-ACG Dev-System-ACG QA-System-ACG Home-Access-ACG External-Developer-ACG Partner-Company-ACG 복수의 ACG 적용 link1개 서버에 허용이 필요한 설정을 모두 추가한 1개의 ACG만 무리하게 적용하려 하기 보다는 위의 예시처럼 용도별로 구분한 ACG를 여러 개 적용하는 것을 추천합니다. 예를 들어 아래와 같이 각각의 용도별 서버들에는 이런 식으로 ACG를 구분해서 적용할 수도 있습니다.\n예를 들어 채팅 서버에 ACG를 적용할 때의 예시는 다음과 같습니다.\n적용 ACG: APP-ACG, Chat-Server-ACG 마찬가지로 QA 빌링 DB에 ACG를 적용할 때의 예시는 다음과 같습니다.\n적용 ACG: DB-ACG, BILL-ACG, QA-System-ACG Custom ACG 적용 순서 link ACG 생성 우선 위의 방법대로 ACG를 용도별로 구분해서 생성합니다. ACG 적용 다음으로 생성한 ACG를 서버에 적용하는 단계입니다. 아래쪽에서 VPC, Classic 각각의 환경별로 살펴보겠습니다. VPC 환경 linkVPC 환경은 NIC에 ACG가 적용되는 구조이므로 NIC당 최대 3개까지 할당할 수 있습니다.\nClassic 환경 linkClassic 환경에서는 서버에 적용되는 구조이고, 최대 5개까지 선택 가능합니다.\n이때 Classic 환경 ACG는 서버를 생성하는 단계에서만 적용할 수 있습니다.\n서버 생성이 완료된 후에는 추가로 ACG를 적용할 수 없습니다.\rCustom ACG 추가 적용-제거 linkClassic 환경과 달리 VPC 환경에서는 ACG가 서버가 아닌 NIC에 적용되는 구조이며, 기존에 적용된 ACG외에 추가로 ACG를 적용하거나 제거할 수 있습니다.\n아래와 같이 서버 상세정보 NIC 항목에서 [ACG 수정] 버튼을 클릭합니다.\nACG 추가 적용 linkACG 수정 화면에서 왼쪽 창에서 적용하려는 ACG를 선택하고 오른쪽 창으로 이동시키면 됩니다.\nACG 제거 linkACG 수정 화면에서 오른쪽 창에서 제거하려는 ACG를 선택하고 왼쪽 창으로 이동시키면 됩니다.\n이때 ACG는 최소 1개가 적용되어 있어야 하므로 마지막 ACG 1개는 제거할 수 없습니다.\r접근소스를 Load Balancer로 설정 linkACG를 설정할 때 접근 소스 항목은 보통 IP주소를 입력하게 됩니다. 하지만 특수한 경우로 Load Balancer를 지정하거나 ACG를 직접 지정하는 경우도 있습니다.\n먼저 로드밸런서를 생성하고 서버와 연결한 후에 서버측 ACG에 로드밸런서의 접근을 허용하는 방법에 대해 알아보겠습니다.\nVPC 환경 linkVPC 환경에서 아래와 같이 로드밸런서의 서브넷 네트워크가 [10.0.4.0/24] 대역이라고 가정해보겠습니다.\n서버의 ACG 규칙 설정 화면에서 아래와 같이 접근소스에 위에서 확인한 로드밸런서의 서브넷 네트워크 [10.0.4.0/24]를 입력하면 됩니다.\nVPC 환경에서 로드밸런서와 서버를 연결할 때에는 ACG 설정 외에도 Network ACL 등 추가로 설정해야 하는 것들이 많이 있습니다. 자세한 설정 방법은 아래 문서를 참고하시기 바랍니다. ⁃ VPC 환경에서 Application Load Balancer 생성하기\rClassic 환경 linkClassic 환경에서는 아래와 같이 로드밸런서의 ACG 소스 명칭이 [ncloud-load-balancer]로 고정되어 있습니다.\nACG 규칙 설정 화면에서 접근소스에 로드밸런서의 ACG 소스 [ncloud-load-balancer]를 입력하면 됩니다.\n접근소스를 ACG로 설정 link다음으로 다른 ACG를 접근소스로 지정하는 경우도 있습니다. 이것은 해당 ACG가 적용된 서버들이 접근할 수 있도록 규칙을 설정하는 것인데, 아래 설정 방법과 예시를 통해 자세히 알아보겠습니다.\nVPC 환경 linkACG 규칙 설정에서 접근 소스 항목에 지정하려는 ACG 이름을 일부 입력하면 아래와 같이 적용 가능한 ACG 리스트가 나타는데 그 중에서 지정하려는 ACG를 선택하면 됩니다.\nVPC 환경에서 ACG를 접근소스를 설정할 때는 동일한 VPC에 생성된 ACG만 접근소스로 설정할 수 있습니다.\rClassic 환경 linkClassic도 마찬가지로 ACG 규칙 설정에서 접근 소스 항목에 지정하려는 ACG 이름을 일부 입력하면 아래와 같이 적용 가능한 ACG 리스트가 나타는데 그 중에서 지정하려는 ACG를 선택하면 됩니다. Classic은 VPC와 달리 특별한 제한이 없습니다.\n예시 link아래와 같이 SVR-1, SVR-2, SVR-3 서버에 각각 ACG-1, ACG-2가 적용되어 있다고 가정해보겠습니다.\n[ACG-1]\n적용서버 : SVR-1, SVR-2 [ACG-2]\n적용서버 : SVR-3 [ACG-2 적용 규칙]\n프로토콜 : TCP 접근소스 : ACG-1 허용포트 : 80 info\r위와 같은 경우 ACG-1이 적용된 SVR-1, SVR-2 서버에서 ACG-2가 적용된 SVR-3 서버로 80포트를 이용한 접근을 허용한다는 의미입니다.\nACG 삭제 linkCustom ACG는 VPC, Classic 환경 모두 [Console] - [Server] - [ACG] 메뉴에서 삭제할 수 있습니다.\n삭제하려는 ACG를 선택하고 [ACG 삭제] 버튼을 클릭합니다.\nACG 삭제 팝업에서 [예] 버튼을 클릭합니다.\n삭제 불가 link아직 적용된 서버나 NIC가 존재하는 ACG는 삭제할 수 없습니다.\nVPC 환경 linkVPC 환경에서 삭제를 시도하면 [ACG에 속해 있는 Network Interface가 존재합니다. 해당 Network Interface에서 ACG를 삭제 후 다시 시도해주세요]라는 메시지가 나타납니다.\nClassic 환경 linkClassic 환경에서 삭제를 시도하면 [서버가 한대라도 ACG 에 적용되어 있는 상태이면, 해당 ACG 는 삭제할 수 없습니다]라는 메시지가 나타납니다.\nDefault ACG 삭제 불가 link기본적으로 생성된 Default ACG는 삭제할 수 없습니다.\n참고 URL link VPC 환경 ACG 설정\nhttps://guide.ncloud-docs.com/docs/server-acg-vpc\nClassic 환경 ACG 설정\nhttps://guide.ncloud-docs.com/docs/server-acg-classic\n문서 업데이트 내역 link\r날짜 내용 2022-07-06 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  195 ,
                href: "\/docs\/security\/security-monitoring\/waf-price-info\/",
                title: "Ncloud Security Monitoring WAF 서비스 요금 정보",
                description: "Ncloud (네이버 클라우드) Security Monitoring WAF 서비스 요금 정보입니다",
                content: "개요 linkNcloud (네이버 클라우드) Security Monitoring 서비스는 무료인 Basic 서비스와 유료인 Managed 서비스가 있고, 그 중에서 유료 서비스인 Managed 서비스는 IDS, Anti-DOS, WAF, Anti-Virus, IPS 등 4가지 서비스를 모두 제공하고 있는데 그 중에서 WAF(Web Application Firewall) 서비스의 이용 요금 구성과 신청 시 주의 사항에 대해 정리해보겠습니다.\n구성 linkWAF 서비스 장비는 [WAF VM + WAF LB]로 구성되어 있습니다. 따라서 사용 요금도 WAF VM 요금과 WAF LB 요금이 별도로 청구됩니다.\n요금 link\r상품명\r과금 구간 (Mbps)\r가격 (월 요금, VAT별도)\r비고\rMulti\nWAF VM\r0 ~ 300 이하\r974,800 원\r리전 단위 판매\n이중화 기본 제공\n(요금은 이중화 가격)\r300 초과 ~ 500 이하\r1,474,800 원 500 초과 ~ 1,000 이하\r2,274,800 원 Single\nWAF VM\r0 ~ 300 이하\r624,800 원\r리전 단위 판매\r300 초과 ~ 500 이하\r924,800 원 500 초과 ~ 1,000 이하\r1,299,800 원 WAF LB\rWAF LB 1개당\r25,200 원\rWAF LB개수는 WAF 모니터링을 신청하려는\n도메인 개수 또는 인증서 개수를 의미\r과금 구간 기준 link과금 구간을 결정, 변경하게 되는 기준은 월 기준 in/out 트래픽 중에서 Peak 트래픽입니다. 그러므로 월 기준으로 단 한번이라도 신청 구간을 초과할 경우 과금 기준이 변경될 수 있습니다.\n추가 도메인 link여러 개의 도메인을 추가할 경우 도메인 개수 만큼 WAF LB 요금이 추가 됩니다.\n서브 도메인의 요금 link 개별 인증서를 사용하는 서브 도메인은 인증서 개수 만큼 WAF LB 요금이 추가 됩니다. Wildcard 인증서를 사용하는 서브 도메인은 추가 요금 없이, 개수 제한 없이 사용 가능합니다. 다만, 서브 도메인 개수나 트래픽에 따라 WAF LB 또는 WAF VM이 추가 되어 요금이 증가할 수 있습니다. 요금 예시 linkMulti WAF link\r해당 월 Peak 트래픽 도메인 또는\n인증서 개수 WAF VM 요금 (VAT 별도) WAF LB 요금 (VAT 별도)\r합계 (VAT 별도)\n(WAF VM 요금 + WAF LB 요금)\r90 Mbps 1개\r974,800 원 25,200 원\r1,000,000 원\r90 Mbps 2개\r974,800 원 50,400 원\r1,025,200 원\r300 Mbps 1개\r974,800 원 25,200 원\r1,000,000 원\r301 Mbps 1개\r1,474,800 원 25,200 원\r1,500,000 원\rSingle WAF link\r해당 월 Peak 트래픽 도메인 또는\n인증서 개수 WAF VM 요금 (VAT 별도) WAF LB 요금 (VAT 별도)\r합계 (VAT 별도)\n(WAF VM 요금 + WAF LB 요금)\r90 Mbps 1개\r624,800 원 25,200 원\r650,000 원\r90 Mbps 2개\r624,800 원 50,400 원\r675,200 원\r300 Mbps 1개\r624,800 원 25,200 원\r650,000 원\r301 Mbps 1개\r924,800 원 25,200 원\r950,000 원\rWAF 이용 요금은 고객 서비스의 서버 정지와 무관하게 청구됩니다. 서버 정지와 함께 Security Monitoring 서비스의 WAF 계약도 함께 해지해야 과금되지 않습니다.\rWAF 신청 시 주의 사항 linkVPC link Application Load Balancer 사용 필수: WAF는 Reverse Proxy 방식으로 사용자별 별도의 WAF 플랫폼을 구성하여 제공하고, HTTP/HTTPS 트래픽에 대한 보안 모니터링을 제공합니다. 따라서 Application Load Balancer를 사용하는 HTTP/HTTPS 서비스에만 제공이 가능합니다. 서비스 도메인 필수: WAF 서비스를 사용하려면 사용자 서비스 도메인의 CNAME을 WAF Load Balancer 도메인 정보로 수정하여 트래픽이 WAF를 향하도록 설정해야 합니다. 그러므로 서비스 도메인이 있어야 서비스를 신청할 수 있습니다. 서비스 인증서 전달: HTTPS 서비스 모니터링을 위해 WAF Load Balancer에 인증서를 설치해야 하며, 서비스 신청 시 사용자 서비스의 인증서도 함께 전달해야 합니다. HTTP 80 리스너 설정: WAF VM과 사용자 서비스 Application Load Balancer 간의 통신은 HTTP 80 port 공인 통신을 사용합니다. 그러므로 사용자 서비스 Application Load Balancer에 HTTP 80 리스너를 기본으로 구성해야 합니다. 리다이렉션 설정: WAF Load Balancer에서 80 포트에 대한 443 리다이렉트 설정도 기본으로 지원하고 있습니다. 따라서 WAF 서비스를 정상적으로 사용하려면 사용자의 Application Load Balancer나 서버에서 HTTP -\u003e HTTPS 리다이렉트가 있는 경우 삭제해야 합니다. HTTP 프로토콜 설정: HTTPS 모니터링 신청 시, 신청한 Application Load Balancer 리스너에 HTTP 프로토콜 설정이 필요합니다. CNAME 설정: WAF(V2) 제공을 위해서 고객 대상 도메인에 CNAME 설정을 해야 합니다. 고객 대상 도메인이 Base 도메인인 경우, CNAME 설정이 불가능하오니 A레코드에 WAF VIP로 설정합니다. 그리고, WAF 구성 후 고객에게 CNAME에 등록할 WAF Load Balancer 도메인 설정 정보 전달 예정입니다. Classic link HTTP/HTTPS 표준 프로토콜 사용 필수: WAF는 HTTP/HTTPS 표준 프로토콜을 사용하는 웹 서비스에 대한 보안 모니터링을 제공합니다. 따라서 네이버 클라우드 플랫폼의 Load Balancer를 사용 중인 서비스에 대한 모니터링을 하려면 Load Balancer Protocol을 반드시 HTTP, HTTPS로 설정해야 합니다. 만약 TCP, SSL로 설정하는 경우 WAF 서비스를 사용할 수 없습니다. 참고 URL link Ncloud Security Monitoring 서비스 안내\nhttps://www.ncloud.com/product/security/securityMonitoring\nNcloud Security Monitoring 가이드\nhttps://guide.ncloud-docs.com/docs/securitymonitoring-overview\n문서 업데이트 내역 link\r날짜 내용 2023-09-18 문서 최초 생성 2023-11-03 서브 도메인 요금 관련 내용 추가 2023-12-07 요금 변경 내역 업데이트 2024-02-19 Single WAF 요금 안내 추가 "
            }
        );
    index.add(
            {
                id:  196 ,
                href: "\/docs\/security\/ssl-vpn\/basic-guide-vpc\/",
                title: "SSL VPN 설정하고 접속하는 방법 | VPC",
                description: "Ncloud(네이버 클라우드) VPC 환경에서 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 설정하고 접속하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 VPC 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\nSSL VPN이란? link VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다. 사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다. 가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다. SSL VPN 서비스 위치 linkNcloud 콘솔에서 SSL VPN의 위치는 [Services] - [Security] - [SSL VPN]에 있습니다.\nSSL VPN 생성 link[SSL VPN 생성] 버튼을 클릭합니다.\n우선 접근할 서버가 속해 있는 VPC를 선택하고, 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다.\nVPC 환경에서는 3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 선택 가능합니다.\nVPC 환경의 SSL VPN은 콘솔에서 자동으로 생성하는 것이 아니라 생성 요청을 하면 Ncloud 담당자가 직접 생성하고 결과를 안내 받는 구조로 되어 있습니다. 생성 완료까지 걸리는 시간은 약 10~20분 이내 이며, 생성이 완료되면 SSL VPN 상태가 [운영중]으로 변경되고, 안내 메일이 도착합니다.\nSSL VPN 생성 완료 linkSSL VPN 생성이 완료되면 아래와 같이 [IP POOL]과 [접속 URL] 정보를 확인할 수 있는데 SSL VPN Agent 접속 시에 중요한 정보이니 잘 확인해야 합니다.\n사용자 설정 linkSSL VPN에 접속할 사용자 정보를 설정합니다. 리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\nVPC 환경은 이차인증이 필수이므로 SMS와 Email 정보를 함께 입력합니다.\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\nRoute Table 설정 link네트워크 설정에서는 우선 접속할 서버가 속해 있는 VPC Subnet의 Route Table에 SSL VPN으로 접근할 수 있게 SSL VPN의 [IP POOL]을 등록해야 합니다.\n접속할 서버 정보 확인\n아래와 같이 접속할 서버의 정보에서 VPC와 Subnet을 확인합니다. 여기서는 Private Subnet에 생성한 서버에 접속할 예정입니다. VPC 서비스 위치 link[VPC] 서비스는 [Console] - [Services] - [Networking]에 위치해 있습니다.\n그리고, 아래와 같이 [VPC Management], [Subnet Management], [Route Table] 메뉴를 확인할 수 있습니다.\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭합니다.\n(Public Subnet에 생성한 서버에 접근해야 할 경우에는 public-table을 선택하고 설정하시면 됩니다.)\n[Destination]에 생성된 SSL VPN 정보에서 확인한 [IP POOL] 정보를 등록하고, [Target Type]은 SSLVPN을 선택, [Target Name]은 위에서 생성한 SSL VPN 이름을 선택하고 [생성] 버튼을 클릭합니다.\nACG 설정 link다음으로 서버에 적용된 ACG에 SSL VPN의 [IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 [ACG 수정] 버튼을 클릭해서 적용된 ACG를 확인합니다.\nACG 수정 화면에서 현재 적용된 ACG 이름을 확인할 수 있습니다.\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\nACG 규칙 설정 화면에서 위에서 확인했던 [IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. 기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\nAgent 다운로드 linkSSL VPN 접속을 위한 Agent를 다운로드 합니다.\nSSL VPN Agent 다운로드 Agent 접속 linkAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다. 서버 선택 창에 위에서 생성했던 SSL VPN 정보에서 확인했던 [접속 URL] 주소를 입력하고, [다음] 버튼을 클릭합니다.\ninfo\r접속 URL 확인하는 방법 주소 변경 후에 [연결] 버튼을 클릭하면 로그인 화면이 나타나는데 위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\n그리고 도착한 OTP 인증 번호를 입력합니다.\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에 [IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n서버 접속 link이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\nAgent 기타 설정 linkSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n트래픽 그래프 linkAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n설정 변경 link처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [SSL VPN 설정 변경] 버튼을 클릭합니다.\nID 개수 변경 link3, 5, 10, 20, 30, 50, 100, 200, 300, 400, 500개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n인증 로그 수집 linkNcloud SSN VPN은 이용자가 SSN VPN에 접속 인증한 로그를 수집할 수 있습니다. [설정] 버튼을 클릭합니다.\n인증 로그 수집을 활성화 하면 [Cloud Log Analytics]에 로그를 전달하여 저장합니다. 해당 상품을 미사용중이면 Cloud Log Analytics 상품 이용 신청을 한 후에 사용하시면 됩니다.\nCloud Log Analytics에서 인증 로그 확인 주의사항 link\rreport\r접속 오류: SSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다. 이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n삭제 link삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n하지만, 바로 삭제가 되지 않고 다음과 같이 “Route Table에서 Target으로 지정된 Route 정보를 모두 삭제해야 삭제가 가능합니다\"라는 메시지가 뜹니다.\n[VPC] - [Route Table]에서 해당 VPC의 Private Subnet을 선택하고 [Routes 설정] 버튼을 클릭해서 등록된 설정을 확인하고 [X] 버튼을 클릭해서 설정을 삭제합니다. Route Table 정보를 삭제한 후에 SSL VPN을 삭제하시면 됩니다.\n참고 URL link Ncloud SSL VPN 개요\nhttps://guide.ncloud-docs.com/docs/sslvpn-overview\nNcloud SSL VPN 사용 가이드 - Classic\nhttps://guide.ncloud-docs.com/docs/sslvpn-start-classic\n문서 업데이트 내역 link\r날짜 내용 2022-05-03 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  197 ,
                href: "\/docs\/security\/ssl-vpn\/basic-guide-classic\/",
                title: "SSL VPN 설정하고 접속하는 방법 | Classic",
                description: "Ncloud(네이버 클라우드) Classic 환경에서 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 설정하고 접속하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) 외부에서 내부에 구성된 네트워크로 암호화된 보안 접속 통신을 제공하는 서비스인 SSL VPN을 Classic 환경에서 설정하고, 서버에 접속하는 방법에 대해 정리해보겠습니다.\nSSL VPN이란? link VPN은 가상 사설망(Virtual Private Network)의 약자로, 외부에서 접근할 수 없는 사설망에 내 PC나 네트워크를 연결시키는 방법을 말합니다. 사설망과의 연결은 가상 터널을 통해 이루어지며, 이 가상 터널을 SSL 암호화로 보호하는 것이 SSL VPN입니다. 가상 터널을 통해 사설망과 연결된 사용자 PC는 사설망의 라우팅 및 ACL 정책에 따라 내부 서버에 접근할 수 있습니다. SSL VPN 생성 link[SSL VPN 생성] 버튼을 클릭합니다.\n우선 등록 가능한 접속 ID 개수에 따른 상품을 선택합니다. Classic 환경에서는 3개, 5개, 10개 상품만 선택 가능합니다. 다음으로 인증 방식은 ID/PW 만으로 접속하는 일차인증과 OTP까지 사용하는 이차 인증 중에서 원하는 방식을 선택합니다. 그리고 이차인증을 선택했을 경우에는 SMS와 Email 어떤 것을 이용할 것인지도 선택하게 됩니다.\n⁃ 인증방식과 OTP 전송 방식은 SSL VPN 생성 시에 한번 선택하면 변경할 수 없으니 주의해야 합니다. ⁃ 만약 변경 하고 싶을 경우에는 SSL VPN을 새로 생성해야 합니다. ⁃ Classic 환경에서는 이차인증을 선택하면 별도의 이용요금이 부과됩니다.\r다음으로 개인정보 수집 및 이용에 동의해야 합니다.\nSSL VPN이 생성되면 다음과 같이 리스트에 서 확인 가능하며 여기서 [SSL VPN IP POOL]은 뒤쪽에서 네트워크 접근 제한을 설정할 때 필요한 중요한 정보입니다.\n사용자 설정 linkSSL VPN에 접속할 사용자 정보를 설정합니다. 리스트에서 SSL VPN을 선택하고 [사용자 설정] 버튼을 클릭합니다.\n사용자 정보는 ID, Passowrd, Email, SMS 등을 입력하고 [추가] 버튼을 클릭합니다.\n사용자가 추가되면 SSL VPN 정보에 사용자 계정 수(등록된 ID 수)에 숫자가 표시되는 것을 확인할 수 있습니다.\nACG 설정 linkSSL VPN을 사용하려면 서버에 적용된 ACG에 [SSL VPN IP POOL]을 등록해야 합니다.\n우선 SSL VPN을 통해서 접속할 서버를 선택하고 적용된 ACG를 확인합니다.\n[Server] - [ACG]에서 위에서 확인한 ACG를 선택하고 [ACG 설정]을 클릭합니다.\nACG 규칙 설정 화면에서 위에서 확인했던 [SSL VPN IP POOL]을 접근 소스에 입력하고, 필요한 포트들을 등록합니다. 기본이 되는 프로토콜과 포트는 리눅스 서버 접속용 TCP 22, 윈도우 서버 접속용 TCP 3389, Ping 확인용 ICMP 등입니다.\nAgent 다운로드 linkSSL VPN 접속을 위한 Agent를 다운로드 합니다.\nSSL VPN Agent 다운로드 Agent 접속 linkAgent 프로그램, BIG-IP Edge Client를 설치하고 실행하면 다음과 같은 화면을 볼 수 있습니다.\nAgent에는 Classic 환경 SSL VPN 서버(Ncloud-kr-01)가 기본으로 설정되어 있는데, 혹시 빠져 있다면 [서버 변경] 버튼을 클릭해서 https://sslvpn-kr-01.ncloud.com을 입력하고 연결 버튼을 클릭합니다.\n위에서 설정했던 VPN 접속용 아이디와 Password를 입력하고 [로그온] 버튼을 클릭합니다.\nOTP 접속도 설정했다면 도착한 인증 번호를 입력합니다.\nSSL VPN에 제대로 연결이 되었는지 확인하기 위해서 cmd 창을 띄워서 ipconfig 명령어를 입력하면 아래 화면처럼 SSL VPN 주소로 설정된 어탭터에 [SSL VPN IP POOL]에 해당하는 IP가 할당된 것을 확인할 수 있습니다.\n서버 접속 link이제 SSL VPN이 연결된 상태에서 서버에 접속해보겠습니다.\nPuTTY 를 실행하고 접속할 서버의 IP를 입력합니다.\n이때 서버 IP는 콘솔에 있는 서버 정보에서 비공인 IP에 표시되는 IP를 입력하면 됩니다.\nwarning\rIP 입력: 이때 혹시나 포트 포워딩이나 공인 IP를 설정하고 그 IP를 입력하는 일이 없도록 주의해야 합니다.\nAgent 기타 설정 linkSSL VPN Agent에는 몇가지 추가 기능이 있는데 아래에서 확인해보겠습니다.\n트래픽 그래프 linkAgent 창에서 [그래프 보기] 버튼을 클릭합니다.\n여기서는 SSL VPN이 연결된 상태의 트래픽을 그래프로 확인할 수 있습니다.\n다음으로 [상세 보기] 버튼을 클릭하면 접속 세부 정보, 로그, 통계, 알림, 라우팅 테이블, IP설정 등의 정보를 확인할 수 있습니다.\n스펙 변경 link처음에 설정한 접속 가능 ID 개수를 변경하고 싶을 경우 SSL VPN을 선택하고 [스펙 변경] 버튼을 클릭합니다.\n3개, 5개, 10개 상품 중에서 원하는 개수로 변경할 수 있습니다.\n주의사항 link\rreport\r접속 오류: SSL VPN이 연결된 상태에서 새로운 서버를 생성하고 접속을 시도하면 아래와 같은 오류 메시지가 뜨면서 서버 접속이 되지 않습니다. 이때는 SSL VPN의 연결을 끊었다가 다시 연결해야 새로 생성한 서버에 접속할 수 있습니다.\n삭제 link삭제를 원할 경우 SSL VPN을 선택하고 상단의 [삭제] 버튼을 클릭합니다.\n참고 URL link Ncloud SSL VPN 개요\nhttps://guide.ncloud-docs.com/docs/sslvpn-overview\nNcloud SSL VPN 사용 가이드 - VPC\nhttps://guide.ncloud-docs.com/docs/sslvpn-start-vpc\n문서 업데이트 내역 link\r날짜 내용 2023-04-25 스크린샷 업데이트 "
            }
        );
    index.add(
            {
                id:  198 ,
                href: "\/docs\/security\/certificate\/ssl-dcv-guide\/",
                title: "SSL인증서 DCV (Domain Control Validation) 인증 방법과 유의사항 정리",
                description: "SSL인증서 DCV (Domain Control Validation) 인증 방법과 유의사항 정리입니다",
                content: "개요 linkHTTPS 접속을 위한 SSL 인증서를 발급 받기 위해서는 DCV (Domain Control Validation)를 인증받아야 하는데, 이때 필요한 인증방법과 유의 사항을 정리해보겠습니다.\nDCV 인증 방법 linkDCV 인증방법은 3가지가 있습니다.\nEmail 인증 DNS 인증 http 인증 Email 인증 linkEmail 인증은 도메인 등록정보에서 확인되는 이메일과 추가로 5개의 임의로 지정된 메일주소로 인증메일을 발송합니다.\n도메인 등록 정보 이메일 link도메인 등록 기관에서 도메인 소유자 정보를 노출하지 않는 블라인드 서비스를 이용하고 있을 경우 인증메일을 받을 수 없습니다. Email 인증을 하기 전에 블라인드 서비스를 해제하고 인증을 요청하셔야 합니다.\n추가 5개의 임의로 지정된 이메일 link임의로 지정된 이메일 주소는 admin, administrator, hostmaster, postmaster, webmaster 등 5가지이며 추가/수정이 불가능합니다.\n위의 총 6개 메일 주소 중에서 적어도 1개는 유효한 메일주소여야 이메일 인증을 문제없이 완료할 수 있습니다.\rNcloud(네이버 클라우드)에서는 2024년 5월 9일부터 WHOIS로 조회하는 도메인 등록 정보 이메일 주소를 통한 이메일 검증 지원이 중단됩니다. 대신 위에서 살펴본 추가 5개 이메일 주소를 통한 도메인 인증은 계속 가능합니다.\r이메일 인증 유의사항 link 해외 발신 이메일이 차단되도록 설정되어 있지 않은지 확인이 필요합니다. 메일함 용량 부족으로 반송되지 않도록 확인이 필요합니다. 자체 메일 서버일 경우 메일서버가 장애가 생기지 않도록 확인이 필요합니다. 스팸 차단 서비스나 장비에서 차단이 될 수도 있으므로 확인이 필요합니다. 참고 : https://www.sslcert.co.kr/products/domain-control-validation#email\nDNS 인증 linkDNS 인증은 다음과 같은 순서로 진행하면 됩니다.\n인증서 신청 사이트에서 CNAME 처리를 위한 DNS 인증용 Host, Record 용 값을 확인합니다. DNS에 위에서 확인한 값으로 CNAME Record를 등록합니다. 인증서 신청 사이트에서 DNS 인증 요청 버튼을 클릭합니다. # 예시\r# {Host값}.test.co.kr CNAME {Record Value}\r_PVG823NLK4DFSVFSANLK.test.co.kr CNAME 089DFCHKJFDSUIFDSLKJ38NF.ssltest.com\rDNS 인증 유의사항 link Host 값 첫번째 문자열이 _(언더바)입니다. CNAME 등록시에 빠뜨리지 않도록 주의해야 합니다. DNS서버에서 TTL 값을 너무 길게 설정하면 그 시간 만큼 인증을 받을 수 없으므로 주의해야 합니다. 참고 : https://www.sslcert.co.kr/products/domain-control-validation#dns\nhttp 인증 linkhttp인증은 http 인증용 코드를 다운로드 받아 해당 도메인 웹사이트에 등록하는 방법입니다.\n인증서 신청 사이트에서 http 인증용 코드 파일을 다운로드 받습니다. 해당 도메인 사이트에 /.well-known/pki-validation/ 경로를 생성합니다. 다운로드 받은 인증 코드 파일을 위 경로에 업로드 합니다. 인증서 신청 사이트에서 http 인증 요청 버튼을 클릭합니다. 해당 도메인이 test.co.kr 일 경우 인증 코드 파일의 경로는 다음과 같은 형식이어야 합니다.\nhttp://test.co.kr/.well-known/pki-validation/[파일명].txt\rhttp 인증 유의사항 link 인증 코드 파일은 수정하면 안됩니다. 인증 코드 파일 포맷은 ANSI 포맷이어야 합니다. SSL 발급 신청시 도메인에 www. 입력하였더라도, DCV 인증시에는 www를 제외하고 검사가 진행됩니다.\n만약 현재 사이트가 www. 로만 접속가능한 상태라면, DCV 인증을 위해 임시라도 www. 제외된 접속이 가능하게 만들어 놓아야 합니다. 참고 : https://www.sslcert.co.kr/products/domain-control-validation#http\n로드밸런서(Load Balancer)를 사용하면서 http 인증할 때 사전작업 linkhttp 인증을 하려고 할 때 로드밸런서를 사용하게 될 경우 로드밸런서의 도메인을 DNS에서 CNAME 처리를 먼저 진행하고, DNS 전파가 완료된 것을 확인한 후에 http 인증을 요청해야 합니다.\n예를 들어 Ncloud (네이버 클라우드)에서는 다음과 같이 처리하면 됩니다.\n# DNS CNAME 처리 예제\rwww.test.co.kr CNAME slb-{생성된 slb 이름}.ncloudslb.com\r참고 URL link 인증서 발급 사이트 : SecureSign\nhttps://www.sslcert.co.kr/\nDCV 인증 절차 안내\nhttps://www.sslcert.co.kr/products/domain-control-validation\n문서 업데이트 내역 link\r날짜 내용 2021-09-09 문서 최초 생성 2024-04-08 Email 인증 방식 변경 사항 업데이트 "
            }
        );
    index.add(
            {
                id:  199 ,
                href: "\/docs\/security\/certificate\/certificate-manager-register-ssl-certificate-guide\/",
                title: "Ncloud Certificate Manager SSL 인증서 등록 가이드",
                description: "Ncloud (네이버 클라우드) Certificate Manager에 SSL 인증서를 등록하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드)에는 인증서를 관리할 수 있는 Certificate Manager 서비스가 있는데, 여기에 SSL 인증서를 등록해두면 Load Balancer 등을 생성할 때 간단하게 인증서를 적용할 수 있습니다.\nCertificate Manager 특징 link 인증서 등록 및 서비스 연동: 공인 SSL 인증서를 등록하여 연계 서비스(Load Balancer, CDN+ 등)에 적용 가능 인증서 정보 제공: 등록된 인증서의 다양한 정보를 제공하여 인증서의 효율적 관리 가능 인증서 만료 알림: 등록된 인증서의 만료 예정일 30일 전부터 5일 단위로 알림(SMS/Email) 발송 조회 가능한 인증서 정보 link아래와 같은 인증서 정보를 조회할 수 있습니다.\n항목 내용 인증서 이름 고객이 설정한 인증서 이름 도메인 인증서 대표 도메인(DN) 추가도메인 인증서에 포함된 하위 도메인(SAN) 상태 정상, 만료 인증 시작일 인증 개시일 인증 종료일 인증 종료일 발급기관 인증서 발급 기관 정보(Certificate Authority) 일련번호 인증서의 고유 번호 PK 정보 퍼블릭 키 정보 사용 서비스 연동된 서비스 및 인스턴스 번호 대표적인 인증서 발급 사이트 link여러 인증서 발급 사이트 중에서 대표적인 몇 곳을 정리하면 다음과 같습니다.\nhttps://www.sslcert.co.kr/ (SecureSign)\nhttps://cert.crosscert.com/ (한국전자인증)\nhttps://hosting.whois.co.kr/new/ssl.php (후이즈)\n인증서 파일 준비 link인증서 발급 업체에서 인증서를 발급 받으면 업체별로 제공하는 파일을 확인할 수 있습니다.\n대표적인 업체들이 제공하는 파일 형태를 4가지 정도의 예시를 통해 확인해보겠습니다.\n예시 1 link예시 1과 같은 형태의 경우 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 3가지 파일이니 기억해 두시기 바랍니다.\n예시 2 link예시 2와 같은 형태도 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 3가지 파일이니 기억해 두시기 바랍니다.\n예시 3 link예시 3과 같은 형태는 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 4가지 파일이니 기억해 두시기 바랍니다.\n예시 4 link예시 4과 같은 형태는 아래 파일들 중에서 Ncloud Certificate Manager에 등록할때 필요한 파일은 붉은 색으로 표시한 5가지 파일이니 기억해 두시기 바랍니다.\n예시 4와 유사한 형태의 경우는, 특히 CA 파일들과 Root CA 파일들이 모두 분리되어 제공되는 경우입니다.\n이용 신청 link인증서 파일을 준비했으므로 인증서를 [Certificate Manager]에 등록할 차례인데, [Certificate Manager]를 이용하려면 먼저 서비스 이용 신청을 해야 합니다.\n[Certificate Manager] - [Subscription]에서 [이용 신청] 버튼을 클릭합니다.\n인증서 등록 link신청이 끝났으면, [Certificate Manager] - [Certificate List]에서 [외부 인증서 등록] 버튼을 클릭합니다.\n인증서를 등록할 때는 아래와 같이 3가지 항목을 입력해야 하는데 각각의 항목에는 위에서 확인했던 3개의 인증서 파일의 내용을 복사해서 붙여넣기하면 됩니다.\n아래와 같이 각각의 파일의 내용을 텍스트 편집기로 열어서 전체 내용을 각 항목에 입력하면 되는데, 위에서 살펴본 인증서 예시별로 확인해보겠습니다.\n예시 1 link Private Key : [인증서 파일명].key.pem , 인증서에 대한 Private Key Certificate Body : [인증서 파일명].crt.pem, 도메인에 대한 인증서 Certificate Chain : ca-chain-bundle.pem, CA와 Root CA 인증서를 합쳐 놓은 파일 예시 2 link Private Key : [인증서 파일명].key , 인증서에 대한 Private Key Certificate Body : [인증서 파일명].crt , 도메인에 대한 인증서 Certificate Chain : chainca.crt (또는 chain.pem) , CA와 Root CA 인증서를 합쳐 놓은 파일 예시 3 link Private Key : [인증서 파일명]_key1.pem , 인증서에 대한 Private Key Certificate Body : [인증서 파일명].crt , 도메인에 대한 인증서 Certificate Chain : (상위)chain.cer + (최상위)chain1.cer , CA와 Root CA 인증서 파일 info\r예시 3과 같은 형태의 인증서 파일을 제공 받았을 경우에는 (상위)chain.cer = CA이며, (최상위)chain1.cer = Root CA 파일입니다. 두개의 파일을 텍스트 편집기로 열어서 각각의 파일 내용을 복사해서 Certificate Chain 항목에 두 파일의 내용을 모두 붙여 넣기 하시면 됩니다. 주의할 점은, 두 파일의 내용 사이 또는 마지막에 줄바꿈 문자 즉, Enter 키는 1번까지만 가능하며 2번이상 들어가면 오류 메시지가 표시됩니다.\n예시 4 link Private Key : [인증서 파일명]_key.pem , 인증서에 대한 Private Key Certificate Body : [인증서 파일명].crt.pem , 도메인에 대한 인증서 Certificate Chain : chain1.crt.pem + chain2.crt.pem + root chain.crt.pem , CA와 Root CA 인증서 파일들 info\r예시 4과 같은 형태의 인증서 파일을 제공 받았을 경우에는 CA 파일이 chain1.crt.pem, chain2.crt.pem 처럼 2개 이상 제공되며, root chain.crt.pem = Root CA 파일입니다. 제공되는 Chain 3개 또는 그 이상 개수의 파일을 텍스트 편집기로 열어서 각각의 파일 내용을 복사해 Certificate Chain 항목에 내용을 모두 붙여 넣기 하시면 됩니다. 주의할 점은, 각각의 파일의 내용 사이 또는 마지막에 줄바꿈 문자 즉, Enter 키는 1번까지만 가능하며 2번이상 들어가면 오류 메시지가 표시됩니다.\n등록 완료 link인증서가 문제 없이 등록되면 아래와 같이 [정상]으로 표시가 되고 인증서의 각종 정보를 확인할 수 있습니다.\n주의 사항 link 파일 등록: 인증서 파일은 -----BEGIN RSA PRIVATE KEY----- 중간 생략 -----END RSA PRIVATE KEY----- 또는 -----BEGIN CERTIFICATE----- 중간 생략 -----END CERTIFICATE----- 와 같은 형식으로 구성되어 있는데, 인증서를 등록할 때는 인증서 파일을 수정하지 말고 파일의 처음부터 끝까지 모두 복사해서 등록하셔야 합니다.\n체인 인증서 추출: 간혹 일부 업체의 경우 도메인 인증서 파일은 제공해주지만, CA 파일과 Root CA 파일은 제공해주지 않는 경우가 있습니다. 이럴 때는 아래에 있는 Ncloud 가이드 중에서 인증서 파일 추출 부분을 참고해서 CA 파일과 Root CA 파일을 추출한 다음에 등록하시면 됩니다.\n참고 URL link Ncloud Certificate Manager 전체 가이드\nhttps://guide.ncloud-docs.com/docs/security-security-15-1\nNcloud Certificate Manager 인증서 파일 추출 가이드\nhttps://guide.ncloud-docs.com/docs/certificatemanager-use-list#CertificateChain%EB%93%B1%EB%A1%9D\n문서 업데이트 내역 link\r날짜 내용 2023-02-08 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  200 ,
                href: "\/docs\/management\/ncloud-vpc-vs-classic-guide\/",
                title: "Ncloud Classic 환경 vs VPC 환경 비교",
                description: "서비스의 Classic 환경과 VPC 환경 각각의 장점과 주요 사용 환경에 대해 정리해보았습니다",
                content: "개요 link네이버 클라우드 (Ncloud)에는 Classic과 VPC 이렇게 2가지의 환경이 있습니다. 각각의 특징을 장점을 중심으로 비교해보도록 하겠습니다.\nClassic 환경 장점 요약 link 서로 다른 계정의 서버들 간에 사설 통신 가능 리전간 서버들의 사설 통신 가능 (한국, 미국, 싱가포르, 홍콩, 일본, 독일) 다양한 설치형 서버 이미지 이용 가능 VPC 환경 장점 요약 link 논리적으로 분리된 Network 사용자가 직접 Network 설계 가능 기존 고객의 데이터센터 네트워크와 유사하게 구현 가능 좀 더 상세하고, 높은 수준의 보안 설정 가능 Classic 환경 장점 상세 link위에서 요약한 장점들을 좀 더 상세하게 살펴보겠습니다.\n서로 다른 계정의 서버들 간 사설 통신 가능 link사용자가 2개 이상의 계정을 보유하고 있을 경우 각 계정에 생성된 서버들간에 사설 통신을 할 수 있습니다.\n리전간 서버들의 사설 통신 가능 link현재 네이버 클라우드는 한국, 미국, 싱가포르, 홍콩, 일본, 독일 이렇게 6개의 리전으로 서비스가 구분되어 있는데, 각 리전에 생성된 서버들끼리 사설 통신을 할 수 있습니다.\n다양한 설치형 서버 이미지 이용 가능 linkClassic 환경에서는 LAMP, Wordpress 등 사용자들이 편하게 각 종 애플리케이션과 DB가 미리 설치된 서버를 쉽게 생성할 수 있도록 설치형 서버 이미지를 제공하고 있습니다. 지원하는 주요 이미지는 다음과 같습니다.\nJenkins, Tensorflow, RabbitMQ, Pinpoint, LAMP, WordPress, Magento, Drupal, Joomla!, Shadowsocks, LEMP, Hugo, Gitlab CE, Node.js, Superset, Tomcat, JEUS, WebtoB, Gradle MySQL, MSSQL, Cubrid, PostgreSQL, MariaDB, Redis, Tibero VPC 환경 장점 상세 link위에서 요약한 장점들을 좀 더 상세하게 살펴보겠습니다.\n논리적으로 분리된 Network link 논리적으로 분리된 Network 체계를 제공하기 때문에 다른 이용자와의 간섭 없이 더 안전하고, 투명한 환경을 구현할 수 있습니다. 사용자가 직접 Network 설계 가능 link 네트워크 서브넷(Subnet) 기능을 통해 용도에 따라 네트워크를 세분화하여 서비스 맞춤형 네트워크를 사용자가 직접 구성하실 수 있습니다 Load Balancer가 Application Load Balancer / Network Load Balancer / Network Proxy Load Balancer 등 3가지로 구분되어 있어, 고객이 각자의 서비스 환경에 최적화된 Load Balancer를 선택할 수 있습니다. 원하는 사설 IP 대역을 직접 할당할 수 있습니다. 그러므로 사용해야 하는 사설 IP대역이 정해져 있어 변경할 수 없거나, 서버의 사설 IP를 변경하기 어려운 경우에도 VPC 환경에서는 원하는 대역의 원하는 IP를 직접 부여할 수 있습니다. 기존 고객의 데이터센터 네트워크와 유사하게 구현 가능 link 기존 고객 데이터센터 네트워크와 유사하게 구현 가능합니다. 즉, 기존에 AWS를 사용하고 있었던 고객은 AWS는 VPC 환경만 제공하기 때문에 거의 비슷하게 구현 가능합니다. 또한 온프레미스 환경의 IDC 센터를 이용했던 고객이 클라우드 환경으로 마이그레이션해야 할 때 VPC 환경은 기존의 구조를 거의 그대로 구현해서 마이그레이션할 수 있습니다. 좀 더 상세하고, 높은 수준의 보안 설정 가능 link 서버 측면에서 접근 제어를 위한 ACG(Access Control Group) 외에도, 네트워크 서브넷 측면에서 접근 제어를 할 수 있도록 NACL(Network Access Control List)을 제공합니다. 이처럼 여러가지 접근제어 기능을 이용해 클라우드 상에서 발생할 수 있는 다양한 공격에 대한 대비가 가능합니다. ACG, NACL등의 네트워크 접근제어 설정에서 Inbound, Outbound 각각에 대한 제어 설정 등 상세한 보안 설정을 직접 할 수 있습니다. VPC 환경 활용사례 link 외부와 인터넷 연결이 필요한 서브넷과 이와 별개로 중요 데이터를 저장하기 위해 외부 접속을 최소화하기 위한 서브넷을 구성하는 경우\n하나의 서브넷에 인터넷 게이트웨이를 연결하여 프런트-엔드(Front-end) 전용 서브넷을 구성하고, 다른 하나의 서브넷에는 NAT 게이트웨이를 연결하여 백-엔드(Back-end)용 서브넷으로 활용\nCloud Connect만을 이용하여 접근할 수 있는 서브넷을 구성하는 경우\nCloud Connect를 이용하여 On-Premise에 있는 고객의 전산망을 클라우드로 확장한 하이브리드 클라우드 구성\n외부와 인터넷 연결이 필요한 서브넷과 이와 별개로 외부 인터넷 연결을 차단하고 VPN을 통해 On-Premise에서만 접근할 수 있는 서브넷을 구성하는 경우\n하나의 서브넷은 외부와 연결되는 일반 구성으로 하고, 다른 하나의 서브넷에 IPsec VPN을 연결하여 VPN 전용 서브넷(VPN Only Subnet)을 구성하는 방식\n다른 두개의 서비스를 각각 다른 사설 IP대역에서 서비스하려는 경우\nVPC를 2개 생성해서 각각 다른 사설 IP 대역을 할당해서 구성 가능\nClassic vs VPC 선택 linkClassic 선택 link 구축하려는 서비스 규모가 작으며 네트워크 설정은 신경 쓰고 싶지 않은 경우는 Classic 환경 리전간 서버끼리 사설통신이 필요하다면 (ex. DB 한국리전, 서비스서버 일본리전) Classic 환경 다양한 설치형 서버 이미지들이 필요하다면 Classic 환경 VPC 선택 link 네트워크 세분화및 서비스에 별도 사설 대역이 필요한 경우는 VPC 환경 서버, 네트워크 통신의 inbound, outbound를 직접 통제하고 싶은 경우는 VPC 환경 좀 더 다양한 기능을 지원하는 상품을 이용하고자 할때는 VPC환경 참고 URL link Ncloud VPC 제품 설명\nhttps://www.ncloud.com/product/networking/vpc\nNcloud VPC 사용 가이드\nhttps://guide.ncloud-docs.com/docs/networking-vpc-vpcoverview\n문서 업데이트 내역 link\r날짜 내용 2021-12-03 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  201 ,
                href: "\/docs\/management\/sub-account\/create-basic-guide\/",
                title: "Ncloud 서브 계정 (Sub Account) 생성 가이드",
                description: "Ncloud (네이버 클라우드) Sub Account (서브 계정) 생성 가이드입니다",
                content: "개요 linkSub Account(서브 계정)는 네이버 클라우드의 서비스 자원을 여러 사용자가 동시에 이용, 관리해야 할 때 필요한 만큼만 권한을 부여해서 사용할 수 있게 해주는 서비스입니다.\nSub Account를 사용하면 사내 담당부서나 담당자별로 지정된 자원에만 접근하도록 하거나, 협력사에게 일부 접근권한을 부여해야 할 때 효과적입니다.\n특징 link네이버 클라우드의 Sub Account는 다음과 같은 특징이 있습니다.\n별도의 로그인 페이지를 이용하여 접속 대시보드에서 서브 계정 수, 그룹 수, 정책 수, 접속 페이지 설정을 확인할 수 있음 그룹, 정책, 역할을 생성해 상세한 권한 설정을 할 수 있음 Access Key를 별도로 생성해서 사용할 수 있음 주요 권한 link 네이버 클라우드 메인 계정과 동일한 접근 권한\nNCP_ADMINISTRATOR 정책을 부여하시면 메인 계정과 동일하게 네이버클라우드플랫폼 내 포털, 콘솔을 접근할 수 있습니다\n네이버 클라우드 콘솔 내 모든 상품/서비스 접근 권한\nNCP_INFRA_MANAGER 정책을 부여하시면 메인 계정과 동일하게 콘솔 내 모든 상품/서비스에 접근할 수 있습니다.\n네이버 클라우드 콘솔 내 각 상품/서비스별 접근 권한\nNCP_상품/서비스명_MANAGER/VIEWER 정책을 부여하시면 해당 상품/서비스에 접근할 수 있습니다.\n네이버 클라우드 포털 내 마이페이지 “이용관리” 메뉴 접근 권한\nNCP_FINANCE_MANAGER 정책을 부여하시면 포털 마이페이지 내 “서비스 이용내역/현황, 프로모션 내역, 청구 내역 추세” 메뉴에 접근할 수 있습니다.\nSub Account 서비스 link[Sub Account] 서비스는 [콘솔] - [Services] - [Management \u0026 Governance] - [Sub Account]에 위치하고 있습니다.\n좀 더 쉽게 찾는 방법은 [콘솔] - [Services]에서 [검색] 기능을 이용하면 됩니다.\n서브 계정 생성 link[Sub Account] - [Sub Accounts]에서 [서브 계정 생성] 버튼을 클릭합니다.\n서브 계정 생성 화면에서는 로그인 아이디, 이름, 이메일 주소를 우선 입력합니다.\n다음으로 접근 유형으로 [Console 접근]과 [API 접근]을 모두 허용할 것인지, 하나만 허용할 것인지 선택하고, Conosole 접근의 경우에 지정한 IP대역에서만 접근하게 할 것인지, 모두 허용할 것인지도 선택합니다.\n휴대폰 문자인증 또는 이메일 인증 등의 2차 인증을 적용할 것인지도 선택합니다.\n비밀번호 설정 link마지막으로 로그인 비밀번호는 [자동 생성] 또는 [직접 입력] 중에서 선택할 수 있으며, 해당 서브 계정으로 로그인 시에 비밀번호를 변경하도록 할 것인지 선택할 수 있습니다.\n자동 생성 link\r자동 생성된 비밀번호는 이 화면에서만 확인 가능하므로 반드시 별도 저장해야 합니다. 직접 입력 link직접 입력하는 비밀번호는 영문자, 숫자, 특수 문자를 조합하여 8자~16자 이내로 입력하면 됩니다.\n계정 정책 추가 link생성된 서브 계정을 클릭하면 서브 계정 상세 설정 화면으로 이동합니다.\n서브 계정 상세 화면에서는 정책, 그룹, Access Key 등을 추가하고 관리할 수 있습니다. 우선 아래쪽에 있는 [정책] 탭에서 [개별 권한 추가] 버튼을 클릭합니다.\n정책 추가 화면에서는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책]과 사용자가 직접 정의하는 [사용자 정의 정책]이 있습니다.\n우선 [관리형 정책]에서 필요한 정책을 선택하고 [추가] 버튼을 클릭합니다.\n정책이 워낙 많기 때문에 가능하면 위쪽의 검색 기능을 이용해서 정책을 찾는 것을 추천합니다.\n여기서는 네이버 클라우드의 플랫폼 내 모든 상품을 이용할 수 있는 권한인 [NCP_INFRA_MANAGER] 선택했고, 아래와 같이 추가된 것을 확인할 수 있습니다.\n접속 환경 설정 link네이버 클라우드 서브 계정은 별도의 로그인 페이지가 존재하는데, [Sub Account] - [Dashboard]에서 서브 계정으로 접속하기 위한 페이지 주소를 입력할 수 있습니다.\n우선 서브 계정 로그인 페이지 접속 접속키를 입력합니다. 입력한 접속키를 바탕으로 로그인 페이지 URL이 결정됩니다.\n추천되는 접속키의 형태는 다음과 같습니다.\n회사명 + α (ex: mycompany, samplecomsub) 서비스명 + α (ex: mygame, testservicesub) 회사명 + 서비스명 + α (ex: mycompanygame, mycomsamplegamesub) 접속키는 영어 소문자와 숫자를 이용해서 3~20자로 구성해야 합니다.\r서브 계정 로그인 페이지 URL은 [주소 복사] 버튼을 클릭하면 복사할 수 있습니다.\n다음으로 [미사용 세션 만료 설정]에서 [변경] 버튼을 클릭하면 로그인된 서브 계정이 아무 활동없이 미사용일 경우 지정한 시간 기준으로 자동 로그아웃이 되도록 설정할 수 있습니다.\n[비밀번호 만료 설정]에서 [변경] 버튼을 클릭해서 비밀번호 만료를 활성화할 경우 지정된 만료일을 초과했을 때 비밀번호를 변경해야만 접속 할 수 있습니다. 활성화 하지 않았을 경우에는 90일이 지난 후에 비밀번호 변경 안내 팝업만 나타납니다.\n접속 - 로그인 link위에서 설정한 접속 페이지 [ https://www.ncloud.com/nsa/******] 에 접속하면 아래와 같이 서브 계정 로그인 화면을 확인할 수 있습니다.\nAPI Key 설정 link서브 계정에서 API Access Key를 사용해야 할 경우 먼저 API GateWay 접근 권한을 부여하고, 서브 계정 상세 화면 [Access Key]탭에서 [추가] 버튼을 클릭해 생성할 수 있습니다.\nAPI Gateway 접근 권한 설정 link우선, 서브 계정 리스트에서 해당 계정을 클릭해서 [서브 계정 세부 정보] 화면으로 이동합니다.\n[서브 계정 세부 정보] 화면에서 [수정] 메뉴 버튼을 클릭합니다. [서브 계정 정보] 수정 화면에서 [접근 권한]에 있는 [API Gateway 접근]을 체크합니다. 그리고, 되도록이면 [지정된 Source에서만 접근 가능] 옵션을 선택하고, 지정된 IP 등을 추가하는 것을 권장합니다. 위 화면에서 [추가] 버튼을 클릭하면 아래와 같이 [접근 가능 Source 지정] 팝업이 나타나는데, IP를 입력하거나 VPC Server를 선택하면 됩니다. API Access Key 추가 link위에서 [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나고 [추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\n계정 그룹 설정 link여러 개의 서브 계정을 묶어서 하나의 그룹으로 구성하면 해당 그룹의 서브 계정에 동일한 정책을 동시에 적용할 수 있습니다.\n사용자 정의 정책 생성 link서브 계정 정책에는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책] 외에도 사용자가 직접 설정하는 [사용자 정의 정책]도 사용할 수 있습니다. [Sub Account] - [Plicies]에서 [정책 생성] 버튼을 클릭합니다.\nVPC 환경에서 정책 생성 link정책 이름을 입력하고, VPC를 선택 후, 어떤 서비스 상품에 적용할 것인지 선택합니다.\n다음으로 Actions 항목에서는 읽기 권한인 View 또는 수정 권한인 Change를 선택하면 아래쪽에 리소스별로 상세한 권한 설정을 할 수 있는 화면이 나타납니다. 모든 설정을 마치고, 아래쪽 [적용대상 추가] 버튼을 클릭하면 됩니다.\nClassic 환경에서 정책 생성 linkClassic 환경에서는 리소스별 상세 권한은 설정할 수 없고, View 또는 Change를 선택한 후에 [적용대상 추가] 버튼을 클릭하면 모든 권한이 추가됩니다.\n아래와 같이 선택한 서비스 상품에 대해 모든 리전, 모든 리소스에 선택한 권한이 지정됩니다.\n참고 URL link Sub Account 사용 가이드\nhttps://guide.ncloud-docs.com/docs/ko/subaccount-overview 문서 업데이트 내역 link\r날짜 내용 2023-08-07 콘솔 UI, 텍스트 업데이트 내역 반영 "
            }
        );
    index.add(
            {
                id:  202 ,
                href: "\/docs\/management\/sub-account\/api-gateway-access-control-guide\/",
                title: "Ncloud API Key 접근 제한 설정하는 방법",
                description: "Ncloud(네이버 클라우드) Sub Account(서브 계정)를 이용해 API Key에 대한 접근 제한을 설정하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드)를 이용하다보면 여러 가지 정보를 조회하거나 서버를 생성하는 등의 작업을 위해 API를 활용하게 되는 경우가 많습니다. 그런데 이때 사용하는 API Key를 접근 제한 없이 사용하게 되면 외부에 유출되거나 했을 때 심각한 보안 문제를 일으키게 되므로 사전에 API Key에 대한 권한을 설정하거나 접근 제한을 설정해서 사용하는 것이 권장됩니다.\n여기서는 API Key를 최소 권한으로 생성하고, 접근 경로를 제한 하는 등의 방법들을 정리해보겠습니다.\n서브 계정 생성 linkAPI Key 보안과 관련해서 가장 중요한 원칙은 메인 계정이 아닌 최소 권한을 가진 서브 계정(Sub Account)에서 API Key를 생성하는 것입니다.\nreport\r메인 계정은 최대 권한을 가지기 때문에 메인 계정으로 생성한 API도 메인 계정과 동일한 최대 권한을 가지게 됩니다. 그러므로 메인 계정으로 API Key를 생성하게 되면 이 Key가 유출되었을 때 심각한 문제가 생기기 때문에 반드시 서브 계정에서 API Key를 생성해야 합니다.\n서브 계정(Sub Account)을 생성하는 방법은 아래 문서를 참고하시기 바랍니다.\n⁃ Ncloud 서브 계정 (Sub Account) 생성 가이드\r테스트를 위해 아래와 같이 서브 계정을 준비하고, 계정을 클릭해서 서브 계정 세부 정보 화면으로 이동합니다. 계정 권한 설정 link서브 계정의 권한은 최소로 설정해야 합니다.\n예를 들어 Object Storage만 접근하는지, VPC Server 관련된 기능만 사용할 것인지, VPC Server 관련된 기능 중에서도 조회 기능만 사용할 것인지, Server 생성 등을 포함한 모든 기능을 사용할 것인지 등의 사용에 필요한 권한을 모두 정리해서 최소한의 권한으로 설정하는 것이 안전합니다.\n우선, 서브 계정 세부 정보 화면에서 아래쪽에 있는 [정책] 탭에 있는 [개별 권한 추가] 버튼을 클릭합니다.\n정책 추가 화면에서는 네이버 클라우드에서 기본으로 제공하는 [관리형 정책]과 사용자가 직접 정의하는 [사용자 정의 정책]이 있습니다.\n우선 [관리형 정책]에서 필요한 정책을 선택하고 [추가] 버튼을 클릭합니다.\n정책이 워낙 많기 때문에 가능하면 위쪽의 검색 기능을 이용해서 정책을 찾는 것을 추천합니다.\n여기서는 테스트를 위해 Function으로 검색해서 [NCP_VPC_CLOUD_FUNCTIONS_MANAGER (VPC 기반 Cloud Functions 서비스 내 모든 기능을 이용할 수 있는 권한)]을 선택했습니다. API Gateway 접근 권한 설정 link우선, [서브 계정 세부 정보] 화면에서 [수정] 메뉴 버튼을 클릭합니다.\n[서브 계정 정보] 수정 화면에서 [접근 권한]에 있는 [API Gateway 접근]을 체크합니다. 그리고, 되도록이면 [지정된 Source에서만 접근 가능] 옵션을 선택하고, 지정된 IP 등을 추가하는 것을 권장합니다. 위 화면에서 [추가] 버튼을 클릭하면 아래와 같이 [접근 가능 Source 지정] 팝업이 나타나는데, IP를 입력하거나 VPC Server를 선택하면 됩니다. ⁃ [VPC Server]의 경우 IP 주소로는 접근할 수 없습니다.\n⁃ 아래 화면처럼 VPC Server 리스트에서 직접 선택해야 접근 가능합니다.\n⁃ 그러므로 다른 계정의 VPC Server는 접근 가능 리소스에 추가할 수 없습니다.\rAPI Access Key 추가 link위에서 [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나고 [추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\n접근 제한 테스트 link그러면 위에서 설정했던 접근 제한 설정이 제대로 작동하는지 테스트 해보겠습니다.\nIP 제한 link위에서 설정한 [접근 가능 Source 지정] 항목에 IP를 설정하지 않거나, 지정되지 않은 IP에서 접근할 경우 아래의 예시와 같은 오류 메시지가 반환됩니다.\n호출 API: getProductList 230\rForbidden\rIP not allowed for authentication.\r계정 권한 제한 link계정에 올바른 권한이 설정되지 않았을 경우 아래와 같은 오류 메시지가 반환됩니다.\n호출 API: createServerInstances 802\rYou do not have authority about action : [VPCServer:Change/createServerInstance].\r호출 API: getDemandCostList 2210\rYou do not have authority about action : [NCP_FINANCE_MANAGER].\r주요 API 최소 권한 link\rAPI\r설명\rClassic/VPC\r최소 권한\rgetProductList\rNcloud 상품 리스트 조회\r공통\r없음\rgetDemandCostList\r청구 비용 리스트 조회\r공통\rNCP_FINANCE_MANAGER\rgetServerInstanceList\r서버 인스턴스(VM) 리스트 조회 VPC\rNCP_VPC_SERVER_VIEWER Classic\rNCP_SERVER_OBSERVER\rcreateServerInstances\r서버 인스턴스(VM) 생성\rVPC\rNCP_VPC_SERVER_MANAGER\rClassic\rNCP_SERVER_MANAGER\rGet Action List\rCloudFunction 액션 리스트 조회\rVPC\rNCP_VPC_CLOUD_FUNCTIONS_VIEWER\rClassic\rNCP_CLOUD_FUNCTIONS_MANAGER\rPost Action\rCloudFunction 액션 실행\rVPC\rNCP_VPC_CLOUD_FUNCTIONS_MANAGER\rClassic\rNCP_CLOUD_FUNCTIONS_MANAGER\rListBuckets\rObjectStorage 버킷 리스트 조회\r공통\rNCP_OBJECT_STORAGE_VIEWER\rcreateAutoScalingGroup\rAuto Scaling Group 생성\rVPC\rNCP_VPC_AUTOSCALING_MANAGER\rSMS API\rSimple \u0026 Easy Notification Service 내\nSMS 발신번호 등록 기능을 제외한 모든 기능\r공통\rNCP_SENS_MANAGER\rgeoLocation\r지정한 IP의 위치 정보 조회\r공통\rNCP_GEOLOCATION_MANAGER\r참고 URL link Ncloud Sub Account 사용 가이드\nhttps://guide.ncloud-docs.com/docs/ko/subaccount-overview\nNcloud API 사용 가이드\nhttps://api.ncloud-docs.com/docs/api-overview\n문서 업데이트 내역 link\r날짜 내용 2023-08-14 문서 최초 생성 2023-12-19 VPC Server 접근 리소스 지정 설명 추가, 스샷 업데이트 "
            }
        );
    index.add(
            {
                id:  203 ,
                href: "\/docs\/management\/sub-account\/sts-temporary-accesskey-create-guide\/",
                title: "Ncloud STS 기간 제한 임시 API AccessKey 발급하기",
                description: "Ncloud(네이버 클라우드) Sub Account의 STS (Secure Token Service) 기능을 이용해 기간 제한 임시 API AccessKey 발급하는 방법입니다",
                content: "개요 link클라우드 환경에서 서비스를 하다 보면 회사 내부의 다른 팀이나 외부 고객사에 서버나 오브젝트 스토리지 등 특정 서비스에 접근할 수 있는 API를 제공해야 하는 하는 경우가 생길 수 있습니다.\n그런데 Ncloud(네이버 클라우드)에서 제공되는 기본 API Access Key는 기간 제한이 없는 Access Key이기 때문에 외부에 제공하게 되면 보안측면에서 위험한 상황이 생길 수 있습니다. 이때 STS를 이용하면 Access Key를 제한된 기간 동안 일회성으로 제공하거나 유효 기간이 매우 짧은 Access Key를 반복적으로 제공하게 되면 훨씬 안전한 서비스를 유지할 수 있습니다.\nSTS란 link[STS (Secure Token Service)]는 Sub Account에 연관되어 제공되는 서비스로 Ncloud (네이버 클라우드) 내 리소스에 대한 액세스를 제어할 수 있는 기간 제한이 있는 임시 Access Key를 생성하는 서비스입니다.\n임시 Access Key는 기간 제한이 없는 서브 계정의 Access Key와 달리 제한된 기간 동안만 유효하며 MFA 등 추가 인증 수단을 적용할 수도 있습니다.\n다른 클라우드 서비스에서는 [Security Token Service(STS)], [임시 보안 자격 증명], [Security Token], [API One Day Token] 등으로 찾아볼 수 있습니다.\nSTS 임시 Access Key 특징 link 임시 Access Key는 서브계정만 생성할 수 있습니다. 메인 계정으로 생성하려고 할 때 발생하는 오류 메시지는 메인 계정 Access Key를 사용했을 때 -\u003e에서 확인 가능합니다. 임시 Access Key는 만료 기한이 존재합니다. Access Key는 몇 분에서 몇 시간까지 지속되도록 생성할 수 있습니다. Access Key가 만료된 후 Ncloud는 더는 그 Access Key를 인식하지 못하거나 그 Access Key를 사용한 API 요청으로부터 이루어지는 어떤 종류의 액세스도 허용하지 않습니다. 임시 Access Key를 생성할 때, MFA 인증을 포함할 수 있습니다. Ncloud는 MFA 수단으로 OTP 인증을 제공합니다. 임시 Access Key가 만료된 후에는 해당 Access Key는 다시 사용할 수 없습니다. 임시 Access Key는 STS API를 호출해서 생성합니다. Sub Account 생성 link\rSTS로 생성하는 임시 Access Key의 권한은 Sub Account의 권한을 그대로 상속 받기 때문에 해당 Access Key를 발급하기 위한 전용 Sub Account를 생성해야 합니다.\r서브 계정(Sub Account)을 생성하는 방법은 아래 문서를 참고하시기 바랍니다.\n⁃ Ncloud 서브 계정 (Sub Account) 생성 가이드\r사용자 정의 정책 생성 linkSub Account에 적용할 정책을 기본으로 제공되는 관리형 정책이 아니라 STS 생성만 허가 하기 위한 사용자 정의 정책을 생성합니다.\n[Sub Account] - [Policies]에서 [사용자 정의 정책] 탭을 선택하고 [정책 생성] 버튼을 클릭합니다.\n정책 정보 설정 link정책 이름과 설명을 입력합니다.\n적용 대상 설정 linkSTS는 VPC, Classic 관계없이 적용되므로 플랫폼 항목은 그대로 두고 나머지 항목은 다음과 같이 설정합니다.\nProduct: Sub Account 선택 Actions: View 항목에서 STS 탭 선택하고, [getStsSessionToken]을 선택 선택을 마친 후 [적용 대상 추가] 버튼을 클릭합니다.\n적용 대상 목록 link선택한 내용을 마지막으로 확인하고 이상이 없으면 [생성] 버튼을 클릭합니다.\n생성된 정책 확인 link정책이 생성되면 [사용자 정의 정책] 탭에 아래와 같이 정책이 나타납니다.\nSub Account에 정책 적용 link[Sub Account] - [Sub Accounts]에서 해당 Sub Account를 선택하고 [정책] 탭에서 [추가] 버튼을 클릭합니다.\n정책 추가 link정책 추가 팝업에서 위에서 만들었던 정책을 선택하고 [추가] 버튼을 클릭합니다.\n적용된 정책 확인 linkSub Account 상세 정보에서 정책 탭에 추가된 정책을 확인할 수 있습니다.\n기간 제한 없는 Access Key 발급 link여기서는 우선 기간 제한이 없는 Access Key를 발급하고 이 Access Key를 이용해서 나중에 기간 제한이 있는 임시 Access Key를 발급하겠습니다.\n[Sub Account] - [Sub Accounts] - [Access Key] 탭에서 [추가] 버튼을 클릭합니다.\nAccess Key 추가 link팝업에서 [추가] 버튼을 클릭해 새로운 Access Key를 추가합니다.\nAccess Key 확인 link[Access Key] 탭에서 추가된 Access Key와 Secret Key를 확인할 수 있습니다.\n기간 제한 임시 Access Key 발급 link임시 Access Key를 발급 받기 위해서는 STS API를 호출해야 합니다.\nSTS API를 이용해 기간 제한이 있는 임시 Access Key를 발급 받으면 아래와 같은 정보를 얻을 수 있습니다.\nAccess Key Secret key Create Time: Key 생성 날짜 Expire Time: Key 만료 날짜 Use MFA: MFA (MultiFactorAuthentication) 사용 여부 API 호출 방법 linkNcloud API 호출 방법에 대한 기본 가이드는 아래 문서를 확인하시면 됩니다.\nPHP로 Ncloud API 호출 방법: https://docs.3rdeyesys.com/api/ncloud_api_call_php_sample.html C#으로 Ncloud API 호출 방법: https://docs.3rdeyesys.com/api/ncloud_api_call_csharp_sample.html Python으로 Ncloud API 호출 방법: https://docs.3rdeyesys.com/api/ncloud_api_call_python_sample.html 임시 Access Key 발급 PHP 샘플 예제 link\r\u003c?php\t$unixtimestamp = round(microtime(true) * 1000);\r$ncloud_sub_account_accesskey = \"{기간 제한 없는 Sub Account API Access Key}\";\r$ncloud_sub_account_secretkey = \"{기간 제한 없는 Sub Account API Secret Key}\";\t$apicall_method = \"POST\";\r$api_server = \"https://sts.apigw.ntruss.com\";\r$api_url = \"/api/v1/credentials\";\r$msg_signature = \"\";\r$array_postvars = Array (\t\"durationSec\" =\u003e 900\r);\r$postvars = json_encode($array_postvars);\r$space = \" \";\r$new_line = \"\\n\";\r$message = $apicall_method\r.$space\r.$api_url\r.$new_line\r.$unixtimestamp\r.$new_line\r.$ncloud_sub_account_accesskey;\t$msg_signature = base64_encode(hash_hmac('sha256', $message, $ncloud_sub_account_secretkey, true));\r$http_header = array(); $http_header[0] = \"Content-Type:application/json; charset=utf-8\";\r$http_header[1] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\r$http_header[2] = \"x-ncp-iam-access-key:\".$ncloud_sub_account_accesskey.\"\";\r$http_header[3] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\tcurl_setopt($ch, CURLOPT_POST, TRUE);\rcurl_setopt($ch, CURLOPT_POSTFIELDS, $postvars);\r$json_response = curl_exec($ch);\rcurl_close($ch);\rif ($json_response)\r{\r$obj_array = json_decode($json_response, 1);\r$sts_accesskey= $obj_array[\"accessKey\"];\r$sts_secretkey= $obj_array[\"keySecret\"];\r$sts_createtime= $obj_array[\"createTime\"];\r$sts_expiretime= $obj_array[\"expireTime\"];\r$sts_use_mfa= $obj_array[\"useMfa\"];\t}\r?\u003e\rPHP 예제 코드 상세 설명 link위 전체 소소코드 중에서 중요한 부분만 다시 살펴보겠습니다.\n기간 제한 없는 API Key link아래 2가지 변수에는 위쪽 기간 제한 없는 Access Key 발급 에서 생성했던 기간 제한 없는 Sub Account API Access Key와 Secret Key를 입력하시면 됩니다.\n\u003c?php\t$ncloud_sub_account_accesskey = \"{기간 제한 없는 Sub Account API Access Key}\";\r$ncloud_sub_account_secretkey = \"{기간 제한 없는 Sub Account API Secret Key}\";\r?\u003e\rSTS API 호출 서버와 URL linkSTS API 서버와 URL은 아래와 같습니다.\n그리고 API 호출 방식은 POST 방식입니다.\n\u003c?php\r$apicall_method = \"POST\";\r$api_server = \"https://sts.apigw.ntruss.com\";\r$api_url = \"/api/v1/credentials\";\r?\u003e\rRequest 파라미터 linkSTS 생성을 위한 Request 파라미터는 총 3가지입니다.\n여기서는 만료시간을 나타내는 durationSec 값만 설정해보았습니다.\n파라미터 필수여부 타입 설명 durationSec N Integer accessKey 지속 시간(초) default: 43,200 (12시간) min: 900 (15분) max: 129,600 (36시간) serialNumber N String OTP 디바이스 nrn 또는 시리얼 번호 tokenCode N Integer OTP 인증 번호 \u003c?php\r$array_postvars = Array (\t\"durationSec\" =\u003e 900\r);\r?\u003e\rAPI Header 설정 linkHeader를 설정할 때 다른 값들은 보통의 API 호출할 때와 동일한데\nSTS로 임시 Access Key를 생성할 때에는 Content-Type과 charset을 포함해야 합니다.\n\u003c?php\r$http_header = array(); $http_header[0] = \"Content-Type:application/json; charset=utf-8\";\r$http_header[1] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\r$http_header[2] = \"x-ncp-iam-access-key:\".$ncloud_sub_account_accesskey.\"\";\r$http_header[3] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\r?\u003e\rAPI 호출 link\rSTS API를 호출할 때에는 반드시 POST 방식으로 호출해야 합니다.\r\u003c?php curl_setopt($ch, CURLOPT_POST, TRUE);\rcurl_setopt($ch, CURLOPT_POSTFIELDS, $postvars);\r?\u003e\rAPI 호출 테스트 linkSTS로 생성한 기간 제한 임시 Access Key로 Ncloud API를 호출하는 테스트를 진행해보겠습니다.\n테스트로 호출할 API 정보는 다음과 같습니다.\ngetServerInstanceList: 사용 중인 서버 인스턴스(VM) 리스트를 조회 권한 없이 호출 link우선 Sub Account에 아무 권한도 주지 않은 상태에서 호출해보면 다음과 같은 결과 메시지를 확인할 수 있습니다.\nreport\rreturnMessage: You do not have authority about action: [VPCSever:View/GetServerInstanceList].\n권한 정책 추가 link이제는 권한을 추가해서 테스트 해보겠습니다.\n[Sub Account] - [Sub Accounts]에서 Sub Account를 선택하고 [정책] 탭에서 [추가] 버튼을 클릭합니다.\n정책 추가 link정책 추가 팝업에서 연관 상품에서 [Server (VPC)]를 선택하면 나타나는 정책 리스트에서 [NCP_VPC_SERVER_VIEWER] 정책을 선택하고 [추가] 버튼을 클릭합니다.\n추가된 정책 확인 link정책 추가 후에 Sub Account 상세 정보 화면에서 추가된 정책을 확인할 수 있습니다.\n권한 추가 후 호출 link권한 정책을 추가 후에 호출해보면 아래와 같이 호출이 성공하고 Success 메시지가 리턴되는 것을 확인할 수 있습니다.\nAccess Key 기한 만료 linkSTS로 기간 제한 있는 임시 Access Key를 만들때 설정했던 만료기한이 지난 후에 해당 Access Key를 사용해 API를 호출하면 아래와 같이 인증 실패 메시지가 리턴됩니다.\nreport\rError: errorCode: 200, message:Authentication Failed, details: This account is not allowed.\n메인 계정 Access Key를 사용했을 때 link처음에 설명한 것처럼 STS 임시 Access Key는 Sub Account로만 생성할 수 있습니다.\n혹시나 메인 계정으로 생성하려고 하면 아래와 같이 오류 메시지가 리턴됩니다.\nreport\rError: errorCode: 401, message:접근 권한 없음\n참고 URL link Ncloud Sub Account 사용 가이드\nhttps://guide.ncloud-docs.com/docs/ko/subaccount-overview\nSTS API 사용 가이드\nhttps://api.ncloud-docs.com/docs/management-sts\n문서 업데이트 내역 link\r날짜 내용 2022-06-07 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  204 ,
                href: "\/docs\/management\/cloud-insight\/basic-guide\/",
                title: "Ncloud 모니터링 서비스 Cloud Insight 설정 가이드",
                description: "Ncloud(네이버 클라우드)에서 성능/운영 지표를 통합 관리해주고 모니터링 해주는 서비스 Cloud Insight 설정 가이드입니다",
                content: "개요 link네이버 클라우드와 사용자 애플리케이션의 성능/운영 지표를 통합 관리하고, 장애나 이벤트가 발생했을 때 SMS 및 Email로 알람 통보를 해주는 서비스인 Cloud Insight 서비스를 설정하는 방법에 대해 정리해보겠습니다.\n적용 서비스 리스트 link위 비교에서도 설명했듯이 Cloud Insight는 Server 뿐만 아니라 네이버 클라우드의 다양한 서비스의 모니터링 정보를 확인할 수 있는데 해당 리스트는 다음과 같습니다.\nClassic link Server Load Balancer VPC link Server(VPC) Load Balancer(VPC) Cloud DB for MySQL(VPC) Cloud DB for MSSQL(VPC) Cloud DB for Redis(VPC) Cloud DB for MongoDB(VPC) Cloud Hadoop(VPC) Auto Scaling Group(VPC) Kubernetes Service(VPC) Search Engine Service(VPC) Cloud Data Streaming Service(VPC) 통합 link Cloud Search Object Storage Cloud Insight 서비스 link[Cloud Insight] 서비스는 [콘솔] - [Services] - [Management \u0026 Governance] - [Cloud Insight(Monitoring)]에 위치하고 있습니다.\n좀 더 쉽게 찾는 방법은 [콘솔] - [Services]에서 [검색] 기능을 이용하면 됩니다.\n이용 신청 linkCloud Insight 서비스는 이용 신청을 해야 사용할 수 있습니다. Classic, VPC 어떤 환경에서든 [Cloud Insight(Monitoring)] - [Subscription]에서 [상품 이용 신청] 버튼을 클릭해서 이용 신청을 합니다.\n대시보드 link이용 신청을 한 후에 [Dashboard] 메뉴에 가면 아래와 같이 현재 사용 중인 서비스 중에서 모니터링 가능한 서비스 리스트를 확인할 수 있습니다.\n또한 기본으로 제공되는 대시보드에서 확인할 수 있는 모니터링 항목을 각 서비스별로 고정되어 있습니다. 추가적인 항목을 확인하려면 별도로 대시보드를 생성해야 하는데 이에 대해서는 아래쪽에서 확인해보겠습니다.\n일부 서비스의 경우 리스트에 나타날 때까지 시간이 걸릴 수도 있습니다. 여유있게 1시간 정도 후에 확인해보시면 됩니다.\rLoad Balancer 모니터링 link\rObject Storage 모니터링 link\rServer 모니터링 link위에서 설명했듯이 Server 제품도 GPU 관련 항목을 제외하면 5가지 정도의 기본 모니터링 항목을 확인할 수 있습니다.\n커스텀 대시보드 link좀 더 상세한 모니터링 데이터를 확인하려면 커스텀 대시보드가 필요하고 그전에 [상세 모니터링]을 설정해야 합니다. 서버 설정에서 [상세 모니터링 설정 변경] 메뉴를 클릭합니다.\n[상세 모니터링 신청] 팝업에서 [예] 버튼을 클릭합니다.\n대시보드 생성 link[Dashboard] 화면에서 [대시보드 생성] 버튼을 클릭합니다.\n생성 팝업에서 대시보드 이름과 설명을 입력합니다.\n생성된 대시보드에서 [위젯 추가] 버튼을 클릭해서 위젯을 추가합니다.\n위젯 이름을 입력하고, 종류는 [Time Series], [Pie Chart], [Table], [Index], [Markdown] 중에서 하나를 선택합니다. 여기서는 [CPU Usage]와 [Time Series]를 선택했습니다.\n다음으로 데이터 설정에서 CPU 사용률에 해당하는 [SERVER/avg_cpu_used_rto] 등 필요한 항목을 선택하고 [선택 항목 추가] 버튼을 클릭합니다.\n항목을 추가하면 아래쪽 화면에 다음과 같이 리스트를 확인할 수 있습니다. 설정이 완료되었으면 [다음] 버튼을 클릭해 마지막 확인을 하고 생성을 완료합니다.\n위에서 추가한 [CPU Usage] 위젯과 함께 추가로 [Server - Load Average], [File System], [Memory Usage], [Net Work (Max In/Out bps)] 데이터를 확인할 수 있는 위젯을 추가하면 다음과 같은 대시보드를 확인할 수 있습니다.\n통보 대상자 등록 link이제 이벤트를 등록하고 알람을 통보 받을 대상자를 등록해보겠습니다.\n먼저 통보 대상자 그룹을 생성합니다. [Cloud Insight(Monitoring)] - [Notification Recipient] 메뉴에서 [전체 대상자] 옆에 있는 [ + ] 버튼을 클릭하고 아래 입력칸에 그룹명을 입력합니다.\n네이버 클라우드 계정 생성을 할 때 기본으로 1명의 대상자가 등록됩니다. 해당 대상자를 위에서 생성한 그룹에 할당하기 위해 선택하고 [할당] 버튼을 클릭합니다.\n그룹 할당 팝업에서 [할당] 버튼을 클릭합니다.\n대상자 리스트에서 해당 대상자에 그룹이 할당된 것을 확인할 수 있습니다.\n이벤트 규칙 등록 link이제 이벤트를 등록해보겠습니다. [Cloud Insight(Monitoring)] - [Configuration] - [Event Rue]에서 [Event Rule 생성] 버튼을 클릭합니다.\n이벤트 규칙을 생성해서 감시가 필요한 상품을 선택합니다. 여기서는 [Sever(VPC)]를 선택하겠습니다.\n[감시 대상 설정]에서 [전체 보기]를 선택하고, 감시 대상에 체크한 후 [다음] 버튼을 클릭합니다.\n감시 항목 및 조건 설정에서 [전체 보기]를 선택하고, Server, Memory 등의 항목 중에서 원하는 항목을 선택합니다.\n여기서는 가장 많이 사용하는 [SERVER의 CPU 사용률]에 해당하는 [SERVER/avg_cpu_used_rto]를 선택하고, 90% 이상인 상태가 5분 이상 지속되면 경고 알림을 보내도록 설정했습니다.\n다음으로 감시 대상에서 설정한 이벤트가 발생했을 때 어떤 액션을 취할 것인가를 설정해보겠습니다.\n설정 가능한 액션은 [알림 메시지 발송], [Integration], [Cloud Functions], [Auto Scaling 정책] 중에서 선택할 수 있는데, 여기서는 [알림 메시지 발송]을 선택하겠습니다.\n통보 대상자 그룹을 선택하고, [Email]과 [SMS]중에서 원하는 것을 선택하고, [리마인드 알림 주기], [종료 알림 여부]를 설정한 후 [다음] 버튼을 클릭합니다.\n마지막으로 이벤트 규칙 이름을 입력하고, 앞에서 설정한 내용들을 확인한 후에 [생성] 버튼을 클릭합니다.\n유지보수 계획 설정 link앞에서 설정한 이벤트 규칙이 업데이트나 점검 등의 유지보수가 진행되는 동안에도 작동되면 유지보수 시간 동안 쉼없이 통보 알람이 울리게 됩니다.\n이런 불편함이 없도록 Cloud Insight에서는 유지보수 계획 일정을 등록해두면 등록된 기간 동안에는 이벤트 규칙에 따른 통보알람이 울리지 않습니다.\n유지보수 일정은 아래와 같이 달력 행태나 리스트 형태로 확인 가능하며 [유지보수 계획 설정하기] 버튼으로 일정을 등록할 수 있습니다.\n제목을 입력하고, 작업 기간, 작업 대상, 디멘션을 선택하면 아래와 같이 선택한 대상과 디멘션이 리스트로 나타납니다. 보통 위에서 설정했던 이벤트 규칙에 해당하는 항목들을 선택하면 됩니다.\n유지보수 계획을 설정하면 아래와 같이 일정에서 확인할 수 있으며 해당 기간 동안에는 이벤트 통보가 진행되지 않습니다.\n참고 URL link Cloud Insight 소개\nhttps://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightoverview\nCloud Insight 사용 가이드\nhttps://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightconsole\nCloud Insight Rule Template 설정 가이드\n"
            }
        );
    index.add(
            {
                id:  205 ,
                href: "\/docs\/management\/cloud-insight\/rule-template-guide\/",
                title: "Ncloud 모니터링 서비스 Cloud Insight Rule Template 설정 가이드",
                description: "Ncloud(네이버 클라우드)에서 성능/운영 지표를 통합 관리해주고 모니터링 해주는 서비스 Cloud Insight에서 Rule Template을 설정하는 방법입니다",
                content: "개요 linkCloud Insight를 설정할 때 매번 서버마다 일일이 설정하는 방법도 있지만 [CPU-메모리-디스크 사용률] 같은 자주 모니터링하는 항목들을 [Template]에 등록해 두면 모니터링을 설정할 때 좀 더 쉽고 정확하게 설정할 수 있는데, 그 방법을 정리해보겠습니다.\nCloud Insight 기본 설정 방법 linkCloud Insight의 기본적인 설정 방법은 아래 링크 문서에서 확인 가능합니다.\n⁃ Cloud Insight Rule Template 설정 가이드\rTemplate 설정 항목 linkTemplate 설정할 때 서비스 상황에 따라 여러가지를 설정할 수 있는데, 여기서 예시로 설정해 볼 항목은 다음과 같습니다.\n서버 평균 CPU 사용률 서버 메모리 사용률 서버 디스크 사용률 Rule Template 설정 link먼저 [Cloud Insight] - [Configuration] - [Template]에서 [Rule Template] 탭을 선택하고, [Rule Template 생성] 버튼을 클릭합니다.\nCPU 사용률 link[서버 평균 CPU 사용률]은 [SERVER] 탭에서 [SEVER/avg_cpu_used_rto] 항목을 선택합니다.\n메모리 사용률 link[서버 평균 메모리 사용률]은 [Memory] 탭에서 [MEMORY/mem_usert] 항목을 선택합니다.\n디스크별 사용 중인 용량 link[디스크별 사용 중인 용량]은 [FILE STSTEM] 탭에서 [FILE STSTEM/fs_usert] 항목을 선택합니다.\n⁃[사용 중인 디스크가 2개 이상인 경우] 서버를 생성할 때 자동으로 추가되는 OS용 기본 디스크 말고 별도로 디스크를 추가했을 경우에는 기본 / 영역외에 추가 디스크가 마운트된 영역에 대해서도 항목을 추가해야 합니다.\n추가 디스크를 /data 디렉토리로 마운트했다고 가정했을 경우 아래 스샷처럼 [FILE STSTEM/fs_usert] 항목 오른쪽에 있는 [+] 버튼을 클릭해서 동일한 항목을 하나 더 추가하고, 디멘션에서 [mnt_nm: /data]를 선택합니다. 다른 곳으로 마운트했을 경우에는 그에 맞는 값을 선택하면 됩니다.\r3가지 항목을 모두 선택하고, [다음] 버튼을 클릭하면 아래와 같이 각 항목별로 조건을 설정할 수 있습니다.\n여기서는 각 수치가 70% 이상일 경우로 설정했고, 몇 분간의 평균값으로 할 것인가는 사용하는 서비스 상황에 따라 조절하시면 됩니다. Event Rule 설정 link다음으로 [Cloud Insight] - [Configuration] - [Event Rule]에서 [Event Rule 생성] 버튼을 클릭합니다.\n감시 상품 선택 linkNcloud Cloud Insight에서 모니터링 할 수 있는 상품은 아래와 같은데 그 중에서 여기서는 VPC Server를 선택하겠습니다.\nClassic Load Balancer Monitor Classic Server VPC Load Balancer Monitor VPC Server Object Storage 감시 대상 설정 link감시 대상은 미리 설정한 그룹이나 Auto Scaling Group에서 선택할 수도 있는데, 여기서는 [전체 보기]를 선택해서 미리 만들어둔 테스트용 서버를 선택하겠습니다.\n감시 항목 설정 link여기가 이 가이드 문서의 가장 중요한 단계인데, 위에서 설정했던 [Template]인 [template-test]를 감시 항목으로 선택해보겠습니다.\n액션 설정 link액션 설정에서 [통보 대상자], [알림 유형], [리마인드 알림 주기], [종료 알림 여부]를 설정합니다.\n최종 확인 link지금까지 설정한 내역을 최종 확인한 후에 이상이 없으면 [생성] 버튼을 클릭해서 Event Rule 생성을 완료합니다.\n기타 linkTarget Group 생성 link위에서는 [Rule Template]만 사용했는데, 여러 대상을 미리 하나의 그룹으로 묶어서 관리할 수도 있습니다.\n[Cloud Insight] - [Configuration] - [Template]에서 [Target Group] 탭을 선택하고, [Target Group 생성] 버튼을 클릭합니다.\n그룹 생성화면에서 원하는 [Product Type]을 선택하고, 선택 가능한 감시 대상 중에서 Group으로 묶을 대상을 선택하고 아래 쪽으로 이동 시킨 후에 [생성] 버튼을 클릭하면 됩니다. 이후에 [Event Rule] 생성할 때 [감시 대상 설정] 단계에서 여기서 설정한 Group을 선택하면 됩니다. 참고 URL link Cloud Insight 소개\nhttps://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightoverview\nCloud Insight 사용 가이드\nhttps://guide.ncloud-docs.com/docs/cloudinsight-cloudinsightconsole\nCloud Insight 기본 설정 가이드\n"
            }
        );
    index.add(
            {
                id:  206 ,
                href: "\/docs\/management\/cloud-log-analytics\/basic-guide\/",
                title: "Ncloud Cloud Log Analytics 설정 가이드",
                description: "Ncloud(네이버 클라우드) 로그 분석 서비스인 Cloud Log Analytics를 생성하고 설정하는 방법입니다",
                content: "개요 linkCloud Log Analytics는 Ncloud(네이버 클라우드)가 제공하는 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석할 수 있는 서비스로, 검색 기능을 이용해 여러 종류의 로그를 한 곳에서 한번에 조회하고 분석할 수 있어 효과적인 로그 관리가 가능합니다.\n로그 템플릿 종류 linkCloud Log Analytics는 텍스트 형식으로 생성되는 모든 종류의 로그 데이터 파일을 수집할 수 있는데, 사전에 제공되는 로그 템플릿 종류는 다음과 같습니다.\nServer SYSLOG Apache 로그(Access log, Apache Error Log) MySQL 설치형 상품의 로그(Error Log, Slow Log) Microsoft SQL Server 설치형 상품의 Error Log Tomcat 로그(Catalina Log) Windows 서버의 Event Log Windows 서버의 각종 text 형식의 로그 Cloud DB for MySQL 로그 Cloud DB for MSSQL 로그 Cloud DB for MongoDB 로그 Cloud DB for PostgreSQL 로그 Application Server Launcher 로그 Application Load Balancer 로그 Search Engine Service 로그 Cloud Data Streaming Service 로그 Bare Metal Server 로그 Ncloud Kubernetes Service Audit 로그 그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다 지원 운영 체제 link지원하는 운영 체제는 다음과 같습니다.\nCentOS/RHEL 6 CentOS 7 CentOS 8 RHEL 8 RHEL 9 Ubuntu 16.04 Ubuntu 18.04 Ubuntu 20.04 Ubuntu 22.04 SLES 15 Debian 9 Debian 10 Debian 11 Windows Server 2012 Windows Server 2016 Windows Server 2019 Windows Server2022 저장 용량 link 최대 100GB까지 저장할 수 있습니다. 100GB 용량을 초과했을 경우 추가 저장 용량 확보를 위해 과거부터 전날까지의 데이터가 삭제될 수 있습니다. CLA로 수집되는 로그량이 하루 10GB 이상을 넘거나 천만 건 이상일 경우 저장된 로그 검색시 성능에 제한이 발생할 수 있습니다. 저장 용량과 저장 기간을 더 늘리길 원할 경우 고객지원으로 문의해야 합니다. 과거 데이터를 보관하려면 [자동 보내기] 기능을 이용하여 과거 데이터를 Object Storage로 백업할 수 있습니다. 로그 보관 기간 link Cloud Log Analytics 서비스는 최대 30일 동안 데이터가 보관되며, 검색 및 대시보드에서 확인할 수 있습니다. 30일이 지난 데이터는 과거 데이터부터 순차적으로 삭제됩니다. 30일이 지나지 않았더라도 저장된 데이터가 100GB를 초과하면 과거부터 전날까지의 데이터가 매일 삭제될 수 있습니다. 이용신청 linkNcloud(네이버 클라우드) 콘솔 [Cloud Log Analytics] - [Subscription]에서 [이용 신청] 버튼을 클릭합니다. Cloud Log Analytics는 Classic, VPC 환경 공통 서비스이므로 어느쪽 환경에서 이용신청을 해도 상관없습니다.\n설정 - Linux link먼저 Linux 서버에서 설정하는 방법을 알아보겠습니다.\n[Cloud Log Analytics] - [Management]에서 로그를 수집할 서버를 선택하고, [수집 설정] 버튼을 클릭합니다.\nLog 수집 설정 화면에서 수집할 로그 템플릿을 선택하거나, 직접 [Custom Log]를 선택해서 로그 형태를 설정한 후에 [적용] 버튼을 클릭합니다.\n로그 수집 Agent 설치 linkLog 수집 설정을 마치면 [로그 수집 Agent] 설치 안내가 나옵니다.\n로그 수집 Agent 설치 명령어에는 URL 뒤쪽에 설치 하려는 서버에 해당하는 **설치키(Install Key)**가 포함되어 있습니다. 그러므로 URL을 수정해서도 안되고 다른 서버에 사용할 수도 없습니다.\n# VPC 환경\rcurl -s http://cm.vcla.ncloud.com/setUpClaVPC/{설치키(Install Key)} | sudo sh\r# Classic 환경\rcurl -s http://cm.cla.ncloud.com/setUpCla/{설치키(Install Key)} | sudo sh\r서버에 실제로 설치해보면 아래와 같이 설치 과정이 진행되고,\n설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n설치된 Agent가 제대로 작동하고 있는지 확인해보면 아래와 같이 active (running) 상태인 것을 확인할 수 있습니다.\nsystemctl status filebeat\r설정 - Windows link다음으로 Windows 서버에서 설정하는 방법을 살펴보겠습니다.\n마찬가지로 서버를 선택하고 [수집 설정] 버튼을 클릭합니다.\n로그 수집 설정에서 Log Template은 [EventLog]를 선택합니다.\n설정을 마치면 Agent 설치 가이드를 확인할 수 있습니다.\n서버에서 [Windows PowerShell]을 열고, 아래 명령어를 실행합니다. 마찬가지로 마지막에는 설치 서버에 해당하는 설치키가 포함되어 있습니다.\n# VPC 환경\rInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\r# Classic 환경\rInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/setUpwinClaVPC/{설치키(Install Key)}\"))\r설치가 완료되면 마지막에 Finish Installation이라는 메시지가 출력됩니다.\n로그 확인 linkAgent 설치 후 [Dashboard]를 확인해보면 로그가 수집되고 있을 것을 알 수 있습니다.\n[Search] 메뉴에서는 로그 내용을 자세히 검색, 확인할 수 있고, 굳이 서버에 접속하지 않더라도 필요한 로그를 콘솔 화면에서 직접 확인할 수 있습니다.\n로그 백업 linkCloud Log Analytics는 수집된 로그를 Object Storage로 내보내기하거나 Excel 파일로 다운로드 해서 백업할 수 있는 기능을 지원합니다.\n수동 백업 link[Search] 메뉴에 [Object Storage로 내보내기]와 [X 다운로드] 버튼이 있습니다.\n[Object Storage로 내보내기] 버튼을 클릭하면 내보내기 할 버킷을 선택할 수 있습니다.\n자동 백업 link[Export Log] 메뉴에서 [자동 내보내기 설정]을 클릭합니다.\n설정 화면에서 내보내기를 할 Object Storage의 버킷을 선택합니다. 혹시 버킷이 생성되지 않았다면 Object Storage로 가서 먼저 버킷을 생성하고 와야 합니다.\n내보내기는 하루에 한번 진행되므로 설정 후 다음 날 Object Storage에서 아래와 같이 파일이 저장되어 있는 것을 확인할 수 있습니다.\n로그 수집 해제 link더 이상 로그를 수집할 필요가 없어지면, 로그 수집 설정을 해제하면 됩니다.\nLinux 서버 로그 수집 해제 link서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\r# VPC 환경\rcurl -s http://cm.vcla.ncloud.com/removeCla | sudo sh\r# Classic 환경\rcurl -s http://cm.cla.ncloud.com/removeCla | sudo sh\rAgent 삭제 명령어를 실행하면 아래와 같이 Success Remove Agent 메시지가 출력됩니다.\nWindows 서버 로그 수집 해제 link마찬가지로 서버를 선택하고 [수집 해제] 버튼을 클릭합니다.\n로그 수집 해제를 위한 가이드에서 로그 수집 Agent 삭제 명령어를 복사합니다.\n# VPC 환경\rInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.vcla.ncloud.com/removewinCla\"))\r# Classic 환경\rInvoke-Expression $((New-Object System.Net.WebClient).DownloadString(\"http://cm.cla.ncloud.com/removewinCla\"))\rAgent 삭제 명령어를 실행하면 아래와 같이 Remove Agent 메시지가 출력됩니다.\nWindows 서버 Agent 삭제 오류 상황 linkWindows 서버에서 Agent 삭제를 시도할 때 아래와 같이 오류 메시지가 발생하는 경우가 있습니다.\n이때는 당황하지 마시고, Agent 삭제 명령어를 다시 한번 실행하면 됩니다.\nreport\rStop-Service: Cannot find any service with service name ‘filebeat’.\n로그 수집 설정에서 EventLog만 선택했을 경우 발생합니다.\r로그 수집 Agent는 윈도 이벤트 로그 수집을 위한 winlogbeat와 그 외 로그를 수집하기 위한 filebeat 두가지가 설치되는데, EventLog만 수집하도록 설정할 경우 filebeat는 실행되지 않습니다. 그 상태에서 Agent를 삭제하려고 하면 실행중이 아닌 filebeat를 실행 중지 시키려고 시도하게 되고, 결국 오류가 발생합니다.\n그러므로 심각한 오류는 아니고 만약을 위해 Agent 삭제 명령어를 한번 더 실행시키는 것으로 문제는 해결됩니다.\n참고 URL link Cloud Log Analytics 사용 가이드\nhttps://guide.ncloud-docs.com/docs/cla-overview 문서 업데이트 내역 link\r날짜 내용 2021-12-14 문서 최초 생성 2023-11-14 기능 개선 사항 적용, 문서 카테고리 변경 2024-02-16 지원 운영체제 리스트 추가 "
            }
        );
    index.add(
            {
                id:  207 ,
                href: "\/docs\/management\/cloud-log-analytics\/cla-template-info\/",
                title: "Ncloud Cloud Log Analytics에서 수집하는 로그 유형",
                description: "Ncloud(네이버 클라우드) 로그 분석 서비스인 Cloud Log Analytics에서 수집하는 로그 유형입니다",
                content: "개요 linkCloud Log Analytics는 네이버 클라우드 플랫폼의 여러 서비스에서 발생하는 다양한 로그들을 한 곳에 모아 저장하고 손쉽게 분석하게 해주는 서비스입니다.\n로그 템플릿 종류 linkCloud Log Analytics에서 수집하는 각 종 서비스의 로그 템플릿 종류는 다음과 같습니다.\nServer SYSLOG Apache 로그(Access log, Apache Error Log) MySQL 설치형 상품의 로그(Error Log, Slow Log) Microsoft SQL Server 설치형 상품의 Error Log Tomcat 로그(Catalina Log) Windows 서버의 Event Log Windows 서버의 각종 text 형식의 로그 Cloud DB for MySQL 로그 Cloud DB for MSSQL 로그 Cloud DB for MongoDB 로그 Cloud DB for PostgreSQL 로그 Application Server Launcher 로그 Application Load Balancer 로그 Search Engine Service 로그 Cloud Data Streaming Service 로그 Bare Metal Server 로그 Ncloud Kubernetes Service Audit 로그 그외 템플릿으로 제공되지 않는 로그도 Custom Log 기능으로 직접 대상 로그를 지정해서 수집할 수 있습니다 지원 운영 체제 link지원하는 운영 체제는 다음과 같습니다.\nCentOS/RHEL 6 CentOS 7 CentOS 8 RHEL 8 RHEL 9 Ubuntu 16.04 Ubuntu 18.04 Ubuntu 20.04 Ubuntu 22.04 SLES 15 Debian 9 Debian 10 Debian 11 Windows Server 2012 Windows Server 2016 Windows Server 2019 Windows Server2022 로그 보관 기간 link로그 데이터의 보관 기간은 30일로, 30일이 지난 데이터는 자동 삭제되며, 사전에 별도로 통지하지 않습니다.\n참고 URL link Cloud Log Analytics 사용 가이드\nhttps://guide.ncloud-docs.com/docs/cla-overview 문서 업데이트 내역 link\r날짜 내용 2021-12-07 문서 최초 생성 2023-11-14 로그 템플릿 종류 추가, 문서 카테고리 변경 2024-02-16 지원 운영체제 리스트 추가 "
            }
        );
    index.add(
            {
                id:  208 ,
                href: "\/docs\/management\/cloud-log-analytics\/windows-iis-log-collect-guide\/",
                title: "Ncloud Cloud Log Analytics에서 Windows IIS Log 수집하는 방법",
                description: "Ncloud(네이버 클라우드) 로그 분석 서비스인 Cloud Log Analytics에서 Windows IIS Log 수집하는 방법입니다",
                content: "개요 linkNcloud(네이버 클라우드) Cloud Log Analytics 서비스에서 Windows 웹서버인 IIS 로그를 수집하는 방법에 대해 정리해보겠습니다.\n테스트 서버 link Windows Server 2019 (64-bit) English Edition 수집 설정 link [Cloud Log Analytics] - [Management]에서 서버를 선택하고 [수집 설정] 버튼을 클릭합니다. [Log 수집 설정] 화면에서 각 설정 항목을 다음과 같이 입력합니다.\nLog Template: Custom Log를 선택합니다. Log Type: 임의의 값을 입력합니다. (예: iislog) Log 경로: 실제 저장되는 로그파일의 경로를 입력합니다. Log 파일 경로 확인 linkIIS Log 파일의 경로는 [IIS Manager]를 실행하고, 사이트 정보에서 [Logging] 메뉴를 선택하면 아래와 같이 [Directory] 항목을 확인할 수 있습니다.\n해당 경로를 찾아가면 아래와 같이 로그 파일이 저장되어 있는 것을 확인할 수 있습니다.\n# 예시\rC:\\inetpub\\logs\\LogFiles\\W3SVC1\\u_ex231114.log\rLog 파일 경로 입력 link실제 Log 파일은 일별 또는 시간 별로 파일명이 다르게 저장되는 경우가 대부분이므로 [Log 경로]에는 다음과 같이 전체 파일을 수집하도록 입력하면 됩니다. 이제 모든 항목을 입력했으면 [추가] 버튼을 클릭합니다.\n# 예시\rC:\\inetpub\\logs\\LogFiles\\W3SVC1\\*.log\r그리고, 입력한 내용에 이상이 없으면 [적용] 버튼을 클릭합니다.\n로그 수집 Agent 설치 link로그 수집 설정을 마치면 [로그 수집 Agent 설치] 방법에 대한 안내 팝업이 나타납니다. 설치 안내 내용 중에서 [로그 수집 agent 설치 명령어] 항목에 있는 [클립보드에 복사하기] 버튼을 클릭해서 설치 명령어를 복사합니다.\n서버의 [Windows PowerShell]을 실행시켜서 위에서 복사한 [로그 수집 agent 설치 명령어] 입력합니다. 설치가 정상적으로 완료되면 [Finish Installation] 이라는 메시지를 확인할 수 있습니다.\n수집된 로그 확인 link설치 후 5분 정도 기다렸다 [Cloud Log Analytics] - [Search] 메뉴에 들어가보면 아래와 같이 수집된 로그를 확인할 수 있습니다.\n참고 URL link Cloud Log Analytics 사용 가이드\nhttps://guide.ncloud-docs.com/docs/cla-overview 문서 업데이트 내역 link\r날짜 내용 2023-11-16 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  209 ,
                href: "\/docs\/management\/webservice-monitoring-system\/wms-basic-guide\/",
                title: "Ncloud Web service Monitoring System 사용 가이드",
                description: "Ncloud(네이버 클라우드) 고객의 웹 서비스를 실제 사용자 환경에서 모니터링하는 서비스 Ncloud Web service Monitoring System 사용 가이드입니다",
                content: "개요 linkNcloud Web service Monitoring System은 고객의 웹 서비스를 실제 사용자 환경에서 모니터링하는 서비스입니다. 웹 서비스 URL을 입력하여 실시간으로 테스트를 진행할 수 있고, 스케줄을 등록하여 반복적으로 모니터링을 할 수도 있으며, 오류 발생 시 알람을 받을 수도 있습니다.\n이용신청 linkNcloud 콘솔 [Management] - [Web service Monitoring System] - [Subscription]에서 이용 신청을 합니다.\n다음으로 [Web Monitoring]에서 [서비스 등록] 버튼을 클릭합니다.\n스텝 작성 link테스트 환경 선택 link모니터링 설정 전에 모니터링 유형, 서비스 유형, 지역 선택 등의 테스트를 진행할 환경을 설정합니다.\n스텝 작성 link스텝은 여러 가지를 추가할 수 있으나 여기서는 간단하게 URL만 추가해서 진행하겠습니다. URL 접속 설정에서는 모니터링 대상이 되는 METHOD (GET, POST, PUT, DELETE, HEAD) 선택 및 URL을 입력합니다.\n⁃ 모니터링 유형에서 URL을 선택해도 스텝을 추가하면 자동으로 SCENARIO로 변경됩니다.\n- 지역 선택은 테스트 환경에서는 1곳만 선택이 가능하고, 다음 단계인 서비스 설정에서 원하는 지역을 모두 선택할 수 있습니다.\r테스트 link모니터링 할 URL을 입력하고 [테스트 시작] 버튼을 클릭하면 아래와 같이 테스트 결과 메시지와 URL 접속 화면 즉, 오브젝트 탐색기가 나타납니다.\nURL 접속 옵션 linkURL 설정에서 추가 설정이 필요할 경우 [옵션] 버튼을 클릭하면 됩니다.\n옵션에서는 Header, Body, Cookie 등의 Request 값을 설정해서 테스트에 적용할 수 있습니다.\n스텝 추가 link이번 설정에서는 URL 접속만 테스트하는 것으로 진행하지만, 추가로 스텝을 추가해서 다양한 모니터링 설정을 하고자 할 경우에는 [스텝 추가] 버튼을 클릭하면 됩니다.\n추가 가능한 스텝에는 [대기 시간], [마우스 클릭], [텍스트 입력], [유효성 검사 (오브젝트 찾기)], [유효성 검사 (텍스트 찾기)], [팝업 창 이동], [사용자 정의 스크립트 실행] 등이 있습니다. 자세한 내용은 아래쪽 스텝 추가 상세 내용에서 다시 확인해보겠습니다.\n오류 확인 link혹시 테스트 결과에 Success가 아닌 Error가 나타났을 경우 아래쪽 [오류 로그]에서 어떤 오류인지 자세히 확인 가능합니다.\n특별한 문제가 없다면 [다음] 버튼을 클릭해서 다음 단계로 이동합니다.\n오류 항목 필터 추가 link오류 유형이 URL, JavaScript인 경우에는 향후 테스트에서 오류로 분류되지 않기를 바라는 항목은 아래 스샷처럼 [+ 추가] 버튼을 클릭해 필터에 추가하면 오류로 측정되지 않도록 할 수 있습니다.\n서비스 설정 link서비스에 필요한 설정을 선택합니다.\n모니터링 실행 주기: 1분이 기본값이며, 5분, 10분을 선택할 수 있습니다. 측정 지역: 국내, 홍콩, 일본, 싱가콜, 미국(서부), 독일 중에서 최소 1곳 이상을 선택하면 됩니다. Request Timeout: 요청 대기 시간을 5초, 10초, 30초 중에서 선택합니다. Run Timeout: 모니터링 전체 시나리오 실행 시간을 30초, 40초, 50초, 60초 중에서 선택합니다. 서비스 등록 link앞에서 선택한 설정을 최종 확인하고, 서비스 이름을 적당히 입력한 후에 [서비스 등록] 버튼을 클릭합니다.\n모니터링 확인 link서비스 등록을 완료하면 모니터링 화면으로 이동하게 되고, 어느 정도 시간이 지나면 아래와 같이 모니터링 결과가 그래프로 나타납니다.\n알람 설정 link모니터링 중에 오류가 발생할 경우 SMS나 Email로 알람을 받도록 설정할 수 있습니다. 알람 설정은 모니터링 화면에서 왼쪽 설정 버튼을 클릭하면 나타나는 [알람 설정] 메뉴를 클릭하면 됩니다.\n알람 설정 항목 link 알람 ON/OFF: 알람을 끄거나 켤 수 있습니다. 발생 조건: 기본 값은 3분 이내에 3건 이상 오류가 발생했을 경우 알람 메시지를 보내게 되어 있으며 원하는 값으로 변경하면 됩니다. 발송 기준: 일정 시간에 1번씩 알람을 받을 것인지, 조건에 해당할 때 마다 바로 받을 것인지 설정합니다. SMS/Email: 통보 대상 관리에 등록된 대상을 선택하고, Email과 SMS를 선택합니다. Webhook: SMS나 Email외에 Slack등의 Webhook URL을 등록해서 알람을 받을 수도 있습니다. 일시 정지 link모니터링 화면 오른쪽 상단에 있는 추가 설정에서 모니터링에 대한 [일시 정지], [스텝 수정], [삭제]를 선택할 수 있습니다.\n모니터링 상세 결과 link모니터링 화면 상단에 있는 서비스 이름을 클릭하면 상세 모니터링 내용을 확인할 수 있습니다.\n모니터링 상세 결과 화면에서는 선택한 기간의 상세 그래프와 각각의 모니터링 결과 리스트를 모두 확인할 수 있습니다.\n성공 상세 결과 link모니터링 결과 리스트에서 Success로 나오는 항목의 날짜를 클릭하면 상세 내역을 확인할 수 있습니다.\n성공했을 경우에는 아래와 같이 간단하게 성공 내역이 표시됩니다.\n오류 상세 결과 link모니터링 결과 리스트에서 Error로 나오는 항목의 날짜를 클릭하면 오류 상세 내역을 확인할 수 있습니다.\n오류 상세 결과 화면에서는 어떤 스텝에서 어떤 유형의 오류가 발생했는지 로그까지 자세히 확인할 수 있습니다.\n지역, 필터 설정 link지역 설정을 변경하거나 필터링할 내용을 설정하고자 할 경우에는 설정에서 [지역 설정], [필터 설정]을 변경하면 됩니다.\n지역 설정 link초기에 서비스 설정에서 선택했던 모니터링 지역을 지역 설정에서 원하는 지역으로 변경할 수 있습니다.\n필터 설정 link모니터링에서 발생한 오류나 이벤트 중에서 알람을 받고 싶지 않은 것이 있다면 필터링에 추가해서 알람 대상에서 제외할 수 있습니다.\nURL: 입력한 로그와 완벽히 일치하는 로그를 필터링하고 싶을 때 URL_PREFIX: 입력한 로그를 포함하고 있는 모든 로그를 필터링하고 싶을 때 JS: 입력한 스크립트와 완벽히 일치하는 스크립트를 필터링하고 싶을 때 JS_PREFIX: 입력한 스크립트를 포함하고 있는 모든 스크립트를 필터링하고 싶을 때 스텝 추가 상세 내용 link[스텝 추가]에서 추가 가능한 스텝은 다음과 같습니다.\nURL 접속 : 입력한 URL에 접속 합니다. 대기 시간 : 입력한 시간 만큼 대기 후에 진행합니다. 마우스 클릭 : 설정된 대상을 찾아 클릭 합니다. 텍스트 입력 : 설정된 대상을 찾아 텍스트를 입력 합니다. 유효성 검사 (오브젝트 찾기) : 페이지에서 설정된 오브젝트를 찾습니다. 유효성 검사 (텍스트 찾기) : 페이지에서 설정된 텍스트를 찾습니다. 팝업 창 이동 : 팝업이 생성된 경우 해당 팝업으로 대상을 전환하여 모니터링 할 수 있습니다. 사용자 정의 스크립트 실행 : 사용자가 설정한 Javascript를 실행합니다. 참고 URL link Ncloud Web service Monitoring System 사용 가이드\nhttps://guide.ncloud-docs.com/docs/management-management-3-1\nNcloud Cloud Log Analytics 스텝 추가 상세 가이드\n"
            }
        );
    index.add(
            {
                id:  210 ,
                href: "\/docs\/management\/webservice-monitoring-system\/wms-step-detail-guide\/",
                title: "Ncloud Web service Monitoring System 스텝 추가 상세 가이드",
                description: "Ncloud(네이버 클라우드) 고객의 웹 서비스를 실제 사용자 환경에서 모니터링하는 서비스 Ncloud Web service Monitoring System 스텝 추가 상세 가이드입니다",
                content: "개요 linkNcloud Web service Monitoring System의 모니터링 스텝에는 URL 접속 외에 텍스트 입력, 오브젝트 클릭 등이 있는데 구체적으로 어떻게 활용할 수 있는지 확인해보겠습니다.\n스텝 종류 link[스텝 추가]에서 추가 가능한 스텝은 다음과 같습니다.\nURL 접속 : 입력한 URL에 접속 합니다. 대기 시간 : 입력한 시간 만큼 대기 후에 진행합니다. 마우스 클릭 : 설정된 대상을 찾아 클릭 합니다. 텍스트 입력 : 설정된 대상을 찾아 텍스트를 입력 합니다. 유효성 검사 (오브젝트 찾기) : 페이지에서 설정된 오브젝트를 찾습니다. 유효성 검사 (텍스트 찾기) : 페이지에서 설정된 텍스트를 찾습니다. 팝업 창 이동 : 팝업이 생성된 경우 해당 팝업으로 대상을 전환하여 모니터링 할 수 있습니다. 사용자 정의 스크립트 실행 : 사용자가 설정한 Javascript를 실행합니다. 스텝 추가 예시 link기본 스텝은 URL 접속 1가지 이지만 위에서 살펴본 여러 스텝들 중에서 몇가지를 아래 스샷처럼 추가해볼 수 있습니다.\n스텝을 추가하고, [테스트 시작]을 클릭하면 아래쪽에 테스트 결과가 각 스텝별로 결과가 Success, Error로 표시됩니다.\n스텝 상세 설명 link각 스텝별로 어떤 역할을 하고, 어떤 설정값을 입력해야 하는지 확인해보겠습니다.\nURL 접속 link모니터링 대상이 되는 URL을 입력하고 접속 방식 (GET, POST, PUT, DELETE, HEAD)을 선택합니다.\n옵션 버튼을 클릭하면 요청 옵션(Header, Body, Cookie) 값을 설정할 수 있습니다.\n대기 시간 link입력한 시간 만큼 대기했다가 다음 스텝을 진행합니다.\n마우스 클릭 link지정한 대상을 찾아서 클릭하고 입력한 시간 만큼 대기후 클릭 Action을 실행합니다.\n아래 예시에서는 search-input-main이라는 id를 가진 Input Box를 찾아서 mysql이라는 텍스트를 입력하게 됩니다.\n텍스트 입력 link지정한 Input 오브젝트를 찾아서 지정한 텍스트를 입력합니다.\n유효성 검사 (오브젝트 찾기) link접속한 페이지에서 지정한 오브젝트를 찾습니다. 여기서 [존재 유/무] 항목은 true, false에 따라 Success와 Error가 결정됩니다.\n예를 들어 id=security인 오브젝트를 찾기 하는 경우 [존재 유/무] 항목 설정에 따른 결과는 다음과 같습니다.\ntrue 설정: id=security인 오브젝트를 찾았을 경우 Success, 못 찾았을 경우 Error false 설정: id=security인 오브젝트를 찾았을 경우 Error, 못 찾았을 경우 Success 유효성 검사 (텍스트 찾기) link접속한 페이지에서 지정한 텍스트를 찾습니다. 여기서 [존재 유/무] 항목은 true, false에 따라 Success와 Error가 결정됩니다.\n예를 들어 Update 텍스트를 찾기 하는 경우 [존재 유/무] 항목 설정에 따른 결과는 다음과 같습니다.\ntrue 설정: Update 텍스트를 찾았을 경우 Success, 못 찾았을 경우 Error false 설정: Update 텍스트를 찾았을 경우 Error, 못 찾았을 경우 Success 팝업창 이동 link해당 페이지에 접속했을 때 팝업창이 생성되는 경우 해당 팝업창으로 이동해서 모니터링을 진행할 수도 있습니다.\n사용자 정의 스크립트 실행 link직접 작성한 자바스크립트를 실행시켜서 결과를 확인할 수도 있습니다.\n[작성하기] 버튼을 클릭하면 아래와 같이 사용자 정의 자바스크립트를 작성할 수 있습니다.\n마우스 클릭으로 스텝 추가하기 link스텝을 추가하는 방법은 위에서 확인한 것처럼 직접 설정값을 입력하는 것 말고도 [테스트 시작] 버튼 클릭 후에 오른쪽 하단에 나타나는 URL 미리 보기 화면 즉, 오브젝트 탐색기에서 직접 마우스 클릭으로 스텝을 추가할 수도 있습니다.\n우선 오브젝트 탐색기에 마우스를 가져가면 아래 스샷처럼 선택 가능한 오브젝트들이 붉은 색 선택 영역으로 표시됩니다.\n이때 해당 오브젝트를 클릭하면 아래 스샷처럼 스텝 추가 팝업 창이 나타납니다.\n현재 오브젝트 탐색기에서 마우스 클릭으로 추가 가능한 스텝은 3가지가 있습니다.\n마우스 클릭 텍스트 입력 유효성 검사 (오브젝트 찾기) 참고 URL link Ncloud Web service Monitoring System 사용 가이드\nhttps://guide.ncloud-docs.com/docs/management-management-3-1\nNcloud Cloud Log Analytics 기본 가이드\n"
            }
        );
    index.add(
            {
                id:  211 ,
                href: "\/docs\/containers\/kubernetes-service-start-guide-linux\/",
                title: "Kubernetes Service 클러스터 생성 및 제어 가이드 | Linux",
                description: "Ncloud(네이버 클라우드) Kubernetes Service 클러스터 생성 및 리눅스 환경에서 제어하는 방법에 대한 소개입니다",
                content: "개요 linkNcloud (네이버 클라우드) VPC 환경에서 Kubernetes(쿠버네티스) 서비스를 생성하고 Linux 환경에서 제어하는 방법에 대해 소개합니다.\n쿠버네티스란? link쿠버네티스(Kubernetes, K8S)는 배포, 스케일링, 그리고 컨테이너화된 애플리케이션의 관리를 자동화 해주는 오픈 소스 컨테이너 오케스트레이션 엔진으로 구글에서 처음 개발하기 시작했으나 현재는 구글이 오픈소스 프로젝트로 공개한 상태입니다.\n특징 link쿠버네티스는 다음과 같은 특징이 있으며, 자세한 내용은 쿠버네티스 공식 페이지를 참고하시기 바랍니다.\n쿠버네티스 공식 페이지: https://kubernetes.io/ko/docs/home/\n서비스 디스커버리와 로드 밸런싱 스토리지 오케스트레이션 자동화된 롤아웃과 롤백 자동화된 빈 패킹(bin packing) 자동화된 복구(self-healing) 시크릿과 구성 관리 사전 준비 link먼저 쿠버네티스 클러스터에 사용할 전용 VPC와 Private 또는 Public Subnet 그리고, Load Balancer용 Subnet이 필요합니다.\nIP 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /17~/26 범위의 Subnet, 로드밸런서 전용 Subnet이 필요합니다. Docker Bridge 대역의 충돌을 방지하기 위해 172.17.0.0/16 범위 내의 Private Subnet, 로드밸런서 전용Subnet은 선택할 수 없습니다.\r쿠버네티스 서비스 위치 linkNcloud 쿠버네티스 서비스는 [콘솔] - [Services] - [Containers]에 위치하고 있습니다.\n클러스터 생성 linkVPC와 Subnet이 준비되었다면, 다음으로 [Kubernetes Sevice] - [Cluster]에서 생성하기를 클릭합니다.\n클러스터 설정 link생성할 클러스터의 정보를 설정해줍니다. 네트워크 타입은 Private과 Public 중에서 선택할 수 있습니다.\nKubernetes Service를 위한 ACG는 자동으로 생성됩니다.\r현재 지원되고 있는 Kubernetes 버전은 [1.26.10], [1.27.9] 입니다.\rNAT Gateway 생성 linkPrivate Subnet을 선택했을 경우에는 아래와 같이 NAT Gateway 생성 안내 팝업이 나타나는데,\nNAT Gateway를 생성해야 아웃바운드 트래픽을 활성화할 수 있기 때문입니다.\n팝업에서 링크를 클릭해서 NAT Gateway 화면으로 이동해 NAT Gateway를 생성합니다.\nNAT Gateway 생성 가이드는 아래 문서를 참고하시기 바랍니다. ⁃ VPC 환경에서 NAT Gateway 설정하기\r노드풀 설정 link노드풀 이름을 입력하고, 서버 이미지와 서버 타입을 선택하고 [추가] 버튼을 클릭합니다.\n현재 지원되고 있는 OS는 [ubuntu 18.04], [ubuntu 20.04] 입니다.\r인증키 설정 link다음으로 워커노드의 인증키를 설정 합니다.\n최종 확인 link설정 정보를 최종적으로 확인한 후 생성버튼을 클릭하여 클러스터를 생성합니다.\n쿠버네티스 클러스터 생성은 30분 정도 소요되므로 여유를 갖고 기다리시면 됩니다.\r생성 완료 link생성이 완료되면 아래와 같이 클러스터와 노드풀의 정보를 확인할 수 있습니다.\n클러스터 정보 중에서 클러스터 UUID는 아래쪽에서 IAM 인증 Kubeconifg 파일을 생성할 때 필요하니 확인해두시기 바랍니다.\n[Server] 메뉴에 가면 노드풀 설정에 따라 생성된 서버를 확인할 수 있습니다.\n(서버 이름은 노드풀 이름으로 입력한 문자열 기준으로 생성되는데, 여기서는 test123-O-OOO 이런 식으로 생성되었습니다.)\n그리고, 추가로 테스트를 위한 CentOS 서버(k8s-test)를 생성했습니다.\nIAM 인증 설정 link클러스터를 제어하기 위해서는 네이버 클라우드 쿠버네티스 서비스에서 제공하는 IAM 인증을 설정해야 합니다.\nncp-iam-authenticator 설치 linkNcloud에서 제공하는 ncp-iam-authenticator 바이너리를 통해 iam 인증 config 파일을 생성 할 수 있습니다.\nncp-iam-authenticator 바이너리를 다운로드 합니다. ~# curl -o ncp-iam-authenticator https://kr.object.ncloudstorage.com/nks-download/ncp-iam-authenticator/v1.0.5/linux/amd64/ncp-iam-authenticator\r다운받은 바이너리에 실행 권한을 추가 합니다. ~# chmod +x ./ncp-iam-authenticator\rbin/ncp-iam-authenticator 파일을 생성하고 $PATH에 추가합니다. bash Profile에 추가 합니다. ~# mkdir -p $HOME/bin \u0026\u0026 cp ./ncp-iam-authenticator $HOME/bin/ncp-iam-authenticator \u0026\u0026 export PATH=$PATH:$HOME/bin\r~# echo 'export PATH=$PATH:$HOME/bin' \u003e\u003e ~/.bash_profile\rncp-iam-authenticator가 정상 작동 하는지 테스트 합니다. ~# ncp-iam-authenticator help\rAPI Access Key 생성 link[Sub Account] - [Sub Accounts]에서 본인의 계정을 선택하고, [API Gateway 접근] 권한을 추가하면 계정 정보 화면에 아래와 같이 [Access Key] 탭이 나타나는데[추가] 버튼을 클릭하면 [Access Key]와 [Secret Key]를 생성할 수 있습니다.\nreport\r메인 계정은 최대 권한을 가지기 때문에 메인 계정으로 생성한 API도 메인 계정과 동일한 최대 권한을 가지게 됩니다. 그러므로 메인 계정으로 API Key를 생성하게 되면 이 Key가 유출되었을 때 심각한 문제가 생기기 때문에 반드시 서브 계정에서 API Key를 생성해야 합니다.\nKubeconfig 파일 생성 link환경변수 설정 linkAPI 인증키를 2가지 방법 중 하나를 이용해 환경변수에 등록합니다.\n첫번째 방법: OS 환경 변수 설정 ~# export NCLOUD_ACCESS_KEY={Ncloud API AccessKey}\r~# export NCLOUD_SECRET_KEY={Ncloud API SecretKey}\r~# export NCLOUD_API_GW=https://ncloud.apigw.ntruss.com\r두번째 방법: 사용자 환경 홈 디렉터리에 configure 설정 ~# mkdir .ncloud ~# cat \u003c\u003c EOF \u003e .ncloud/configure\r[DEFAULT]\rncloud_access_key_id = {Ncloud API AccessKey}\rncloud_secret_access_key = {Ncloud API SecretKey}\rncloud_api_url = https://ncloud.apigw.ntruss.com\rEOF\rKubeconifg 파일 생성 link환경변수에 등록이 되었다면 파일을 생성 할 차례입니다.\n아래 명령어로 클러스터에 대한 IAM 인증 Kubeconifg 파일을 생성합니다.\n클러러스터 UUID 값은 클러스터 상세보기의 [클러스터 이름 (UUID)] 에서 확인 할수 있습니다.\r~# ncp-iam-authenticator create-kubeconfig --region --clusterUuid --output .yaml\r## 예시\r~# ncp-iam-authenticator create-kubeconfig --region KR --clusterUuid 12345678-1234-1234-1234-1234567890 --output kubeconfig.yaml\rkubectl 설치 link쿠버네티스 클러스터를 제어할 kubectl을 설치하기 위해 필요한 파일을 다운로드 받습니다.\n~# curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\r다운 받은 파일을 설치합니다.\n~# sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\r# 버전 확인\r~# kubectl version --client --output=yaml\rkubectl 실행 link생성한 IAM 인증 kubeconfig 파일을 이용하여 kubectl 명령어를 테스트하여 정상 동작 하는지 확인 합니다.\n실행하면 아래와 같이 현재 동작 중인 노드 서버 리스트를 확인할 수 있습니다.\n~# kubectl get node --kubeconfig kubeconfig.yaml\r실행 명령어 단축 link위와 같은 kubectl 명령은 뒤쪽에 kubeconfig 환경 설정 파일까지 입력해야 해서 다소 불편한데, 간단하게 줄일 수 있는 방법이 있습니다.\n우선 만들어진 kubeconfig.yaml 파일을 .kube/ 디렉토리 아래에 config로 이름을 바꾸어 이동 혹은 복사 합니다.\n~# cp kubeconfig.yaml .kube/config\r이렇게 하면 Kubectl을 사용 시 아래와 같이 –kuebeconfig 명령어 없이 사용 할 수 있습니다.\n~# kubectl get node\r참고 URL link 쿠버네티스 사용 가이드\nhttps://guide.ncloud-docs.com/docs/k8s-k8soverview\n클러스터 이용 가이드\nhttps://guide.ncloud-docs.com/docs/k8s-k8suse-cluster\nkubectl 설치 가이드\nhttps://guide.ncloud-docs.com/docs/k8s-k8sstart#Kubectl\nWindows 환경에서 쿠버네티스 제어하기\n"
            }
        );
    index.add(
            {
                id:  212 ,
                href: "\/docs\/containers\/kubernetes-service-start-guide-windows\/",
                title: "Kubernetes Service 클러스터 생성 및 제어 가이드 | Windows",
                description: "Ncloud(네이버 클라우드) Kubernetes Service 클러스터 생성 및 Windows 환경에서 제어하는 방법에 대한 소개입니다",
                content: "개요 linkNcloud (네이버 클라우드) VPC 환경에서 Kubernetes(쿠버네티스) 서비스를 생성하고 Windows 환경에서 제어하는 방법에 대해 소개합니다.\n쿠버네티스란? link쿠버네티스(Kubernetes, K8S)는 배포, 스케일링, 그리고 컨테이너화된 애플리케이션의 관리를 자동화 해주는 오픈 소스 컨테이너 오케스트레이션 엔진으로 구글에서 처음 개발하기 시작했으나 현재는 구글이 오픈소스 프로젝트로 공개한 상태입니다.\n특징 link쿠버네티스는 다음과 같은 특징이 있으며, 자세한 내용은 쿠버네티스 공식 페이지를 참고하시기 바랍니다.\n쿠버네티스 공식 페이지: https://kubernetes.io/ko/docs/home/\n서비스 디스커버리와 로드 밸런싱 스토리지 오케스트레이션 자동화된 롤아웃과 롤백 자동화된 빈 패킹(bin packing) 자동화된 복구(self-healing) 시크릿과 구성 관리 사전 준비 link먼저 쿠버네티스 클러스터에 사용할 전용 VPC와 Private 또는 Public Subnet 그리고, Load Balancer용 Subnet이 필요합니다.\nIP 대역(10.0.0.0/8,172.16.0.0/12,192.168.0.0/16) 내에서 /17~/26 범위의 Subnet, 로드밸런서 전용 Subnet이 필요합니다. Docker Bridge 대역의 충돌을 방지하기 위해 172.17.0.0/16 범위 내의 Private Subnet, 로드밸런서 전용Subnet은 선택할 수 없습니다.\r쿠버네티스 서비스 위치 linkNcloud 쿠버네티스 서비스는 [콘솔] - [Services] - [Containers]에 위치하고 있습니다.\n클러스터 생성 linkVPC와 Subnet이 준비되었다면, 다음으로 [Kubernetes Sevice] - [Cluster]에서 생성하기를 클릭합니다.\n클러스터 설정 link생성할 클러스터의 정보를 설정해줍니다. 네트워크 타입은 Private과 Public 중에서 선택할 수 있습니다.\nKubernetes Service를 위한 ACG는 자동으로 생성됩니다.\r현재 지원되고 있는 Kubernetes 버전은 [1.26.10], [1.27.9] 입니다.\rNAT Gateway 생성 linkPrivate Subnet을 선택했을 경우에는 아래와 같이 NAT Gateway 생성 안내 팝업이 나타나는데,\nNAT Gateway를 생성해야 아웃바운드 트래픽을 활성화할 수 있기 때문입니다.\n팝업에서 링크를 클릭해서 NAT Gateway 화면으로 이동해 NAT Gateway를 생성합니다.\nNAT Gateway 생성 가이드는 아래 문서를 참고하시기 바랍니다. ⁃ VPC 환경에서 NAT Gateway 설정하기\r노드풀 설정 link노드풀 이름을 입력하고, 서버 이미지와 서버 타입을 선택하고 [추가] 버튼을 클릭합니다.\n현재 지원되고 있는 OS는 [ubuntu 16.04], [ubuntu 18.04], [ubuntu 20.04] 입니다.\r인증키 설정 link다음으로 워커노드의 인증키를 설정 합니다.\n최종 확인 link설정 정보를 최종적으로 확인한 후 생성버튼을 클릭하여 클러스터를 생성합니다.\n쿠버네티스 클러스터 생성은 30분 정도 소요되므로 여유를 갖고 기다리시면 됩니다.\r생성 완료 link생성이 완료되면 아래와 같이 클러스터와 노드풀의 정보를 확인할 수 있습니다.\n클러스터 정보 중에서 클러스터 UUID는 아래쪽에서 IAM 인증 Kubeconifg 파일을 생성할 때 필요하니 확인해두시기 바랍니다.\n[Server] 메뉴에 가면 노드풀 설정에 따라 생성된 서버를 확인할 수 있습니다.\n(서버 이름은 노드풀 이름으로 입력한 문자열 기준으로 생성되는데, 여기서는 test123-O-OOO 이런 식으로 생성되었습니다.)\nIAM 인증 설정 link클러스터를 제어하기 위해서는 네이버 클라우드 쿠버네티스 서비스에서 제공하는 IAM 인증을 설정해야 합니다.\nncp-iam-authenticator 설치 linkNcloud에서 제공하는 ncp-iam-authenticator 바이너리를 통해 iam 인증 config 파일을 생성 할 수 있습니다.\nncp-iam-authenticator 바이너리를 다운로드 합니다. \u003e curl -o ncp-iam-authenticator.exe https://kr.object.ncloudstorage.com/nks-download/ncp-iam-authenticator/v1.0.5/windows/amd64/ncp-iam-authenticator.exe\rncp-iam-authenticator가 정상 작동 하는지 테스트 합니다. \u003e ncp-iam-authenticator help\rAPI 인증키 생성 link네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\nKubeconfig 파일 생성 linkAPI 인증키를 2가지 방법 중 하나를 이용해 환경변수에 등록합니다.\n1. OS 환경 변수 설정\n\u003e SET NCLOUD_ACCESS_KEY={Ncloud API AccessKey}\r\u003e SET NCLOUD_SECRET_KEY={Ncloud API SecretKey}\r\u003e SET NCLOUD_API_GW=https://ncloud.apigw.ntruss.com\r2. 사용자 계정 홈 폴더에 configure 설정\nWindows 사용자 계정 폴더에 .ncloud 폴더를 만들고 아래와 같은 내용으로 configure 파일을 생성합니다.\n\u003e mkdir C:\\Users\\{User Account}\\.ncloud\r\u003e copy con C:\\Users\\{User Account}\\.ncloud\\configure\r[DEFAULT]\rncloud_access_key_id = {Ncloud API AccessKey}\rncloud_secret_access_key = {Ncloud API SecretKey}\rncloud_api_url = https://ncloud.apigw.ntruss.com\r^Z\r3. Kubeconifg 파일 생성\n환경변수에 등록이 되었다면 파일을 생성 할 차례입니다.\n아래 명령어로 클러스터에 대한 IAM 인증 Kubeconifg 파일을 생성합니다.\n클러러스터 UUID 값은 클러스터 상세보기의 [클러스터 이름 (UUID)] 에서 확인 할수 있습니다.\r\u003e ncp-iam-authenticator create-kubeconfig --region --clusterUuid --output .yaml\r## 예시\r\u003e ncp-iam-authenticator create-kubeconfig --region KR --clusterUuid 12345678-1234-1234-1234-1234567890 --output kubeconfig.yaml\rkubectl 설치 link쿠버네티스 클러스터를 제어할 kubectl을 설치하기 위해 필요한 파일을 다운로드 받고, 버전 정보를 확인합니다.\n아래 두가지 방법 중에 하나를 선택해 다운로드 받으시면 됩니다.\nDownload the latest release v1.24.0\n\u003e curl -LO https://dl.k8s.io/release/v1.24.0/bin/windows/amd64/kubectl.exe\r\u003e kubectl version --client --output=yaml\rkubectl 실행 link생성한 IAM 인증 kubeconfig 파일을 이용하여 kubectl 명령어를 테스트하여 정상 동작 하는지 확인 합니다.\n실행하면 아래와 같이 현재 동작 중인 노드 서버 리스트를 확인할 수 있습니다.\n\u003e kubectl get node --kubeconfig kubeconfig.yaml\r실행 명령어 단축 link위와 같은 kubectl 명령은 뒤쪽에 kubeconfig 환경 설정 파일까지 입력해야 해서 다소 불편한데, 간단하게 줄일 수 있는 방법이 있습니다.\n우선 만들어진 kubeconfig.yaml 파일을 .kube/ 디렉토리 아래에 config로 이름을 바꾸어 이동 혹은 복사 합니다.\n\u003e copy kubeconfig.yaml .kube\\config\r이렇게 하면 Kubectl을 사용 시 아래와 같이 –kuebeconfig 명령어 없이 사용 할 수 있습니다.\n\u003e kubectl get node\r참고 URL link 쿠버네티스 사용 가이드\nhttps://guide.ncloud-docs.com/docs/k8s-k8soverview\n클러스터 이용 가이드\nhttps://guide.ncloud-docs.com/docs/k8s-k8suse-cluster\nkubectl 설치 가이드\nhttps://guide.ncloud-docs.com/docs/k8s-k8sstart#Kubectl\nLinux 환경에서 쿠버네티스 제어하기\n"
            }
        );
    index.add(
            {
                id:  213 ,
                href: "\/docs\/ai-services\/clova-ocr\/template-ocr-guide\/",
                title: "Ncloud Clova OCR 서비스 중에서 Template OCR 사용 방법 안내",
                description: "Ncloud (네이버 클라우드) Clova OCR 서비스 중에서 Template OCR을 사용하는 방법 안내입니다",
                content: "개요 linkNcloud (네이버 클라우드) [Clova OCR]은 전송한 문서나 이미지를 인식하여 사용자가 지정한 영역의 텍스트와 데이터를 정확하게 추출하는 서비스입니다. 여기서는 [Clova OCR]에서 제공하는 OCR 서비스 종류 중에서 [Template OCR]의 사용 방법을 [사업자등록증]을 예시로 정리해보겠습니다.\n서비스 이용 시 주의 사항 link[Clova OCR] 이용 시 주의 사항은 다음과 같습니다.\n서비스 계정당 권장되는 호출 성능은 최대 1 tps입니다. 더 높은 호출 성능을 원하는 경우 고객 지원으로 문의하셔야 합니다. 인식 요청 시 45도 이상 회전된 문서는 인식률이 저하될 수 있습니다. OCR 종류 link[Clova OCR]에서 제공하는 OCR 서비스의 종류는 다음과 같습니다.\nGeneral OCR: 텍스트/표를 추출하는 OCR Template OCR: 판독 영역을 직접 지정하여 인식값 추출 후 테스트 및 결과 전송이 가능한 템플릿 빌더를 지원하는 OCR Document OCR: 머신러닝 기반으로 문서의 의미적 구조를 이해하는 특화 모델 엔진을 탑재하여 입력 정보(key-value)를 자동 추출하는 OCR 도메인 생성 link우선 [CLOVA OCR] - [Domain]에서 [도메인 생성] 버튼을 클릭합니다.\nGeneral OCR과 Template OCR을 위한 [일반/템플릿 도메인]과 Document OCR을 위한 [특화 모델 도메인]중에서 [일반/템플릿 도메인 생성] 버튼을 클릭합니다. 생성 link도메인명과 도메인 코드를 입력하고, 지원 언어를 선택합니다.\n서비스 타입은 템플릿, 인식 모델은 Basic, 서비스 플랜은 Free를 선택하고 [생성] 버튼을 클릭합니다.\n⁃ CLOVA OCR은 도메인별 서비스 플랜에 따라 요금이 부과됩니다.\n⁃ Free 서비스 플랜을 제외한 모든 서비스 플랜은 CLOVA OCR API를 호출하지 않아도 기본 요금이 부과됩니다.\n⁃ 서비스 플랜에 따라 기본으로 제공되는 API 호출 수가 다르며, 기본 제공 건수 초과 시 추가 요금이 부과됩니다.\r템플릿 생성 link이제 템플릿을 생성하기 위해 도메인 정보에서 오른쪽 끝에 있는 [템플릿 빌더] 버튼을 클릭합니다.\n템플릿 빌더 link템플릿 빌더 화면에서는 API Gateway 연동, 템플릿 관리, 테스트, 사용 지표 확인등을 할 수 있습니다.\n왼쪽에 있는 메뉴에서 [템플릿 목록]을 선택하고, [템플릿 생성] 버튼을 클릭합니다. 템플릿 기본 정보 입력 link템플릿 기본 정보 항목에서 [템플릿명]을 입력하고 [확인] 버튼을 클릭해서 사용 가능한 템플릿 이름인지 확인합니다.\n사용 가능한 [템플릿명]인 것이 확인되면 아래쪽에 있는 대표 샘플 이미지 등록 영역이 활성화 됩니다. 이 영역을 클릭해서 대표 샘플 이미지를 등록합니다. 대표 샘플 설정 link대표 샘플 이미지를 등록하면 [대표 샘플명]을 입력해야 [대표 샘플의 판독 필드]를 지정할 수 있다는 안내 메시지가 나타나니다.\n[대표 샘플명]을 입력하고 [확인] 버튼을 클릭하면 [대표 샘플의 판독 필드]를 지정할 수 있는데 [사업자등록증] 부분을 선택했습니다. [대표 샘플의 판독 필드]를 지정하고 나면, 템플릿 분류의 정확도 향상을 위해 대표 샘플명과 비슷한 유사어를 등록하라는 안내 메시지를 확인할 수 있습니다. [유사어 관리] 버튼을 클릭해서 [대표 샘플명]인 [사업자등록증]의 유사어를 [사 업 자 등 록 증], [사업자 등록증]등으로 입력했습니다. 판독 필드 지정 link이제 실제로 이미지에서 판독할 필드를 지정해보겠습니다.\n[필드 추가] 버튼을 클릭하면 필드 지정 영역이 이미지 위에 나타나는데, 원하는 영역을 선택하고 [] 아이콘을 클릭합니다. 여기서는 등록번호 영역을 선택했습니다.\n판독 필드 선택을 하고 나면 오른쪽 아래에 첫번째 판독 필드를 뜻하는 [필드 01] 항목이 생성되는데, 여기에 [필드 이름]을 입력합니다. 마찬가지로 [법인명], [대표자], [사업장 소재지], [업태], [종목]까지 총 6개 필드를 지정하고, [필드 이름]을 입력한 후 [저장] 버튼을 클릭합니다. 배포 관리 link생성이 끝난 템플릿을 실제로 사용하려면 [베타 배포]를 해야 합니다. 왼쪽 상단에 있는 [배포 관리] 메뉴로 이동해서 [베타 배포] 버튼을 클릭합니다.\n[베타 배포] 확인 팝업에서 [확인] 버튼을 클릭합니다. [베타 배포]가 완료되면 현재 배포 상태를 확인할 수 있습니다. 테스트 link베타 배포가 끝났으면 이제 테스트를 해보겠습니다. [테스트] 메뉴에서 [파일 업로드] 버튼을 클릭합니다.\n파일 업로드 팝업창에서 파일을 업로드 합니다. 테스트할 파일을 업로드하면 무료 테스트 횟수 300회에 대한 안내를 볼 수 있습니다. 테스트 결과 link테스트 결과 화면에서는 왼쪽에 업로드된 이미지 파일의 판독 영역을 볼 수 있고 오른쪽에는 판독 영역에서 판독한 텍스트를 확인할 수 있습니다.\n요금관련 주의 사항 link\r⁃ General OCR 및 Free 서비스 플랜을 제외한 모든 서비스 플랜의 경우 CLOVA OCR API 호출을 하지 않아도 기본 유지 비용이 발생하므로 주의해 주십시오.\n⁃ CLOVA OCR API 호출 수는 서비스 플랜별 제공 건수가 다르며 포함 구간 초과 시 추가 비용이 발생하므로 주의해 주십시오.\n⁃ Template OCR의 1회 호출 기준은 빌더에서 설정한 템플릿의 인식 영역의 수(최대 50개)입니다. 초과 시 추가 과금이 발생합니다. \u003c예시\u003e Template의 Box 영역의 수가 130개인 경우 3회 API 호출로 과금\n⁃ Batch 기능 이용 시 긴 이미지, 표 추출 등 설정에 따라 추가 비용이 발생하므로 주의해 주십시오.\r참고 URL link Ncloud CLOVA OCR 기본 가이드\nhttps://guide.ncloud-docs.com/docs/ko/clovaocr-overview\nNcloud CLOVA OCR Templage 생성 가이드\nhttps://guide.ncloud-docs.com/docs/clovaocr-template\n문서 업데이트 내역 link\r날짜 내용 2024-02-14 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  214 ,
                href: "\/docs\/ai-services\/clova-ocr\/template-ocr-api-guide\/",
                title: "Ncloud Clova OCR - Template OCR API 연동 PHP 샘플 예제",
                description: "Ncloud (네이버 클라우드) Clova OCR API를 이용해 Template OCR을 사용하는 방법 안내입니다",
                content: "개요 linkNcloud (네이버 클라우드) [Clova OCR]은 전송한 문서나 이미지를 인식하여 사용자가 지정한 영역의 텍스트와 데이터를 정확하게 추출하는 서비스입니다. 여기서는 API를 이용해서 Template OCR로 [사업자등록증]을 인식하는 예제를 PHP 코드로 정리해보겠습니다.\n서비스 배포 link테스트는 Template을 미리 생성한 상태에서 진행해보겠습니다. Template 생성 방법은 아래 링크의 문서에서 확인하시면 됩니다.\n⁃ Ncloud Clova OCR 서비스 중에서 Template OCR 사용 방법\r[배포 관리]에서 [서비스 배포] 버튼을 클릭해서 해당 템플릿을 서비스 배포합니다. 서비스 배포 확인 팝업창에서 [확인] 버튼을 클릭합니다. [서비스 배포]가 완료되면 아래와 같이 배포 상태와 배포 종료 시간을 확인할 수 있습니다. API Gateway 연동 link[설정] - [API Gateway 연동] 탭에서 [연동] 버튼을 클릭합니다.\n[API Gateway 연동]은 기본이 자동 연동입니다. API 연동에 필요한 [Secret Key]를 만들기 위해서 [생성] 버튼을 클릭합니다. 생성된 [Secret key]와 [API Gateway Invoke URL]을 복사해서 API 연동 코드에 사용합니다. 인식 필드 linkAPI 연동 코드를 작성하기 전에 이전에 생성했던 템플릿에서 인식 필드를 다시 한번 확인했보겠습니다.\n필드 01: 등록번호 필드 02: 법인명 필드 03: 대표자 필드 04: 사업장 소재지 필드 05: 업태 필드 06: 종목 PHP 샘플 코드 linkClova OCR API는 크게 2가지 방법으로 나눌 수 있습니다.\n파일 URL을 전달하는 방법 파일을 업로드하는 방법 아래 PHP 코드는 2가지 방법으로 각각 구현되어 있습니다. 그리고 각 코드의 상세 설명은 아래쪽에서 정리해보겠습니다.\n파일 URL\r파일 업로드\r\u003c?php // Secret Key\r$ncloud_clova_ocr_secretkey = \"Ijkouhuh****중간 생략****Ht86ghvhj\u0026T*^VHJ\u0026T*R^FVHJHJ\"; // API Gateway Invoke URL\r$api_url = \"https://***.apigw.ntruss.com/custom/v1/28410/****중간 생략****/infer\";\r// Template ID\r$ncloud_clova_ocr_template_ids = [28222];\r$unixtimestamp = round(microtime(true) * 1000);\r// http 호출 헤더값 설정\r$http_header = array(); $http_header[0] = \"X-OCR-SECRET: \".$ncloud_clova_ocr_secretkey.\"\";\r$http_header[1] = \"Content-Type:application/json; charset=utf-8\";\r$ocr_request_id = \"ocr-test\".$unixtimestamp;\r// 전송할 값들을 배열 형태로 저장\r$postvars = [\r\"version\"=\u003e \"V2\",\r\"requestId\"=\u003e $ocr_request_id,\r\"timestamp\"=\u003e $unixtimestamp,\r\"lang\"=\u003e \"ko\",\r\"images\"=\u003e [\r[\r\"format\"=\u003e \"jpg\",\r\"name\"=\u003e \"ocr-test\",\r\"data\"=\u003e null,\r\"url\"=\u003e \"https://kr.object.ncloudstorage.com/(버킷 이름)/ocr-test.jpg\",\r\"templateIds\"=\u003e $ncloud_clova_ocr_template_ids\r]\r]\r];\r// 배열 형태로 저장한 값들을 json 형태로 변환\r$json_portvars = json_encode($postvars);\r// api 호출\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_url);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE); curl_setopt($ch, CURLOPT_POST, TRUE);\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\rcurl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\r$json_response = curl_exec($ch);\r$err = curl_error($ch);\r$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\rcurl_close($ch);\rif ($json_response \u0026\u0026 $status_code == \"200\")\r{\r$obj_response_array = json_decode($json_response, true);\r$obj_clova_ocr_data = $obj_response_array[\"images\"][0];\r// 사업자 등록번호\r$business_number = $obj_clova_ocr_data[\"fields\"][0];\r$business_number= $business_number[\"inferText\"];\r//=============== 중간 생략 ================= //\r// 종목\r$business_item = $obj_clova_ocr_data[\"fields\"][5];\r$business_item= $business_item[\"inferText\"];\recho(\"사업자 등록번호:\".$business_number.\"\n\");\recho(\"종목:\".$business_item.\"\n\");\r} else {\r$obj_error_response_array = json_decode($json_response, true);\r}\r?\u003e\r\u003c?php // 업로드한 파일을 바이너리로 읽어서 BASE64로 인코딩\r$ocr_upload_file = $_FILES[\"clova_ocr_upload_file\"];\r$ocr_upload_file_tmp_name = $ocr_upload_file[\"tmp_name\"];\r$ocr_upload_file_binary = fread(fopen($ocr_upload_file_tmp_name, \"r\"), filesize($ocr_upload_file_tmp_name));\r$ocr_upload_file_string = base64_encode($ocr_upload_file_binary);\r// Secret Key\r$ncloud_clova_ocr_secretkey = \"Ijkouhuh89****중간 생략****hvhj\u0026T*^VHJ\u0026T*R^FVHJHJ\"; // API Gateway Invoke URL\r$api_url = \"https://***.apigw.ntruss.com/custom/v1/28410/****중간 생략****/infer\";\r// Template ID\r$ncloud_clova_ocr_template_ids = [28222];\r$unixtimestamp = round(microtime(true) * 1000);\r// http 호출 헤더값 설정\r$http_header = array(); $http_header[0] = \"X-OCR-SECRET: \".$ncloud_clova_ocr_secretkey.\"\";\r$http_header[1] = \"Content-Type:application/json; charset=utf-8\";\r$ocr_request_id = \"ocr-test\".$unixtimestamp;\r// 전송할 값들을 배열 형태로 저장\r$postvars = [\r\"version\"=\u003e \"V2\",\r\"requestId\"=\u003e $ocr_request_id,\r\"timestamp\"=\u003e $unixtimestamp,\r\"lang\"=\u003e \"ko\",\r\"images\"=\u003e [\r[\r\"format\"=\u003e \"jpg\",\r\"name\"=\u003e \"ocr-test\",\r\"data\"=\u003e $clova_ocr_upload_file_string,\r\"url\"=\u003e null,\r\"templateIds\"=\u003e $ncloud_clova_ocr_template_ids\r]\r]\r];\r// 배열 형태로 저장한 값들을 json 형태로 변환\r$json_portvars = json_encode($postvars);\r// api 호출\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_url);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE); curl_setopt($ch, CURLOPT_POST, TRUE);\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\rcurl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\r$json_response = curl_exec($ch);\r$err = curl_error($ch);\r$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\rcurl_close($ch);\rif ($json_response \u0026\u0026 $status_code == \"200\")\r{\r$obj_response_array = json_decode($json_response, true);\r$obj_clova_ocr_data = $obj_response_array[\"images\"][0];\r// 사업자 등록번호\r$business_number = $obj_clova_ocr_data[\"fields\"][0];\r$business_number= $business_number[\"inferText\"];\r//=============== 중간 생략 ================= //\r// 종목\r$business_item = $obj_clova_ocr_data[\"fields\"][5];\r$business_item= $business_item[\"inferText\"];\recho(\"사업자 등록번호:\".$business_number.\"\n\");\recho(\"종목:\".$business_item.\"\n\");\r} else {\r$obj_error_response_array = json_decode($json_response, true);\r}\r?\u003e\r코드 상세 설명 link 우선, 도메인에서 API Gateway 연동 후에 생성된 Secret Key와 Invoke URL을 복사해서 입력하고, Template ID도 설정합니다. \u003c?php // Secret Key\r$ncloud_clova_ocr_secretkey = \"Ijkouhuh89bj89y****중간 생략****j\u0026T*^VHJ\u0026T*R^FVHJHJ\"; // API Gateway Invoke URL\r$api_url = \"https://***.apigw.ntruss.com/custom/v1/*****/****중간 생략****/infer\";\r// Template ID\r$ncloud_clova_ocr_template_ids = [28222];\r?\u003e\r다음으로 http 호출 헤더값으로, 위에서 변수에 저장했던 Secret Key와 Content-Type을 설정합니다. \u003c?php\r// http 호출 헤더값 설정\r$http_header = array(); $http_header[0] = \"X-OCR-SECRET: \".$ncloud_clova_ocr_secretkey.\"\";\r$http_header[1] = \"Content-Type:application/json; charset=utf-8\";\r?\u003e\r다음으로 POST로 전송할 값들을 json 형태로 저장합니다. 파일 URL\r파일 업로드\r\u003c?php\r// 전송할 값들을 배열 형태로 저장\r$postvars = [\r\"version\"=\u003e \"V2\",\r\"requestId\"=\u003e $ocr_request_id,\r\"timestamp\"=\u003e $unixtimestamp,\r\"lang\"=\u003e \"ko\",\r\"images\"=\u003e [\r[\r\"format\"=\u003e \"jpg\",\r\"name\"=\u003e \"ocr-test\",\r\"data\"=\u003e null,\r\"url\"=\u003e \"https://kr.object.ncloudstorage.com/(버킷 이름)/ocr-test.jpg\",\r\"templateIds\"=\u003e $ncloud_clova_ocr_template_ids\r]\r]\r];\r// 배열 형태로 저장한 값들을 json 형태로 변환\r$json_portvars = json_encode($postvars);\r?\u003e\r\u003c?php\r// 업로드한 파일을 바이너리로 읽어서 BASE64로 인코딩\r$ocr_upload_file = $_FILES[\"clova_ocr_upload_file\"];\r$ocr_upload_file_tmp_name = $ocr_upload_file[\"tmp_name\"];\r$ocr_upload_file_binary = fread(fopen($ocr_upload_file_tmp_name, \"r\"), filesize($ocr_upload_file_tmp_name));\r$ocr_upload_file_string = base64_encode($ocr_upload_file_binary);\r// 전송할 값들을 배열 형태로 저장\r$postvars = [\r\"version\"=\u003e \"V2\",\r\"requestId\"=\u003e $ocr_request_id,\r\"timestamp\"=\u003e $unixtimestamp,\r\"lang\"=\u003e \"ko\",\r\"images\"=\u003e [\r[\r\"format\"=\u003e \"jpg\",\r\"name\"=\u003e \"ocr-test\",\r\"data\"=\u003e $ocr_upload_file_string,\r\"url\"=\u003e null,\r\"templateIds\"=\u003e $ncloud_clova_ocr_template_ids\r]\r]\r];\r// 배열 형태로 저장한 값들을 json 형태로 변환\r$json_portvars = json_encode($postvars);\r?\u003e\rversion: “V2\"로 고정\nrequestId: 임의의 값\ntimestamp: UNIX TimeStamp\nlang: 판독할 문서의 언어\nimages: 판독할 문서의 정보\nformat: 문서 포맷 (jpg, jpeg, png, tiff, pdf 등) name: 임의의 값 data: 파일을 업로드할 경우의 파일 데이터, URL을 전송할 경우 이 값은 null로 설정 url: 파일의 url을 전송할 경우에 사용, 파일을 업로드할 경우 이 값은 null로 설정 templateIds: 판독에 사용할 Template 아이디들을 배열 형태로 설정 준비를 모두 마쳤으면 API를 호출합니다.\n\u003c?php\r// api 호출\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_url);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE); curl_setopt($ch, CURLOPT_POST, TRUE);\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\rcurl_setopt($ch,CURLOPT_POSTFIELDS, $json_portvars);\r$json_response = curl_exec($ch);\r$err = curl_error($ch);\r$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\r?\u003e\r마지막으로 API 호출 후 반환된 결과 값을 파싱해서 출력해봅니다. \u003c?php\r$obj_response_array = json_decode($json_response, true);\r$obj_clova_ocr_data = $obj_response_array[\"images\"][0];\r// 사업자 등록번호\r$business_number = $obj_clova_ocr_data[\"fields\"][0];\r$business_number= $business_number[\"inferText\"];\r//=============== 중간 생략 ================= //\r// 종목\r$business_item = $obj_clova_ocr_data[\"fields\"][5];\r$business_item= $business_item[\"inferText\"];\recho(\"사업자 등록번호:\".$business_number.\"\n\");\recho(\"종목:\".$business_item.\"\n\");\r?\u003e\rTemplate을 생성할 때 설정했던 인식 필드에서 [필드 01]은 첫번째 값으로 반환되므로 여기서는 $obj_clova_ocr_data[“fields”][0]에 해당됩니다. 마찬가지로 나머지 필드도 순서대로 가져오면 인식된 값을 확인할 수 있습니다.\n결과 link\r참고 URL link Ncloud CLOVA OCR 기본 가이드\nhttps://guide.ncloud-docs.com/docs/ko/clovaocr-overview\nNcloud CLOVA OCR Templage 생성 가이드\nhttps://guide.ncloud-docs.com/docs/clovaocr-template\n문서 업데이트 내역 link\r날짜 내용 2024-02-19 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  215 ,
                href: "\/docs\/ai-services\/korean-name-romanizer\/php-sample\/",
                title: "Ncloud Korean Name Romanizer 서비스 이용하기 PHP 샘플 예제",
                description: "Ncloud(네이버 클라우드) Papago Korean Name Romanizer 서비스 이용하기 PHP 샘플 예제입니다",
                content: "개요 linkPapago Korean Name Romanizer는 한글로 된 이름을 로마자 표기로 변환해주는 서비스로, 현행 로마자 표기법을 따라 변환한 이름과 통계적으로 많이 사용되는 로마자 이름도 함께 제안 받을 수 있습니다.\nPapago Korean Name Romanizer는 OpenAPI 형태로 제공되며 여기서는 PHP로 호출하는 방식을 살펴볼텐데, 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n이용 요금 linkPapago Korean Name Romanizer는 무료로 제공되는 서비스이며, 일 25,000자, 월 750,000자 내에서 사용 가능하며 상향이 필요한 경우 고객지원으로 문의하면 됩니다.\nAPI 이용 신청 linkPapago Korean Name Romanizer를 이용하기 위해서는 [네이버 클라우드 콘솔] - [AI·NAVER API] - [Application]에서 등록을 해야 합니다.\n아래와 같이 NAVER 서비스에서 Papago Korean Name Romanizer를 선택하고, 이름과 사용할 서비스 환경을 입력하고 등록하면 됩니다.\nPapago Korean Name Romanizer는 웹페이지, 모바일앱 어디서든 사용 가능하며 URL이나 앱 패키지이름, Bundle ID 등을 입력하시면 됩니다.\nApplication 등록을 하고 나면 다음과 같은 화면을 볼 수 있는데 여기서 인증 정보를 확인해야 합니다.\n인증키 확인 linkPapago Korean Name Romanizer API를 호출하려면 Client ID와 Client Secret 로 이루어진 Application Key를 사용해야 하는데 아래와 같이 [인증 정보] 버튼을 클릭하면 확인할 수 있습니다.\nAPI 호출 샘플 코드 link\r\u003c?php\r$korean_name = \"변환할 한글 이름\";\t$client_id = \"Client ID\";\r$client_secret = \"Client Secret\";\r$enc_korean_name = urlencode($korean_name);\r$getvars = \"query=\".$enc_korean_name;\r$api_url = \"https://naveropenapi.apigw.ntruss.com/krdict/v1/romanization?\".$getvars;\r$is_post = false;\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_url);\rcurl_setopt($ch, CURLOPT_POST, $is_post);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\r$headers = array();\r$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\r$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\r$json_response = curl_exec ($ch);\r$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\rcurl_close ($ch);\rif($status_code == 200){\r$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\rif (count($rows_response[\"aResult\"]) \u003e 0){\r$rows_result = $rows_response[\"aResult\"][0];\r$sFirstName = $rows_result[\"sFirstName\"];\r$aItems = $rows_result[\"aItems\"];\r}else{\r$roman_name = \"변환할 수 없는 이름입니다\";\r}\r}else{\r$roman_name = \"Error 내용:\".$json_response;\r}\r?\u003e\r코드 상세 설명 linkApplication Key link\r$client_id = \"Client ID\";\r$client_secret = \"Client Secret\";\r네이버 클라우드 콘솔에서 Papago Korean Name Romanizer 서비스를 등록하고 인증 정보에서 확인한 [Client ID] 와 [Client Secret]를 가져와서 사용하면 됩니다.\n파라미터 설정 link\r$enc_korean_name = urlencode($korean_name);\r$getvars = \"query=\".$enc_korean_name;\r$is_post = false;\r변환할 한글 이름을 urlencode로 인코딩하고, GET 방식으로 호출하면서 넘겨줄 변수에 할당합니다.\nAPI URL link\r$api_url = \"https://naveropenapi.apigw.ntruss.com/krdict/v1/romanization?\".$getvars;\rPapago Korean Name Romanizer의 API URL은 위와 같고, GET 방식으로 호출하므로 url 뒤에 파라미터를 붙여서 전송합니다.\nhttp 호출 헤더값 설정 link\r$headers = array();\r$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\r$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\r위에서 가져온 Application Key를 호출할 API에 헤더값으로 설정해서 호출하게 됩니다.\n결과값 반환 link\r$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\rif (count($rows_response[\"aResult\"]) \u003e 0){\r$rows_result = $rows_response[\"aResult\"][0];\r$sFirstName = $rows_result[\"sFirstName\"];\r$aItems = $rows_result[\"aItems\"];\rforeach ($aItems as $item){\r$roman_name = $item[\"name\"];\r$score = $item[\"score\"];\r}\r}else{\r$roman_name = \"변환할 수 없는 이름입니다\";\r}\rPapago Korean Name Romanizer에서 json형태로 반환된 값을 배열에 담아 사용하면 됩니다.\n반환되는 값은 한글 성과 변환된 로마자 이름과 빈도수가 담긴 배열입니다.\nPapago Korean Name Romanizer에서 변환할 수 없는 이름일 경우 상태코드는 정상이지만 배열에 정보가 없기 때문에 예외처리를 해주어야 합니다.\n사용 한도 및 알람 설정 linkPapago Korean Name Romanizer 서비스는 과도한 사용을 방지하기 위해 일별 25,000자, 월별 750,000자의 제한이 있습니다.\n그리고 지정된 한도 내에서 일정한 사용을 초과하면 알람을 받도록 설정할 수 있습니다.\n아래처럼 Application 등록 화면에서 [한도 및 알람 설정] 버튼을 클릭하면 확인할 수 있습니다.\n참고 URL link Ncloud Korean Name Romanizer 기본 가이드\nhttps://api.ncloud-docs.com/docs/ai-naver-papagokoreannameromanizer 문서 업데이트 내역 link\r날짜 내용 2021-05-24 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  216 ,
                href: "\/docs\/application-services\/nshorturl\/nshorturl-php-sample\/",
                title: "PHP로 nShortURL 서비스 이용하기 샘플 예제",
                description: "Ncloud (네이버 클라우드) 서비스 중에서 길고 복잡한 URL을 간단하고 짧게 바꿔주는 API nShortURL을 PHP로 이용하는 샘플 예제입니다",
                content: "개요 linkSNS를 사용하거나 SMS를 보낼 때 길고 복잡한 URL은 무척 불편하기에 짧게 바꿔주는 서비스들이 인기를 얻었습니다.\n대표적으로 goo.gl, bit.ly 등이 있는데 현재 구글의 goo.gl는 서비스가 종료되었습니다.\n그래서 이를 대신해서 네이버 클라우드에 있는 길고 복잡한 URL을 간단하고 짧게 바꿔주는 API 서비스 nShortURL 서비스를 추천합니다. nShortURL은 OpenAPI 형태로 제공되는데 여기서는 PHP로 호출하는 방식을 살펴볼텐데, 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\n이용 요금 linknShortURL은 무료로 제공되는 서비스이며, 일 25,000건, 월 750,000건 내에서 사용 가능하며 상향이 필요한 경우 고객지원으로 문의하면 됩니다.\nAPI 이용 신청 linknShortURL을 이용하기 위해서는 [네이버 클라우드 콘솔] - [AI·NAVER API] - [Application]에서 등록을 해야 합니다.\n아래와 같이 NAVER 서비스에서 nShortURL을 선택하고, 이름과 사용할 서비스 환경을 입력하고 등록하면 됩니다.\nnShortURL은 웹페이지, 모바일앱 어디서든 사용 가능하며 URL이나 앱 패키지이름, Bundle ID 등을 입력하시면 됩니다.\nApplication 등록을 하고 나면 다음과 같은 화면을 볼 수 있는데 여기서 인증 정보를 확인해야 합니다.\n인증키 확인 linknShortURL API를 호출하려면 Client ID와 Client Secret 로 이루어진 Application Key를 사용해야 하는데 아래와 같이 [인증 정보] 버튼을 클릭하면 확인할 수 있습니다.\nAPI 호출 샘플 코드 link\r\u003c?php\r$long_url = \"변환할 URL\";\t$client_id = \"Client ID\";\r$client_secret = \"Client Secret\";\r$api_url = \"https://naveropenapi.apigw.ntruss.com/util/v1/shorturl\";\r$enc_url = urlencode($long_url);\r$postvars = \"url=\".$enc_url;\t$is_post = true;\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_url);\rcurl_setopt($ch, CURLOPT_POST, $is_post);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\rcurl_setopt($ch, CURLOPT_POSTFIELDS, $postvars);\r$headers = array();\r$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\r$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\r$json_response = curl_exec ($ch);\r$status_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);\rcurl_close ($ch);\rif($status_code == 200) {\r$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\r$rows_result = $rows_response[\"result\"];\r$short_url = $rows_result[\"url\"];\r$hash_val = $rows_result[\"hash\"];\r$org_url = $rows_result[\"orgUrl\"];\r} else {\r$short_url = \"Error 내용:\".$json_response;\r}\r?\u003e\r코드 상세 설명 linkApplication Key link\r$client_id = \"Client ID\";\r$client_secret = \"Client Secret\";\r네이버 클라우드 콘솔에서 nShortURL 서비스를 등록하고 인증 정보에서 확인한 [Client ID] 와 [Client Secret]를 가져와서 사용하면 됩니다.\nAPI URL link\r$api_url = \"https://naveropenapi.apigw.ntruss.com/util/v1/shorturl\";\rnShortURL의 API URL은 위와 같습니다.\n파라미터 설정 link\r$enc_url = urlencode($long_url);\r$postvars = \"url=\".$enc_url;\t$is_post = true;\r변환할 URL을 urlencode로 인코딩하고, POST 방식으로 호출하면서 넘겨줄 변수에 할당합니다.\nhttp 호출 헤더값 설정 link\r$headers = array();\r$headers[] = \"X-NCP-APIGW-API-KEY-ID: \".$client_id;\r$headers[] = \"X-NCP-APIGW-API-KEY: \".$client_secret;\r위에서 가져온 Application Key를 호출할 API에 헤더값으로 설정해서 호출하게 됩니다.\n결과값 반환 link\r$rows_response = json_decode($json_response, JSON_OBJECT_AS_ARRAY);\r$rows_result = $rows_response[\"result\"];\r$short_url = $rows_result[\"url\"];\r$hash_val = $rows_result[\"hash\"];\r$org_url = $rows_result[\"orgUrl\"];\rnShortURL에서 json형태로 반환된 값을 배열에 담아 사용하면 됩니다.\n반환되는 값은 짧게 변환된 URL와 해시값, 그리고 원본 URL입니다.\n사용 한도 및 알람 설정 linknShortURL 서비스는 과도한 사용을 방지하기 위해 일별 25,000회, 월별 750,000회의 제한이 있습니다.\n그리고 지정된 한도 내에서 일정한 사용을 초과하면 알람을 받도록 설정할 수 있습니다.\n아래처럼 Application 등록 화면에서 [한도 및 알람 설정] 버튼을 클릭하면 확인할 수 있습니다.\n참고 URL link Ncloud nShortURL API 가이드\nhttps://api.ncloud-docs.com/docs/ai-naver-nshorturl 문서 업데이트 내역 link\r날짜 내용 2021-04-30 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  217 ,
                href: "\/docs\/application-services\/cloud-outbound-mailer\/bulk-mail-send-guide\/",
                title: "Ncloud Cloud Outbound Mailer로 대량 메일 발송하는 방법",
                description: "Ncloud(네이버 클라우드) Cloud Outbound Mailer로 대량 메일 발송하는 방법입니다",
                content: "개요 link네이버 클라우드 서비스 중에서 각 종 공지나 이벤트, 마케팅으로 회원들에게 대량의 메일을 발송해야 할 때 사용할 수 있는 것이 Cloud Outbound Mailer 입니다.\n대량 메일을 발송하는 방법은 여러가지 있지만, 그 중에서도 가장 자주, 간편하게 사용하는 것이 Excel 등의 파일을 업로드 해서 발송하는 방법입니다.\n이용 신청 linkCloud Outbound Mailer는 먼저 이용신청을 하셔야 합니다. [Console] - [Cloud Outbound Mailer] - [Mailing list] 에서 [이용 신청] 버튼을 클릭하시면 됩니다.\n다음으로 서비스 이용약관에 동의하시면 됩니다.\n도메인 인증 link\rreport\r도메인 인증: Gmail에서는 2024년 2월부터 새로운 이메일 발신자 가이드라인을 적용하면서 도메인 인증을 받지 않은 경우 메일이 스팸처리되거나 제대로 전송되지 않을 수 있다고 공지하고 있습니다. 그래서 Ncloud에서도 도메인 인증을 받아야만 Gmail로 메일 발송할 수 있도록 하고 있습니다. 그러므로 메일 발송 전에 도메인 인증을 받는 것을 권장합니다.\n⁃ "
            }
        );
    index.add(
            {
                id:  218 ,
                href: "\/docs\/application-services\/cloud-outbound-mailer\/domain-authentication-guide\/",
                title: "Ncloud Cloud Outbound Mailer 도메인 인증 방법 3가지(SPF, DKIM, DMARC) 안내",
                description: "Ncloud (네이버 클라우드) Cloud Outbound Mailer에서 도메인을 인증하는 방법 3가지(SPF, DKIM, DMARC)에 대한 안내입니다",
                content: "개요 linkNcloud (네이버 클라우드) Cloud Outbound Mailer를 사용할 때 도메인을 등록하고 SPF(Sender Policy Framework), DKIM(DomainKeys Identified Mail), DMARC(Domain-based Message Authentication, Reporting, and Conformance) 인증을 받으면 발신자 자격을 입증할 수 있고 타인이 도메인을 사칭해 메일을 발송하는 것을 막을 수 있습니다.\n또한, 인증된 도메인임을 증명함으로써 수신측 메일 서비스에서 차단되거나 스팸 처리될 가능성도 매우 낮아지는 이점이 있으므로 가능하면 도메인 인증을 하는 것이 좋습니다.\nreport\rGmail 공지: 특히 Gmail에서는 2024년 2월부터 새로운 이메일 발신자 가이드라인을 적용하면서 도메인 인증을 받지 않은 경우 메일이 스팸처리되거나 제대로 전송되지 않을 수 있다고 공지하고 있습니다. ⁃ https://support.google.com/a/answer/81126?sjid=17985022532965146045-AP\n도메인 인증 종류 link SPF(Sender Policy Framework) 인증: 메일 발신자 정보가 DNS에 등록된 메일 서버 정보와 일치하는지 확인하여 발신자 위조 여부를 확인합니다. DKIM(DomainKeys Identified Mail) 인증: 메일 헤더에 디지털 서명을 추가하여 메일의 위변조 여부를 확인합니다. DMARC(Domain-based Message Authentication, Reporting, and Conformance) 인증: SPF 및 DKIM과 함께 작동하여 메일 발신자를 인증하면서, SPF 및 DKIM 인증에 실패한 도메인의 발신 메일을 어떻게 처리할지 설정할 수 있습니다. 위 3가지 인증을 모두 적용해야 메일이 문제 없이 도착할 수 있습니다.\r도메인 등록 link[Cloud Outbound Mailer] - [Domain Management]에서 [도메인 등록] 버튼을 클릭합니다.\n이미 도메인이 등록되어 있다면 다음 단계로 이동합니다.\n등록 절차 link 이메일 발송 주소로 사용할 도메인을 입력 후, 인증 토큰 생성 버튼을 클릭합니다. 인증 토큰이 생성되면 [복사하기] 버튼을 클릭하여 인증 토큰 정보를 복사합니다. [등록] 버튼을 클릭하여 도메인 등록을 완료합니다. 복사한 인증 토큰을 등록하신 도메인 DNS의 TXT 레코드에 추가합니다. Domain Management 메뉴에서 등록된 도메인 선택 후, [인증] 버튼을 클릭합니다. DNS 변경의 적용에는 시간이 소요될 수 있습니다. 정상적으로 TXT 레코드 등록을 완료했으나 인증이 되지 않는 경우 잠시 후 다시 [인증] 버튼을 클릭해 주세요. 인증 대기 link등록을 완료하면 아래와 같이 미인증 상태로 인증대기 중인 화면을 확인할 수 있습니다.\n인증 토큰 적용 link해당 도메인을 등록한 DNS 서비스 업체에서 [인증 토큰]을 등록하면 되는데, 여기서는 Ncloud의 DNS 서비스인 [Global DNS]에서 아래와 같이 등록했습니다.\n인증 확인 linkDNS 서비스에 [인증 토큰]을 등록하고 잠시 기다렸다가 [도메인 인증 토큰] 항목에 있는 [인증] 버튼을 클릭하면 아래와 같이 [인증 일시] 시각을 확인할 수 있습니다.\n인증에 실패했다는 메시지가 나타날 경우 조금 더 기다렸다가 다시 [인증] 버튼을 클릭해보고, 그래도 인증에 실패하면 DNS에 [인증 토큰]이 제대로 등록되었는지 확인해보시기 바랍니다.\nSPF 인증 link도메인 인증이 끝났으면 다음으로 [SPF] 인증을 해보겠습니다.\nSPF(Sender Policy Framework) 인증은 메일 발신자 정보가 DNS에 등록된 메일 서버 정보와 일치하는지 확인하여 발신자 위조 여부를 확인하기 위한 인증입니다.\n우선 [SPF 레코드] 항목에 있는 [보기] 버튼을 클릭합니다. 인증 레코드 확인 link팝업에 나타난 인증 레코드를 복사합니다.\nv=spf1 include:email.ncloud.com ~all\rDNS 레코드 등록 link위에서 복사한 인증 레코드를 DNS에 등록합니다. 이때 기존에 등록된 SPF 레코드가 존재할 경우에는 기존 레코드 문자열에 포함해서 등록해야 합니다.\n# 신규 등록일 경우\rv=spf1 include:email.ncloud.com ~all\r# 다른 SPF 레코드가 존재할 경우 예시\rv=spf1 ip4:123.123.123.123 include:email.ncloud.com ~all\r신규 등록일 경우\r다른 SPF 레코드가 존재할 경우\r인증 확인 link인증 레코드를 등록하고 잠시 기다렸다가 [SPF 레코드] 항목에 있는 [인증] 버튼을 클릭하면 아래와 같이 [인증 일시] 시각을 확인할 수 있습니다.\n인증에 실패했다는 메시지가 나타날 경우 조금 더 기다렸다가 다시 [인증] 버튼을 클릭해보고, 그래도 인증에 실패하면 DNS에 [인증 레코드]가 제대로 등록되었는지 확인해보시기 바랍니다.\n인증 사용 link인증이 완료되었으면, 향후 [Cloud Outbound Mailer]에서 메일을 발송할 때 [SPF 인증]이 적용되도록 [사용]하기를 설정해야 합니다. 아래 스샷처럼 [SPF 레코드] 항목에 있는 [사용] 버튼을 클릭합니다.\n[SPF 인증] 사용하기가 설정되면 아래와 같이 [사용 중] 상태로 바뀌면서 [사용 중지] 버튼이 활성화 됩니다. DKIM 인증 link다음으로 [DKIM] 인증을 해보겠습니다.\nDKIM(DomainKeys Identified Mail) 인증은 메일 헤더에 디지털 서명을 추가하여 메일의 위변조 여부를 확인하기 위한 인증입니다.\n우선 [DKIM] 서명키를 확인하기 위해 [DKIM 레코드] 항목에 있는 [보기] 버튼을 클릭합니다. 서명 키 확인 link아래와 같이 팝업에 나타난 [DKIM] 서명키를 복사해서 DNS에 등록합니다.\nDNS에 등록할 때 TXT 레코드의 호스트명은 반드시 mailer._domainkey를 사용해야 합니다.\rTXT 레코드는 255자의 길이 제한이 있는데, Ncloud에서 제공하는 DKIM 서명키는 255자를 넘기 때문에 분할하여, multi-line으로 등록하셔야 합니다. Ncloud Global DNS를 사용할 경우에는 분할할 필요 없이 그대로 등록하면 자동으로 분할 등록되므로 편리합니다. DNS 설정에서 255자 이상의 TXT 레코드 등록하는 방법: https://docs.3rdeyesys.com/docs/networking/dns/global-dns-configure-long-txt-record/ DNS 등록 link아래와 같이 호스트명을 mailer._domainkey로 입력하고, [DKIM] 서명키를 등록했습니다.\n인증 사용 link인증이 완료되었으면, 향후 [Cloud Outbound Mailer]에서 메일을 발송할 때 [DKIM 인증]이 적용되도록 [사용]하기를 설정해야 합니다. 아래 스샷처럼 [DKIM] 항목에 있는 [사용] 버튼을 클릭합니다.\n[DKIM 인증] 사용하기가 설정되면 아래와 같이 [사용 중] 상태로 바뀌면서 [사용 중지] 버튼이 활성화 됩니다. DMARC 인증 link[DMARC] 인증은 다른 인증과 달리 레코드 값을 직접 설정해서 등록해야 합니다. 자세한 방법은 아래쪽에서 확인해보겠습니다.\nDMARC 레코드 값 준비 link DMARC 레코드 이름, 즉 호스트명은 반드시 _dmarc를 입력해야 합니다. DMARC 레코드의 값은 아래와 같은 형식으로 구성됩니다.\n예시: v=DMARC1; p=none; aspf=r; adkim=r; rua=mailto:report@example.com 항목\r입력 값 및 설명\r필수 여부 v\r버전을 의미\nDMARC1으로 입력\r필수 p\r수신 서버에서 DMARC로 인증되지 않은 메일에 대한 처리 방법\n- none: 조치하지 않고 메일 수신\n- quarantine: 스팸 메일함으로 수신\n- reject: 수신을 차단하고 반송 처리\r필수 sp\r하위 도메인에서 전송된 메일에 대한 정책\n- none: 조치하지 않고 메일 수신\n- quarantine: 스팸 메일함으로 수신\n- reject: 수신을 차단하고 반송 처리\r필수 아님 aspf\r메일 정보와 spf 서명의 문자열 일치 여부 설정\n- s: 모든 부분 일치\n- r: (기본값) 부분 일치를 허용 (서브 도메인 허용)\r필수 아님 adkim\r메일 정보와 dkim 서명의 문자열 일치 여부 설정\n- s: 모든 부분 일치\n- r: (기본값) 부분 일치를 허용 (서브 도메인 허용)\r필수 아님 rua\r해당 도메인의 DMARC 처리 보고서를 수신할 이메일 주소\n- 메일 주소 앞에 mailto: 입력\n- 쉼표(,)를 연결하여 여러 이메일 주소 지정 가능\r필수 아님 DNS 등록 link아래와 같이 호스트명을 _dmarc로 입력하고, [DMARC] 레코드를 등록했습니다.\n인증 확인 link인증 레코드를 등록하고 잠시 기다렸다가 [DMARC 인증] 항목에 있는 [인증 일시] 시각이 나타나는 것을 확인할 수 있습니다.\n도메인 인증 결과 테스트 link실제로 Gmail로 메일을 발송한 후 인증 결과를 테스트 해보겠습니다.\nGmail 계정쪽으로 메일을 발송한 후 Gmail에 접속해서 도착한 메일을 선택하고 오른쪽 끝에 있는 [ ] 아이콘을 클릭하면 나타나는 메뉴에서 [원본 보기]를 선택합니다.\n인증 PASS link메일의 [원본 보기]를 확인해보면 아래와 같이 [SPF], [DKIM], [DMARC] 3가지 인증 모두 PASS 즉, 인증이 정상적으로 완료되었다는 것을 알 수 있습니다.\n참고 URL link Ncloud Cloud Outbound Mailer 가이드\nhttps://guide.ncloud-docs.com/docs/email-email-1-1\nNcloud Cloud Outbound Mailer 도메인 인증 가이드\nhttps://guide.ncloud-docs.com/docs/cloudoutboundmailer-use-domain\n문서 업데이트 내역 link\r날짜 내용 2024-01-26 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  219 ,
                href: "\/docs\/developer-tools\/sourcecommit\/external-repository-copy-get\/",
                title: "Ncloud SourceCommit에서 GitHub Repository 복사해오기",
                description: "Ncloud(네이버 클라우드) SourceCommit에서 외부 리포지토리 복사하기 기능으로 GitHub Repository 복사해오는 방법입니다",
                content: "개요 linkNcloud SourceCommit에서 GitHub Repository를 복사해서 가져오기 위해서는 [외부 리포지토리 복사] 기능을 이용해야 하는데, Public Repository는 간단하게 가져올 수 있지만, Private Repository는 GitHub에서 생성한 별도의 Personal access token을 사용해야 가져올 수 있어서 그 내용을 정리해보겠습니다.\n외부 리포지토리 복사 linkSourceCommit에서 [외부 리포지토리 복사] 버튼을 클릭합니다.\nPublic Repository link퍼블릭 리포지토리는 아래와 같이 [복사할 Git URL] 정보를 입력한 후에 [Git 연결 확인] 버튼을 클릭해서 올바른 리포지토리인지 확인 후 [다음] 버튼을 클릭해 이후 과정을 진행하면 완료됩니다.\nPrivate Repository link프라이빗 리포지토리는 [프라이빗 리포지토리 여부] 옵션을 켜고 [ID]와 [Password]를 입력해야 복사해 올 수 있습니다.\nPassword 오류 link깃허브 계정과 패스워드를 입력하고 [Git 연결 확인] 버튼을 클릭해 보면 ID 또는 Password가 올바르지 않다는 메시지가 나타납니다.\n올바르게 입력했음에도 이런 오류가 발생하는 것은 2021년 8월부터 외부에서 깃허브에 연결하려고 할 때 계정 패스워드를 사용하지 않고 토큰을 사용하는 방식으로 바뀌었기 때문입니다.\n깃허브 공지 내용을 보면 다음과 같습니다.\nFrom GitHub Blog “In July 2020, we announced our intent to require the use of token-based authentication (for example, a personal access, OAuth, or GitHub App installation token) for all authenticated Git operations. Beginning August 13, 2021, we will no longer accept account passwords when authenticating Git operations on GitHub.com.\rPersonal Access Token 생성 link그러면 이제 Personal access token을 생성해보겠습니다.\n깃허브 사이트에 접속해서 [계정] - [Settings]를 클릭합니다.\n[Settings] 화면 아래쪽에 [Developer settings] 메뉴를 클릭합니다.\n[Developer settings] 화면에서 [Personal access tokens] 메뉴를 클릭하고, [Generate new token] 버튼을 클릭합니다.\nToken 생성 link우선 Personal access token 생성 화면에서 토큰 이름을 입력하고, 만료기간을 설정합니다.\n그리고, 토큰으로 이용 가능한 기능의 범위 즉, 권한 설정을 해야 하는데 단순히 리포지토리를 복사하는 용도라면 [repo] 그룹 항목만 체크하셔도 됩니다.\n설정을 마친 후에 아래쪽에 있는 [Generate token] 버튼을 클릭합니다.\nToken 복사 link생성된 Personal access toke을 복사합니다.\n{% include warning.html title=“주의” content=“생성된 Token은 바로 복사해 두셔야 합니다. 이 화면을 벗어나면 두번 다시 토큰 문자열을 확인할 수 없습니다.\nMake sure to copy your personal access token now. You won’t be able to see it again!” %}\nPersonal Access Token 입력 link[Password] 항목에 Personal Access Token을 입력하고, [Git 연결 확인] 버튼을 클릭하면 문제없이 연결되는 것을 확인할 수 있습니다.\n보안상품 연동 link리포지토리에 악성코드 필터링 보안 시스템인 [File Safer]를 연동하고 싶은 경우 [File Safer 이용 신청] 링크를 클릭해 먼저 이용신청을 하시면 됩니다.\n최종 확인 link입력한 정보들이 이상이 없는지 최종 확인을 하고 [생성] 버튼을 클릭합니다.\nRepository 확인 link생성된 리포지토리를 이렇게 확인할 수 있고, 리포지토리 이름을 클릭하면 리포지토리 내용을 확인할 수 있습니다.\n아래와 같이 깃허브에서 복사된 내용을 확인할 수 있습니다.\nPersonal Access Token 분실 linkPersonal Access Token이 기억나지 않거나 분실했을 경우에는 다음과 같은 방법으로 재생성 하시면 됩니다.\n[Settings] - [Developer settings] - [Personal access token] 메뉴에서 토큰 이름을 클릭합니다.\n토큰 수정 메뉴에서 [Regenerate token] 버튼을 클릭합니다.\n혹시 만료 기간을 수정려면 수정한 후에 [Regenerate token] 버튼을 클릭합니다.\n재 생성된 [Personal access token]을 복사합니다. 마찬가지로 이 화면을 벗어나면 두번 다시 확인할 수 없으니 꼭 복사해서 별도로 저장합니다.\n참고 URL link Ncloud SourceCommit 사용 가이드\nhttps://guide.ncloud-docs.com/docs/sourcecommit-overview 문서 업데이트 내역 link\r날짜 내용 2022-04-20 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  220 ,
                href: "\/docs\/developer-tools\/sourcecommit\/git-client-clone-guide\/",
                title: "Ncloud SourceCommit 리포지토리 Git 클라이언트로 로컬PC에 복제하기",
                description: "Ncloud(네이버 클라우드) SourceCommit의 리포지토리를 Git 클라이언트로 접속해 로컬PC에 복제(Clone)하는 방법입니다",
                content: "개요 linkNcloud SourceCommit에서 GitHub Repository를 복사해서 가져오기 위해서는 [외부 리포지토리 복사] 기능을 이용해야 하는데, Public Repository는 간단하게 가져올 수 있지만, Private Repository는 GitHub에서 생성한 별도의 Personal access token을 사용해야 가져올 수 있어서 그 내용을 정리해보겠습니다.\n외부 리포지토리 복사 linkSourceCommit에서 [외부 리포지토리 복사] 버튼을 클릭합니다.\nPublic Repository link퍼블릭 리포지토리는 아래와 같이 [복사할 Git URL] 정보를 입력한 후에 [Git 연결 확인] 버튼을 클릭해서 올바른 리포지토리인지 확인 후 [다음] 버튼을 클릭해 이후 과정을 진행하면 완료됩니다.\nPrivate Repository link프라이빗 리포지토리는 [프라이빗 리포지토리 여부] 옵션을 켜고 [ID]와 [Password]를 입력해야 복사해 올 수 있습니다.\nPassword 오류 link깃허브 계정과 패스워드를 입력하고 [Git 연결 확인] 버튼을 클릭해 보면 ID 또는 Password가 올바르지 않다는 메시지가 나타납니다.\n올바르게 입력했음에도 이런 오류가 발생하는 것은 2021년 8월부터 외부에서 깃허브에 연결하려고 할 때 계정 패스워드를 사용하지 않고 토큰을 사용하는 방식으로 바뀌었기 때문입니다.\n깃허브 공지 내용을 보면 다음과 같습니다.\nFrom GitHub Blog “In July 2020, we announced our intent to require the use of token-based authentication (for example, a personal access, OAuth, or GitHub App installation token) for all authenticated Git operations. Beginning August 13, 2021, we will no longer accept account passwords when authenticating Git operations on GitHub.com.\rPersonal Access Token 생성 link그러면 이제 Personal access token을 생성해보겠습니다.\n깃허브 사이트에 접속해서 [계정] - [Settings]를 클릭합니다.\n[Settings] 화면 아래쪽에 [Developer settings] 메뉴를 클릭합니다.\n[Developer settings] 화면에서 [Personal access tokens] 메뉴를 클릭하고, [Generate new token] 버튼을 클릭합니다.\nToken 생성 link우선 Personal access token 생성 화면에서 토큰 이름을 입력하고, 만료기간을 설정합니다.\n그리고, 토큰으로 이용 가능한 기능의 범위 즉, 권한 설정을 해야 하는데 단순히 리포지토리를 복사하는 용도라면 [repo] 그룹 항목만 체크하셔도 됩니다.\n설정을 마친 후에 아래쪽에 있는 [Generate token] 버튼을 클릭합니다.\nToken 복사 link생성된 Personal access toke을 복사합니다.\nreport\r주의: 생성된 Token은 바로 복사해 두셔야 합니다. 이 화면을 벗어나면 두번 다시 토큰 문자열을 확인할 수 없습니다.\nMake sure to copy your personal access token now. You won’t be able to see it again!\nPersonal Access Token 입력 link[Password] 항목에 Personal Access Token을 입력하고, [Git 연결 확인] 버튼을 클릭하면 문제없이 연결되는 것을 확인할 수 있습니다.\n보안상품 연동 link리포지토리에 악성코드 필터링 보안 시스템인 [File Safer]를 연동하고 싶은 경우 [File Safer 이용 신청] 링크를 클릭해 먼저 이용신청을 하시면 됩니다.\n최종 확인 link입력한 정보들이 이상이 없는지 최종 확인을 하고 [생성] 버튼을 클릭합니다.\nRepository 확인 link생성된 리포지토리를 이렇게 확인할 수 있고, 리포지토리 이름을 클릭하면 리포지토리 내용을 확인할 수 있습니다.\n아래와 같이 깃허브에서 복사된 내용을 확인할 수 있습니다.\nPersonal Access Token 분실 linkPersonal Access Token이 기억나지 않거나 분실했을 경우에는 다음과 같은 방법으로 재생성 하시면 됩니다.\n[Settings] - [Developer settings] - [Personal access token] 메뉴에서 토큰 이름을 클릭합니다.\n토큰 수정 메뉴에서 [Regenerate token] 버튼을 클릭합니다.\n혹시 만료 기간을 수정려면 수정한 후에 [Regenerate token] 버튼을 클릭합니다.\n재 생성된 [Personal access token]을 복사합니다. 마찬가지로 이 화면을 벗어나면 두번 다시 확인할 수 없으니 꼭 복사해서 별도로 저장합니다.\n참고 URL link Ncloud SourceCommit 사용 가이드\nhttps://guide.ncloud-docs.com/docs/sourcecommit-overview 문서 업데이트 내역 link\r날짜 내용 2022-06-02 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  221 ,
                href: "\/docs\/developer-tools\/jenkins\/install-guide-on-rocky-linux\/",
                title: "Ncloud Jenkins 서버 설치 가이드 | Rocky Linux",
                description: "Ncloud (네이버 클라우드) VPC 환경에서 Rocky Linux에 Jenkins 서버를 설치하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드)의 Classic 환경에서는 Jekins 서버 이미지를 제공하고 있지만, VPC 환경에서는 제공하지 않기에 VPC 환경 록키 리눅스(Rocky Linux) 서버에 Jekins 서버를 설치하는 과정을 정리해보겠습니다.\nJenkins란 linkJenkins는 지속적 통합(Continuous Integration, CI)과 지속적 배포(Continuous Delivery, CD)를 위한 대표적인 도구로 빌드, 테스트, 배포 프로세스를 자동화하여 소프트웨어 품질 향상과 개발 생산성 향상에 도움을 주는 도구입니다.\nJenkins 특징 link 지속적 통합을 사용하여 빌드, 테스트, 배포 과정을 자동화하여 개발 생산성을 향상할 수 있습니다. 자동화 테스트를 통하여 소프트웨어 품질을 향상할 수 있습니다. 지속적인 통합을 통해 안정적인 릴리즈를 빠르게 배포할 수 있습니다. 설치 과정 link패키지 저장소 추가 link먼저 Jenkins의 패키지 저장소를 추가합니다.\nwget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo\rGPG 키 추카 link그런 다음 Jenkins GPG 키를 다음과 같이 추가 합니다.\nrpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\r패키지 업데이트 link그리고, 패키지 관련한 보안-버그 수정 사항만 최소한으로 업데이트를 진행합니다.\ndnf -y upgrade-minimal\rJAVA 설치 linkJenkins를 구동하기 위해서 필요한 JAVA 11 버전을 설치합니다.\ndnf -y install java-11-openjdk\rJAVA 버전 선택 link현재 시스템에 설치된 JAVA는 기본 설치 버전인 [java-1.8.0]과 좀 전에 설치한 [java-11] 이렇게 2가지인데, Jenkins는 [java-11] 버전을 사용하므로 다음 명령어로 [java-11] 버전이 기본으로 적용되도록 설정을 변경하겠습니다.\n명령어 입력 후 나타난 선택화면에서 [java-11] 버전에 해당하는 2번을 입력합니다. 그리고, 변경이 제대로 되었는지 java 버전을 확인합니다.\nupdate-alternatives --config java\rjava -version\rJenkins 설치 link모든 준비가 끝났으면 Jenkins를 설치합니다.\ndnf -y install jenkins\rJenkins 서비스 시작 linkJekins 서비스를 시작하고 정상 작동을하고 있는지 다음과 같이 확인합니다.\nsystemctl daemon-reload\rsystemctl enable jenkins\rsystemctl start jenkins\rsystemctl status jenkins\r방화벽 ACG 설정 linkJekins 서버가 사용하는 기본 포트는 8080 입니다. Ncloud 방화벽 ACG에서 8080 포트를 허용해줍니다.\n초기 설정 linkPort 변경 link\rJenkins의 기본 접속 Port는 8080인데 /etc/sysconfig/jenkins 의 JENKINS_PORT= 항목에서 변경 할 수 있습니다.\rvi /etc/sysconfig/jenkins\r초기 패스워드 확인 link설치가 완료 되면 http://{서버 IP주소}:8080 으로 접속하면 아래의 스크린샷처럼 초기 어드민 패스워드를 입력하는 화면이 나타납니다.\n초기 어드민 패스워드는 /var/lib/jenkins/secrets/initialAdminPassword 파일에 기록되어 있습니다.\ncat 명령어로 초기 패스워드를 확인합니다.\ncat /var/lib/jenkins/secrets/initialAdminPassword\r플러그인 설치 link플러그인 설치는 추천 플러그인을 설치하는 옵션과 직접 선택해서 설치하는 옵션이 있습니다. 일단 여기서는 추천 플러그인을 선택하겠습니다.\n추천 플러그인을 선택하면 아래와 같이 설치과정이 나타납니다.\n직접 플러그인을 선택할 경우 아래와 같이 여러 플러그인 중에서 설치하고 싶은 플러그인을 선택할 수 있습니다.\n어드민 계정 정보 입력 link플러그인 설치를 마치면 아래와 같이 어드민 계정 정보를 입력하게 됩니다.\n설치 완료 link필요한 정보를 모두 입력하고 나면 마지막으로 Jekins URL을 확정하고 저장합니다.\n설치가 모두 끝났습니다.\n이제 Jekins에 접속하면 아래와 같은 화면을 확인할 수 있습니다.\n오류 상황 link위 순서대로 설치를 진행했다면 문제 없이 설치가 되겠지만, 혹시나 설치 중에 중요한 과정을 빠뜨렸을 경우 아래아 같이 [Jenkins]를 시작하려고 할 때 오류가 발생하게 됩니다.\nsystemctl start jenkins\rJob for jenkins.service failed because the control process exited with error code.\rSee \"systemctl status jenkins.service\" and \"journalctl -xe\" for details.\r오류 원인 분석 link위 오류 메시지에서 2가지 방법으로 상세한 오류 내용을 확인해보겠습니다.\n우선 첫번째 명령 [systemctl status jenkins.service]으로 확인을 해보았으나 별다른 내용은 나오지 않습니다. systemctl status jenkins.service\r● jenkins.service - Jenkins Continuous Integration Server\rLoaded: loaded (/usr/lib/systemd/system/jenkins.service; enabled; vendor preset: disabled)\rActive: failed (Result: exit-code) since Fri 2023-06-30 17:08:01 KST; 1min 25s ago\rProcess: 6494 ExecStart=/usr/bin/jenkins (code=exited, status=1/FAILURE)\rMain PID: 6494 (code=exited, status=1/FAILURE)\rJun 30 17:08:01 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\rJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Service RestartSec=100ms expired, scheduling restart\rJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Scheduled restart job, restart counter is at 5.\rJun 30 17:08:01 jenkins-test systemd[1]: Stopped Jenkins Continuous Integration Server.\rJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Start request repeated too quickly.\rJun 30 17:08:01 jenkins-test systemd[1]: jenkins.service: Failed with result 'exit-code'.\rJun 30 17:08:01 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\rJun 30 17:08:03 jenkins-test systemd[1]: jenkins.service: Start request repeated too quickly.\rJun 30 17:08:03 jenkins-test systemd[1]: jenkins.service: Failed with result 'exit-code'.\rJun 30 17:08:03 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\r다음으로 [journalctl -xe] 명령을 입력해보니 상당히 긴 로그가 나오는데, 차근차근 살펴보다 보니 원인을 찾을 수 있었는데, 그 부분만 발췌해보면 아래와 같습니다. journalctl -xe\r#------------- 중간 생략 --------------#\r-- Unit jenkins.service has begun starting up.\rJun 30 17:37:41 jenkins-test jenkins[7588]: jenkins: invalid Java version: openjdk version \"1.8.0_352\"\rJun 30 17:37:41 jenkins-test jenkins[7588]: OpenJDK Runtime Environment (build 1.8.0_352-b08)\rJun 30 17:37:41 jenkins-test jenkins[7588]: OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\rJun 30 17:37:41 jenkins-test systemd[1]: jenkins.service: Main process exited, code=exited, status=1/FAILURE\rJun 30 17:37:41 jenkins-test systemd[1]: jenkins.service: Failed with result 'exit-code'.\r-- Subject: Unit failed\r-- Defined-By: systemd\r-- Support: https://lists.freedesktop.org/mailman/listinfo/systemd-devel\r--\r-- The unit jenkins.service has entered the 'failed' state with result 'exit-code'.\rJun 30 17:37:41 jenkins-test systemd[1]: Failed to start Jenkins Continuous Integration Server.\r-- Subject: Unit jenkins.service has failed\r-- Defined-By: systemd\r-- Support: https://lists.freedesktop.org/mailman/listinfo/systemd-devel\r--\r-- Unit jenkins.service has failed.\r--\r-- The result is failed.\r#------------- 중간 생략 --------------#\r오류 로그 중에서 핵심이 되는 부분은 바로 이 문장입니다. jenkins: invalid Java version: openjdk version '1.8.0_352'\r오류 해결 link즉, 오류 원인은 JAVA 버전이었습니다. 현재의 Jenkins는 [java-11] 버전을 사용하는데, [java-11]을 설치하지 않았거나 현재 시스템에 JAVA가 [java-11] 뿐만 아니라 [java-1.8.0] 버전도 함께 설치되어 있는데, [java-1.8.0] 버전이 기본 버전으로 설정된 상태여서 생기는 문제입니다.\n위쪽 설치 단계에서 확인했던 아래 명령으로 JAVA 기본 버전을 [java-11]로 변경해주고 Jenkins를 시작하면 문제가 없습니다.\nJAVA 기본 버전 변경하기 update-alternatives --config java\rjava -version\r참고 URL link Jeins Redhat Packages\nhttps://pkg.jenkins.io/redhat-stable/\nJenkins User Documentation\nhttps://www.jenkins.io/doc/\n문서 업데이트 내역 link\r날짜 내용 2023-07-03 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  222 ,
                href: "\/docs\/developer-tools\/jenkins\/install-guide-on-ubuntu\/",
                title: "Ncloud Jenkins 서버 설치 가이드 | Ubuntu",
                description: "Ncloud (네이버 클라우드) VPC 환경에서 Ubuntu에 Jenkins 서버를 설치하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드)의 Classic 환경에서는 Jekins 서버 이미지를 제공하고 있지만, VPC 환경에서는 제공하지 않기에 VPC 환경 Ubuntu 서버에 Jekins 서버를 설치하는 과정을 정리해보겠습니다.\nJenkins란 linkJenkins는 지속적 통합(Continuous Integration, CI)과 지속적 배포(Continuous Delivery, CD)를 위한 대표적인 도구로 빌드, 테스트, 배포 프로세스를 자동화하여 소프트웨어 품질 향상과 개발 생산성 향상에 도움을 주는 도구입니다.\nJenkins 특징 link 지속적 통합을 사용하여 빌드, 테스트, 배포 과정을 자동화하여 개발 생산성을 향상할 수 있습니다. 자동화 테스트를 통하여 소프트웨어 품질을 향상할 수 있습니다. 지속적인 통합을 통해 안정적인 릴리즈를 빠르게 배포할 수 있습니다. 설치 과정 link루트 인증서 설치 linkJenkins의 저장소 추가시 인증서 에러가 발생할 경우를 대비해 루트 인증서를 설치 합니다.\napt-get -y install ca-certificates\r저장소 키 추가 link이제 Jenkins의 패키지 저장소를 추가 하기 위한 저장소 키를 가져옵니다.\ncurl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io.key \\\r| sudo tee /usr/share/keyrings/jenkins-keyring.asc \u003e /dev/null\r저장소 추가 link그런다음 Jenkins의 패키지 저장소 항목을 추가 합니다.\necho deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \\\rhttps://pkg.jenkins.io/debian-stable binary/ | sudo tee \\\r/etc/apt/sources.list.d/jenkins.list \u003e /dev/null\rJAVA 설치 linkJenkins를 구동하기 위해서는 JAVA가 필요하고, 추가로 fontconfig도 설치합니다.\n※ JAVA의 경우 Jenkins최신버전을 기준으로 8 혹은 11 버전이 필요 합니다.\rapt-get update\rapt-get -y install fontconfig openjdk-11-jre\rJenkins 설치 link모든 준비가 끝났으면 Jenkins를 설치합니다.\napt-get -y install jenkins\rJenkins 서비스 시작 linkJekins 서비스를 시작하고 정상 작동하고 있는지 다음과 같이 확인합니다.\nsystemctl start jenkins\rsystemctl status jenkins\r방화벽 ACG 설정 linkJekins 서버가 사용하는 기본 포트는 8080 입니다. Ncloud 방화벽 ACG에서 8080 포트를 허용해줍니다.\n초기 설정 linkPort 변경 link\rJenkins의 기본 접속 Port는 /etc/default/jenkins 의 HTTP_PORT= 항목에서 변경 할 수 있습니다.\r초기 패스워드 확인 link설치가 완료된 후 http://{서버 IP주소}:8080 으로 접속하면 아래의 스크린샷처럼 초기 어드민 패스워드를 입력하는 화면이 나타납니다.\n초기 어드민 패스워드는 /var/lib/jenkins/secrets/initialAdminPassword 파일에 기록되어 있습니다.\ncat 명령어로 초기 패스워드를 확인합니다.\ncat /var/lib/jenkins/secrets/initialAdminPassword\r플러그인 설치 link플러그인 설치는 추천 플러그인을 설치하는 옵션과 직접 선택해서 설치하는 옵션이 있습니다. 일단 여기서는 추천 플러그인을 선택하겠습니다.\n추천 플러그인을 선택하면 아래와 같이 설치과정이 나타납니다.\n직접 플러그인을 선택할 경우 아래와 같이 여러 플러그인 중에서 설치하고 싶은 플러그인을 선택할 수 있습니다.\n어드민 계정 정보 입력 link플러그인 설치를 마치면 아래와 같이 어드민 계정 정보를 입력하게 됩니다.\n설치 완료 link필요한 정보를 모두 입력하고 나면 마지막으로 Jekins URL을 확정하고 저장합니다.\n설치가 모두 끝났습니다.\n이제 Jekins에 접속하면 아래와 같은 화면을 확인할 수 있습니다.\n참고 URL link Jeins Redhat Packages\nhttps://pkg.jenkins.io/redhat-stable/\nJenkins User Documentation\nhttps://www.jenkins.io/doc/\n문서 업데이트 내역 link\r날짜 내용 2023-07-14 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  223 ,
                href: "\/docs\/developer-tools\/jenkins\/install-guide-on-centos\/",
                title: "Ncloud Jenkins 서버 설치 가이드 | CentOS",
                description: "Ncloud (네이버 클라우드) VPC 환경에서 CentOS에 Jenkins 서버를 설치하는 방법입니다",
                content: "개요 linkNcloud (네이버 클라우드)의 Classic 환경에서는 Jekins 서버 이미지를 제공하고 있지만, VPC 환경에서는 제공하지 않기에 VPC 환경 Ubuntu 서버에 Jekins 서버를 설치하는 과정을 정리해보겠습니다.\nJenkins란 linkJenkins는 지속적 통합(Continuous Integration, CI)과 지속적 배포(Continuous Delivery, CD)를 위한 대표적인 도구로 빌드, 테스트, 배포 프로세스를 자동화하여 소프트웨어 품질 향상과 개발 생산성 향상에 도움을 주는 도구입니다.\nJenkins 특징 link 지속적 통합을 사용하여 빌드, 테스트, 배포 과정을 자동화하여 개발 생산성을 향상할 수 있습니다. 자동화 테스트를 통하여 소프트웨어 품질을 향상할 수 있습니다. 지속적인 통합을 통해 안정적인 릴리즈를 빠르게 배포할 수 있습니다. 설치 과정 link루트 인증서 설치 linkJenkins의 저장소 추가시 인증서 에러가 발생할 경우를 대비해 루트 인증서를 설치 합니다.\napt-get -y install ca-certificates\r저장소 키 추가 link이제 Jenkins의 패키지 저장소를 추가 하기 위한 저장소 키를 가져옵니다.\ncurl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io.key \\\r| sudo tee /usr/share/keyrings/jenkins-keyring.asc \u003e /dev/null\r저장소 추가 link그런다음 Jenkins의 패키지 저장소 항목을 추가 합니다.\necho deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \\\rhttps://pkg.jenkins.io/debian-stable binary/ | sudo tee \\\r/etc/apt/sources.list.d/jenkins.list \u003e /dev/null\rJAVA 설치 linkJenkins를 구동하기 위해서는 JAVA가 필요하고, 추가로 fontconfig도 설치합니다.\n※ JAVA의 경우 Jenkins최신버전을 기준으로 8 혹은 11 버전이 필요 합니다.\rapt-get update\rapt-get -y install fontconfig openjdk-11-jre\rJenkins 설치 link모든 준비가 끝났으면 Jenkins를 설치합니다.\napt-get -y install jenkins\rJenkins 서비스 시작 linkJekins 서비스를 시작하고 정상 작동하고 있는지 다음과 같이 확인합니다.\nsystemctl start jenkins\rsystemctl status jenkins\r방화벽 ACG 설정 linkJekins 서버가 사용하는 기본 포트는 8080 입니다. Ncloud 방화벽 ACG에서 8080 포트를 허용해줍니다.\n초기 설정 linkPort 변경 link\rJenkins의 기본 접속 Port는 /etc/default/jenkins 의 HTTP_PORT= 항목에서 변경 할 수 있습니다.\r초기 패스워드 확인 link설치가 완료된 후 http://{서버 IP주소}:8080 으로 접속하면 아래의 스크린샷처럼 초기 어드민 패스워드를 입력하는 화면이 나타납니다.\n초기 어드민 패스워드는 /var/lib/jenkins/secrets/initialAdminPassword 파일에 기록되어 있습니다.\ncat 명령어로 초기 패스워드를 확인합니다.\ncat /var/lib/jenkins/secrets/initialAdminPassword\r플러그인 설치 link플러그인 설치는 추천 플러그인을 설치하는 옵션과 직접 선택해서 설치하는 옵션이 있습니다. 일단 여기서는 추천 플러그인을 선택하겠습니다.\n추천 플러그인을 선택하면 아래와 같이 설치과정이 나타납니다.\n직접 플러그인을 선택할 경우 아래와 같이 여러 플러그인 중에서 설치하고 싶은 플러그인을 선택할 수 있습니다.\n어드민 계정 정보 입력 link플러그인 설치를 마치면 아래와 같이 어드민 계정 정보를 입력하게 됩니다.\n설치 완료 link필요한 정보를 모두 입력하고 나면 마지막으로 Jekins URL을 확정하고 저장합니다.\n설치가 모두 끝났습니다.\n이제 Jekins에 접속하면 아래와 같은 화면을 확인할 수 있습니다.\n참고 URL link Jeins Redhat Packages\nhttps://pkg.jenkins.io/redhat-stable/\nJenkins User Documentation\nhttps://www.jenkins.io/doc/\n문서 업데이트 내역 link\r날짜 내용 2023-07-08 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  224 ,
                href: "\/docs\/media\/vod-station\/basic-guide\/",
                title: "Ncloud VOD Station 생성 가이드",
                description: "Ncloud (네이버 클라우드) VOD Station 생성 가이드입니다",
                content: "개요 linkNcloud(네이버 클라우드) VOD Station은 저장된 영상을 다양한 디바이스에서 시청할 수 있도록 변환하는 인코딩 기능과 동영상 파일을 패킷타이징하여 네트워크를 효율적으로 사용할 수 있는 스트리밍 기능을 제공하는 VOD 전용 서비스입니다.\n특징 linkVOD Station 서비스의 특징은 다음과 같습니다.\n하나의 서비스로 인코딩과 송출 가능: 여러 가지 VOD 서비스를 고민할 필요 없이 VOD Station 하나로 인코딩과 스트리밍이 가능합니다. 영상의 길이와 해상도에 따른 합리적 과금: 영상의 길이와 코딩 후 변환된 해상도에 따라 요금이 책정되므로 합리적인 비용으로 서비스를 이용할 수 있습니다. 고품질의 안정적인 스트리밍: Progressive Download 방식이 아닌 영상을 패킷타이징하여 송출하는 방식이므로 안정적인 품질로 스트리밍을 제공할 수 있습니다. 간편한 CDN 생성: CDN(Content Delivery Network) 선택 옵션을 통해 VOD 스트리밍 서비스에 최적화된 CDN을 쉽게 생성할 수 있습니다. 서비스 간의 유연한 연동: 인코딩, 보안, 비디오 플레이어와의 연동 등 VOD 서비스에 필요한 유연한 연동을 제공합니다. 제공 기능 linkVOD Station이 제공하는 기능은 다음과 같은 것들이 있습니다.\n인코딩 On-the-fly 패킷타이징 템플릿 인코딩 설정 DRM 썸네일 추출저장 최적의 CDN 생성(선택 옵션) 사전 준비 사항 linkVOD Station을 이용하기 위해서는 반드시 필요한 것이 2가지 있는데 다음과 같습니다.\nObject Storage: 원본 미디어 파일과 변환된 영상 파일을 저장하기 위한 공간 CDN: 영상 배포를 위한 콘텐츠 스트리밍 플랫폼 서비스 위치 linkNcloud Console에서 [VOD Station] 서비스 위치는 아래와 같이 [Media] - [VOD Station]에 있습니다.\nObject Storage Bucket 생성 linkVOD Station을 좀 더 편하게 생성하려면 VOD Station 생성 전에 먼저 Object Storage에 Bucket을 생성하는 것이 좋습니다.\nBucket 생성 link예를 들어 아래와 같이 용도별 Bucket 3개를 생성합니다.\nvod-station-input: 동영상 원본 파일을 저장할 Bucket vod-station-output: 인코딩이 완료된 동영상을 저장할 Bucket vod-station-thumbnail: 동영상에서 추출한 썸네일 이미지를 저장할 Bucket 아래와 같이 Bucket 3개를 생성했습니다. 파일 업로드 linkBucket 생성 후에 [vod-station-input] Bucket에 테스트할 동영상 파일을 업로드 합니다.\n이용 신청 link다음으로 [VOD Station] - [Subscription]에서 이용 신청을 합니다.\n이용 신청이 끝나면 [Category]를 생성하라는 안내 팝업이 나타납니다.\n카테고리 생성 link카테고리 생성 화면은 다음과 같은데 아래쪽에서 차례대로 살펴보겠습니다.\n인코딩 설정 link인코딩 설정 방법은 미리 지정된 템플릿을 이용해서 간편하게 설정할 수도 있고, 원하는 옵션으로 직접 설정할 수도 있는데, 여기서는 [템플릿 간편 설정]으로 진행하겠습니다.\n템플릿 간편 설정\n템플릿 간편 설정에는 [실속형 콘텐츠], [비즈니스 콘텐츠], [초고화질 콘텐츠] 등의 3가지 옵션이 있는데, 아래쪽에서 확인할 수 있습니다. 인코딩 템플릿\n인코딩 템플릿의 상세 옵션을 확인하려면 [템플릿 간편 설정] 옆에 있는 아이콘을 클릭하면 아래와 같이 자세히 확인할 수 있습니다. 직접 설정\n템플릿을 사용하지 않고 상세 옵션을 직접 설정하려면 [설정함] 옵션을 선택하고 [추가] 버튼을 클릭합니다. 상세 옵션\n인코딩 옵션을 직접 설정하는 경우 아래와 같이 17개의 Video 옵션과 4개의 Audio 옵션 중에서 최대 5개를 선택할 수 있습니다. 파일 경로 설정 link가능하면 썸네일은 설정함을 선택하고, [+ 선택] 버튼을 클릭해 아웃풋 파일 경로와 썸네일 아웃풋 파일 경로를 설정하도록 하겠습니다.\n아웃풋 파일 경로 설정\n파일 경로 설정 팝업에서 미리 생성해 둔 [vod-station-output] Bucket을 선택합니다. 썸네일 아웃풋 파일 경로 설정 마찬가지로 썸네일 경로 설정 팝업에서 미리 생성해 둔 [vod-station-thumbnail] Bucket을 선택합니다. 고급 설정 link고급 설정에서는 [재생구간 설정]과 [워터마크 이미지]를 추가할 수 있는데, 서비스 상황에 맞에 선택하시면 되고, 여기서는 설정하지 않고 완료하겠습니다.\n최종 확인 link위에서 설정한 값들을 최종 확인한 후에 이상이 없으면 [생성] 버튼을 클릭합니다.\n파일 인코딩 link이제 생성된 카테고리 리스트에서 [신규파일 인코딩] 버튼을 클릭해 인코딩할 파일을 등록합니다.\n파일 경로 선택\n인풋 파일 경로는 [오브젝트 스토리지]와 별도의 [HTTP 다운로드 URL]을 선택할 수 있는데 여기서는 앞에서 생성한 오브젝트 스토리지를 선택하겠습니다. 파일 선택\n오브젝트 스토리지 버킷에서 앞에서 업로드한 인코딩할 파일을 선택합니다. 인코딩 시작\n선택한 파일이 맞는지 최종 확인하고 이상이 없으면 [확인] 버튼을 클릭합니다. 인코딩 상태 확인 link위에서 선택한 파일의 인코딩 상태 확인은 [VOD Station] - [Status]에서 확인 가능합니다.\n썸네일 파일 확인 link썸네일 파일은 앞에서 생성하고 선택했던 오브젝트 스토리지 [vod-station-thumbnail] 버킷에서 아래와 같이 확인할 수 있습니다.\n채널 생성 link인코딩이 끝났으면, 이제 스트리밍을 위한 채널을 생성해야 합니다.\n[VOD Station] - [Channel]에서 [채널 생성] 버튼을 클릭해 VOD Streaming을 구성하기 위한 새로운 채널을 생성합니다.\n채널 생성 구성 항목 link채널 생성 시에 입력 또는 선택이 필요한 항목들을 차례대로 살펴보겠습니다.\nObject Storage Bucket 선택\nStreaming할 파일의 위치는 위에서 설정했던 인코딩된 파일의 위치인 [vod-station-output] 버킷을 선택합니다.\nObject Storage 비공개 파일 접근\nObject Storage 비공개 파일 접근 설정은 [허용]을 선택하는 것을 추천합니다. VOD Station은 Object Storage 의 “공개 안함” 권한을 가진 파일도 스트리밍할 수 있는 기능을 제공하므로 Object Storage 에 있는 원본 파일의 권한을 “공개” 대신 “공개 안함” 으로 설정함으로써 컨텐츠의 보안 수준을 높일 수 있습니다.\nProtocol\nProtocol은 [HLS], [DASH] 중에서 선택하거나 두 가지 모두 선택할 수 있습니다.\nSegment 설정\nSegment 설정도 서비스 상황에 맞에 선택하시면 됩니다.\nCDN 설정\nVOD Station은 CDN 연동이 필수인 상품으로 [신규 생성]을 선택해 VOD Station에 최적화된 CDN을 자동 생성하거나, 기존 CDN 연동 또는 차후 별도의 CDN을 생성할 수도 있지만, 가급적 [신규 생성] 옵션을 선택하는 것을 추천드립니다. 콘텐츠 보호 설정\nDRM 등의 콘텐츠 보호 설정이 필요할 경우 관련된 설정을 추가할 수 있습니다. 채널 생성 완료\n채널은 생성과 함께 운영상태로 전환되고, 그에 따라 과금이 발생하게 됩니다. 생성된 채널 확인\n채널이 생성되면 아래와 같이 파일리스트와 채널 정보를 확인할 수 있습니다. 자세한 채널 정보는 상단에 있는 [채널 정보] 버튼을 클릭하면 확인할 수 있습니다. 채널 정보 link위에서 확인한 채널 리스트에서 [채널 정보] 버튼을 클릭하면 아래와 같은 채널 정보를 확인할 수 있는데, 이 채널 정보 중에서 중요한 항목은 아래에 표시한 3가지 입니다.\nObject Storage Bucket (암호화명) Protocol CDN 재생경로 재생 경로 URL 확인 linkCDN에 위치한 VOD의 재생 경로 URL은 다음과 같은 요소로 구성되어 있습니다.\ninfo\rURL Template: https://[CDN Domain]/[Protocol]/[EncryptedBucketName]/[Path]/[Video Filename]/[Manifest]\nDomain\rProtocol\rBucketName\rPath\rFileName\rManifest\rexample.cdn.ntruss.com\r~aiEihf7l39******fs890ilkjlkfts_\r/hls\r/example_category\r/example.mp4\r/index.m3u8\r/dash\r/manifest.mpd\rCDN 도메인\r암호화된 Bucket 이름\r스트리밍\n프로토콜\r카테고리 이름으로\n구성된 폴더 경로\r파일명\r스트리밍을 위한\nManifest 파일\rURL 예시 linkChannel에서 확인했던 파일 하나를 선택해서 재생 URL이 어떻게 구성되는지 예시를 들어보겠습니다.\ninfo\r파일명 예시: test-category/VOD-Station_AVC_HD_1Pass_30fps.mp4\ninfo\r재생 경로 URL: test-category/VOD-Station_AVC_HD_1Pass_30fps.mp4\n재생 URL 빠르게 확인하기 link재생 경로 URL이 복잡하게 구성되어 있다보니 직접 작성하기 쉽지 않은데, 이럴 때는 아래와 같은 방법으로 빠르게 확인할 수 있습니다.\n사용하시는 웹브라우저(여기서는 크롬을 사용)에 HLS, DASH 프로토콜 파일을 플레이할 수 있는 기능이 설치되어 있으면 보다 간편하게 확인 가능합니다.\n웹브라우저 확장 프로그램 설치\n혹시 설치되어 있지 않을 경우 크롬 웹스토어 [확장 프로그램]에서 HLS, DASH Player를 아래와 같이 검색해서 설치합니다. CDN 재생경로 URL 생성\n확장 프로그램이 설치되었으면 [VOD Station] - [Channel]에서 파일 리스트 오른쪽에 있는 [HLS URL 생성] 또는 [DASH URL 생성] 버튼을 클릭합니다. CDN 재생경로 URL 확인\n그러면 아래와 같이 웹브라우저에서 해당 파일이 재생되면서 주소창에서 재생 URL을 확인할 수 있습니다. Video Player Enhancement link모든 작업이 완료된 영상을 재생하려면 [Video Player Enhancement] 서비스를 이용하면 되는데 자세한 사용 방법은 아래 가이드 문서에서 확인할 수 있습니다.\n⁃ Video Player Enhancement 사용 가이드\r참고 URL link Ncloud VOD Station 가이드\nhttps://guide.ncloud-docs.com/docs/ko/vodstation-vodstationoverview "
            }
        );
    index.add(
            {
                id:  225 ,
                href: "\/docs\/media\/video-player-enhancement\/basic-guide\/",
                title: "Ncloud Video Player Enhancement 사용 가이드",
                description: "Ncloud (네이버 클라우드) Video Player Enhancement 사용 가이드입니다",
                content: "개요 linkNcloud(네이버 클라우드) [Video Player Enhancement]는 웹/앱에서 비디오 또는 오디오와 같은 미디어 재생을 위한 서비스로, Live Station, VOD Station과 연동을 통해, 다양한 디바이스 환경에서 시청자에게 최고 품질의 경험을 제공합니다.\n특징 linkVideo Player Enhancement 서비스의 특징은 다음과 같습니다.\nLive Station \u0026 VOD Station과 손쉽게 연동 가능 HTML5 표준 : HTML5 표준에 맞게 제작된 SaaS 기반의 서비스로 별도의 APP 설치 없이 모든 디바이스 및 OS Browser에서 재생 가능 사용자가 직접 커스터마이징 : Console 에서 UI \u0026 UX 패널 제공하여 고객이 직접 커스터마이징을 할 수 있음 (유료 버전) 개발 시간 단축 : 스크립트 코드 예제를 통해 플레이어를 웹페이지 내 손쉽게 임베디드가 가능하며 완성된 코드 제공을 통해 개발 시간을 단축 시킬 수 있음 제공 기능 linkVOD Station이 제공하는 기능은 다음과 같은 것들이 있습니다.\n다양한 재생 옵션 설정을 위한 기능 콘텐츠 보안: MultiDRM (FairPlay, Widevine, PlayReady) 및 Visible Watermark 기능 제공 모바일 SDK: Native SDK 제공 (AOS - Kotlin, iOS - Swift) 커스터마이징: 콘솔에 UI/UX 설정을 위한 기능 제공 CMAF LL-HLS 지원 사전 준비 사항 link[Video Player Enhancement]을 테스트 하기 위해 [VOD Station]에 스트리밍 가능한 영상 파일을 미리 등록해 두겠습니다.\n[VOD Station] 사용 방법은 아래 가이드 문서에서 확인할 수 있습니다. ⁃ VOD Station 생성 가이드\r서비스 위치 linkNcloud Console에서 [Video Player Enhancement] 서비스 위치는 아래와 같이 [Media] - [Video Player Enhancement]에 있습니다.\n서비스 신청 link[Video Player Enhancement] 서비스를 사용하기 위해서는 먼저 [서비스 신청] 버튼을 클릭해 서비스를 신청해야 합니다.\n서비스 선택 link[Video Player Enhancement] 서비스는 무료 서비스인 Basic 버전과 유료 서비스인 Standard 버전이 있습니다. 각각이 제공하는 기능이 다르므로 잘 살펴보고 선택하시면 됩니다.\nreport\r주의: 서비스를 유료로 신청 또는 무료에서 유료로 전환 후에는 다시 무료로 전환이 불가합니다.\n서비스 신청이 끝났으면 플레이어를 생성해야 합니다. 플레이어 생성 link플레이어 생성 화면에서는 현재 계약된 정보가 표시되며, 무료인 경우 [유료 전환] 버튼도 확인할 수 있습니다.\n기본 설정 link기본 설정에서는 플레이어를 사용할 [사이트 도메인] 또는 [앱 패키지 ID]를 입력해야 합니다.\n⁃ 사이트 도메인은 플레이어가 노출될 사이트 도메인에 대한 유효성을 확인하기 위함입니다.\n⁃ 등록된 도메인이 아닐 경우 플레이어가 동작하지 않습니다.\n⁃ 사이트 도메인은 5개까지 입력 가능합니다.\n⁃ 5개 이상 입력이 필요할 경우 네이버 클라우드 영업팀에 별도 문의 부탁 드립니다.\r플레이어 옵션 link플레이어가 생성되면 플레이어 옵션 미리보기를 할 수 있습니다.\n미리보기 link미리 보기 화면에서 플레이어의 기본 스크립트를 확인할 수 있는데 [복사] 버튼을 클릭해서 스크립트를 가져옵니다.\n플레이어 스크립트 기본 템플릿 link위에서 복사해 온 플레이어 스크립트는 기본적으로 다음과 같은 형태로 구성되어 있습니다.\n플레이어 샘플 예제 link[VOD Station]에 등록한 스트리밍 파일을 이용한 샘플 스크립트 예제는 다음과 같습니다.\n⁃ VOD Station 생성 가이드\r플레이어 실행 화면 link위 스크립트로 생성한 플레이어를 실행하면 아래와 같이 영상이 플레이 되는 것을 확인할 수 있습니다.\n{% include warning.html title=“음소거 옵션” content=“autostart: true 상태에서 muted 옵션과 관계없이 무조건 음소거 상태로 나타나는 경우가 많은데, 이것은 웹브라우저의 자체 정책으로 인해 영상의 자동재생이 차단되는 것을 막기 위해 음소거 상태로 플레이됩니다. \" %}\n플레이어 상세 옵션 link\r프로퍼티\r유형\r설명\r기본값\r옵션값\r라이선스\r필수여부\r*playlistarray플레이리스트없음무료O\rautostartboolean자동재생여부TRUE무료X\rmutedboolean음소거FALSE무료X\rkeyboardShortcutboolean키보드 단축키TRUE무료X\rcontrolsboolean컨트롤바 사용 여부TRUE무료X\ruistringUI 설정allall, mobile , pc무료X\r**controlBtnarray컨트롤바 버튼 on/off유료X\rprogressBarColorstring컨트롤바 컬러#4299f5유료X\rcontrolActiveTimenumber컨트롤바 활성 시간(ms)3000유료X\rstartMutedInfoNotVisibleboolean음소거 알림FALSE유료X\raspectRatiostring화면비16/916/9 , 4/3 , 1/1 , 9/16 , 21/9무료X\robjectFitstring영상 화면 맞춤containcontain , cover , fill무료X\rplayRateSettingarray배속 선택 옵션[0.5,0.75,1,1.5,2]유료X\rseekingPreviewboolean영상 구간 이동 미리보기TRUE유료X\rautoPauseboolean탭 비활성화 시 자동멈춤FALSE무료X\rrepeatboolean영상 반복FALSE무료X\rtouchGesturesboolean터치 제스처TRUE유료X\rdescriptionNotVisibleboolean영상 메타 데이터FALSE유료X\rlangstringUI 언어설정autoauto , ko , en , ja , zh무료X\rlowLatencyModebooleanCMAF LL-HLSFALSE유료X\r*playlist 상세 속성 link\r프로퍼티\r유형\r설명\r기본값\r옵션값\r라이선스\r필수여부\rfilestring재생하고자 하는 video 정보\rsourcesarray\rvideo에 여러가지 해상도를 제공하는 경우 사용\rfilestring해상도별 video 파일 경로\rlabelstring해상도 조절 컨트롤에 표시되는 텍스트\rdefaultboolean기본 해상도로 적용\rfile로 대체 가능무료X\rposterstringvideo 재생 전 표시할 이미지없음무료X\rdescriptionarray\rPlayer 상단에 표시할 메타데이터\rtitle string제목 표시\rcreated_at string날짜 표시\rprofile_name string채널명 or 업로더 닉네임\rprofile_image string채널이미지 or 업로더 프로필 이미지\rcallback function메타데이터 클릭시 발생시킬 이벤트\r없음유료X **controlBtn 상세 속성 link\r프로퍼티\r유형\r설명\r기본값\rplayboolean플레이버튼TRUE\rfullscreenboolean전체화면 전환TRUE\rvolumeboolean볼륨컨트롤TRUE\rtimesboolean시간정보 UITRUE\rpictureInPictureboolean미니플레이어TRUE\rsettingboolean세팅 버튼TRUE\r통계 link[Player Statistics] 화면에서는 플레이어 사용량 등의 통계를 확인할 수 있습니다.\n참고 URL link Ncloud Video Player Enhancement 개요\nhttps://guide.ncloud-docs.com/docs/videoplayerenhancement-overview\nNcloud Video Player Enhancement 사용 가이드\nhttps://guide.ncloud-docs.com/docs/videoplayerenhancement-user-guide\n문서 업데이트 내역 link\r날짜 내용 2023-03-22 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  226 ,
                href: "\/docs\/api\/ncloud-api-call-php-sample\/",
                title: "PHP로 Ncloud API를 호출하는 샘플 예제",
                description: "PHP로 Ncloud API를 호출하는 샘플 예제",
                content: "개요 link네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 PHP로 호출하는 샘플 예제를 정리해봅니다.\n네이버 클라우드 API는 RESTful API 방식으로 제공되며, XML와 JSON 형식으로 응답합니다 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\nAPI 호출 샘플 코드 link\r\u003c?php\r// 기본 데이터 설정\r$unixtimestamp = round(microtime(true) * 1000);\r$ncp_accesskey = \"네이버 클라우드 AccessKey\";\r$ncp_secretkey = \"네이버 클라우드 SecretKey\";\t$api_server = \"https://billingapi.apigw.ntruss.com\";\r// API URL 예시 : 상품별 가격 리스트 호출 api\r$api_url = \"/billing/v1/product/getProductPriceList\";\r$api_url = $api_url.\"?regionCode=KR\u0026productItemKindCode=VSVR\";\r$apicall_method = \"GET\";\r$space = \" \";\r$new_line = \"\\n\";\r$is_post = false;\r// hmac으로 암호화할 문자열 설정\r$message = $apicall_method\r.$space\r.$api_url\r.$new_line\r.$unixtimestamp\r.$new_line\r.$ncp_accesskey;\t// hmac_sha256 암호화\r$msg_signature = hash_hmac(\"sha256\", $message, $ncp_secretkey, true);\r$msg_signature = base64_encode($msg_signature);\r// http 호출 헤더값 설정\r$http_header = array();\r$http_header[0] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\r$http_header[1] = \"x-ncp-iam-access-key:\".$ncp_accesskey.\"\";\r$http_header[2] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\r// api 호출\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\tcurl_setopt($ch, CURLOPT_POST, $is_post);\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\r$response = curl_exec($ch);\rcurl_close($ch);\r?\u003e\r코드 상세 설명 link유닉스 타임 스탬프 link\r$unixtimestamp = round(microtime(true) * 1000);\r네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요합니다.\nPHP에서 일반적으로 사용하는 time()함수는 10자리 형식이기 때문에 여기서는 microtime()을 사용합니다.\nmicrotime(true)은 float 형식의 값을 리턴하므로 1000을 곱하고 정수로 반올림합니다.\n$val1 = time();\r$val2 = microtime(true);\r$val3 = round(microtime(true) * 1000);\r/*\r$val1 : 1617699570\r$val2 : 1617699570.1146\r$val3 : 1617699570115\r*/\r네이버 클라우드 인증키 link\r$ncp_accesskey = \"네이버 클라우드 AccessKey\";\r$ncp_secretkey = \"네이버 클라우드 SecretKey\";\t네이버 클라우드 인증키는 네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\nhmac으로 암호화할 문자열 설정 link\r$apicall_method = \"GET\";\r$space = \" \";\r$new_line = \"\\n\";\r암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\n$message = $apicall_method\r.$space\r.$api_url\r.$new_line\r.$unixtimestamp\r.$new_line\r.$ncp_accesskey;\t네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\ninfo\rAPI 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\nhmac_sha256 방식으로 암호화 link\r$msg_signature = hash_hmac(\"sha256\", $message, $ncp_secretkey, true));\r$msg_signature = base64_encode($msg_signature);\rhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 $message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\nhttp 호출 헤더값 설정 link\r$http_header = array();\r$http_header[0] = \"x-ncp-apigw-timestamp:\".$unixtimestamp.\"\";\r$http_header[1] = \"x-ncp-iam-access-key:\".$ncp_accesskey.\"\";\r$http_header[2] = \"x-ncp-apigw-signature-v2:\".$msg_signature.\"\";\rAPI를 호출할 때는 http 헤더값에 다음 3가지를 추가해서 호출합니다.\n유닉스 타임스탬프 네이버 클라우드 API AccessKey hmac_256 으로 암호화한 문자열 여기서 전송하는 타임스탬프는 위에서 $message를 암호화할 때 사용한 타임스탬프와 동일한 값이어야 합니다.\napi 호출 link\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_server.$api_url);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\tcurl_setopt($ch, CURLOPT_POST, $is_post);\rcurl_setopt($ch, CURLOPT_HTTPHEADER, $http_header);\r$response = curl_exec($ch);\r이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\n리턴값은 호출하는 용도별로 json 또는 xml 형태로 반환됩니다.\n응답 예시 link\r\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\r9a6b9f7c-f688-4cec-841f-634d355cef1e\r0\rsuccess\r2\rVSVR\rServer (VPC)\rBM\rBareMetal\r''' 중략 '''\rBM\rBareMetal\rBM\rBareMetal\r0\r24\r137438953472\r4123168604160\rLOCAL\rLocal storage\rSSD\rSSD\rG1 ''' 중략 '''\r참고 URL link Ncloud API 가이드\nhttps://api.ncloud-docs.com/docs/ko/home/ 문서 업데이트 내역 link\r날짜 내용 2021-04-06 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  227 ,
                href: "\/docs\/api\/ncloud-api-call-csharp-sample\/",
                title: "C#으로 Ncloud API를 호출하는 샘플 예제",
                description: "C#으로 Ncloud API를 호출하는 샘플 예제",
                content: "개요 link네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 C#으로 호출하는 샘플 예제중에서 핵심인 인증을 위한 암호화 문자열 생성 코드를 정리해보겠습니다.\n암호화 샘플 코드 link\rpublic string unixTimeStamp;\rpublic string ncpAccessKey = \"네이버 클라우드 AccessKey\";\rpublic string ncpSecretKey = \"네이버 클라우드 SecretKey\";\tpublic string apiCallMethod = \"GET\";\rpublic string apiServer = \"https://billingapi.apigw.ntruss.com\";\rpublic string apiUrl = \"네이버 클라우드 API URL\";\rpublic string MakeSignature()\r{\rstring msgSignature;\rstring space = \" \";\rstring newLine = \"\\n\";\r// 13자리 유닉스 타임스탬프 설정\rDateTime now = DateTime.Now;\rDateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0);\rdouble totalMilliSeconds = now.Subtract(unixOriginalTime).TotalMilliseconds;\runixTimeStamp = Math.Round(totalMilliSeconds).ToString();\r// hmac으로 암호화할 문자열 설정\rstring message = new StringBuilder()\r.Append(apiCallMethod)\r.Append(space)\r.Append(apiUrl)\r.Append(newLine)\r.Append(unixTimeStamp)\r.Append(newLine)\r.Append(ncpAccessKey)\r.ToString();\r// hmac_sha256 암호화\rbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\rbyte[] bytes = Encoding.UTF8.GetBytes(message);\rusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\r{\rbyte[] hash = sha256.ComputeHash(bytes);\rmsgSignature = Convert.ToBase64String(hash);\r}\rreturn msgSignature;\r}\r코드 상세 설명 link네이버 클라우드 인증키 link\rpublic string ncpAccessKey = \"네이버 클라우드 AccessKey\";\rpublic string ncpSecretKey = \"네이버 클라우드 SecretKey\";\t네이버 클라우드 인증키는 네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\n유닉스 타임스탬프 link\rDateTime now = DateTime.Now;\rDateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0);\rdouble totalMilliSeconds = now.Subtract(unixOriginalTime).TotalMilliseconds;\runixTimeStamp = Math.Round(totalMilliSeconds).ToString();\r네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요하므로 TotalMilliseconds 값을 가져와서 소수점 아래는 반올림해서 정수값만 취합니다.\n여기서 전달하는 타임스탬프값이 네이버 클라우드 API Gateway의 시간과 5분 이상 차이가 나면 인증 실패가 됩니다.\n그런데 API Gateway는 UTC 기준으로 설정되어 있기 때문에 C#으로 만든 애플리케이션을 로컬PC등의 UTC+9 시간으로 설정된 곳에서 1970년 1월 1일 00시 기준으로 계산하면 9시간의 시간차가 발생해 인증이 실패하게 됩니다.\n정리하면 다음과 같습니다.\nAPI Gateway 타임스탬프 : UTC 현재시간 - 1970년 1월 1일 00시 로컬PC 타임스탬프 : UTC+9 현재시간 - 1970년 1월 1일 09시 즉, 로컬PC 등은 API Gateway보다 9시간 빠르기 때문에 동일한 타임스탬프 값을 얻으려면 1970년 1월 1일 09시 기준으로 계산해야 한다는 것입니다. 그래서 위의 코드에서 DateTime unixOriginalTime = new DateTime(1970, 1, 1, 9, 0, 0); 이렇게 적용했습니다.\rhmac으로 암호화할 문자열 설정 link\rpublic string apiCallMethod = \"GET\";\rstring space = \" \";\rstring newLine = \"\\n\";\r암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\nstring message = new StringBuilder()\r.Append(apiCallMethod)\r.Append(space)\r.Append(apiUrl)\r.Append(newLine)\r.Append(unixTimeStamp)\r.Append(newLine)\r.Append(ncpAccessKey)\r.ToString();\r네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\ninfo\rAPI 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\nhmac_sha256 방식으로 암호화 link\rbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\rbyte[] bytes = Encoding.UTF8.GetBytes(message);\rusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\r{\rbyte[] hash = sha256.ComputeHash(bytes);\rmsgSignature = Convert.ToBase64String(hash);\r}\rhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\n응답 예시 link\r\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\r9a6b9f7c-f688-4cec-841f-634d355cef1e\r0\rsuccess\r2\rVSVR\rServer (VPC)\rBM\rBareMetal\r''' 중략 '''\rBM\rBareMetal\rBM\rBareMetal\r0\r24\r137438953472\r4123168604160\rLOCAL\rLocal storage\rSSD\rSSD\rG1 ''' 중략 '''\r참고 URL link Ncloud API 가이드\nhttps://api.ncloud-docs.com/docs/ko/home/ 문서 업데이트 내역 link\r날짜 내용 2021-04-07 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  228 ,
                href: "\/docs\/api\/ncloud-api-call-python-sample\/",
                title: "Python으로 Ncloud API를 호출하는 샘플 예제",
                description: "Python으로 Ncloud API를 호출하는 샘플 예제",
                content: "개요 linkNcloud (네이버 클라우드) 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 Python으로 호출하는 샘플 예제를 정리해봅니다.\nNcloud API는 RESTful API 방식으로 제공되며, XML와 JSON 형식으로 응답합니다 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\nAPI 호출 샘플 코드 link\rimport sys\rimport os\rimport hashlib\rimport hmac\rimport base64\rimport requests\rimport time\r# unix timestamp 설정\rtimestamp = int(time.time() * 1000)\rtimestamp = str(timestamp)\r# Ncloud API Key 설정\rncloud_accesskey = \"네이버 클라우드 AccessKey\"\rncloud_secretkey = \"네이버 클라우드 SecretKey\"\r# 암호화 문자열 생성을 위한 기본값 설정\rapicall_method = \"GET\"\rspace = \" \"\rnew_line = \"\\n\"\r# API 서버 정보\rapi_server = \"https://billingapi.apigw.ntruss.com\"\r# API URL 예시 : 상품별 가격 리스트 호출 api\rapi_url = \"/billing/v1/product/getProductPriceList\"\rapi_url = api_url +\"?regionCode=KR\u0026productCode=SPCF000000000001\u0026responseFormatType=json\"\r# hmac으로 암호화할 문자열 생성\rmessage = apicall_method + space + api_url + new_line + timestamp + new_line + ncloud_accesskey\rmessage = bytes(message, 'UTF-8')\r# hmac_sha256 암호화\rncloud_secretkey = bytes(ncloud_secretkey, 'UTF-8')\rsigningKey = base64.b64encode(hmac.new(ncloud_secretkey, message, digestmod=hashlib.sha256).digest())\r# http 호출 헤더값 설정\rhttp_header = {\r'x-ncp-apigw-timestamp': timestamp,\r'x-ncp-iam-access-key': ncloud_accesskey,\r'x-ncp-apigw-signature-v2': signingKey\r}\r# api 호출\rresponse = requests.get(api_server + api_url, headers=http_header)\rprint (response.text)\r코드 상세 설명 link유닉스 타임 스탬프 linkNcloud API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요합니다.\ntime.time()은 float 형식의 값을 리턴하므로 1000을 곱하고 정수로 반올림하고, 문자열로 변환합니다.\ntimestamp = int(time.time() * 1000)\rtimestamp = str(timestamp)\rNcloud API 인증키 설정 link\rncloud_accesskey = \"네이버 클라우드 AccessKey\"\rncloud_secretkey = \"네이버 클라우드 SecretKey\"\rNcloud API 인증키는 Ncloud 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\nwarning\r발급된 API 인증키는 사용중지/삭제가 가능하므로, 사용하지않는 API 인증키는 사용중지 또는 삭제하는것을 권장합니다.\nhmac으로 암호화할 문자열 설정 link암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\nAPI 호출 방식은 GET과 POST 둘 다 가능한데, 일반적으로 많이 사용되는 GET 방식으로 소개하고, POST 방식은 아래쪽에 코드만 정리해두었습니다.\napicall_method = \"GET\"\rspace = \" \"\rnew_line = \"\\n\"\rAPI 서버와 URL 정보 linkAPI 서버와 URL 정보를 설정하면서 API 호출 후 리턴되는 결과값을 json, xml 어떤 형태로 받을 것인지를 responseFormatType=json, responseFormatType=xml 형식으로 설정할 수 있습니다. 기본 값은 xml로 값을 설정하지 않으면 xml로 리턴됩니다.\n# API 서버 정보\rapi_server = \"https://billingapi.apigw.ntruss.com\"\r# API URL 예시 : 상품별 가격 리스트 호출 api\rapi_url = \"/billing/v1/product/getProductPriceList\"\rapi_url = api_url +\"?regionCode=KR\u0026productCode=SPCF000000000001\u0026responseFormatType=json\"\rreport\rAPI URL 설정: API 서버와 URL 정보를 설정할 때 2가지를 구분해서 설정하는 것이 좋습니다. 암호화 문자열을 설정할 때 도메인에 해당하는 API 서버 정보를 제외한 뒤쪽의 API URL만 사용하는데, https://로 시작하는 API 서버 정보까지 포함하면 API 호출 시에 오류가 발생하기 때문입니다.\ninfo\rAPI 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\n암호화 문자열 생성 linkNcloud API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 \\n을 이용해서 하나의 문자열로 설정합니다.\nmessage = apicall_method + space + api_url + new_line + timestamp + new_line + access_key\rmessage = bytes(message, 'UTF-8')\rhmac_sha256 방식으로 암호화 linkhmac sha256 방식으로 Ncloud API SecretKey를 이용하여 message를 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\nncloud_secretkey = bytes(ncloud_secretkey, 'UTF-8')\rsigningKey = base64.b64encode(hmac.new(ncloud_secretkey, message, digestmod=hashlib.sha256).digest())\rhttp 호출 헤더값 설정 linkAPI를 호출할 때는 http 헤더값에 다음 3가지를 추가해서 호출합니다.\n유닉스 타임스탬프 Ncloud API AccessKey hmac_256 으로 암호화한 문자열 http_header = {\r'x-ncp-apigw-timestamp': timestamp,\r'x-ncp-iam-access-key': ncloud_accesskey,\r'x-ncp-apigw-signature-v2': signingKey\r}\rinfo\rtimestamp: 이때 전송하는 timestamp는 위에서 message를 암호화할 때 사용한 timestamp와 동일한 값이어야 합니다. 그리고, API Gateway 서버와 시간 차가 5분 이상 인 경우 유효하지 않은 요청으로 간주되어 호출 오류가 발생합니다.\napi 호출 link이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\n리턴값은 호출하는 용도별로 json 또는 xml 형태로 반환됩니다.\nresponse = requests.get(api_server + api_url, headers=http_header)\r응답 예시 link\r{\"getProductPriceListResponse\": {\r\"requestId\": \"3e4fa6**-f967-4***-a8a9-9dd75****2d65\",\r\"returnCode\": \"0\",\r\"returnMessage\": \"success\",\r\"totalRows\": 1,\r\"productPriceList\": [\r{\r\"productItemKind\": {\r\"code\": \"CF\",\r\"codeName\": \"Cloud Functions\"\r},\r\"productItemKindDetail\": {},\r\"productCode\": \"SPCF000000000001\",\r\"productName\": \"Cloud Functions\",\r\"productDescription\": \"Cloud Functions\",\r\"softwareType\": {},\r\"productTypeDetail\": {},\r\"gpuCount\": 0,\r\"cpuCount\": 0,\r\"memorySize\": 0,\r\"baseBlockStorageSize\": 0,\r\"dbKind\": {},\r\"osInfomation\": \"\",\r\"platformType\": {},\r\"osType\": {},\r\"platformCategoryCode\": \"\",\r\"diskType\": {},\r\"diskDetailType\": {},\r\"generationCode\": \"\",\r\"priceList\": [\r{\r\"priceNo\": \"3870\",\r\"priceType\": {\r\"code\": \"MTRAT\",\r\"codeName\": \"Meter rate\"\r},\r\"chargingUnitType\": {\r\"code\": \"QUERY\",\r\"codeName\": \"Query\"\r},\r\"ratingUnitType\": {\r\"code\": \"SECT\",\r\"codeName\": \"Period unit\"\r},\r\"chargingUnitBasicValue\": \"1000000\",\r\"productRatingType\": {\r\"code\": \"CFREQ\",\r\"codeName\": \"Cloud Functions Request\"\r},\r\"unit\": {\r\"code\": \"REQ_CNT\",\r\"codeName\": \"Number of requests (per month)\"\r},\r\"price\": 0,\r\"conditionType\": {},\r\"conditionPrice\": 0,\r\"priceDescription\": \"Number of requests (1000000) * Price\",\r\"freeUnit\": {},\r\"freeValue\": 0,\r\"meteringUnit\": {\r\"code\": \"REQ_CNT\",\r\"codeName\": \"Number of requests (per month)\"\r},\r\"startDate\": \"2018-04-10T00:00:00+0900\",\r\"periodUnitList\": [\r{\r\"startValue\": 0,\r\"endValue\": 1000000,\r\"price\": 0\r},\r{\r\"startValue\": 1000000,\r\"endValue\": -1,\r\"price\": 200\r}\r],\r\"countryUnitList\": [],\r\"packageUnitList\": []\r}\r]\r}\r]\r}}\rPOST 방식 호출 코드 linkNcloud API는 일반적으로 GET 방식으로 호출하지만, POST 방식으로 호출하는 경우는 다음처럼 구성할 수 있습니다.\nimport sys\rimport os\rimport hashlib\rimport hmac\rimport base64\rimport requests\rimport time\r# unix timestamp 설정\rtimestamp = int(time.time() * 1000)\rtimestamp = str(timestamp)\r# Ncloud API Key 설정\rncloud_accesskey = \"네이버 클라우드 AccessKey\"\rncloud_secretkey = \"네이버 클라우드 SecretKey\"\r# 암호화 문자열 생성을 위한 기본값 설정\rapicall_method = \"POST\"\rspace = \" \"\rnew_line = \"\\n\"\r# API 서버 정보\rapi_server = \"https://billingapi.apigw.ntruss.com\"\r# API URL 예시 : 상품별 가격 리스트 호출 api\rapi_url = \"/billing/v1/product/getProductPriceList\"\r# hmac으로 암호화할 문자열 생성\rmessage = apicall_method + space + api_url + new_line + timestamp + new_line + access_key\rmessage = bytes(message, 'UTF-8')\r# hmac_sha256 암호화\rncloud_secretkey = bytes(ncloud_secretkey, 'UTF-8')\rsigningKey = base64.b64encode(hmac.new(ncloud_secretkey, message, digestmod=hashlib.sha256).digest())\r# http 호출 헤더값 설정\rhttp_header = {\r'x-ncp-apigw-timestamp': timestamp,\r'x-ncp-iam-access-key': ncloud_accesskey,\r'x-ncp-apigw-signature-v2': signingKey\r}\r# POST 파라미터\rpost_data =(\r('regionCode','KR'),\r('productCode','SPCF000000000001'), ('responseFormatType','json')\r)\r# api 호출\rresponse = requests.post(api_server + api_url, headers=http_header, data=post_data)\rprint (response.text)\r오류 상황 linkPython으로 코드를 작성할 때 발생할 수 있는 오류를 정리해보겠습니다.\nimport requests 오류 linkrequests는 Python에서 http 호출에 필요한 라이브러리입니다. 설치되어 있지 않으면 다음과 같은 오류가 발생할 수 있습니다.\nreport\rModuleNotFoundError: No module named ‘requests’\n다음과 같이 requests 라이브러리를 설치하면 해결 됩니다.\nD:\\python\u003e pip install requests\rCollecting requests\rDownloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\r|████████████████████████████████| 63 kB 790 kB/s\rCollecting urllib3\u003c1.27,\u003e=1.21.1\rDownloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\r|████████████████████████████████| 138 kB ...\rCollecting idna\u003c4,\u003e=2.5\r|████████████████████████████████| 61 kB ...\rCollecting certifi\u003e=2017.4.17\rDownloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\r|████████████████████████████████| 149 kB 6.4 MB/s\rCollecting charset-normalizer~=2.0.0\rDownloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\rInstalling collected packages: urllib3, idna, charset-normalizer, certifi, requests\rSuccessfully installed certifi-2021.10.8 charset-normalizer-2.0.12 idna-3.3 requests-2.27.1 urllib3-1.26.8f\rpip upgrade 오류 linkPython 코드 작성과 직접 관계가 있는 것은 아니지만 Windows 환경에서 pip 버전을 업그레이드 하라는 메시지가 나타나서 아래와 같이 업그레이드를 하려고 할 때 오류 메시지가 발생하는 경우가 있습니다.\nD:\\python\u003e pip install --upgrade pip\rreport\rERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다\n이럴 때는 Command Prompt를 관리자 권한으로 실행하시면 해결 됩니다.\n참고 URL link Ncloud API 가이드\nhttps://api.ncloud-docs.com/docs/ko/home/ 문서 업데이트 내역 link\r날짜 내용 2022-02-24 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  229 ,
                href: "\/docs\/api\/ncloud-api-call-powershell-sample\/",
                title: "Windows PowerShell에서 Ncloud API를 호출하는 샘플 예제",
                description: "Windows PowerShell에서 Ncloud API를 호출하는 샘플 예제",
                content: "개요 link네이버 클라우드 인프라와 상품 및 솔루션 등의 활용을 도와주는 API를 Windows PowerShell에서 호출하는 샘플 예제를 정리해봅니다.\n네이버 클라우드 API는 RESTful API 방식으로 제공되며, XML와 JSON 형식으로 응답합니다 우선 전체 소스코드를 살펴보고 다음으로 주요 코드를 상세하게 살펴보겠습니다.\nAPI 호출 샘플 코드 link\rfunction Sign-Request(\r[string] $api_server,\r[string] $api_url, [string] $apicall_method, [string] $ncloud_accesskey, [string] $ncloud_secretkey )\r{ $unixtimestamp = [DateTimeOffset]::Now.ToUnixTimeSeconds() * 1000\r$space = \" \"\r$new_line = \"`n\"\r$message = $apicall_method + $space +\r$api_url + $new_line +\r$unixtimestamp + $new_line +\r$ncloud_accesskey $signature = Compute-HMACSHA256Hash $ncloud_secretkey $message\r# Return request headers\rreturn @{\r\"x-ncp-apigw-timestamp\" = $unixtimestamp;\r\"x-ncp-iam-access-key\" = $ncloud_accesskey;\r\"x-ncp-apigw-signature-v2\" = $signature\r}\r}\rfunction Compute-HMACSHA256Hash(\r[string] $secret, # base64 encoded\r[string] $content\r)\r{\r$hmacsha = New-Object System.Security.Cryptography.HMACSHA256\rtry {\r$hmacsha.key = [Text.Encoding]::UTF8.GetBytes($secret)\r$signature = $hmacsha.ComputeHash([Text.Encoding]::UTF8.GetBytes($message)) return [Convert]::ToBase64String($signature)\r}\rfinally {\r$hmacsha.Dispose()\r}\r}\r# API 서버와 URL 예시 : 상품별 가격 리스트 호출 api\r$api_server = \"https://billingapi.apigw.ntruss.com\";\r$api_url = \"/billing/v1/product/getProductPriceList\";\r$api_url = $api_url + \"?regionCode=KR\u0026productItemKindCode=VSVR\";\r$apicall_method = \"GET\"\r$body = $null\r$ncloud_accesskey = \"Ncloud AccessKey\"\r$ncloud_secretkey = \"Ncloud SecretKey\"\r$api_full_url = $api_server + $api_url\r$headers = Sign-Request $api_server $api_url $apicall_method $ncloud_accesskey $ncloud_secretkey\rInvoke-WebRequest -Uri $api_full_url -Method $apicall_method -Headers $headers -Body $body\r코드 상세 설명 link유닉스 타임 스탬프 link\r$unixtimestamp = [DateTimeOffset]::Now.ToUnixTimeSeconds() * 1000\r네이버 클라우드 API를 호출할 때는 13자리 형식의 유닉스 타임 스탬프가 필요합니다.\n계산한 날짜 값에 1000을 곱해서 13자리로 만듭니다.\nhmac으로 암호화할 문자열 설정 link암호화할 문자열을 설정하는데 필요한 값을 사전에 정의합니다.\n$space = \" \"\r$new_line = \"`n\"\r$message = $apicall_method + $space +\r$api_url + $new_line +\r$unixtimestamp + $new_line +\r$ncloud_accesskey\t네이버 클라우드 API에서는 호출 방식(GET, POST)과 도메인을 제외한 API URL, 유닉스 타임스탬프, API ACCESSKEY를 공백과 개행문자 `n을 이용해서 하나의 문자열로 설정합니다.\ninfo\rAPI 가이드: API URL은 용도별로 각기 다른데, 네이버 클라우드 API 가이드 사이트에서 확인할 수 있습니다. https://api.ncloud-docs.com/docs/ko/home/\nhmac_sha256 방식으로 암호화 link\r$signature = Compute-HMACSHA256Hash $ncloud_secretkey $message\rfunction Compute-HMACSHA256Hash(\r[string] $secret, # base64 encoded\r[string] $content\r)\r{\r$hmacsha = New-Object System.Security.Cryptography.HMACSHA256\rtry {\r$hmacsha.key = [Text.Encoding]::UTF8.GetBytes($secret)\r$signature = $hmacsha.ComputeHash([Text.Encoding]::UTF8.GetBytes($message)) return [Convert]::ToBase64String($signature)\r}\rfinally {\r$hmacsha.Dispose()\r}\r}\rhmac sha256 방식으로 네이버 클라우드 API SecretKey를 이용하여 $message 문자열을 암호화 즉, 해시값을 만들고, 다시 base64로 인코딩합니다.\nhttp 호출 헤더값 설정 link\r# Return request headers\rreturn @{\r\"x-ncp-apigw-timestamp\" = $unixtimestamp;\r\"x-ncp-iam-access-key\" = $ncloud_accesskey;\r\"x-ncp-apigw-signature-v2\" = $signature\r}\rAPI를 호출할 때는 http 헤더값에 다음 3가지를 추가해서 호출합니다.\n유닉스 타임스탬프 네이버 클라우드 API AccessKey hmac_256 으로 암호화한 문자열 여기서 전송하는 타임스탬프는 위에서 $message를 암호화할 때 사용한 타임스탬프와 동일한 값이어야 합니다.\n네이버 클라우드 인증키 link\r$ncloud_accesskey = \"Ncloud AccessKey\"\r$ncloud_secretkey = \"Ncloud SecretKey\"\t네이버 클라우드 인증키는 네이버 클라우드 포탈 -\u003e 마이페이지 -\u003e 계정관리 -\u003e 인증키 관리 - API 인증키 관리 메뉴에서 Access Key ID와 Secret Key를 가져오셔야 하며, 아직 만들어진 Key가 없다면 새로 만드셔야 합니다.\napi 호출 link\r$headers = Sign-Request $api_server $api_url $apicall_method $ncloud_accesskey $ncloud_secretkey\rInvoke-WebRequest -Uri $api_full_url -Method $apicall_method -Headers $headers -Body $body 이제 위에서 준비한 값들을 사용해서 API를 호출합니다.\n리턴값은 호출하는 용도별로 json 또는 xml 형태로 반환됩니다.\n응답 예시 link\r\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\r397d3d13-2b2a-42d2-96d0-20ff63df69dc\r0\rsuccess\r121\rVSVR\rServer (VPC)\rBM\rBareMetal\r''' 중략 '''\rBM\rBareMetal\rBM\rBareMetal\r0\r24\r137438953472\r4123168604160\rLOCAL\rLocal storage\rSSD\rSSD\rG1 ''' 중략 '''\r참고 URL link Ncloud API 가이드\nhttps://api.ncloud-docs.com/docs/ko/home/ 문서 업데이트 내역 link\r날짜 내용 2022-12-29 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  230 ,
                href: "\/docs\/aws\/s3-lifecycle-management\/",
                title: "AWS S3 수명 주기 (LifeCycle) 설정하기",
                description: "AWS S3 수명 주기 (LifeCycle) 설정하기",
                content: "개요 linkAWS S3에서는 버킷내 특정 디렉토리 하위 파일들에 대해 지정된 날짜가 지난 후 만료(삭제)가 되도록 설정할 수 있습니다. 수명 주기 관리(LifeCycle Management)라고 불리는 이 방법은 파일관리 뿐만 아니라 비용절감에도 도움이 됩니다.\n수명주기 설정 linkAWS 콘솔에 접속 후 수명 주기를 적용할 S3 버킷으로 이동해 [관리] 메뉴 클릭합니다.\n[수명 주기 규칙 생성] 버튼을 클릭합니다.\n수명 주기 규칙 이름을 입력하고, 규칙 범위는 [하나 이상의 필터를 사용하여 이 규칙의 범위 제한]을 선택합니다.\n접두사에는 수명 주기를 적용할 디렉토리나 파일 등의 필터를 작성합니다. 예를 들어 images 디렉토리가 포함된 모든 파일에 적용하려면 images/ 라고 입력합니다. 이때 버킷명은 제외하고 입력해야 합니다.\n수명 주기 규칙 작업에서 [객체의 현재버전 만료], [객체의 이전버전 영구 삭제] 두가지 항목을 선택하면, 몇일 후에 삭제할 것인지를 설정할 수 있는 [객체 생성 후 경과 일수], [객체가 이전 버전이 된 후 경과 일수] 항목이 나타납니다. 여기에 원하는 날짜를 각각 입력하고, [규칙 생성] 버튼을 클릭합니다.\n주의사항 linkAWS 수명 주기 관련해서 주의해야 할 사항이 몇가지 있습니다.\n수명 주기 규칙 작동 시점 link수명 주기 규칙이 생각한 것보다 늦게 작동하는 경우가 있습니다. 이는 Amazon S3가 객체의 전환 또는 만료(삭제) 날짜를 익일 자정(UTC)부터 계산하기 때문입니다.\n예를 들어 2020년 1월 1일 10:30(UTC)에 객체를 생성하고 3일 후 객체가 만료(삭제)되도록 수명 주기 규칙을 설정할 경우 객체의 만료(삭제) 날짜는 2020년 1월 5일 00:00(UTC)이 됩니다. 따라서 수명 주기 규칙이 충족되었는지 확인하기 전에 충분한 시간이 경과했는지 확인해야 합니다.\n수명 주기 규칙 접두사 필터 설정 link수명 주기 규칙에서 접두사 필터에 디렉토리를 지정할 경우 접두사 필터의 끝에 / 문자를 지정해야 합니다. 접두사 필터의 처음에 / 문자가 있으면 수명 주기 규칙이 올바르게 평가되지 않습니다.\n즉, images 디렉토리가 포함된 모든 파일에 적용하려면 images/ 라고 입력해야 합니다.\n참고 URL link AWS S3 수명 주기 관리 가이드\nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lifecycle-mgmt.html\n수명 주기 규칙 작동 지연 관련 FAQ\nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/s3-lifecycle-rule-delay/\n문서 업데이트 내역 link\r날짜 내용 2021-09-16 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  231 ,
                href: "\/docs\/aws\/cloud-watch-log\/",
                title: "AWS CLOUDWATCH LOG 수집 매뉴얼",
                description: "AWS에서 CLOUDWATCH LOG를 수집하기 위해 필요한 절차와 오류 대처법에 대한 매뉴얼입니다",
                content: "사전 작업 linkIAM 계정생성 및 권한 부여 linkcloudwatch log수집을 위해서는 서버 작업과 별도로 IAM 계정생성과 권한할당 작업을 선 진행하여야하며 작업이 완료된 후 계정의 액세스키[^1], 비밀키를 발급 받는다.\n계정생성 계정생성- 계정이름 입력- 액서스 유형 Programmatic access 선택 권한설정 기존 정책 직접 연결 선택 - CloudWatchAgentServerPolicy정책 추가 키확인 액세스 키 확인 및 비밀키 확인 서버 작업 link설치 작업 link awslogs 설치는 다음 명령어를 통해 설치 yum -y install awslogs\naws configure를 통한 IAM 키 입력\naws configure 명령어 입력 - 액세스키 요구 및입력 - 비밀키 요구및 입력(위 IAM계정의 키 입력)\n설정 관련 link /etc/awslogs/awscli.conf\nregion = ap-northeast-2 추가 설정없이 리전만 로그 수집을 위한 리전으로 변경\n/etc/awslogs/awslog.conf\n해당 컨피그 파일의 제일 하단에 로그 수집 대상 로그를 아래의 형식으로 작성\n[/var/log/messages] – 수집로그 경로와 파일 지정\ndatetime_format = %b %d %H:%M:%S (로그의 데이터 포맷 지정)\nfile = /var/log/messages (로그 파일 위치)\nbuffer_duration = 5000 (로그 이벤트를 일괄 처리하는 기간을 지정합니다. 최소값은 5000ms이고, 기본값은 5000ms입니다.)\nlog_stream_name = {instance_id} (대상로그 스트림 이름 지정{instance_id}, {hostname}, {ip_address})\ninitial_position = start_of_file\nlog_group_name = /var/log/messages(cloudwatch 로그 그룹네임 지정 )\ntime_zone=LOCAL\nmulti_line_start_pattern ={datetime_format} (로그 줄 단위 기준점. datetime_fomat 멀티라인 처리)\n/var/log/awslogs.log\nawslogs서비스 실행 후 발생되는 로그.\n실행 및 자동실행 등록 link 실행 명령어 service awslogs start 리붓시 자동실행 등록 chkconfig awslogs on (amazon linux2 인 경우 systemctl enable awslogsd.service) cloudwatch 설정 link정상적으로 서버의 로그가 수집된다면 cloudwatch - log항목에서 서버에서 지정한 로그 그룹네임이 보이며 이를 클릭시 서버 인스턴스 ID별로 로그 수집되는 내역 확인 가능\n수집된 데이터는 대시보드를 통해 데이터를 보여주는기능은 바로 가능하나 이를 가지고 그래프를 통한 시각화를 할수 없어 지표를 통한 그래프를 생성하여야함.\ncloudwatch -로그- 로그그룹중 필터기능을 쓸 지표선택 -지표 필터 클릭\n지표 필터 추가 버튼 클릭\n필터링 하고자하는 값을 넣고 [정규식지원]패턴 테스트 후 지표할당 클릭\n이후 지표 네임스페이스는 로그 그룹 네임 중 추출하고자하는 지표영역 지표이름은 해당 지표를 선택\ncloudwatch - 지표 선택 - 모든 지표에서 로그 그룹 필터를 적용한 로그 그룹의 incomingLogEvents선택\n그래프로 표시된 지표 탭 선택 - 필터가 적용된 그래프가 나오며 그래프의 작업 대시보드 추가를 선택하여\n대시보드로 그래프 등록\n오류 대처 법 link로그 수집이 되지 않고 awslogs.log파일에 아래와 같이 로그 가 찍히는 경우 처리 방안\n{% include warning.html title=“reason” content=“timestamp is more than 2 hours in future.” %}\n/var/lib/awslogs/agent-state를 삭제\n해당 방법으로 처리시 수집되는 로그가 처음부터 다시 로그가 수집됩 sqlite3 명령어를 통해 agent-state 오류 처리\nsudo sqlite3 /var/lib/awslogs/agent-state select * from stream_state; 통해 문제가 되는 소스ID확인 select * from push_state where k=“확인된 소스ID”; update push_state set v=’… insert new value here …’ where k=‘7675f84405fcb8fe5b6bb14eaa0c4bfd’; service awslogs restart 참고 URL link AWS CloudWatch Logs 에이전트 참조\nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/AgentReference.html\nAWS EC2 Linux CloudWatch 인스턴스에 Logs 에이전트 설치\nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html\nAWS CloudWatch logs acting weird\nhttps://stackoverflow.com/questions/40604940/cloudwatch-logs-acting-weird\n문서 업데이트 내역 link\r날짜 내용 2020-11-05 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  232 ,
                href: "\/docs\/etc\/smtp-auth-error-troubleshooting-using-gmail-account\/",
                title: "Gmail을 이용해 smtp 메일 발송할 때 인증오류 해결 방법",
                description: "Gmail을 이용해 smtp 메일 발송할 때 인증오류 해결 방법입니다",
                content: "개요 link웹서버나 애플리케이션 등에서 gmail 계정을 이용해서 smtp로 메일을 발송하는 경우가 있습니다.\n관리자의 안내 메일이나 소수회원을 위한 다량메일 발송등을 하는 것이 그런 경우인데\n예전에는 보안 수준이 낮은 앱의 액세스 허용 옵션으로 가능했었지만, 최근에는 이 설정으로도 해결되지 않는 경우가 많습니다.\n이럴 때 확실하게 인증할 수 있는 방법이 구글계정 2단계 인증 사용과 앱 비밀번호 설정입니다.\n인증 오류 메시지 link위에서 이야기한 2단계 인증과 앱 비밀번호를 사용하지 않고 smtp로 구글계정\nreport\r인증 오류 메시지: The SMTP server requires a secure connection or the client was not authenticated. The server response was: 5.7.0 Authentication Required.\n이 문제, 인증 오류 메시지를 해결하려면 아래 내용대로 설정을 하시면 해결됩니다.\n2단계 인증 link2단계 인증이란 구글계정에 로그인 할 때 아이디와 비밀번호 외에 추가로 인증 절차를 거쳐 로그인을 인증하는 것을 말합니다.\n2단계 인증 방법에는 다음과 같은 종류가 있습니다.\nGoogle 메시지 앱 비밀번호 백업 코드 백업 전화 휴대전화 내장 보안 키 인증 설정하기 link우선 구글계정으로 로그인해서 계정-보안 메뉴로 이동합니다.\n보안 메뉴에서 [Google에 로그인]이라는 곳에 보면 [2단계 인증] 메뉴가 있습니다.\n현재는 사용 안함으로 설정되어 있는데 클릭해서 설정을 시작합니다.\nhttps://myaccount.google.com/security\n2단계 인증에 대한 기본적인 안내와 함께 설정이 시작됩니다.\n2단계 로그인할 때 메시지를 받을 기기가 나타납니다. 또는 보안 키 장치나 다른 방법을 옵션으로 선택할 수 있습니다.\n로그인을 하고 나면 관련 메시지가 앞 단계에서 선택한 장치에 도착합니다. 저는 휴대폰을 선택했기에 Gmail 앱을 확인해보겠습니다.\n이렇게 휴대폰의 Gmail 앱을 열면 안내 메시지가 도착해있고, [예] 버튼을 선택하면 됩니다.\n휴대폰에서 [예]를 선택하면 설정화면이 자동으로 다음으로 넘어와 있습니다. 여기서는 백업 옵션에 대한 방법을 선택합니다. 저는 문자 메시지를 선택했습니다.\r잠시 후에 휴대폰 문자메시지로 [국외발신] G-254796(이)가 Google 인증코드입니다. 라는 메시지가 도착합니다.\n이 중에서 뒤에 있는 6자리 숫자 코드를 입력하면 됩니다.\n이제 마지막으로 2단계 인증을 사용할 것인지 최종 확인을 합니다. [사용 설정] 버튼을 클릭하시면 2단계 인증이 적용됩니다.\n적용된 2단계 인증에 대한 안내화면입니다. Google 메시지가 2단계 인증 기본값으로 설정되어 있고, 그 외에 음성 또는 문자 메시지도 이용 가능하다는 내용입니다.\n이제 위쪽에 있는 뒤로 돌아가기 버튼을 클릭해서 메인화면으로 돌아갑니다.\n메인화면으로 돌아가면 2단계 인증이 사용으로 설정된 것을 확인할 수 있고, 그 아래에 앱 비밀번호 항목이 새로 생긴 것을 알 수 있습니다.\n앱 비밀번호 설정 link앱 비밀번호 설정을 시작하면 어떤 앱에서 사용할 것인지, 기기는 어떤 것인지 선택하는 화면이 나옵니다.\n메일, 캘린더, 연락처, Youtube 등이 있는데 저희는 Smtp를 할 것이기 때문에 기타(맞춤 이름)을 선택합니다.\n기타를 선택하면 기기선택은 필요없기 때문에 앱 이름만 원하는대로 입력합니다. 여기서는 Smtp Client라고 입력하고 생성 버튼을 클릭합니다.\n드디어 16자리 앱 비밀번호가 생성되었습니다. 이 번호를 반드시 복사해서 따로 저장을 하고 확인 버튼을 클릭합니다.\n앱 비밀번호 화면에서는 현재 생성된 비밀번호를 삭제하거나 추가 할 수 있습니다.\n다시 계정 보안 메인 화면으로 돌아오면 앱 비밀번호 1개가 설정되었다는 것을 확인할 수 있습니다.\n앱 비밀번호 적용 link그러면 smtp 소스코드에서 어떻게 앱 비밀번호를 적용하는지 확인해보겠습니다.\nPHP link\r$mail = new PHPMailer();\r$mail-\u003eIsSMTP();\r$mail-\u003eSMTPAuth = true;\r$mail-\u003eSMTPSecure = \"tls\";\r$mail-\u003eHost = \"smtp.gmail.com\";\r$mail-\u003ePort = 587;\r$mail-\u003eUsername = \"Gmail 계정\";\r$mail-\u003ePassword = \"앱 비밀번호\";\r.Net C# link\rSmtpClient client = new SmtpClient(\"smtp.gmail.com\", 587);\rclient.UseDefaultCredentials = false;\rclient.EnableSsl = true;\rclient.DeliveryMethod = SmtpDeliveryMethod.Network;\rclient.Credentials = new System.Net.NetworkCredential(\"Gmail 계정\", \"앱 비밀번호\");\r이렇게 기존에 gmail 계정 비밀번호를 입력하던 곳에 앱 비밀번호를 입력하면 문제없이 잘 접속됩니다.\n기타 사항 link앱 비밀번호는 PC에서 Outlook으로 gmail을 연동할 때 등 여러 경우에 아래와 같이 설정해서 사용할 수 있습니다.\n그리고 2단계 인증을 사용하게 되면 기존의 보안 수준이 낮은 앱의 액세스 설정을 사용할 수 없습니다.\r참고 URL link 구글 계정 보안 설정\nhttps://myaccount.google.com/security 문서 업데이트 내역 link\r날짜 내용 2020-11-30 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  233 ,
                href: "\/docs\/etc\/php-to-telegram-message-send\/",
                title: "PHP로 텔레그램 비공개 채널에 메시지 전송하기",
                description: "PHP로 텔레그램(Telegram) 대화방인 비공개 채널에 메시지 전송하는 방법입니다",
                content: "개요 link업무를 진행하다보면 서버나 서비스에 장애가 발생했을 때 즉시 알림을 받거나 서버 상태 모니터링이나 매출 등의 서비스 이용 지표 등을 매일 자동으로 통보 받는 경우가 있습니다. 예전에는 이메일이나 SMS 메시지로 받는 경우가 대부분이었는데, 요즘은 관련된 사람들이 함께 들어와 있는 메신저 채팅방으로 알림을 동시에 받는 경우도 많아지고 있습니다.\n그럴 때 사용하는 방법 중에서 여기서는 텔레그램(Telegram)의 대화방인 비공개 채널에 메시지를 전송하는 것을 PHP로 구현해보겠습니다.\n구현 순서 link 텔레그램 채팅 봇을 생성 텔레그램 채널을 비공개로 생성 비공개 채널에 위에서 생성한 채팅 봇을 관리자로 등록 PHP로 채팅 봇을 이용해 비공개 채널에 메시지를 전송 채팅 봇 생성 link텔레그램(Telegram) 메신저에서 채팅 봇을 생성하고 관리해주는 봇인 [BotFather]를 검색합니다. 여러 개의 봇들이 나타나는데 그 중에서 인증 마크가 붙어 있는 텔레그램 공식 봇을 선하고 채팅 방에 들어갑니다.\n[BotFather] 채팅 봇 방에 들어가면 채팅 봇에 대한 설명과 봇 API 매뉴얼 링크를 확인할 수 있습니다.\n이제 채팅 봇 생성을 위해 /start 명령을 입력하면 아래와 같이 채팅 봇 생성, 관리에 대한 명령어들을 확인할 수 있습니다.\n다음으로 새로운 채팅 봇을 생성하는 명령어인 /newbot을 입력하면, 채팅 봇 이름과 채팅 봇 유저명을 입력하라는 안내가 나옵니다. 차례대로 입력하면 되는데, 여기서 입력하는 이름을 텔레그램 내에서 고유한 값이므로 간단한 이름을 입력하면 중복된 이름이라 생성이 되지 않으니 자신만의 고유한 이름을 입력합니다.\n그리고 두번째로 입력하는 채팅 봇 유저명(username for your bot)은 반드시 마지막이 bot로 끝나야 합니다. 두가지 모두 입력하고 나면 아래쪽에 채팅 봇과 연동하기 위한 API Token을 확인할 수 있는데, 이 Token을 PHP에서 사용하게 됩니다.\n채팅 봇이 생성되었는지 텔레그램에서 검색해보면 아래와 같이 확인할 수 있습니다.\n채널 생성 link채널을 생성하기 위해 텔레그램 왼쪽 메뉴를 클릭합니다.\n메뉴 화면에서 [채널 만들기]를 클릭합니다.\n원하는 채널명을 입력하고, 만들기를 클릭하면, 공개-비공개를 선택할 수 있는데 여기서는 [비공개 채널]을 선택하고 저장합니다.\n저장하고 나면 다음으로 [참가자 추가] 화면이 나타나는데 위에서 생성했던 채팅 봇 이름을 입력해서 확인하고, 선택 후에 [추가] 버튼을 클릭합니다.\n그러면 아래와 같이 [봇은 관리자로서만 추가될 수 있습니다]라는 메시지가 나타납니다. 바로 [관리자로 세우기] 버튼을 클릭합니다.\n관리자의 권한은 여러가지가 있는데 원하는 권한을 부여하고 [저장] 버튼을 클릭합니다.\n채팅 방 ID 확인 link메시지를 전송하기 위해서는 현재 생성된 비공개 채널의 chat_id를 확인해야 합니다.\n우선, 채널에서 아무 메시지나 입력합니다. (꼭 하셔야 합니다)\n다음으로 웹브라우저에서 다음 주소를 입력합니다. 주소에는 위에서 확인했던 API Token이 들어갑니다.\nhttps://api.telegram.org/bot[API Token]/getUpdates\r# 예시\rhttps://api.telegram.org/bot123456789:JFDS89FMJK8932-MKJE8FNBH3289I/getUpdates\r입력하면 나타나면 결과에서 “chat” : {“id” : -12586498, ….} 와 같은 형식의 id 값을 복사합니다. 이 값이 바로 비공개 채널의 chat_id 입니다.\n메시지 전송 코드 작성 link마지막으로 메시지를 전송하는 PHP 코드를 작성해보겠습니다.\n위에서 구했던 [API Token], [chat_id]를 아래 코드에 입력하고 실행하면 됩니다.\n\u003c?php\rfunction php_to_telegram_msg_send($msg) {\r$api_token = \"API Token\";\r$chat_id = \"채팅방 ID\";\r$api_url = \"https://api.telegram.org/bot\".$api_token.\"/sendMessage\";\r$post_vars = \"chat_id=\".$chat_id.\"\u0026text=\".urlencode($msg);\r$content_type = \"Content-Type: application/x-www-form-urlencoded\";\r$ch = curl_init();\rcurl_setopt($ch, CURLOPT_URL, $api_url);\rcurl_setopt($ch, CURLOPT_HEADER, false);\rcurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\rcurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);\rcurl_setopt($ch, CURLOPT_POST, true);\rcurl_setopt($ch, CURLOPT_TIMEOUT, 5);\rcurl_setopt($ch, CURLOPT_HTTPHEADER, array($content_type));\rcurl_setopt($ch, CURLOPT_POSTFIELDS, $post_vars);\r$return = curl_exec($ch);\rcurl_close($ch);\rreturn $return;\r}\r$tgm_msg = \"\";\t$tgm_msg = $tgm_msg.\"메시지 테스트\";\r$output = php_to_telegram_msg_send($tgm_msg);\t?\u003e\r위 코드를 실행하면 아래와 같이 비공개 채널에 메시지가 도착한 것을 확인할 수 있습니다.\n메시지 스타일 적용 link텔레그램 채팅 봇 API는 메시지에 bold, underline 등의 몇가지 html 스타일을 지원합니다.\nhtml 스타일을 적용하기 위해서는 전송 파라미터에 parse_mode=html을 추가해야 합니다.\n그러면 위 전송 코드 중에서 변경해야 하는 코드만 정리해보겠습니다.\n\u003c?php\r/* 전송 파라미터에 parse_mode=html을 추가합니다. */\r$post_vars = \"chat_id=\".$chat_id.\"\u0026text=\".urlencode($msg).\"\u0026parse_mode=html\";\t$tgm_msg = $tgm_msg.\"bold\".\"\\r\\n\";\r$tgm_msg = $tgm_msg.\"italic\".\"\\r\\n\";\r$tgm_msg = $tgm_msg.\"\\$now_date = date('Y-m-d');\".\"\\r\\n\";\r$tgm_msg = $tgm_msg.\"strike\".\"\\r\\n\";\r$tgm_msg = $tgm_msg.\"underline\".\"\\r\\n\";\r$tgm_msg = $tgm_msg.\"\\$now_date = date('Y-m-d');\".\"\\r\\n\";\r$tgm_msg = $tgm_msg.\"email@test.com\".\"\\r\\n\";\r$tgm_msg = $tgm_msg.\"email@test.com\".\"\\r\\n\";\r?\u003e\r위 코드처럼 스타일을 적용하고 실행하면 아래와 같이 표시됩니다.\n참고 URL link 텔레그램 채팅 봇 안내\nhttps://core.telegram.org/bots/\n텔레그램 채팅 봇 API 가이드\nhttps://core.telegram.org/bots/api/\n텔레그램 채팅 봇 API 메시지 스타일 가이드\nhttps://core.telegram.org/api/entities/\n문서 업데이트 내역 link\r날짜 내용 2021-11-10 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  234 ,
                href: "\/docs\/etc\/pdf-merge-php-sample\/",
                title: "Pdf 문서 합치기 PHP로 구현하는 방법",
                description: "여러 PDF 문서를 하나의 문서로 합치는 merge 기능을 PHP로 구현하는 방법입니다",
                content: "개요 link요즘은 회사 업무에서 파일을 전달할 때 PDF 문서를 활용하는 경우가 매우 많습니다.\n그런데 이때 보내야 하는 PDF 문서가 여러개 일 경우 받는 쪽에서 각각의 파일을 일일이 열어봐야 해서 불편한 경우가 있습니다.\n이럴때 여러 PDF 문서를 합쳐서 하나의 문서로 만들어 보내면 편리한 경우에 사용할 수 있는 PDF 문서 합치기 - merge 기능을 PHP로 구현하는 방법입니다.\n라이브러리 설치 linkPDF 문서를 합쳐 주는 기능을 가진 라이브러리는 [ php pdf merger ]라고 검색해보면 여러가지 버전이 존재하는데 여기서는 Jurosh 라는 사람이 만든 것을 사용하겠습니다.\n우선 composer 를 이용해서 라이브러리를 설치합니다.\ncomposer require jurosh/pdf-merge\r기본 사용법 link아래 기본 사용법은 라이브러리 개발자가 GitHub에 올려둔 가이드에 있는 사용법입니다.\n\u003c?php\rrequire 'vendor/autoload.php';\r// and now we can use library\r$pdf = new \\Jurosh\\PDFMerge\\PDFMerger;\r// add as many pdfs as you want\r$pdf-\u003eaddPDF('path/to/source/file.pdf', 'all', 'vertical')\r-\u003eaddPDF('path/to/source/file1.pdf', 'all')\r-\u003eaddPDF('path/to/source/file2.pdf', 'all', 'horizontal');\r// call merge, output format `file`\r$pdf-\u003emerge('file', 'path/to/export/dir/file.pdf');\r?\u003e\r응용 사용법 link여기서는 파일 업로드 웹페이지를 통해 업로드 된 여러 파일들을 합쳐서 다운로드 받는 방식으로 구현해보겠습니다.\n\u003c? php\rrequire 'vendor/autoload.php';\r$pdf = new \\Jurosh\\PDFMerge\\PDFMerger;\r$source_file_array = Array();\r$source_filename_array = Array();\r$source_file_array = $_FILES[\"pdf_file\"];\r$source_filename_array = $source_file_array[\"name\"];\r$upload_filename_array = $source_file_array[\"tmp_name\"];\r$cnt_file = count($source_filename_array);\rfor ($i = 0; $i \u003c $cnt_file; $i++)\r{\r$pdf-\u003eaddPDF($upload_filename_array[$i], 'all', 'vertical'); }\r$output_filename = $source_filename_array[0];\r$pdf-\u003emerge('download', $output_filename);\r?\u003e\r업로드 된 파일명 배열에 저장 link\r\u003c? php\r$source_file_array = $_FILES[\"pdf_file\"];\r$source_filename_array = $source_file_array[\"name\"];\r$upload_filename_array = $source_file_array[\"tmp_name\"];\r?\u003e\r합칠 파일들 리스트에 추가 link업로드 된 개수 만큼 파일들을 리스트에 추가합니다.\n$pdf-\u003eaddPDF의 파라미터에는 옵션으로 페이지와 문서방향이 들어갑니다.\n$pdf-\u003eaddPDF(파일경로, 페이지, 문서방향);\n\u003c? php\r$cnt_file = count($source_filename_array);\rfor ($i = 0; $i \u003c $cnt_file; $i++)\r{\r$pdf-\u003eaddPDF($upload_filename_array[$i], 'all', 'vertical'); }\r/* 사용 예시\r$pdf-\u003eaddPDF($upload_filename_array[$i], 'all', 'vertical');\r$pdf-\u003eaddPDF($upload_filename_array[$i], '1,3,6', 'horizontal');\r$pdf-\u003eaddPDF($upload_filename_array[$i], '12-16', 'vertical');\r*/\r?\u003e\r파일 합치기 link합치기 옵션은 [download], [browser], [file], [string] 이렇게 4가지가 있습니다.\n보통 로컬PC로 다운로드 받을 때는 [download], 서버에 저장할 때는 [file]를 선택하면 됩니다.\n\u003c? php\r$pdf-\u003emerge('download', $output_filename);\r$pdf-\u003emerge('browser', $output_filename);\r$pdf-\u003emerge('file', $output_filename);\r$pdf-\u003emerge('string', $output_filename);\r?\u003e\r한글 깨짐 해결 linkPDF 파일을 합치면 문서 내의 텍스트는 한글이나 기타 UTF-8 문자들이 문제없이 잘나타납니다.\n그런데 파일명은 UTF-8이 지원되지 않아 한글이 깨지는 현상이 나타납니다.\n이를 해결하기 위해서는 여기서 사용한 pdf merger 소스 파일을 수정해야 합니다.\n소스파일 위치는 ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php 입니다.\nPDFMerger.php 파일에서 파일 합치기 함수 merge를 찾습니다.\n\u003c? php\r/* ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php */\r/*== 기존 ==*/ public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf') {\r/* ====*/\r/* 중략 */\r/* ====*/\rif ($mode == 'S') {\rreturn $fpdi-\u003eOutput($outputpath, 'S');\r} else {\rif ($fpdi-\u003eOutput($outputpath, $mode) == '') {\rreturn true;\r} else {\rthrow new Exception(\"Error outputting PDF to '$outputmode'.\");\rreturn false;\r}\r}\r}\r/*== 수정 ==*/ public function merge($outputmode = 'browser', $outputpath = 'newfile.pdf') {\r/* ====*/\r/* 중략 */\r/* ====*/\rif ($mode == 'S') {\rreturn $fpdi-\u003eOutput($outputpath, 'S', true);\r} else {\rif ($fpdi-\u003eOutput($outputpath, $mode, true) == '') {\rreturn true;\r} else {\rthrow new Exception(\"Error outputting PDF to '$outputmode'.\");\rreturn false;\r}\r}\r}\r?\u003e\r위에서 바뀐 부분은 Output 함수의 파라미터 하나입니다.\n\u003c? php\r// 기존\r$fpdi-\u003eOutput($outputpath, 'S');\r$fpdi-\u003eOutput($outputpath, $mode);\r// 수정\r$fpdi-\u003eOutput($outputpath, 'S', true);\r$fpdi-\u003eOutput($outputpath, $mode, true);\r?\u003e\r왜 그런지 실제 Output 함수가 선언된 곳을 찾아가보겠습니다. 파일 위치는 ./vendor/setasign/fpdf/fpdf.php 입니다.\n아래와 같이 Output 함수의 파라미터는 3개로 마지막이 UTF-8 여부를 설정하는 것이었습니다.\n그러므로 마지막 파라미터를 true 로 설정만 해도 한글, UTF-8 문제가 해결됩니다.\n\u003c? php\r/* ./vendor/setasign/fpdf/fpdf.php */\rfunction Output($dest='', $name='', $isUTF8=false)\r{\r/* 중략 */\r}\r?\u003e\r문서 속성 추가 link또 하나의 문제가 제목, 작성자, 주제 등의 문서 속성 정보가 추가되지 않는다는 점입니다.\n이 또한 파일 2개를 수정해야 합니다.\n문서 합치기 파일 (ex: pdf_merge.php) link\r\u003c? php\r// 문서 속성 정보를 추가합니다.\r$author = \"써드아이시스템\";\r$creator = \"써드아이시스템\";\r$title = \"문서 제목\";\r$subject = \"문서 주제\";\r$keywords = \"키워드\";\r// merge 함수에 문서 속성 옵션을 추가합니다.\r$pdf-\u003emerge('download', $output_filename, $author, $creator, $title, $subject, $keywords);\r?\u003e\rmerge 함수 정의 파일 (PDFMerger.php) link위치 : ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php\n\u003c? php\r/* ./vendor/jurosh/pdf-merge/src/Jurosh/PDFMerge/PDFMerger.php */\r// 파라미터 추가\rpublic function merge($outputmode = 'browser', $outputpath = 'newfile.pdf', $author = '3rdEYESYS', $creator = '3rdEYESYS', $title = 'title', $subject = 'subject', $keywords = 'keywords') {\r/* 중략 */\r// 속성 항목 설정\r$fpdi-\u003eSetAuthor($author, true);\r$fpdi-\u003esetCreator($creator, true);\r$fpdi-\u003esetTitle($title, true);\r$fpdi-\u003esetSubject($subject, true);\r$fpdi-\u003esetKeywords($keywords, true);\r}\r?\u003e\r문서 속성을 저렇게 설정하면 되는 이유는 해당 함수가 정의된 곳을 찾아보면 알 수 있습니다.\n파일 위치는 ./vendor/setasign/fpdf/fpdf.php 입니다.\n\u003c? php\r/* ./vendor/setasign/fpdf/fpdf.php */\rfunction SetTitle($title, $isUTF8=false)\r{\r// Title of document\r$this-\u003emetadata['Title'] = $isUTF8 ? $title : utf8_encode($title);\r}\rfunction SetAuthor($author, $isUTF8=false)\r{\r// Author of document\r$this-\u003emetadata['Author'] = $isUTF8 ? $author : utf8_encode($author);\r}\rfunction SetSubject($subject, $isUTF8=false)\r{\r// Subject of document\r$this-\u003emetadata['Subject'] = $isUTF8 ? $subject : utf8_encode($subject);\r}\rfunction SetKeywords($keywords, $isUTF8=false)\r{\r// Keywords of document\r$this-\u003emetadata['Keywords'] = $isUTF8 ? $keywords : utf8_encode($keywords);\r}\rfunction SetCreator($creator, $isUTF8=false)\r{\r// Creator of document\r$this-\u003emetadata['Creator'] = $isUTF8 ? $creator : utf8_encode($creator);\r}\r?\u003e\r참고 URL link PDF Merge GitHub Source and Download\nhttps://github.com/jurosh/php-pdf-merge 문서 업데이트 내역 link\r날짜 내용 2021-05-03 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  235 ,
                href: "\/docs\/etc\/phpspreadsheet-sample-code\/",
                title: "PhpSpreadsheet 설정 샘플 코드",
                description: "PHP로 Excel 문서 생성, 데이터 읽기를 할 수 있는 PhpSpreadsheet 설정 샘플 코드입니다",
                content: "개요 linkPHP에서 Excel 문서를 읽거나 Excel 형태로 문서를 저장해야 할 때 주로 PhpSpreadsheet를 사용하게 됩니다. 이전에는 PHPExcel이라는 이름이었으나 현재는 해당 버전의 개발-유지보수가 중단되고 새로운 프로젝트로 PhpSpreasheet라는 이름으로 업그레이드 되었습니다.\n또한 PhpSpreadsheet는 Excel 뿐만 아니라 PDF 형식으로도 파일을 저장할 수 있어서 많이 사용되고 있습니다.\n이번에는 이 PhpSpreadsheet로 문서를 저장할 때 사용하는 주요 소스 코드의 샘플을 정리해보겠습니다.\n클래스 로드 link\r\u003c?php\rrequire 'vendor/autoload.php';\ruse PhpOffice\\PhpSpreadsheet\\IOFactory;\ruse PhpOffice\\PhpSpreadsheet\\Spreadsheet;\r$spreadsheet = new Spreadsheet();\r?\u003e\r기본 설정 link\r\u003c? php\r// 문서 가로,세로 방향 설정\t$spreadsheet-\u003egetActiveSheet()-\u003egetPageSetup()\r-\u003esetOrientation(\\PhpOffice\\PhpSpreadsheet\\Worksheet\\PageSetup::ORIENTATION_PORTRAIT);\r// 문서 사이즈 설정\r$spreadsheet-\u003egetActiveSheet()-\u003egetPageSetup()\r-\u003esetPaperSize(\\PhpOffice\\PhpSpreadsheet\\Worksheet\\PageSetup::PAPERSIZE_A4);\r// 문서 정보 설정\r$spreadsheet-\u003egetProperties()-\u003esetCreator(\"써드아이시스템\")\r-\u003esetLastModifiedBy(\"써드아이시스템\")\r-\u003esetTitle(\"문서 타이틀\")\r-\u003esetSubject(\"문서 제목\")\r-\u003esetDescription(\"문서 설명\")\r-\u003esetKeywords(\"키워드\")\r-\u003esetCategory(\"카테고리\");\r// 문서 좌우 여백 설정\r$spreadsheet-\u003egetActiveSheet()-\u003egetPageMargins()-\u003esetTop(0.5);\t$spreadsheet-\u003egetActiveSheet()-\u003egetPageMargins()-\u003esetBottom(0.25);\r$spreadsheet-\u003egetActiveSheet()-\u003egetPageMargins()-\u003esetRight(0.75);\r$spreadsheet-\u003egetActiveSheet()-\u003egetPageMargins()-\u003esetLeft(0.75);\r?\u003e\r셀 값 설정 link\r\u003c? php\t$spreadsheet-\u003esetActiveSheetIndex(0)-\u003esetCellValue(\"C11\", $value);\r$spreadsheet-\u003esetActiveSheetIndex(0)-\u003esetCellValue(\"B25\", \"셀 값 설정\\r\\n다음 줄\");\r?\u003e\r셀에 이미지 설정 link\r\u003c? php\r$drawing_logo = new \\PhpOffice\\PhpSpreadsheet\\Worksheet\\Drawing();\t$drawing_logo-\u003esetName('Logo');\r$drawing_logo-\u003esetDescription('3rdEYESYS Logo');\r$drawing_logo-\u003esetPath('/ncp/data/www/img/3rdeyesys_logo.png');\r$drawing_logo-\u003esetCoordinates('A1');\r$drawing_logo-\u003esetWidth(230);\r$drawing_logo-\u003egetShadow()-\u003esetVisible(true);\r$drawing_logo-\u003esetWorksheet($spreadsheet-\u003egetActiveSheet());\r?\u003e\r셀 병합 link\r\u003c? php\t// 동일한 행에서 병합\r$spreadsheet-\u003egetActiveSheet()-\u003emergeCells(\"A1:D1\");\r// 여러 행에서 병합\r$spreadsheet-\u003egetActiveSheet()-\u003emergeCells(\"G5:I7\");\r// 변수 사용\rfor ($j = 52; $j \u003c= 57; $j++)\r{\r$spreadsheet-\u003egetActiveSheet()-\u003emergeCells(\"B\".$j.\":C\".$j);\r}\r?\u003e\r행 높이 설정 link\r\u003c?php\rfor ($j = 1; $j \u003c= 5; $j++)\r{\r$spreadsheet-\u003egetActiveSheet()-\u003egetRowDimension($j)-\u003esetRowHeight(12);\r}\r$spreadsheet-\u003egetActiveSheet()-\u003egetRowDimension(10)-\u003esetRowHeight(35);\r?\u003e\r열 너비 설정 link\r\u003c?php\r// 특정 열 너비 설정\r$spreadsheet-\u003egetActiveSheet()-\u003egetColumnDimension(\"A\")-\u003esetWidth(3);\r// 범위 내 여러 열 너비 설정\rforeach(range(\"B\",\"J\") as $columnID) {\r$spreadsheet-\u003egetActiveSheet()-\u003egetColumnDimension($columnID)-\u003esetWidth(15);\r}\r?\u003e\r셀 스타일 지정 link\r\u003c?php\r// 셀 스타일을 배열 형식으로 저장\r// 순서대로 border, font, 배경색 지정하는 스타일\r$styleArray_Cell = [\r'borders' =\u003e [\r'allBorders' =\u003e [\r'borderStyle' =\u003e \\PhpOffice\\PhpSpreadsheet\\Style\\Border::BORDER_THIN,\r'color' =\u003e ['argb' =\u003e 'FF20AFA5']\r]\r],\r'font' =\u003e [\r'bold' =\u003e true,\r'size' =\u003e 9,\r'color' =\u003e ['argb' =\u003e 'FFFFFFFF'],\r],\r'fill' =\u003e[\r'fillType' =\u003e \\PhpOffice\\PhpSpreadsheet\\Style\\Fill::FILL_SOLID,\r'color' =\u003e ['argb' =\u003e 'FF20AFA5']\r]\r];\r// 특정 셀에 스타일 적용\r$spreadsheet-\u003egetActiveSheet()\r-\u003egetStyle(\"B40\")-\u003eapplyFromArray($styleArray_Cell);\r// 특정 범위의 여러 셀에 스타일 동시 적용\r$spreadsheet-\u003egetActiveSheet()\r-\u003egetStyle(\"G45:G46\")-\u003eapplyFromArray($styleArray_Cell);\r// 특정 셀에 폰트 스타일 직접 적용\r$spreadsheet-\u003egetActiveSheet()\r-\u003egetStyle(\"B80\")-\u003egetFont()-\u003esetSize(13)-\u003esetBold(true);\r?\u003e\rPDF 로 저장 link\r\u003c?php\r$spreadsheet-\u003esetActiveSheetIndex(0);\r// Mpdf 클래스 별로 설치해야 함\rIOFactory::registerWriter('Pdf', \\PhpOffice\\PhpSpreadsheet\\Writer\\Pdf\\Mpdf::class);\r$out_put_file_full_name = \"sample.pdf\";\r// Redirect output to a client’s web browser (PDF)\rheader('Content-Type: application/pdf; charset=utf-8' );\rheader('Content-Disposition: attachment;filename=\"'.$out_put_file_full_name.'\"');\rheader('Cache-Control: max-age=0');\r$writer = IOFactory::createWriter($spreadsheet, 'Pdf');\r$writer-\u003esave('php://output');\rexit;\r?\u003e\rPhpSpreadsheet를 사용해서 pdf 파일을 저장하려면 Mpdf 를 추가로 설치해야 합니다.\n이와 관련된 내용은 다음 문서에서 다시 정리하겠습니다.\nExcel로 저장 link\r\u003c?php\r$spreadsheet-\u003esetActiveSheetIndex(0);\r// Redirect output to a client’s web browser (Excel2007)\r$out_put_file_full_name = \"sample.xlsx\";\rheader('Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet');\rheader('Content-Disposition: attachment;filename=\"'.$out_put_file_full_name.'\"');\rheader('Cache-Control: max-age=0');\r// If you're serving to IE over SSL, then the following may be needed\rheader ('Expires: Mon, 26 Jul 2022 05:00:00 GMT'); // Date in the past\rheader ('Last-Modified: '.gmdate('D, d M Y H:i:s').' GMT'); // always modified\rheader ('Cache-Control: cache, must-revalidate'); // HTTP/1.1\rheader ('Pragma: public'); // HTTP/1.0\r$writer = IOFactory::createWriter($spreadsheet, 'Xlsx');\t$writer-\u003esave('php://output');\rexit;\r?\u003e\r참고 URL link PhpSpreadsheet Documentation\nhttps://phpspreadsheet.readthedocs.io/\nPhpSpreadsheet GitHub Source and Download\nhttps://github.com/PHPOffice/PhpSpreadsheet\n문서 업데이트 내역 link\r날짜 내용 2021-04-03 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  236 ,
                href: "\/docs\/etc\/markdown\/jekyll\/base-theme-install-guide\/",
                title: "jekyll 설치(윈도 10) with base-theme",
                description: "윈도 10 환경에 base-theme를 사용한 jekyll을 설치하는 방법입니다",
                content: "설치 전체과정 요약 link Ruby 설치 ridk 설치 gem 업데이트 jekyll, Bundler 설치 Ruby 설치 link일반적으로 jekyll를 사용한다면 최신 버전을 사용하면 되겠지만 여기서는 base-theme를 기반으로 하기 때문에 호환에 잘되는 2.5를 설치합니다.\nRuby Installer 다운로드 경로\nhttps://rubyinstaller.org/downloads/ 위 사이트에서 rubyinstaller-devkit-2.5.8-2-x64 를 다운 받아 설치하면 됩니다.\nRuby 설치가 끝나면서 완료화면에 Run ‘ridk install’ to setup MSYS2 and development toolchain. 이라는 옵션이 나타납니다.\n반드시 선택하고 완료를 하시기 바랍니다.\nridk 설치 link앞단계인 Ruby 설치 완료에서 ridk install을 선택했다면 ridk 설치 커맨드 창이 나타납니다.\n(혹시 선택하지 않았다면 커맨드 창을 열어서 ridk install 을 입력하면 됩니다)\n이때 설치 옵션을 선택할 수 있는데 1,2,3 을 선택하고 Enter 키를 입력하면 설치가 진행됩니다.\ngem 업데이트 link\rgem update\rJekyll, Bundler 설치 link\rgem install jekyll bundler\rbase-theme 설치 linkbase-theme는 jekyll의 여러 테마 중에서 CloudCannon에서 제작한 테마입니다.\n다운로드 경로\nhttps://github.com/CloudCannon/base-jekyll-template 위 다운로드 경로에서 소스를 직접 다운 받거나 GitHub Desktop을 이용해서 가져오면 됩니다.\n블로그 실행, 접속 link작업하면서 결과물을 확인할 때는 다음과 같은 명령어로 입력하고 브라우져에서 http://127.0.0.1:4000/ 로 접속하시면 되니다.\nbundle exec jekyll serve\r### 사이트 빌드\r작업이 끝난 결과물을 실제 서버나 gitHub에 업로드, 배포할 경우에는 다음 명령어로 빌드 한 후에 **_site**에 생성된 html 등을 사용하시면 됩니다.\rbundle exec jekyll build\r추가 패키지 설치 link혹시 블로그 실행, 접속에서 오류가 발생하면 나타나는 메시지를 보고 처리를 해주면 됩니다.\n혹시 필요한 gem이 설치되지 않았을 경우에는 다음과 같이 설치해주면 됩니다.\ngem install public_suffix -v 3.0.1\r기본 블로그 생성 link위에서 소개한 것처럼 테마를 사용하는 것이 아닌 기본 설정만의 블로그를 새로 만들려면 다음과 같이 입력하면 됩니다.\njekyll new PATH\r기본 블로그를 만들고 접속하면 다음과 같은 화면이 나타납니다.\n참고 URL link jekyll 한국어 홈페이지\nhttps://jekyllrb-ko.github.io/\njekyll base-theme 데모 사이트\nhttps://orange-ape.cloudvent.net/\n문서 업데이트 내역 link\r날짜 내용 2021-01-04 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  237 ,
                href: "\/docs\/etc\/markdown\/jekyll\/base-theme-customizing\/",
                title: "jekyll base-theme 커스터마이징",
                description: "jekyll base-theme의 디자인과 각종 요소들을 커스터마이징하는 방법입니다",
                content: "폰트 교체 linkbase-theme는 기본 폰트가 Merriweather로 되어 있습니다.\n영어 표기에는 적당하지만, 한글 표기에는 좋지 않아 나눔고딕 폰트로 변경하였습니다.\n그리고 폰트 파일을 별도로 추가하기 보다는 구글에서 제공하는 폰트 경로를 설정하는 방식으로 교체했습니다.\n구글에서 제공하는 폰트 리스트와 적용 방법은 아래 사이트에서 확인 가능합니다.\nhttps://fonts.google.com/ html 수정 link파일 위치 : \\_layouts\\default.html\ncss 수정 link파일 위치: \\_sass\\typography.scss\nbody {\rheight: 100%;\rmax-height: 100%;\rfont-family: 'Nanum Gothic', sans-serif;\r}\r한글 검색 오류 수정 linkbase-theme 기본 설정으로는 한글 등 utf-8 언어 검색이 되지 않습니다.\n그에 따라 몇가지 수정을 하면 한글 검색이 가능해집니다.\njs 파일 위치: \\js\\search.js\n기존:\rwindow.index = lunr(function () {\rthis.field(\"id\");\rthis.field(\"title\", {boost: 10});\rthis.field(\"categories\");\rthis.field(\"url\");\rthis.field(\"content\");\r});\r수정: window.index = new lunr.Index;\rwindow.index.field('id');\rwindow.index.field('title', { boost: 10 });\rwindow.index.field('author');\rwindow.index.field('category');\rwindow.index.field('content');\r다음으로 charset 을 설정합니다.\nhtml 파일 위치 : \\search.html\n기존: 수정: 상단 header bg 교체 link파일 위치: \\_sass\\header.scss\n기존:\rheader {\rbackground: $header-color;\r}\r수정: header {\rbackground: url(\"/images/ncp-header-bg.png\");\rbackground-size: 2200px;\r}\rlogo 파일 교체 link파일 위치: \\_includes\\logo.html\n기존:\r..중략..\r수정:\r상단 메뉴 수정 link파일 위치: \\_data\\navigation.yml\n- name: Docs\rlink: /\rtarget: _self\r- name: FAQ\rlink: /faq/\rtarget: _self\r- name: Company\rlink: https://3rdeyesys.com\rtarget: _blank\r상단 header에 검색 박스 추가 link파일 위치: \\_includes\\navigation.html\n{% if page.url != \"/\" %}\r\\{% include search.html %}\r{% endif %}\r하단 footer social 아이콘 수정 link파일 위치: \\_data\\footer.yml\n- name:\rlink: https://www.facebook.com/3rdeyesys\rsocial_icon: Facebook\rtarget: _blank\r- name:\rlink: mailto:biz@3rdeyesys.com\rsocial_icon: Email\rtarget: _blank\r코드 블럭 스타일 수정 link 첫째줄만 들여쓰기 되는 현상 수정 컨텐츠 넓이 정도로 영역이 자동 할당되도록 수정 과도한 padding, margin 영역 축소 파일 위치: \\_sass\\dark-theme.scss\n기존:\r.highlight { padding: 10px 15px;\r}\r수정: .highlight { padding: 7px 30px 7px 10px;\rdisplay:inline-block;\r}\r파일 위치: \\\\_sass\\elements.scss\r기존:\rcode, pre, tt {\tpadding: 2px 5px;\r}\r수정: code, pre, tt {\tmargin: 0px;\rdisplay:inline-block;\r}\r참고 URL link jekyll 한국어 홈페이지\nhttps://jekyllrb-ko.github.io/\njekyll base-theme 데모 사이트\nhttps://orange-ape.cloudvent.net/\n문서 업데이트 내역 link\r날짜 내용 2021-02-23 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  238 ,
                href: "\/docs\/etc\/markdown\/jekyll\/documentation-theme-install-guide\/",
                title: "Jekyll Documentation Theme 설치 가이드",
                description: "윈도 10 환경에서 Jekyll Documentation Theme를 설치하는 방법입니다",
                content: "Documentation Theme 특징 link이 기술문서에 사용된 Documentation Theme의 가장 큰 특징은 다음과 같습니다.\n⁃ 문서를 카테고리별로 정렬해서 보여주는 네비게이션 리스트\n⁃ 문서 상단에 보여주는 문서 목차 (TOC)\n⁃ 다양한 상단 네비게이션 구성\n⁃ Tag를 활용해서 비슷한 주제의 문서를 함께 확인할 수 있음\r설치 전체과정 요약 link Ruby 설치 ridk 설치 Documentation Theme 다운로드 Jekyll gem 설치 Bundler 설치 {% include tip.html content=“이미 Ruby 2.5등 3.0 이전 버전이 설치되어 있더라도 3.0을 설치하시는 걸 추천드립니다. build 속도 개선 등 많은 기능이 향상 되었습니다.” %}\nRuby 설치 linkjekyll 최신 버전은 2022-03-03 현재 v.3.1이지만 여기서는 Documentation Theme를 기반으로 하기 때문에 호환이 잘되는 3.0을 설치합니다.\nRuby Installer 다운로드 경로\nhttps://rubyinstaller.org/downloads/ 위 사이트에서 rubyinstaller-devkit-3.0.3-1-x64 를 다운 받아 설치하면 됩니다.\nRuby 설치 화면에서 PATH와 파일 확장자 연결에 체크 되어 있는지 확인하고 [Install] 버튼을 클릭합니다.\n설치할 컴포넌트 선택화면에서 모두 선택하거나 최소한 MSYS2 development toolchain은 꼭 선택하고 [Next] 버튼을 클릭합니다. 설치에 필요한 공간은 972MB 정도 됩니다.\nRuby 설치가 끝나면서 완료화면에 Run ‘ridk install’ to setup MSYS2 and development toolchain. 이라는 옵션이 나타납니다. 꼭 설치해야 하는 툴이므로 반드시 선택하고 완료를 해서 바로 설치화면으로 이동하도록 합니다.\nridk 설치 link앞단계인 Ruby 설치 완료에서 ridk install을 선택했다면 ridk 설치 커맨드 창이 나타납니다.\n(혹시 선택하지 않았다면 커맨드 창을 열어서 ridk install 을 입력하면 됩니다)\n이때 설치 옵션을 선택할 수 있는데 Enter 키를 입력하면 기본 옵션인 1, 3으로 설치가 진행됩니다.\nDocumentation Theme 설치 linkDocumentation Theme는 jekyll의 여러 테마 중에서 문서 작성에 특화된 테마입니다.\n다운로드 경로 link https://github.com/tomjoht/documentation-theme-jekyll 위 다운로드 경로에서 소스를 직접 다운 받거나 GitHub Desktop을 이용해서 가져오면 됩니다.\nLive Demo link실제 Documentaion Theme를 적용하면 어떤 사이트를 만들 수 있는지 미리 확인해볼 수 있는 Live Demo 사이트가 있습니다.\nhttps://idratherbewriting.com/documentation-theme-jekyll/ Jekyll gem 설치 link우선 jekyll을 설치합니다.\ngem install jekyll\rBundler 설치 link 다운로드 받은 Documentation theme 폴더를 오픈합니다.\nGemfile 과 Gemfile.lock 파일을 삭제하거나 이름을 변경합니다.\n다음 명령으로 bundler를 설치합니다: gem install bundler\nBundler를 초기화 합니다: bundle init\n초기화 작업이 진행되면서 Gemfile 파일이 생성됩니다.\nGemfile을 열어서 기존 내용을 삭제하고 다음 내용으로 변경합니다.\nsource \"https://rubygems.org\"\rgem 'jekyll', '~\u003e 4.2.1'\rgroup :jekyll_plugins do gem 'jekyll-seo-tag', '~\u003e 2.7.0'\rgem 'jekyll-sitemap', '~\u003e 1.4.0'\rgem 'wdm', '~\u003e 0.1.1'\rgem 'kramdown-parser-gfm'\rend\rgem \"webrick\", \"~\u003e 1.7\"\rGemfile을 저장합니다.\n다음 명령어로 필요한 gem을 설치합니다: bundle install\n사이트 실행, 접속 link작업하면서 결과물을 확인할 때는 다음과 같은 명령어로 입력하고 브라우져에서 http://127.0.0.1:4000/ 로 접속하시면 되니다.\nbundle exec jekyll serve\r최종 결과 화면 link위 절차대로 모두 실행하면 아래와 같은 화면을 볼 수 있습니다.\n사이트 빌드 link작업이 끝난 결과물을 실제 서버나 gitHub에 업로드, 배포할 경우에는 다음 명령어로 빌드 한 후에 _site에 생성된 html 등을 사용하시면 됩니다.\nbundle exec jekyll build\r추가 패키지 설치 link혹시 사이트 실행, 접속에서 오류가 발생하면 나타나는 메시지를 보고 처리를 해주면 됩니다.\n혹시 필요한 gem이 설치되지 않았을 경우에는 다음과 같이 설치해주면 됩니다.\n# gem 수동 설치 예시\rgem install public_suffix -v 3.0.1\r참고 URL link jekyll 한국어 홈페이지\nhttps://jekyllrb-ko.github.io/\njekyll base-theme 데모 사이트\nhttps://idratherbewriting.com/documentation-theme-jekyll/\n문서 업데이트 내역 link\r날짜 내용 2021-01-04 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  239 ,
                href: "\/docs\/etc\/markdown\/jekyll\/documentation-theme-page-create-guide\/",
                title: "Jekyll Documentation Theme 문서 작성 기본 가이드",
                description: "Jekyll Documentation Theme 문서 작성하는 기본 방법입니다",
                content: "문서 편집툴 linkVisual Studio Code linkWindows에서 Jekyll 문서를 편집하는 경우에는 Command 창을 열어서 로컬 사이트를 실행하거나 빌드하고, 오류가 발생하면 실시간으로 나타나는 오류 메시지를 확인하면서 작업하게 됩니다. 이때 문서 편집툴과 Command 창을 별도로 띄워놓고 확인하는 것이 불편한데 Visual Studio Code를 사용하면 아래 스샷처럼, 문서 편집화면과 터미널 창을 함께 보면서 작업 가능해서 무척 편리합니다.\n다운로드: https://code.visualstudio.com/ md 파일 생성 link작성하려는 문서를 markdown 파일의 확장자인 .md 파일로 생성합니다.\n파일 경로 link파일경로는 /pages 폴더 아래쪽에 카테고리 별로 적당히 나누어서 관리하기 편하게 구성하면 됩니다.\n# 파일 경로와 폴더 구성 예시\r- pages\rL api\rL ncloud_api_call_csharp_sample.md\rL ncloud_api_call_php_sample.md\rL ncloud_api_call_python_sample.md\rL database\rL ncloud_database_compare.md\rL ncloud_database_mysql_auto_backup.md 문서 속성 설정 link문서 상단에 아래 예시와 같은 각 문서의 속성을 설정하는 부분이 있습니다.\n---\rtitle: Jekyll Documentation Theme 문서 작성 기본 가이드\rdescription: Jekyll Documentation Theme 문서 작성하는 기본 방법입니다\rkeywords: Markdown, Windows, Hugo\rtags: [markdown, jekyll, windows]\rsidebar: docs_main_sidebar\rpermalink: /etc/etc_jekyll_documentation_theme_page_create_guide.html\rlast_updated: 2022-03-07\r---\rtitle linktitle 항목은 문서 제목과 최종 html의 태그, \u003cmeta property=“og:title” /\u003e 태그 등에 사용됩니다.\n\u003cdiv class=\"prism-codeblock \"\u003e\r\u003cpre id=\"ee86cd1\" class=\"language-html \"\u003e\r\u003ccode\u003e\rkeywords linkkeywords 항목은 최종 html의 태그에 사용됩니다.\ndescription linkdescription 항목은 문서 요약 내용인 summary와 최종 html의 태그와 태그에 사용됩니다.\ntags linktags를 설정해 두면 동일한 tag를 가진 문서들을 모아서 함께 볼 수 있습니다.\nsidebar link전체 문서를 카테고리 별로 표시하는 왼쪽 사이드바의 이름을 설정합니다.\n경우에 따라서는 사이드바를 여러 개 만들어서 문서 성격에 따라 다르게 표시할 수도 있습니다.\nsidebar 파일은 /_data/sidebars/ 폴더에 docs_main_sidebar.yml 형식으로 있습니다.\npermalink linkpermalink는 문서의 최종 html 페이지 URL 입니다. md 파일의 위치와 관계없이 원하는 형태의 URL로 설정할 수 있습니다.\n# md 파일 위치 예시\r/pages/compute/server/server_compare.md\r# permalink 예시\r/compute/compute_server_compare.html\rlast_updated link문서의 최종 수정일을 뜻하는 것으로 날짜 기준으로 최근 업데이트된 문서를 정렬한다거나 여러 가지로 사용할 수 있습니다.\n목차 레벨 설정 link목차 레벨은 3가지로 구분됩니다.\n## Second-level heading\rResult:\nSecond-level heading\n### Third-level heading\rResult:\nThird-level heading\n#### Fourth-level heading\rResult:\nFourth-level heading\n이미지 설정 link이미지는 이미지에 대한 html 태그가 설정된 파일을 include 하게 됩니다.\n{% image src=\"etc/etc_jekyll_documentation_theme_page_create_guide_03.png\" width=\"845\" alt=\"Jekyll Documentation Theme 문서 작성하는 기본 방법\" %}\r실제 image.html 파일 내용은 다음과 같습니다.\n{% if {{include.url}} %}{% endif %}\r{% if {{include.url}} %}{% endif %}\r{% if {{include.caption}} %}{{include.caption}}{% endif %}\rURL 링크 설정 linkURL 링크는 markdown에서 기본으로 제공되는 형식이 있지만 target 설정이나 word-break 등의 스타일을 적용하기 불편해서 html 태그를 그대로 사용합니다.\nhttps://rubyinstaller.org/downloads/\r링크에 적용된 style=‘work-break:break-all’은 한글이 아닌 영문만으로 구성된 주소 등은 길이가 길 경우 다음 줄로 내려가서 표시되지 않고 지정된 영역을 벗어나서 표시되는 경우가 있는데 이를 방지하고 강제로 다음 줄로 내려서 표시하는 기능입니다.\rCode Syntax highlighting 설정 linkSyntax highlighting은 다음과 같이 적용할 수 있습니다.\n``` c#\rbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\rbyte[] bytes = Encoding.UTF8.GetBytes(message);\rusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\r{\rbyte[] hash = sha256.ComputeHash(bytes);\rmsgSignature = Convert.ToBase64String(hash);\r}\r```\r결과는 다음과 같이 표시됩니다.\nbyte[] hmac_key = Encoding.UTF8.GetBytes(ncpSecretKey);\rbyte[] bytes = Encoding.UTF8.GetBytes(message);\rusing (HMACSHA256 sha256 = new HMACSHA256(hmac_key))\r{\rbyte[] hash = sha256.ComputeHash(bytes);\rmsgSignature = Convert.ToBase64String(hash);\r}\rSyntax highlighting이 지원되는 대표적인 형식 리스트는 다음과 같습니다.\napache, batch, c, config(conf), console, cpp(c++), csharp(c#), css docker, email, go, html, java, javascript(js), json, jsp, liquid markdown(md), nginx, objective_c(objc), perl, php, powershell, python ruby, scss, sql, ssh, swift, xml, yml(yml) Alert, CallOut 설정 link문서 내용 중에 강조나 경고, Tip 등을 표시하기 위해 Alert이나 CallOut 기능을 사용합니다.\nAlerts linkAlerts 사용 방법은 아래와 같고 4종류가 있습니다.\n{% include note.html content=\"This is note.\" %}\rinfo\rThis is tip.\ninfo\rThis is note.\nwarning\rThis is important.\nreport\rThis is warning.\n그리고, 앞쪽의 Note, Tip 등을 다른 글자로 바꾸려면 다음과 같이 title 항목을 적용하면 됩니다.\n{% include note.html title=\"제목\" content=\"This is note.\" %}\rinfo\r제목: This is note.\n{% include warning.html title=\"ERROR 1227 (42000)\" content=\"Access denied; you need (at least one) the SUPER...\" %}\rreport\r“ERROR 1227 (42000): Access denied; you need (at least one) the SUPER…\nCallOut Version-1 link기본으로 제공되는 CallOut Version-1은 다음과 같이 사용합니다.\n{% include callout_v2.html type=\"danger\" content=\"This is my **danger** type callout\" %}\r사용 가능한 종류는 다음과 같습니다. This is my danger type callout\rThis is my default type callout\rThis is my primary type callout\rThis is my success type callout\rThis is my info type callout\rThis is my warning type callout\rCallOut Version-2 link기본으로 제공되는 Version-1에서 스타일을 변경한 CallOut Version-2는 다음과 같이 level 속성도 추가해서 사용합니다. level의 기본 값은 3입니다.\n{% raw %}{% include callout_v2.html type=\"danger\" level=\"3\" content=\"This is my **danger** type callout version-2\" %}{% endraw %}\rThis is my danger type callout version-2 level-1\rThis is my default type callout version-2 level-2\rThis is my primary type callout version-2 level-3\rThis is my success type callout version-2 level-3\rThis is my info type callout version-2 level-4\rThis is my warning type callout version-2 level-5\r사이드바 설정 link제일 중요한 사이드바는 /_data/sidebars/docs_main_sidebar.yml 파일이며 다음과 같이 설정합니다.\n여기서 주의해야 할 것은 들여쓰기 간격이 일치해야 오류가 발생하지 않습니다.\ntitle : 사이드바에 표시되는 제목입니다. 너무 길 경우 적당히 줄이는 것을 추천합니다. url : 문서 url 전체 경로입니다. - title: 서버 접속 방법(Linux) - 공인IP 없을 때\rurl: /compute/ncloud_compute_server_connect_no_public_ip.html\routput: web\rSubFolder 등이 포함된 전체적인 구조는 다음과 같습니다.\nentries:\r- title: sidebar\rproduct: Technical Documentation\rversion: folders:\r- title: Compute\ricon: fa-solid fa-server\rurl: /compute/ncloud_compute_server_connect_no_public_ip.html\routput: web\rfolderitems:\r- title: 서버 접속 방법(Linux) - 공인IP 없을 때\rurl: /compute/ncloud_compute_server_connect_no_public_ip.html\routput: web\rsubfolders:\r- title: Cloud Functions\routput: web\rsubfolderitems:\r- title: Cloud Functions Action을 cmd에서 C#으로 작성하기\rurl: /compute/ncloud_compute_cloud_functions_dotnet_csharp_cmd.html\routput: web\r- title: Networking\ricon: fas fa-network-wired\rurl: /networking/ncloud_networking_service_port_info.html\routput: web\rfolderitems:\r- title: 주요 서비스 포트(Port) 정보\rurl: /networking/ncloud_networking_service_port_info.html\routput: web\r- title: Tag archives\ricon: fas fa-file-archive\rurl: /tag/tag_archives_overview.html\routput: web\rfolderitems:\r- title: Tag archives overview\rurl: /tag/tag_archives_overview.html\routput: web\rsubfolders:\r- title: Tag archive pages\routput: web\rsubfolderitems:\r- title: Classic pages\rurl: /tag/tag_classic.html\routput: web\rtag 설정 linktag를 표시하기 위해서는 몇가지 단계를 거쳐야 합니다.\n문서 속성 설정에 tag 정보 추가하기 허용 tag list 파일에 추가하기 tag 문서 추가하기 사이드바에 추가하기 문서 속성 설정에 tag 정보 추가 link이 내용은 위에서 이미 살펴본 내용입니다. 문서 상단 속성 설정에 추가하면 됩니다.\ntags: [markdown, jekyll, windows]\r허용 tag list 파일에 추가 link/_data/tags.yml 파일에 tag를 추가합니다.\nallowed-tags:\r- account\r- acg\r- analytics\rtag 문서 추가 link/tags/ 폴더에 tag_account.md처럼 문서를 작성합니다.\n문서는 다음과 같이 구성됩니다. title, tagName, permalink 이렇게 3가지 정보만 설정하면 됩니다.\ntitle: \"Account\"\rtagName: account\rsearch: exclude\rpermalink: /tag/tag_account.html\rsidebar: docs_main_sidebar\rfolder: tags\r사이드바에 추가 link사이드바 /_data/sidebars/docs_main_sidebar.yml 파일에 추가해줍니다.\n- title: Account pages\rurl: /tag/tag_account.html\routput: web\r위치는 아래쪽에 아래와 같은 구성으로 되어있습니다.\n- title: Tag archives\ricon: fas fa-file-archive\rurl: /tag/tag_archives_overview.html\routput: web\rfolderitems:\r- title: Tag archives overview\rurl: /tag/tag_archives_overview.html\routput: web\rsubfolders:\r- title: Tag archive pages\routput: web\rsubfolderitems:\r- title: Classic pages\rurl: /tag/tag_classic.html\routput: web\rTop 메뉴 설정 link상단 네비게이션 메뉴는 /_data/topnav.yml 파일에서 설정할 수 있습니다.\nurl: 내부 페이지 링크 external_url : 외부 사이트 링크 topnav:\r- title: Topnav\ritems:\r- title: Update\rurl: /update/update.html\r- title: News\rurl: /news/news.html\r- title: FAQ\rurl: /faq/faq.html\r- title: Tag\rurl: /tag/tag_archives_overview.html\r- title: Company\rexternal_url: https://3rdeyesys.com/\r- title: 1:1 문의하기\rexternal_url: https://www.3rdeyesys.com/question/\r참고 URL link jekyll 한국어 홈페이지\nhttps://jekyllrb-ko.github.io/\njekyll base-theme 데모 사이트\nhttps://idratherbewriting.com/documentation-theme-jekyll/\n문서 업데이트 내역 link\r날짜 내용 2022-03-07 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  240 ,
                href: "\/docs\/etc\/markdown\/mkdocs\/basic-install-guide\/",
                title: "MkDocs 설치 가이드 (윈도 10)",
                description: "윈도 10 환경에서 mkdocs를 설치하는 방법입니다",
                content: "설치 전체과정 요약 link Python 다운로드\nPython 설치\n2-1. Add Python 3.9 to PATH 옵션 선택\n2-2. Disable path length limit 선택\nmkdocs 설치\n3-1. pip install mkdocs-material\n3-2. python.exe -m pip install –upgrade pip\n3-3. pip install mkdocs-awesome-pages-plugin\n3-4. mkdocs new {폴더명}\n3-5. cd blog-mkdocs 이동 후 mkdocs serve\nPython 다운로드 linkmkdocs를 사용하려면 먼저 Python을 설치해야 합니다.\nhttps://www.python.org/downloads/\n2020-11-27일 현재 최신버전은 3.9.0입니다.\nPython 설치하기 linkPATH 추가 linkPython 설치 시작화면에 PATH에 python을 추가하는 옵션이 있습니다. “Add Python 3.9 to PATH” 옵션을 선택하고 설치를 시작하면 됩니다.\nPATH 문자 길이 제한 해제 link윈도에는 기본설정에 파일경로가 최대 260자로 제한되어 있는데, 이 제한을 풀것인지 확인하는 과정입니다.\n“Disable path length limit” 옵션이 나오는데, 특별한 문제가 없다면 해제하고 가면 됩니다.\nmkdocs 설치 linkmkdocs 설치하는 방법이 여러가지 있지만 가장 많이 사용되는 테마인 material 테마를 적용한 상태로 설치합니다.\npip install mkdocs-material\rpip 업그레이드 linkmkdocs를 설치하고 나면 pip 업그레이드에 대한 안내가 나옵니다.\nWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\rYou should consider upgrading via the 'c:\\users\\{***}\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\r안내에 나온대로 pip를 업그레이드 해줍니다.\npython.exe -m pip install --upgrade pip\rawesome-pages-plugin 설치 link문서 구조나 네비게이션을 좀 더 쉽게 표현하고 구성하게 해주는 플러그인입니다. 기본적으로 설치해두는 것이 여러모로 편리합니다.\npip install mkdocs-awesome-pages-plugin\r블로그 문서 생성 link이제 기본으로 필요한 것들은 다 설치했으니 블로그를 만들어봅시다. mkdocs new {폴더명}\nmkdocs new blog-mkdocs\r블로그 실행 link이제 웹브라우져에서 블로그를 확인해봅시다. 위에서 만들어진 폴더로 이동합니다.\ncd blog-mkdocs\rmkdocs serve\r그러면 http://127.0.0.1:8000 주소로 접속하면 기본 블로그를 확인해볼 수 있고 mkdocs serve 명령으로 문서 변경을 실시간으로 감지해서 문서를 수정하면 브라우져에 바로바로 반영됩니다.\n블로그 배포문서 생성 link이제 만들어진 블로그 문서를 github 등이나 기타 서버로 배포하려면 다음과 같은 명령어를 입력하면 됩니다.\nmkdocs build\r그러면 아까 만들어진 blog-mkdocs 폴더 밑에 site 라는 폴더가 생성되고 그곳에 필요한 html 문서들이 만들어집니다.\n설치과정 스크린샷 모음 link\r참고 URL link MkDocs 홈페이지\nhttps://www.mkdocs.org/ 문서 업데이트 내역 link\r날짜 내용 2020-11-30 문서 최초 생성 "
            }
        );
    index.add(
            {
                id:  241 ,
                href: "\/docs\/help\/faq\/",
                title: "FAQ",
                description: "Answers to frequently asked questions.",
                content: ""
            }
        );
    index.add(
            {
                id:  242 ,
                href: "\/docs\/help\/news\/",
                title: "NEWS",
                description: "Answers to frequently asked questions.",
                content: ""
            }
        );
    index.add(
            {
                id:  243 ,
                href: "\/docs\/help\/update\/",
                title: "Updates",
                description: "Updates.",
                content: ""
            }
        );
    index.add(
            {
                id:  244 ,
                href: "\/docs\/",
                title: "Docs",
                description: "",
                content: ""
            }
        );
    search.addEventListener('input', show_results, true);

    function show_results(){
        const maxResult =  5 ;
        const minlength =  0 ;
        var searchQuery = sanitizeHTML(this.value);
        var results = index.search(searchQuery, {limit: maxResult, enrich: true});

        
        const flatResults = new Map(); 
        for (const result of results.flatMap(r => r.result)) {
        if (flatResults.has(result.doc.href)) continue;
        flatResults.set(result.doc.href, result.doc);
        }

        suggestions.innerHTML = "";
        suggestions.classList.remove('d-none');

        
        if (searchQuery.length < minlength) {
            const minCharMessage = document.createElement('div')
            minCharMessage.innerHTML = `Please type at least <strong>${minlength}</strong> characters`
            minCharMessage.classList.add("suggestion__no-results");
            suggestions.appendChild(minCharMessage);
            return;
        } else {
            
            if (flatResults.size === 0 && searchQuery) {
                const noResultsMessage = document.createElement('div')
                noResultsMessage.innerHTML = "No results for" + ` "<strong>${searchQuery}</strong>"`
                noResultsMessage.classList.add("suggestion__no-results");
                suggestions.appendChild(noResultsMessage);
                return;
            }
        }

        
        for(const [href, doc] of flatResults) {
            const entry = document.createElement('div');
            suggestions.appendChild(entry);

            const a = document.createElement('a');
            a.href = href;
            entry.appendChild(a);

            const title = document.createElement('span');
            title.textContent = doc.title;
            title.classList.add("suggestion__title");
            a.appendChild(title);

            const description = document.createElement('span');
            description.textContent = doc.description;
            description.classList.add("suggestion__description");
            a.appendChild(description);

            suggestions.appendChild(entry);

            if(suggestions.childElementCount == maxResult) break;
        }
    }
    }());
</script>
        
    </body>
</html>